<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小火箭的博客</title>
  
  <subtitle>愿世界和平！！！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.xiemingzhao.com/"/>
  <updated>2019-09-16T15:00:40.213Z</updated>
  <id>http://www.xiemingzhao.com/</id>
  
  <author>
    <name>小火箭</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Deep &amp; Cross Network for Ad Click Predictions</title>
    <link href="http://www.xiemingzhao.com/2019/07/29/Deep%20&amp;%20Cross%20Network%20for%20Ad%20Click%20Predictions--%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.xiemingzhao.com/2019/07/29/Deep &amp; Cross Network for Ad Click Predictions--学习笔记/</id>
    <published>2019-07-28T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:40.213Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1708.05123.pdf" target="_blank" rel="noopener">原始论文：Deep &amp; Cross Network for Ad Click Predictions</a></p><h2 id="深度和交叉网络的广告点击预测"><a href="#深度和交叉网络的广告点击预测" class="headerlink" title="深度和交叉网络的广告点击预测"></a>深度和交叉网络的广告点击预测</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>特征工程已经成为许多预测模型成功的关键。然而，这个过程是不平常的并且经常会要手动特征工程或者穷举搜索。DNNs能够自动地学习特征交叉项；然而，它们都是隐式地生成所有交叉项，并且学习所有类型的交叉特征不一定有效。在本文中，我们提出深度和交叉网络(DCN)，它保持了深度模型的优势，并且又超越了这，它是一种在学习某种边界程度特征交叉项中更为有效的新奇网络。此外，DCN显示地在每一层应用特征交叉，不要求做人工程特征工程，同时也只是给DNN模型增加了一些可以忽略不计的复杂度。我们的实验结果已经证明它在CTR预测数据集和密集的分类数据集上，相对于其他高级模型在模型准确性和记忆方法上都具有优越性。</p><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a><strong>1 介绍</strong></h3><p>点击率（CTR）预测是一个大规模的问题，它对数十亿美元的在线广告业来说至关重要。在广告业中，广告商会想发布商付费以在发布商的网站上展示他们的广告。一个普遍的付费模式是平均点击成本（CPC）模型，即广告商仅在点击发生的时候才会付费。因此，出版商的收入很大程度上依赖于能够准确预测CTR。</p><a id="more"></a><p>识别出常用的预测特征且同时探索出那些看不见的或者稀少的交叉特征是做出好预测的关键。然而，网站级别的推荐系统的数据主要都是离散的和类别型的，这就导致了一个大的和稀疏的特征空间，而这对于特征探索来说是一个挑战。这就限制了大多数的大规模系统都是线性模型例如逻辑回归。</p><p>线性模型是简单的，可解释的并且容易扩展的；然而，它们受限于自己的表达能力。另一方面，交叉特征已经被证明能够有效地提高模型的表达力。不幸的是，它一般要求人工特征工程或者穷举来找到这些特征；再者，泛化出这些看不见的特征交叉项是很困难的。</p><p>在本文中，我们致力于通过引入一个新的神经网络结构来避免特征工程任务——一个<em>交叉网络</em>——它是以自动的方式显示地应用在特征交叉中。交叉网络由多层网络组成，其中特征的最高交叉维度完全由网络层的深度决定。每一层网络都以及已经存在的特征生成一个更高度的交叉项，同时又保留了前一层网络的交叉项。我们将交叉忘了和一个深度神经网络（DNN）进行联合训练。DNN能够捕获特征中的非常复杂的交叉项；然而，相比于我们的交叉忘了它需要同一数量级的参数，也无法形成显示的交叉特征，并且可能无法有效地学习某些特征交叉项。然而，交叉和深度部分的联合训练能够有效地捕获预测性的特征交叉项，并且在Criteo CTR数据集上提供了一个最先进的效果表现。</p><p><strong>1.1 相关工作</strong><br>由于数据集的规模和维度急剧性的增加，于是提出了很多的方法用来避免特定任务中的大规模特征工程，大部分都是基于嵌入技术和神经网络的。</p><p>因式分解机（FMs）将稀疏特征映射到低维的稠密向量上，并且从这些特征的内积中学习特征交叉项。场感知因式分解机（FFMs）让每个特征都可以学习到多个向量，其中每个响亮都是与一个场相关的。遗憾的是，FM和FFM浅显的结构限制了它们的模型表达力。有许多的工作都是为了将FM扩展到一个更高的级别，但是一个缺点就是产生了大量的参数从而大大增加了原本他们不期望产生的计算成本。深度神经网络（DNN）就可以学习到一些重要的高维的特征交叉项，这得益于它们的嵌入向量和非线性的激活函数。最近残差网络的成功使得训练一个非常深的网络有了可能。深度交叉扩展了残差网络，同时通过对所有输入类型的堆叠达到了自动特征学习的效果。</p><p>深度学习的非凡成功引出了它的表达力的理论分析。有研究表明，在给定足够多的的隐含单元或者隐含层的时候，DNN能够再某种平滑线的假设条件下取近似一个有任意准确性的函数。再者，实际上已经发现了DNN在有合适参数的时候就已经能够表现地很好了。一个关键的原因就是实际使用的大多数函数都不是任意选择的。</p><p>一个依然存在的问题就是DNN是否真的在那些实际中使用的表征函数中是最有效的一个。在Kaggle竞赛中，许多胜利者的解决方法中人工精心设计的特征都是低阶的、确切形式且有效地。另一方面，从DNN中学习到的特征都是隐含的且高度非线性的。这就表明了设计一个模型要能够学习到相比于普通的DNN更加有效且确切的有界阶特征交叉项。</p><p>wide-and-deep就是这种想法创建的模型。它将交叉特征作为线性模型的输入，然后将线性模型和DNN模型进行联合训练。然而，wide-and-deep是否成功很大程度上依赖于交叉特征的事前选择，一个指数级的问题就是是否存在还没发现的更有效的方法。</p><p><strong>1.2 主要贡献</strong><br>在本文中，我们提出了Deep &amp; Cross Network（DCN）模型，它能够在同时有稀疏输入和密集输入的时候进行网站规模的自动化特征学习。DCN能够有效地抓取有界阶的有用特征交叉项，学习高度非线性的交叉项，并且不要求人工特征工程或者穷举，同时又只有较低的计算成本。</p><p>本文主要的贡献包括：</p><ul><li>我们提出了一个将特征交叉应用在每一层的新交叉网络，它能够有效地学习到具有预测价值的有限阶交叉特征，并且不要求进行人工特征工程或者穷举。</li><li>交叉忘了是简单且有效的。通过设计，每一层多项式的最高阶都在增加并且由层数的深度决定。整个网络是由从低阶到高阶的交叉项以及所有不同的系数组成的。</li><li>交叉网络是能够有效记忆的，并且能够很简单地实现。</li><li>一个带有交叉网络的DNN，在参数个数少一个量级的情况下，它的对数损失依然比普通的DNN要低。</li></ul><h3 id="2-深度-amp-交叉网络（DCN）"><a href="#2-深度-amp-交叉网络（DCN）" class="headerlink" title="2 深度&amp;交叉网络（DCN）"></a><strong>2 深度&amp;交叉网络（DCN）</strong></h3><p>在这一部分，我们将会介绍深度&amp;交叉网络（DCN）模型的结构。DCN是开始于embedding和stacking层的，紧接着是一个交叉网络和一个深度网络并行。按顺序接着是一个最终的联合层用来合并两个网络的输出。完整的DCN模型如图1中所示。</p><p><img src="https://i.postimg.cc/RCJsj7cj/D-C-1.jpg" alt="D&amp;C-1.jpg"></p><p><strong>2.1 嵌入和堆叠层</strong><br>我们考虑包含稀疏和密集特征的输入数据。在网站级规模的推荐系统如CTR预估中，输入数据大部分都是类别型特征，例如“country=usa”。这样的特征经常会被进行one-hot编码，例如“[0,1,0]”；然而，这就经常导致产生过高维的特征空间来适用大型词典。</p><p>为了降低维度，我们使用了一个embedding过程来将这些二值特征转换成密集的实值向量（通常称为嵌入向量）：</p><script type="math/tex; mode=display">x_{embed,i}=W_{embed,i}x_i</script><p>其中$x_{embed,i}$是嵌入向量，$x_i$是第i个类别的二值输入，$W_{embed,i} \ \in \mathbb R^{n_e \times n_v}$是对应的嵌入矩阵，它可以和网络中其他的参数一起进行优化，$n_e,n_v$分别是嵌入层大小和词典的大小。</p><p>最后，我们将嵌入向量和标准化后的密集特征进行堆叠，形成一个最终的向量：</p><script type="math/tex; mode=display">x_0 = [x_{embed,1}^T,...,x_{embed,k}^T,x_{dense}^T]</script><p>然后再将这个向量喂入到网络中去。</p><p><strong>2.2 交叉网络</strong><br>我们创新交叉网络的关键思想就是以一个有效地方式来显示地应用特征交叉。交叉网络由交叉层组成，每一层都有如下的公式：</p><script type="math/tex; mode=display">x_{l+1} = x_0 x_l^T w_l + b_l x_l = f(x_l , w_l, b_L) + x_l</script><p>其中$x_l,x_{l+1} \ \in \ \mathbb R^d$都是列向量，分别表示第l层和第l+1层交叉网络的输出$w_l, b_l \ \in \ \mathbb R^d$是第l层网络的权重和偏置项参数。每一交叉层在特征交叉f之后都反加上它的输入部分，并且映射函数$f:\mathbb R^d \rightarrow \mathbb R^d$拟合$x_{l+1}-x_l$的残差。一个交叉层的可视化展示如图2所示。</p><p><img src="https://i.postimg.cc/8Cn4Ycsp/D-C-2.jpg" alt="D&amp;C-2.jpg"></p><p><strong>高阶特征交叉项</strong>。交叉网络特殊的结构造就了交叉特征的阶数随着网络层数增加而增加。第l层交叉网络的多项式最高阶数（相对于输入层来说）是l+1。事实上，交叉网络包含了所有的交叉项$x_1^{\alpha_1} x_2^{\alpha_2}…x_d^{\alpha_d}$，其中d取值从1到l+1。详细的分析在章节3。</p><p><strong>复杂度分析</strong>$L_c$表示交叉层的个数，d表示输入层的维度。然后，交叉网络中的参数个数就是：</p><script type="math/tex; mode=display">d \times L_c \times 2</script><p>交叉网络的时间和空间复杂度是关于输入层维度的线性增长。因此，交叉网络相比与其深度部分仅引入了一个微乎其微的复杂度部分，这使得DCN的整体复杂度与传统的DNN基本一致。这个有效性是得益于$x_0x_l^T$的秩为1的属性，这使得我们可以无需计算和存储整个矩阵的时候生成所有的交叉项。</p><p>交叉网络很少的参数限制了模型的能力。为了获得更高阶的非线性交叉项，我们并行引入了深度网络。</p><p><strong>2.3 深度网络</strong><br>深度网络部分是一个全连接的前向神经网络，其每一层的公式可以表示成如下：</p><script type="math/tex; mode=display">h_{l+1} = f(W_lh_l+b_l)</script><p>其中$h_l \in \mathbb R^{n_l},h_{l+1}\in \mathbb R^{n_{l+1}}$分别是第l和第l+1隐含层；$W_l \in \mathbb R^{n_{l+1} \times n_l}, b_l \in \mathbb R^{n_{l+1}}$是第l深度层的参数；$f(\cdot)$是ReLU激活函数。</p><p><strong>复杂度分析</strong>。为了简化，我们假设所有的深度网络层都是等维度的。$L_d$表示深度网络的层数，m表示深度网络层的大小。那么深度网络的参数个数就是：</p><script type="math/tex; mode=display">d \times m + m + (m^2 + m) \times (L_d -1)</script><p><strong>2.4 联合层</strong><br>联合层是合并了了两个网络的输出部分，然后将合并后的向量喂入到标准的逻辑层中。</p><p>下面就是二分类问题的公式：</p><script type="math/tex; mode=display">p = \sigma([x_{l_1}^L,h_{L_2}^T w_{logits})</script><p>其中$x_{L_1} \in \mathbb R^d, h_{L_2} \in \mathbb R^m$分别是交叉网络和深度网络的输出，$w_{logits} \in \mathbb R^{(d+m)}$是合并层的参数向量，并且$\sigma(x) = 1/(1+exp(-x))$。</p><p>损失函数是带有正则项的对数损失函数，</p><script type="math/tex; mode=display">loss = -\frac{1}{N} \sum_{i=1}^N y_i log(p_i) + (1-y_i) log(1-p_i) + \lambda \sum_l ||w_l||^2</script><p>其中$p_i$是根据前一个公式计算的概率值，$y_i$是真实的标签，N是输入层的总数，$\lambda$是L2正则项参数。</p><p>我们将两个网络联合一起进行训练，这使得每一个单独的网络在训练过程中可以感知到其他部分。</p><h3 id="3-交叉网络分析"><a href="#3-交叉网络分析" class="headerlink" title="3 交叉网络分析"></a><strong>3 交叉网络分析</strong></h3><p>在这一部分，我们分析DCN的交叉网络为了更好地理解它的有效性。我们我们提拱了三个角度：多项式近似，泛化成FM，和高效映射。为了简化，我们假设$b_i = 0$。</p><p><em>注意</em>。将$w_j$中的第i个元素表示成$w_j^{(i)}$。对于多索引$\alpha = [\alpha_1,…,\alpha_d] \in \mathbb N^d$和$x = [x_1,…,x_d] \in \mathbb R^d$，我们定义$|\alpha| = \sum_{i=1}^d \alpha_i$。</p><p><em>术语</em>。交叉项（单个的）的等级$x_1^{\alpha_1}x_2^{\alpha_2}…x_d^{\alpha_d}$定义为$|\alpha|$。多项式的阶数由交叉项的最高阶来确定。</p><p><strong>3.1 多项式近似</strong><br>根据魏尔斯特拉斯逼近定理，闭区间上的连续函数可以用多项式函数一致逼近。因此，我们将从多项式逼近的角度来分析交叉网络。特别地，交叉网络近似的同次多项式类，以一种有效地、更具表达力的并且泛化的方式拟合现实数据集。</p><p>我们仔细地研究了关于交叉网络的同次多项式类的近似。我们定义$P_n(x)$表示n次多项式：</p><script type="math/tex; mode=display">P_n(x) = \{\sum_{\alpha} w_{\alpha} x_1^{\alpha_1} x_2^{\alpha_2}...x_d^{\alpha_d}|0 \leq |\alpha| \leq n, \alpha \in \mathbb N^d\}</script><p>这个类中的每个多项式都有$O(d^n)$个系数。我们证明了，仅仅需要$O(d)$个参数，交叉网络就可以包含同次多项式汇总的所有交叉项，并且每一项的系数都互不相同。</p><p><em>定理3.1</em> 考虑一个l层交叉网络，其第i+1层定义为$x_{i+1} = x_0x_i^Tw_i + x_i$。网络的输入设为$x_0 = [x_1,x_2,…,x_d]^T$，输出为$g_l(x_0) = x_l^Tw_l$，其中参数为$w_i,b_i \in \mathbb R^d$。然后，这个多项式$g_l(x_0)$将会衍生出下面的多项式类：</p><script type="math/tex; mode=display">\{\sum_{\alpha} c_{\alpha}(w_0,...,w_L) x_1^{\alpha_1} x_2^{\alpha_2}...x_d^{\alpha_d}|0 \leq |\alpha| \leq l+1, \alpha \in \mathbb N^d \}</script><p>其中$c_{\alpha} = M_{\alpha} \sum_{i \in B_{\alpha}} \sum_{j \in P_{\alpha}} \prod_{k = 1}^{|\alpha|} w_{i_k}^{(j_k)}$，$M_{\alpha}$是常数，且与$w_i$无关，$i = [i_1,…,i_{|\alpha|}] 和 j = [j_1,…,i_{|\alpha|}]$是对应的索引，$B_{\alpha} = \{y \in \{0,1,…,l\}^{|\alpha|}||y_i &lt; y_j \cap y_{|\alpha|} = l\}$，并且$P_{\alpha}$是索引所有排列组成的集合$(1,…,1 \cdots d,…,d)$。</p><p>定理3.1的证明在附录中。我们给定一个示例，考虑$x_1x_2x_3$的系数$c_{\alpha}$，其中$\alpha = (1,1,1,0,…,0)$。对于某些常数，当$l = 2, c_{\alpha} = \sum_{i,j,k \in P_{\alpha}} w_0^{(i)} w_1^{(j)} w_2^{(k)}$；当$l = 3, c_{\alpha} = \sum_{i,j,k \in P_{\alpha}} w_0^{(i)} w_1^{(j)} w_3^{(k)} +  w_0^{(i)} w_2^{(j)} w_3^{(k)} +  w_1^{(i)} w_2^{(j)} w_3^{(k)}$。</p><p><strong>3.2 FM的推广</strong><br>交叉网络这种参数分享的思想类似于FM模型，进一步将其扩展到一个深度结构。</p><p>在FM模型中，特征$x_i$是伴随着一个参数向量$v_i$，并且交叉项$x_ix_j$的权重是由$(v_i,v_i)$计算得到的。在DCN汇总，$x_i$是和标量集$\{w_k^{(i)} \}_k^l$相关的，并且$x_i x_j$的权重是由集合$\{w_k^{(i)} \}_{k=0}^l$ 和 $\{w_k^{(j)} \}_{k=0}^l$中的各参数相乘得到的。模型每个特征学习的一些参数是独立于其他特征的，交叉项的权重是对应参数的某种联合。参数贡献不仅能够是的模型更加有效，而且也能使得模型能够产生看不见的特征交叉项并且使其对于噪声更加稳健。例如，使用带有稀疏特征的数据集的时候。如果两个二值类特征$x_i$和$x_j$很少或者从来不会在训练集中出现，即$x_i \neq 0 \wedge x_j \neq 0$，所以学习到的$x_i,x_j$的权重就不会在预测中输出有异议的信息。</p><p>FM模型是一个比较浅显的结构，其职能表征出2次的交叉项。相反，DCN能够构建所有的交叉项$x_1^{\alpha_1}x_2^{\alpha_2}…x_d^{\alpha_d}$其中$|\alpha|$由一些决定于网络层深度的常数来界定，如定理3.1所声明。因此，交叉网络是将参数共享这种思想从单层扩展到了多层和高次交叉项。注意到，不同于高阶的FM模型，一个交叉网络中的参数的个数仅仅随着输入层维度而线性增的长。</p><p><strong>3.3 高效地投影</strong><br>每一个交叉网络层都会将$x_0和x_l$映射出它们之间所有的成对交叉项，并且以一种有效的方式产生输入层的维度。</p><p>考虑$\tilde x \in \mathbb R^d$作为一个交叉层的输入。交叉层会隐式地构建出$d^2$个成对交叉项$x_i \tilde x_j$，并且会以一个高效记忆的方式将它们映射到d维空间。然而，直接的方式将会带来三倍的成本。</p><p>我们的交叉层提供了有效地解决方案来将成本降低到关于d维的线性函数。对于$x_p = x_0 \tilde x^T w$。这实际上等于：</p><script type="math/tex; mode=display">x_p^T = [x_1\tilde x_1 ... x_1 \tilde x_d \ ... \ x_d \tilde x_1 ... x_d \tilde x_d] \left[\begin{array}{cccc}w&0&...&0 \\ 0&w&...&0 \\ ...&...&...&... \\ 0&0&...&w \end{array} \right]</script><p>其中行向量包含所有的$d^2$个成对的交叉向量$x_i\tilde x_j$，投影矩阵有一个固定的对角结构，其中$w\in \mathbb R^d$是一个列向量。</p><h3 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4 实验结果"></a><strong>4 实验结果</strong></h3><p>在这一部分，我们字啊一些流行的预测数据及上评估DCN模型的表现。</p><p><strong>4.1 Criteo Display Ads 数据</strong><br>Criteo Display广告数据及是为了预测广告点击率的。它包含13个整数型特征和26个类别型特征，其中每个类别都有高基数集。对于这个数据集，<strong>在对数损失上有0.001的提升就可以被认为是实践显著的。</strong>当考虑一个大的用户基础的时候，预测准确率的一个小提升就潜在地带来公司收益的大增长。数据包含11GB的横跨7天的用户日志（大约4100万条记录）。我们使用前6天的数据进行预测，并且将第7天的数据随机地等量地分成测试集和验证集。</p><p><strong>4.2 实现细节</strong><br>DCN是在TensorFlow上实现的，我们简短地讨论一些DCN训练中的一些实现细节。</p><p><em>数据的处理和嵌入*</em>。实值特征是使用对数变化来进行标准化处理的。对于类别特征，我们将特征嵌入成具有维度$6 \times (category cardinality)^{1/4}$的密集向量。将所有的嵌入结果全部连接到一起形成一个1026维的向量。</p><p><em>优化</em>。我们使用Adam这种小批量随机优化的优化器。批量大小社会为512。批量标准化应用在了深度网络中，并且将梯度裁剪常数（gradient clip norm）设为100.</p><p><em>正则化</em>。我们使用early stopping机制，因为我们使用L2正在和dropout都不起作用。</p><p><em>超参数</em>。我们汇报了对隐含层个数，隐含层大小，初始学习率以及交叉层个数进行grid search的结果。隐含层的个数是从2到5，隐含层的大小是从32到1024.对于DCN，交叉层的个数是从1到6,。初始学习率从0.0001到0.001，每次增加0.0001。所有的实验都使用了early stopping，训练步数设为150000，过拟合发生的时候就会提前停止。</p><p><strong>4.3 模型比较</strong><br>我们将DCN和5种模型进行了比较：没有交叉网络的DCN模型（DNN），逻辑回归（LR），因式分解机（FMs），Wide&amp;Deep模型（W&amp;D）和深度交叉模型（DC）。</p><p><em>DNN</em>。嵌入层、输出层以及过程中的超参数都是用与DCN一致的。唯一和DCN不用的就是没有交叉层。</p><p><em>LR</em>。我们使用Siby1——一个大型的机器学习系统来区分逻辑回归。整数型特征会被离散到一个对数尺度。交叉特征将会由一个精致且复杂的特诊供选择工具来进行筛选。所有的单特征是都会被使用。</p><p><em>FM</em>。我们使用了带有特定细节的FM模型。</p><p><em>W&amp;D</em>。不同于DCN，它的宽部分作为输入原始稀疏特征，并且依赖于穷举和知识域来选取有预测价值的交叉特征。我们跳过了这一块的比较因为没有比较好的方法来选择交叉特征。</p><p><em>DC</em>。相比于DCN，DC没有显示地构造交叉特征。它主要依靠堆叠和残差项来隐式地创造交叉特征。我们使用和DCN相同的嵌入层，紧接着是另一个ReLu层来生成输入数据到残差单元系列中。残差单元的个数一半设为1到5之间，输入维度和交叉维度一般是从100到1026。</p><h3 id="4-4-模型表现"><a href="#4-4-模型表现" class="headerlink" title="4.4 模型表现"></a><strong>4.4 模型表现</strong></h3><p>在这一部分，我们首先会列出不同模型在对数损失下的最好的结果，然后我们会将DCN和DNN进行仔细对比，之后，我们再进一步分析引入交叉网络的效果。</p><p><strong>不同模型的表现</strong>。不同模型的对数损失的最好测试结果都列在了表1中。最优的超参数设置是DCN模型有2个深层且大小为1024和6个交叉层，DNN则有大小为1024的5层网络，DC模型有5个输入维度为424交叉维度为537的残差单元，LR模型有42个交叉特征。最终发现最深的交叉结构获得了最好的表现结果，这表明交叉网络中高次的特征交叉项是有用的。如我们所见，DCN要远好于所有其他的模型。特别地，它优于最先进的DNN模型，而且仅仅是相对于DNN用了40%的内存消费。</p><p><em>表1 不同模型的最优对数损失</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">Model</th><th style="text-align:center">DCN</th><th style="text-align:center">DC</th><th style="text-align:center">DNN</th><th style="text-align:center">FM</th><th style="text-align:center">LR</th></tr></thead><tbody><tr><td style="text-align:center">Logloss</td><td style="text-align:center"><strong>0.4419</strong></td><td style="text-align:center">0.4425</td><td style="text-align:center">0.4428</td><td style="text-align:center">0.4464</td><td style="text-align:center">0.4474</td></tr></tbody></table></div><p>对于每个模型的最优超参数设置，我们也汇报了10次不同对数损失测试结果的均值和标准差：<br>$DCN:0.4422 \pm 9 \times 10^{-5}$<br>$DNN:0.4430 \pm 3.7 \times 10^{-4}$<br>$DC:0.4430 \pm 4.3 \times 10^{-4}$。<br>如我们如看到的，DCN一致的大幅优于其他模型。</p><p><strong>DCN和DNN之间的比较</strong>。考虑到交叉网络仅仅额外引入了O(d)个参数，我们就将DCN和它——一个传统的DNN进行比较，并且将实验结果展现出来尽管存在较大的内存预算和损失公差。</p><p>接下来，我们将会汇报一定数量参数的损失数据，它们都是在所有的学习率和模型结构上得到的最好的验证集的损失。嵌入层的参数个数被省略了，因为在我们所有模型的计算中这一部分保持不变。</p><p>表2展示了要获得一个达到预期对数损失阈值的模型所需要的最少的参数个数。从表2中我们可以看出DCN的内存有效性要比单一的DNN模型高出近一个量级，这得益于交叉网络能够有效地学习到有限次的特征交叉项。</p><p><em>表2 要获得一个达到预期对数损失阈值的模型所需要的最少的参数个数</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">Logloss</th><th style="text-align:center">0.4430</th><th style="text-align:center">0.4460</th><th style="text-align:center">0.4470</th><th style="text-align:center">0.4480</th></tr></thead><tbody><tr><td style="text-align:center">DNN</td><td style="text-align:center">3.2E6</td><td style="text-align:center">1.5E5</td><td style="text-align:center">1.5E5</td><td style="text-align:center">7.8E4</td></tr><tr><td style="text-align:center">DCN</td><td style="text-align:center">7.9E5</td><td style="text-align:center">7.3E4</td><td style="text-align:center">3.7E4</td><td style="text-align:center">3.7E4</td></tr></tbody></table></div><p>表2对比了固定内存预算的神经网络的表现。我们可以看到，DCN一致的比DNN要好。在一个小参数体制里，交叉网络参数的个数和深度网络相比相差无几，但是可以看到明显提升这就表明交叉网络在学习有用特征交叉项中更为有效。在大参数体制中，DNN缩小了一些差距了。然而，DCN仍然要比DNN好一大截，这表明它可以有效地学习到一些很有用的甚至一个大DNN都学不到的特征交叉项。</p><p><em>表3 不同的内存预算下获得的最好的对数损失</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">参数</th><th style="text-align:center">5E4</th><th style="text-align:center">1E5</th><th style="text-align:center">4E5</th><th style="text-align:center">1.1E6</th><th style="text-align:center">2.5E6</th></tr></thead><tbody><tr><td style="text-align:center">DNN</td><td style="text-align:center">0.4480</td><td style="text-align:center">0.4471</td><td style="text-align:center">0.4439</td><td style="text-align:center">0.4433</td><td style="text-align:center">0.4431</td></tr><tr><td style="text-align:center">DCN</td><td style="text-align:center"><strong>0.4465</strong></td><td style="text-align:center"><strong>0.4453</strong></td><td style="text-align:center"><strong>0.4432</strong></td><td style="text-align:center"><strong>0.4426</strong></td><td style="text-align:center"><strong>0.4423</strong></td></tr></tbody></table></div><p>我们从更精确的细节来分析对于给定的DNN模型，引入交叉网络的DCN模型的影响。我们首先对比了拥有同样层数和层大小的DNN和DCN模型的最好表现，然后我们展示了验证集的对数损失是如何随着交叉网络层数的增加而变化的。表4展示了DCN和DNN模型在对数损失上面的区别。在同一实验设定下，从最优的对数损失上看DCN模型一致的优于有相同结构的单一DNN模型。这种对于所有超参数的改进是一致的，降低了参数在初始化和随机优化中的随机性影响。</p><p><em>表4 DCN和DNN在验证集上的对数损失之间的区别</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">Layers/Nodes</th><th style="text-align:center">32</th><th style="text-align:center">64</th><th style="text-align:center">128</th><th style="text-align:center">256</th><th style="text-align:center">512</th><th style="text-align:center">1024</th></tr></thead><tbody><tr><td style="text-align:center">2</td><td style="text-align:center">-0.28</td><td style="text-align:center">-0.10</td><td style="text-align:center">-0.16</td><td style="text-align:center">-0.06</td><td style="text-align:center">-0.05</td><td style="text-align:center">-0.08</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">-0.19</td><td style="text-align:center">-0.10</td><td style="text-align:center">-0.13</td><td style="text-align:center">-0.18</td><td style="text-align:center">-0.07</td><td style="text-align:center">-0.05</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">-0.12</td><td style="text-align:center">-0.10</td><td style="text-align:center">-0.06</td><td style="text-align:center">-0.09</td><td style="text-align:center">-0.09</td><td style="text-align:center">-0.21</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">-0.21</td><td style="text-align:center">-0.11</td><td style="text-align:center">-0.13</td><td style="text-align:center">-0.00</td><td style="text-align:center">-0.06</td><td style="text-align:center">-0.02</td></tr></tbody></table></div><p>图3展示了在随机选择的设置中我们增加交叉层数的改进效果。对于图3中的深度网络，当增加了一个交叉层的时候有一个明显的提升。随着更多的交叉层引入的时候，对于某些模型设置会使得对数损失继续下降，这表明引入交叉项对于预测是有效的；鉴于对于其他模型设置对数损失开始波动甚至出现微幅增加，这就表明高阶的特征交叉项的银如意是没有太大作用的</p><p><img src="https://i.postimg.cc/Hxcz1m7Q/D-C-3.jpg" alt="D&amp;C-3.jpg"></p><h3 id="4-5-非CTR数据集"><a href="#4-5-非CTR数据集" class="headerlink" title="4.5 非CTR数据集"></a><strong>4.5 非CTR数据集</strong></h3><p>我们证明了DCN模型在非CTR预测问题中也表现得很好。我们使用来自UCI提供的森林植被类型（forest covertype）（581012样本和54个特征）和 希格斯粒子（Higgs）（11M样本和28个特征）数据集。数据集随机得被分为训练集（90%）和测试集（10%）。对于超参数进行了梯度搜索。深度网络层数从1到10，大小从50到300.交叉网络层数从4到10。残差单元的个数从1到5，他们的出入维度和交叉维度从50到300。对于DCN，输入向量会被直接喂入交叉网络。</p><p>对于森林植被类型数据，DCN在最少的内存消费下获得了最好的测试集准确率0.9740。DNN和DC都是0.9737。DCN最优的超参数设置是8个交叉层且大小为54，6个深度网络层且大小为292，DNN则是有7层大小为292的深度网络层，DC则是有输入维度为271交叉维度为287的4个残差单元。</p><p>对于希格斯粒子数据集，DCN模型获得的最好对数损失测试结果是0.4494，而DNN是0.4506。DCN最优的超参数设定是4层大小为28的交叉网络和4层大小为209深度网络层，DNN则是10层大小为196的深度网络层。DCN在仅用了DNN一半的内存情况下依然表现得比其要好。</p><h3 id="5-结论和未来方向"><a href="#5-结论和未来方向" class="headerlink" title="5 结论和未来方向"></a><strong>5 结论和未来方向</strong></h3><p>区分有效的特征交叉项已经称为了许多预测模型成功的关键。遗憾的是，过程往往需要进行手工特征和穷举。DNN是比较受欢迎的自动特征学习模型；然而，学到的特征是隐式的并且高度非线性的，同时网络并不一定需要很大而且无法学习到某些特征。本文剔除的Deep &amp; Cross Network模型能够处理大的稀疏和密集特征集，并且可以联合传统的深度表示来显示地学习有限次的交叉特征。交叉特征的阶数在每一个交叉层都会增加一。我们的实验结果已经证明了它在系数数据集和密集数据集上都要优于其他最先进的算法，优势体现在模型的准确率和内存使用上。</p><p>我们会进一步地在其他模型中探索使用交叉层，使得深度交叉网络能够有效地训练，研究交叉网络在多项式近似中的有效性，并且在优化过程中可以更好地理解深度网络的交叉项。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1708.05123.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：Deep &amp;amp; Cross Network for Ad Click Predictions&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;深度和交叉网络的广告点击预测&quot;&gt;&lt;a href=&quot;#深度和交叉网络的广告点击预测&quot; class=&quot;headerlink&quot; title=&quot;深度和交叉网络的广告点击预测&quot;&gt;&lt;/a&gt;深度和交叉网络的广告点击预测&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;特征工程已经成为许多预测模型成功的关键。然而，这个过程是不平常的并且经常会要手动特征工程或者穷举搜索。DNNs能够自动地学习特征交叉项；然而，它们都是隐式地生成所有交叉项，并且学习所有类型的交叉特征不一定有效。在本文中，我们提出深度和交叉网络(DCN)，它保持了深度模型的优势，并且又超越了这，它是一种在学习某种边界程度特征交叉项中更为有效的新奇网络。此外，DCN显示地在每一层应用特征交叉，不要求做人工程特征工程，同时也只是给DNN模型增加了一些可以忽略不计的复杂度。我们的实验结果已经证明它在CTR预测数据集和密集的分类数据集上，相对于其他高级模型在模型准确性和记忆方法上都具有优越性。&lt;/p&gt;
&lt;h3 id=&quot;1-介绍&quot;&gt;&lt;a href=&quot;#1-介绍&quot; class=&quot;headerlink&quot; title=&quot;1 介绍&quot;&gt;&lt;/a&gt;&lt;strong&gt;1 介绍&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;点击率（CTR）预测是一个大规模的问题，它对数十亿美元的在线广告业来说至关重要。在广告业中，广告商会想发布商付费以在发布商的网站上展示他们的广告。一个普遍的付费模式是平均点击成本（CPC）模型，即广告商仅在点击发生的时候才会付费。因此，出版商的收入很大程度上依赖于能够准确预测CTR。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="推荐" scheme="http://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="排序" scheme="http://www.xiemingzhao.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="CTR预估" scheme="http://www.xiemingzhao.com/tags/CTR%E9%A2%84%E4%BC%B0/"/>
    
      <category term="神经网络" scheme="http://www.xiemingzhao.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Deep &amp; Cross" scheme="http://www.xiemingzhao.com/tags/Deep-Cross/"/>
    
  </entry>
  
  <entry>
    <title>DeepFM:A Factorization-Machine based Neural Network for CTR Prediction</title>
    <link href="http://www.xiemingzhao.com/2019/06/29/DeepFM-A%20Factorization-Machine%20based%20Neural%20Network%20for%20CTR%20Prediction--%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.xiemingzhao.com/2019/06/29/DeepFM-A Factorization-Machine based Neural Network for CTR Prediction--学习笔记/</id>
    <published>2019-06-28T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:48.888Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1703.04247.pdf" target="_blank" rel="noopener">原始论文：DeepFM:A Factorization-Machine based Neural Network for CTR Prediction</a></p><h2 id="DeepFM-基于神经网络的因式分解机做点击率预估"><a href="#DeepFM-基于神经网络的因式分解机做点击率预估" class="headerlink" title="DeepFM:基于神经网络的因式分解机做点击率预估"></a>DeepFM:基于神经网络的因式分解机做点击率预估</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>对于推荐系统中的最大化CTR来说，学习那些用户行为背后的复杂而精确的特征交叉项是至关重要的。尽管有很大的提升，但是方法似乎在低阶或者高阶的交差项上带有很强的偏置项，又或者会要求专业性的特征工程。在这篇文章，我们会展示可以构造出一个端到端的学习模型，特别是对于低阶和高阶的交叉项的学习。DeepFM，提出的这个模型联合了因式分解机的推荐能力和一个新的神经网络结构在特征方面的深度学习能力。相比于Google提出的最新的Wide &amp; Deep模型，DeepFM的“wide”和“deep”部分有一个共享输入层，并且除了最原始的特征不需要额外的特征工程。综合性的实验结果证明了DeepFM相比于其他的CTR模型在基础数据及和商业数据集上都有着更好的效果和效率。</p><a id="more"></a><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a><strong>1 介绍</strong></h3><p>点击率(CTR)预测对于推荐系统是至关重要的，它是估计用户对某个商业项目进行点击的概率。大部分的推荐系统的目标是最大化点击次数，所以返回给用户的项目可以按照估计出的CTR进行排序；然而对于其他的高级应用例如在线广告，提升CTR可以增加企业的收入，所以总体上来说，排序的策略可以调整为CTR*bid，这里的bid是指用户每次点击给系统产生的收益。但是不管怎样，不断提升CTR可以创造更多的收益。不论什么情况，可以明确地是准确地预测CTR是最关键的。</p><p>通过用户的点击行为序列学习到背后潜在的特征交叉项对于CTR预测是特别重要的。根据我们在主流的app商店的研究，发现用户常常在用餐时间下载外卖类app，这就是一种二阶的交互信息：app应用类别和时间，这类的二阶交互信息可以用以CTR预估。再比如，男性青少年偏爱射击类和角色扮演游戏，这表明了这个三阶的交叉项：包含了性别，年龄和app的应用类别，也是有助于CTR。总的来说，这些用户行为背后的特征交互是非常复杂的，这里的低阶和高阶的特征交叉项都有着特别重要的作用。2016年谷歌的Wide &amp; Deep model系统基于低阶和高阶特征的交互信息在整体上都带来了额外的性能提升。</p><p>建模的核心挑战在于特征之间的交互信息。一些容易理解的特征交叉项可以有专业的人设计出来（例如上述举例的）。然而，大多数的特征交互项是隐藏于数据背后且难以利用先验知识发现的（例如啤酒与尿布的案例，是通过通过数据的而不是专家发现的），这种是仅可以通过机器学习字段捕获的。基于对于一些易理解的交互项来说，它们看上去也不像转接能够构造出来的，特别是在特征数量特别庞大的时候。</p><p>尽管普通的线性模型特别的简单，例如FTRL，但是在实际应用中却展示了相当好的效果。然而，线性模型缺少学习特征交叉项的能力，所以一般是在后期手动方式添加特征之间的交互项。这样的方法不仅难以泛化到高阶特征，也难以应付训练集中较少或者尚未出现的特征。2010年提出的因子分解机(FM)可以解决这个问题，FM是通过隐向量的内积表现特征之间的交叉项。尽管原则上FM可以构建高阶的特征交叉项，但是在实际中考虑到构建特征之间更高阶的关系会更加复杂，所以一般只采用2阶。</p><p>深度学习在特征表示上是一个很强大的算法，所以在学习复杂的特征交叉项上也具有很大潜力。所以就扩展出了一些想法，例如用CNN和RNN来做CTR预估。但是基于CNN的模型只能处理相邻特征，而基于RNN的模型由于天然的序列依赖特性更适于CTR领域。2016年有学者提出了Factorization-machine supported Neural Network (FNN)，该模型用FM进行预训练，再输入到DNN，因此这也使得模型受限于FM。Qu等人于2016年提出Product-based Neural Network (PNN)在嵌入层和全连接层之间引入一个product 层来表示特征之间的相互作用。其实FNN和PNN都仅仅能够表达低阶的特征间相互作用，且程度有限。为了能够同时表达低阶和高阶的特征信息，cheng等人于2016年提出一个混合网络结构：Wide &amp; Deep模型，该模型融合了一个线性模型（wide）和深度学习模型。在这个模型中，两个部分wide part和deep part分别需要两个不同的输入，其中wide part需要依赖专家的特征工程。</p><p>可以看出现有模型偏向于低或高阶特征交互，或依赖于特征工程。在本文，我们证明了可以构建一个学习模型，它是可以通过端到端的方式学习到所有阶数的特征交叉项，而除了原始的特征不需要任何额外的特征工程我们的主要贡献总结如下：</p><ul><li>我们提出了一个新的神经网络模型DeepFM，它是结合了FM和深度神经网络（DNN）的结构。它既可以像FM一样构建低阶的特征交叉项也可以像DNN一样拟合高阶的特特征交叉项。而不像Wide &amp; Deep模型，DeepFM可以在无需任何特征工程的条件下进行端到端的训练。</li><li>我们对DeepFM在基础数据集和商业数据集上都进行了评估，结果表明了它相对于目前已存在的CTR预估模型有一致性的提升效果。</li></ul><h3 id="2-我们的方法"><a href="#2-我们的方法" class="headerlink" title="2 我们的方法"></a><strong>2 我们的方法</strong></h3><p>假设数据的训练集包含n个样本$(\mathcal{X},y)$，其中$\mathcal{X}$是一个包含m个特征域的数据集，一版记录了相关的用户和物品对，并且$y \in (0,1)$对应的标签标示用户的点击行为（1表示用户点击了物品，否则为0）。$\mathcal{X}$可能会包含类别型特征（例如性别，位置）和连续型特征（例如年龄）。每个类别型特征都会被表示成一个one-hot编码的向量，每个连续型特征都会用它自己的值表示，或者在进行离散后也表示成一个one-hot编码的向量。然后，每个样本都会被转换成$(x,y)$，其中$x = [x_{field_1},x_{field_2},\cdots, x_{field_j},\cdots,x_{field_m}]$是一个d维的向量，$x_{field_1}$是$\mathcal{X}$中第j个特征的向量表示。一般的，x是一个高维且极度稀疏的向量。CTR预估的任务就是构建一个预测模型$\hat y = CTR_model(x)$来预估在给定上下文的条件下一个用户点击某个app的概率。</p><h4 id="2-1-DeepFM"><a href="#2-1-DeepFM" class="headerlink" title="2.1 DeepFM"></a><strong>2.1 DeepFM</strong></h4><p>我们的目标是学习高阶和低阶的特征交叉项。为了做到这个，我们提出了基于神经网络的因式分解机（DeepFM）。如图1所示，DeepFM由两部分组成，<em>FM部分和deep部分</em>，二者共享同一输入层。对于特征i，一个标量$w_i$作为权重来表示其一阶的重要性，一个潜在的向量$V_i$用来衡量它与其他特征的交叉项的重要性。$V_i$被喂入FM部分取构建2阶的特征交叉项，同时也被喂入深度部分取构建高阶的特征交叉项。所有的参数，包括$w_i，V_i$和网络参数$(W^{(l)},b^{(l)})$都在合并的模型中进行联合训练的：</p><script type="math/tex; mode=display">\hat y = sigmoid(y_{FM}+y_{DNN})</script><p>其中，$\hat y \in (0,1)$是预测的CTR，$y_{FM}$是FM部分的输出结果，$y_{DNN}$是深度部分的输出结果。</p><p><img src="https://i.postimg.cc/657HJBcP/DeepFM-1.jpg" alt="DeepFM-1.jpg"></p><p><strong>FM部分</strong><br>FM部分是一个因式分解机，它是在[Rendle,2010]中提出来用在推荐中学习特征交叉项的。除了线性的（一阶）特征交叉项，FM还利用特征间的隐向量的内积构建了成对的（二阶）特征交叉项。相比于以前的方法，特别是在数据集很稀疏的时候它可以更有效地捕获到二阶特征交叉项。在以前的算法中，特征i和j组成的交叉项的参数只能在某一数据记录同时出现特征i和j的时候才能得到训练。而在FM模型中，它们会通过它们的隐含向量$V_i和V_j$的内积计算得到。得益于这种灵活的设计，无论i（或j）何时出现在数据记录中FM模型都能够训练隐含向量$V_i(V_j)$。因此，那些从不或者很少出现在训练数据中的特征交叉项可以有FM模型很好的学习到。</p><p><img src="https://i.postimg.cc/ZRKcfm0V/DeepFM-2.jpg" alt="DeepFM-2.jpg"></p><p>如图2所示，FM的输出是由一个累加单元加上一系列内几单元组成的：</p><script type="math/tex; mode=display">y_{FM} = <w,x> + \sum_{j_1 = 1}^d \sum_{j_2 = j_1 + 1}^d <V_i,V_j> x_{j_1} \cdot x_{j_2}</script><p>其中$w \in R^d 和 V_i \in R^k$（k是给定的）。累加单元$(<w,x>)$反映了一阶特征的重要性，内积单元代表了二阶特征交叉项的影响。</w,x></p><p><strong>Deep部分</strong><br><img src="https://i.postimg.cc/wxrVkSzQ/DeepFM-3.jpg" alt="DeepFM-3.jpg"></p><p>深度部分是一个前馈神经网络，通常是来学习高阶特征交叉项的。如图3所示，一条数据记录（一个向量）被喂入神经网络。相比于输入数据是图片或者音频的神经网络，即输入数据是连续且密集的，CTR预估模型的输入数据则大不相同，它要求一个新设计的网络结构。特别地，CTR预估的原始特征输入向量一般都是高度稀疏的、超高维度的、类别型和连续型混合的并且聚合到特征域的（例如性别，位置，年龄）。这表明嵌入层是在将数据输入到第一层隐含层之前将输入向量压缩到了一个低维且密集的实值向量，否则网路将无法进行训练。</p><p><img src="https://i.postimg.cc/yNKnZcKq/DeepFM-4.jpg" alt="DeepFM-4.jpg"></p><p>图4提取了输入层到嵌入层的子网络结构。我们能够之处这个网络结构中的两个有趣的特点：1）尽管不同输入特征域向量的长度不同，但是它们 的嵌入向量确实相同大小(k)的；2）FM中的隐含特征向量（V）是作为网络的权重，它们是学习到的用来将输入特征向量压缩成嵌入向量的。在论文[Zhang tw al., 2016]，V是由FM提前训练好的值来作为初始化的。在这里，不是使用FM的隐含特征向量来初始化网络，而是除了DNN模型外，我们是将FM模型作为我们整体学习框架中的一部分。如此，我们就不需要通过FM来提前训练了，相反我们是将整体的网络结构以端到端的方式来进行联合训练。将嵌入层的输出表示成：</p><script type="math/tex; mode=display">a^{(0)} = [e_1,e_2,...,e_m]</script><p>其中$e_i$是第i个特征的嵌入，m是特征的个数。然后，$a^{(0)}$是喂入到深度神经网络的，并且前向的过程是：</p><script type="math/tex; mode=display">a^{(l+1)} = \sigma(W^{(l)}a^{(l)} + b^{(l)})</script><p>其中l是网络的层数，$\sigma$是激活函数。$W^{(l)},a^{(l)}, b^{(l)}$分别是输出，模型权重和第l层的偏置项。之后，一个密集的实值特征向量就产生了，这最终会输入到CTR预估模型的sigmiod激活函数中去：$y_{DNN} = \sigma(W^{|H|+1} \cdot a^H + b^{|H|+1})$，其中$|H|$是隐含层的数量。</p><p>值得指出的是FM部分和deep部分共享同一特征嵌入层，这就带来了两个好处：1）可以从原始特征中同时学习了低阶和高阶的特征交叉项；2）不需要像Wide &amp; Deep一样在输入层上做专门的特征工程。</p><h4 id="2-2-与其他神经网络之间的关系"><a href="#2-2-与其他神经网络之间的关系" class="headerlink" title="2.2 与其他神经网络之间的关系"></a><strong>2.2 与其他神经网络之间的关系</strong></h4><p>受到深度学习在多种应用中取得巨大成功的影响，最近很多用来做CTR预估的深度模型被开发出来。这一部分将我们提出的DeepFM与其他现存的CTR预估深度模型进行比较。</p><p><img src="https://i.postimg.cc/28Bx928R/DeepFM-5.jpg" alt="DeepFM-5.jpg"></p><p><strong>FNN</strong>：如图5左侧所示，FNN是一个FM初始化的前馈神经网络模型[Zhang et al., 2016]。FM预训练的方法导致了两个限制：1）嵌入层的参数会由FM完全决定；2）引入的预训练步骤会使得模型的有效性降低。此外，FNN仅能捕获高阶的特征交叉项。相反，DeepFM不需预训练并且能够学习到高阶和低阶的特征交叉项。</p><p><strong>PNN</strong>：为了抓取高阶的特征交叉项，PNN在嵌入层和第一层隐含层之间强加了一个乘积层[Qu et al., 2016]。根据乘积运算的不同类型，又有三种不同的模型：IPNN,OPNN和PNN<em>，其中IPNN是基于向量内积的，OPNN是基于外积的，PNN</em>是基于内积和外积一起的。</p><p>为了使得计算更加有效，作者提出了一个内积和外积的近似计算：1）内积可以通过消除某些神经元来近似计算；2）外积可以通过将m个k维的特征向量压缩成一个k维的向量来近似计算。然而，我们发现外积相对于内积不太可靠，这是因为外积的这种近似计算会丢失很多信息使得结果不稳定。尽管内积相对比较可靠，它仍然需要很高的计算复杂度，因为乘积层的输出是与第一层隐含层所有的神经单元相连的。不同于PNN，DeepFM中的乘积层的输出仅与最终的输出层（一个神经元）相连。例如FNN，所有的PNN都忽略低阶特征交叉项。</p><p><strong>Wide &amp; Deep</strong>：Wide &amp; Deep（图5右侧所示）是由谷歌提出的来同时构建低阶和高阶特征交叉项的。如论文[Cheng te al., 2016]所示，它在“宽”部分部分的输入时需要专业的特征工程（例如，在app推荐中的用户安装的app和展示的app间的交叉特征）。相反，DeepFM不需要太多大额专业知识来处理输入层就可以直接地从原始特征中学习。</p><p>一个简单地扩展就是用FM替换这个模型中的LR部分（本文的第三部分我们也评估了这一扩展）。这个扩展类似于DeepFM，但是DeepFM在FM和deep部分之间共享了嵌入层。这种特征嵌入层共享的方法通过低阶和高阶特征交叉项影响了（以回传的方式）特征的表达，这就使得其可以更精确的构建特征表达。</p><p><img src="https://i.postimg.cc/tJ9N1jGh/Deep-FM-t1.jpg" alt="Deep-FM-t1.jpg"></p><p><strong>总结</strong>：综上所述，DeepFM和其他深度模型之间关系主要是表1中提到的4个方面。如我们所见，DeepFM是一个不需要预训练和特征工程的模型，并且能够抓取低阶和高阶的特征交叉项。</p><h3 id="3-实验"><a href="#3-实验" class="headerlink" title="3 实验"></a><strong>3 实验</strong></h3><p><strong>数据集</strong><br>我们基于以下两个数据集来评估我们提出的DeepFM模型的效果和效率：</p><p><strong>1) Criteo Dataset</strong>：Criteo Dataset包含4500万的用户点击记录，有13个连续型特征和26个类别型特征。我们将数据集随机得分为两部分：90%用来作为训练集，剩下的10%作为测试集。</p><p><strong>2)Company Dataset</strong>：为了验证DeepFM模型在真实的工业CTR预估中的表现，我们在Company Dataset数据集上进行了实验。我们从Company App Store的游戏中心收集了连续7天的的用户点击记录数据作为训练集，下一天的数据作为测试集。全部收集的数据集大概有10亿条记录。在这个数据集中，有应用的特征（例如名称和类型等等），用户特征（例如用户下载的应用等等），上下文特征（例如操作时间等等）。</p><p><strong>评估指标</strong><br>在我们的实验中主要使用两个评价指标：<strong>AUC</strong>和<strong>Logloss</strong>。</p><p><strong>模型比较</strong><br>我们在实验中比较了9个模型：<strong>LR, FM, FNN, PNN (三种变体), Wide &amp; Deep, 和 DeepFM.</strong>在Wide &amp; Deep模型中，为了消除特征工程的工作量，我们将原始的 Wide &amp; Deep 模型中宽部分的LR用FM来代替。为了区别 Wide &amp; Deep 的这两种变体模型，我们分别把它们命名为 LR &amp; DNN 和 FM &amp; DNN。</p><p><strong>参数设定</strong><br>为了在Criteo dataset数据集上评估模型，我们追随[Qu et al., 2016]中的FNN和PNN的参数设定：(1)dropout:0.5;(2)网络结构：400-400-400；（3）优化器：Adam；（4）激活函数：IPNN用tanh，其他的深度模型用relu。为了公平，我们的DeepFM模型使用同样的设定。LR和FM的优化器分别是FTRL和Adam，并且FM隐含的维度是10.</p><p>为了在公司的数据集上获得每个模型最好的效果，我们仔细地进行参数学习，会在3.3部分详细讨论。</p><h4 id="3-2-效果评估"><a href="#3-2-效果评估" class="headerlink" title="3.2 效果评估"></a><strong>3.2 效果评估</strong></h4><p>在这一部分，我们会评估3.1部分列出的模型，并且在两个数据集上对比它们的效果和效率。</p><p><strong>效率对比</strong><br><img src="https://i.postimg.cc/vmvhLT84/DeepFM-6.jpg" alt="DeepFM-6.jpg"></p><p>深度学习模型的销量在现实世界中是非常重要的。我们通过以下公式对比了各个模型在Criteo数据集上的效率表现：$\frac{|training time of deep CTR model|}{|training time of LR|}$。结果如图6所示，包含了在CPU（左侧）和GPU（右侧）上的测试结果，我们观察到了以下结果：1）FNN的预训练使其变得不是很有效率；2）尽管IPNN 和 PNN*在GPU上的表现要好于其他模型，但由于内积计算的操作使得他们仍然具有很高的计算成本；3）DeepFM几乎在所有的测试中表现地最有效率。</p><p><strong>效果对比</strong><br><img src="https://i.postimg.cc/prkYz6P3/Deep-FM-t2.jpg" alt="Deep-FM-t2.jpg"></p><p>不同CTR预估模型在Criteo和Company*的数据集上的表现如表2所示，我们可以得到如下观察结果：</p><ul><li>学习特征交叉项能够提升CTR预估模型的效果。这一发现实际上是来自于LR（它是唯一一个没有考虑特征交叉的模型）的表现要差于其他模型。对于Company* 和 Criteo数据集来说，DeepFM作为最好的模型其表现在AUC上要比LR分别高出0.86%和4.18%。</li><li>同时学习高阶和低阶的特征交叉项能够提高CTR预估模型的表现。DeepFM 模型的表现要好于那些仅仅学习低阶特征交叉项（例如FM）或者高阶特征交叉项（例如FNN, IPNN, OPNN, PNN*）的模型。相比于第二好的模型，DeepFM 在两个数据集上的AUC分别提升了0.37%和0.25%（Logloss 分别提升了0.42% 和0.29%）。</li><li>同时学习高阶和低阶的特征交叉项的时候，还共享特征的嵌入能够提高CTR预估模型的表现。DeepFM 的表现要好于那些在学习高阶和低阶特征交叉项的时候使用不同的特征嵌入的模型（例如LR &amp; DNN 和 FM &amp; DNN）。相比于这两个模型，在 Company* 和 Criteo 数据集上，DeepFM在AUC上要分别提升0.48%和0.33%（在Logloss上分别提升0.61%和0.66%）。</li></ul><p>总的来说，我们提出的 DeepFM 模型打败了其他的竞争者，在Company* 数据集上的AUC 和 Logloss分别提升了0.37%和0.42%。实际上，离线AUC评估指标的小改进很肯带来在线CTR的显著提升。如[Cheng et al., 2016]中所述，相比于LR，Wide &amp; Deep 将AUC提高了0.275%（离线），在线的CTR提高了3.9%。公司应用商店的每日流量价值百万美元，因此即使是几个百分点的CTR提升也能够带来每年百万美元的额外收入</p><h4 id="3-3-超参数研究"><a href="#3-3-超参数研究" class="headerlink" title="3.3 超参数研究"></a><strong>3.3 超参数研究</strong></h4><p>我们研究了在公司数据集上不同模型的不同超参数的影响力。顺序是：1）激活函数；2）dropout率；3）每层神经元个数；4）隐含层的层数；5）网络形状。</p><p><strong>激活函数</strong><br>根据[Qu et al., 2016]所述，在深度模型中<em>relu</em>和<em>tanh</em>是比<em>sigmoid</em>更适合的。再本文中，我们对比了深度模型在使用relu和tanh的效果。如图7所示，除了IPNN外，在所有的深度模型中relu都比tanh更加合适。可能的原因是relu降低了稀疏性。</p><p><img src="https://i.postimg.cc/Xqrgbgf5/DeepFM-7.jpg" alt="DeepFM-7.jpg"></p><p><strong>Dropout</strong><br>Dropout[Srivastava et al., 2014]是网络中一个神经元保留下来的概率。Dropout 是一种用来折中神经网络的准确度和复杂度的正则技术。我们分别尝试了dropout在1.0,0.9,0.8,0.7,0.6,0.5下的效果。如图8所示，所有的模型当它们的dropout提前设定好的时候（0.6到0.9）都取得了它们最好的表现。结果表明往模型中加入一些合理的随机性能够增强模型的稳健性。</p><p><img src="https://i.postimg.cc/sX6JqLhy/DeepFM-8.jpg" alt="DeepFM-8.jpg"></p><p><strong>每层的神经网络个数</strong><br>当其他因素保持一致的时候，增加每一层的神经元个数会引入更高的复杂度。正如我们从图9可以观察到的，增加每一层的神经元个数并不总是能够带来收益。例如，当每一层神经元的个数从400增加到800的时候，DeepFM 的表现趋于稳定；更糟的是，当我们把神经元车上从400增加到800的时候OPNN表现反尔变差了。这是因为过度复杂的模型容易造成过拟合。在我们的数据集中，每一层设定200-400神经元是一个不错的选择。</p><p><img src="https://i.postimg.cc/7hjnYT9W/DeepFM-9.jpg" alt="DeepFM-9.jpg"></p><p><strong>隐含层的个数</strong><br>如图10所呈现的，增加隐含层的个数在一开始能够提高模型的表现，然而，如果层数一直增加他们的表现则会逐渐变差。这种现象一版也是由于过拟合造成的。</p><p><img src="https://i.postimg.cc/HxxwwtPN/Deep-FM-10.jpg" alt="Deep-FM-10.jpg"></p><p><strong>网络形状</strong><br>我们测试了4种网络形状：不变、增长、减小和菱形。当我们改变网络的结构，我们会固定隐含层的个数以及总神经元的个数。例如，当隐含层数量是3且总神经元个数是600的时候，四中网络形状是：不变（200-200-200），增长（100-200-300），减小（300-200-100）和菱形（150-300-150）。正如从图11中可以看到，“不变”的网络形状一般要好于其他三种形状，这也与之前的研究保持了一致性[Larochelle et al., 2009]。</p><p><img src="https://i.postimg.cc/g04yL74R/Deep-FM-11.jpg" alt="Deep-FM-11.jpg"></p><h3 id="4-相关工作"><a href="#4-相关工作" class="headerlink" title="4 相关工作"></a><strong>4 相关工作</strong></h3><p>在这篇文章，我们提出了一个新的深度学习网络结构用来做CTR预估。最相关的领域就是推荐系统中的CTR预估和深度学习。在这一部分，我们讨论一下这两个领域的相关工作。</p><p>CTR预估在推荐系统是特别地重要。除了一般的线性模型和FM，还有一些其他的模型会被用来做CTR预估，例如基于树，基于张量的模型，支持向量机，以及贝叶斯模型。</p><p>其他相关的领域就是推荐系统中的深度学习了。在第1部分和第2.2部分，我们已经提到了几个用来做CTR预估的深度学习模型，因此在这里我们不再讨论它们。一些深度模型一般会被用于推荐任务而不是CTR预估。[Salakhutdinov et al., 2007; Sedhain et al., 2015; Wang et al., 2015]提出通过深度学习来改进协同过滤。[Wang andWang, 2014; van den Oord et al., 2013]的作者通过深度学习来提取一些满意的特征用于改进音乐推荐。[Chen et al., 2016]设计了一个深度学习网路用来构建广告展示中的图片特征和基础特征。[Covington et al., 2016]开发了一个两部神经网络框架用来做YouTube的视频推荐。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a><strong>结论</strong></h3><p>在本文中，我们提出了DeepFM模型，是一个基于神经网络的因式分解机用来做CTR预估，克服了当前最先进模型的缺点并获得了一个更好的表现。DeepFM 是联合训练了一个深度部分和FM部分。它是通过以下几个优势获得了更好地表现：1）它不需要任何预训练；2）它能够同时学习高阶和低阶的特征交叉项；3）它引入了一个特征嵌入层共享的策略来避免特征工程。我们在两个实际数据集上进行了大量的实验来比较DeepFM和最先进模型之间的效果和效率。我们的实验结果表名了：1）DeepFM在两个数据集上的AUC和Logloss的表现都要好于最先进的模型；2）DeepFM相比于当下最先进有效的深度模型而言要更有效率。</p><p>在未来的研究中有两个有趣的方向。一个是探索一些策略（例如引入pooling层）来增强学习更有用的高阶特征交叉项。另一个就是在GPU集群上训练DeepFM来解决大规模数据的问题。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.04247.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：DeepFM:A Factorization-Machine based Neural Network for CTR Prediction&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;DeepFM-基于神经网络的因式分解机做点击率预估&quot;&gt;&lt;a href=&quot;#DeepFM-基于神经网络的因式分解机做点击率预估&quot; class=&quot;headerlink&quot; title=&quot;DeepFM:基于神经网络的因式分解机做点击率预估&quot;&gt;&lt;/a&gt;DeepFM:基于神经网络的因式分解机做点击率预估&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;对于推荐系统中的最大化CTR来说，学习那些用户行为背后的复杂而精确的特征交叉项是至关重要的。尽管有很大的提升，但是方法似乎在低阶或者高阶的交差项上带有很强的偏置项，又或者会要求专业性的特征工程。在这篇文章，我们会展示可以构造出一个端到端的学习模型，特别是对于低阶和高阶的交叉项的学习。DeepFM，提出的这个模型联合了因式分解机的推荐能力和一个新的神经网络结构在特征方面的深度学习能力。相比于Google提出的最新的Wide &amp;amp; Deep模型，DeepFM的“wide”和“deep”部分有一个共享输入层，并且除了最原始的特征不需要额外的特征工程。综合性的实验结果证明了DeepFM相比于其他的CTR模型在基础数据及和商业数据集上都有着更好的效果和效率。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="推荐" scheme="http://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="排序" scheme="http://www.xiemingzhao.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="CTR预估" scheme="http://www.xiemingzhao.com/tags/CTR%E9%A2%84%E4%BC%B0/"/>
    
      <category term="神经网络" scheme="http://www.xiemingzhao.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="DeepFM" scheme="http://www.xiemingzhao.com/tags/DeepFM/"/>
    
  </entry>
  
  <entry>
    <title>LTR信息检索评价指标</title>
    <link href="http://www.xiemingzhao.com/2019/06/27/%5BLTR%5D%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87--%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.xiemingzhao.com/2019/06/27/[LTR]信息检索评价指标--学习笔记/</id>
    <published>2019-06-26T16:00:00.000Z</published>
    <updated>2019-09-16T15:23:36.928Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-RP"><a href="#1-RP" class="headerlink" title="1 RP"></a>1 RP</h2><p>R（recall）表示召回率、查全率，指查询返回结果中相关文档占所有相关文档的比例；P（precision）表示准确率、精度，指查询返回结果中相关文档占所有查询结果文档的比例。假设有如下的混淆矩阵：</p><div class="table-container"><table><thead><tr><th style="text-align:center">—-</th><th style="text-align:center">Predict P</th><th style="text-align:center">Predict N</th></tr></thead><tbody><tr><td style="text-align:center">Target P</td><td style="text-align:center">TP</td><td style="text-align:center">FN</td></tr><tr><td style="text-align:center">Target N</td><td style="text-align:center">FP</td><td style="text-align:center">TN</td></tr></tbody></table></div><a id="more"></a><p>正确率、召回率（查全率）、精准度、$F_{\beta}$ score、假阳率以及真阳率：</p><script type="math/tex; mode=display">Accuracy = \frac{TP+FN}{TP+TN+FP+FN}</script><script type="math/tex; mode=display">Recall=\frac{TP}{TP+FN}</script><script type="math/tex; mode=display">Precision=\frac{TP}{TP+FP}</script><script type="math/tex; mode=display">F_{\beta}=(1+\beta^2) \cdot \frac{Precision \cdot Recall}{\beta^2 \cdot Precision + Recall}</script><p>其中，F-Score/F-measure 作为综合指标，平衡 recall 和 precision 的影响，较为全面的评价一个模型。F1-Score 表示准确率和召回率一样重要；F2-Score 表示召回率比准确率重要一倍；F0.5-Score 表示准确率比召回率重要一倍。</p><script type="math/tex; mode=display">FPR=\frac{FP}{FP+TN}</script><script type="math/tex; mode=display">TPR=\frac{TP}{TP+FN}</script><p><img src="https://i.postimg.cc/XX64QYxH/AUC.png" alt="AUC.png"></p><p>其中：<br>假阳率FPR=ROC曲线的X轴指标<br>真阳率TPR=ROC曲线的Y轴指标=召回率<br>AUC值就是曲线右下部分面积。</p><h2 id="2-MAP"><a href="#2-MAP" class="headerlink" title="2 MAP"></a>2 MAP</h2><p><img src="https://i.postimg.cc/28dVMsvb/PR.jpg" alt="PR.jpg"><br>如上图的PR曲线，对其进行积分求曲线下方的面积，就是AP(Average Precision)，即</p><script type="math/tex; mode=display">AP=\int_0^1 p(r) dr</script><p>其中，p 表示 precision，r 表示 recall，p 是一个以 r 为参数的函数，AP 的计算是对排序位置敏感的，相关文档排序的位置越靠前，检索出相关的文档越多，AP 值越大。</p><p>近似计算约等于 AAP（Aproximate Average Precision）：</p><script type="math/tex; mode=display">AAP=\sum_{k=1}^Np(k)\Delta r(k)=\frac{\sum_{k=1}^Np(k) \cdot rel(k)}{number Of Relevant Documents}</script><p>其中，N 代表所有相关文档的总数，p(k) 表示能检索出 k 个相关文档时的 precision 值，而 △r(k) 则表示检索相关文档个数从 k-1 变化到 k 时（通过调整阈值）recall 值的变化情况。<br>rel(k) 表示第 k 个文档是否相关，若相关则为1，否则为0，则可以简化公式为：</p><script type="math/tex; mode=display">AP=\frac{1}{N} \cdot \sum_{i=1}^N\frac{i}{position(i)}</script><p>其中，N 表示相关文档总数，position(i) 表示第 i 个相关文档在检索结果列表中的位置。</p><p>MAP（Mean Average Precision）即多个查询的平均正确率（AP）的均值，从整体上反映模型的检索性能。</p><p>下面举一个例子来说明上述公式的计算：<br>查询 query1 对应总共有4个相关文档，查询 query2 对应总共有5个相关文档。当通过模型执行查询1、2时，分别检索出4个相关文档（Rank=1、2、4、7）和3个相关文档（Rank=1、3、5）。<br>则 query1AP=(1/1+2/2+3/4+4/7)/4=0.83，query2AP=(1/1+2/3+3/5+0+0)/5=0.45，最后 MAP=(0.83+0.45)/2=0.64。</p><h2 id="3-NDCG"><a href="#3-NDCG" class="headerlink" title="3 NDCG"></a>3 NDCG</h2><h3 id="3-1-CG-Cumulative-Gain-累计效益"><a href="#3-1-CG-Cumulative-Gain-累计效益" class="headerlink" title="3.1 CG(Cumulative Gain)累计效益"></a>3.1 CG(Cumulative Gain)累计效益</h3><script type="math/tex; mode=display">CG@k=\sum_{i=1}^k rel_i</script><p>其中 k 表示 k 个文档组成的集合，rel 表示第 i 个文档的相关度，例如相关度分为以下几个等级：</p><div class="table-container"><table><thead><tr><th style="text-align:center">Relevance Rating</th><th style="text-align:center">Value</th></tr></thead><tbody><tr><td style="text-align:center">Perfect</td><td style="text-align:center">5</td></tr><tr><td style="text-align:center">Excellent</td><td style="text-align:center">4</td></tr><tr><td style="text-align:center">Good</td><td style="text-align:center">3</td></tr><tr><td style="text-align:center">Fair</td><td style="text-align:center">2</td></tr><tr><td style="text-align:center">Simple</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">Bad</td><td style="text-align:center">0</td></tr></tbody></table></div><h3 id="3-2-DCG-Discounted-Cumulative-Gain"><a href="#3-2-DCG-Discounted-Cumulative-Gain" class="headerlink" title="3.2 DCG(Discounted Cumulative Gain)"></a>3.2 DCG(Discounted Cumulative Gain)</h3><p>在 CG 的计算中没有考虑到位置信息，例如检索到三个文档的相关度依次为（3，-1，1）和（-1，1，3），根据 CG 的计算公式得出的排名是相同的，但是显然前者的排序好一些。</p><p>所以需要在 CG 计算的基础上加入位置信息的计算，现假设根据位置的递增，对应的价值递减，为 1/log2(i+1)，其中 log2(i+1) 为折扣因子；</p><script type="math/tex; mode=display">DCG@k=\sum_{i=1}^k \frac{rel_i}{log_2 (i+1)}</script><p>另一种增加相关度影响比重的 DCG 计算公式：</p><script type="math/tex; mode=display">DCG@k=\sum_{i=1}^k \frac{2^{rel_i}-1}{log_2 (i+1)}</script><h3 id="3-3-IDCG-idea-DCG"><a href="#3-3-IDCG-idea-DCG" class="headerlink" title="3.3 IDCG(idea DCG)"></a>3.3 IDCG(idea DCG)</h3><p>理想情况下，按照相关度从大到小排序，然后计算 DCG 可以取得最大值情况。</p><script type="math/tex; mode=display">IDCG@k=\sum_{i=1}^{|REL|} \frac{2^{rel_i}-1}{log_2 (i+1)}</script><p>其中 |REL| 表示文档按照相关度从大到小排序，取前 k 个文档组成的集合。就是按理想排序情景的前k个。</p><h3 id="3-4-NDCG-Normalized-DCG"><a href="#3-4-NDCG-Normalized-DCG" class="headerlink" title="3.4 NDCG(Normalized DCG)"></a>3.4 NDCG(Normalized DCG)</h3><p>由于每个查询所能检索到的结果文档集合长度不一致，k 值的不同会影响 DCG 的计算结果。所以不能简单的对不同查询的 DCG 结果进行平均，需要先归一化处理。</p><p>NDCG 就是利用 IDCG 进行归一化处理，表示当前的 DCG 与理想情况下的 IDCG 相差多大：</p><script type="math/tex; mode=display">NDCG@k=\frac{DCG@k}{IDCG@K}</script><p>这样每个查询的 NDCG 均在 0-1 范围内，不同查询之间就可以进行比较，求取多个查询的平均 NDCG。</p><h2 id="4-ERR"><a href="#4-ERR" class="headerlink" title="4 ERR"></a>4 ERR</h2><h3 id="4-1-PR-reciprocal-rank"><a href="#4-1-PR-reciprocal-rank" class="headerlink" title="4.1 PR(reciprocal rank)"></a>4.1 PR(reciprocal rank)</h3><p>倒数排名，指检索结果中第一个相关文档的排名的倒数。</p><script type="math/tex; mode=display">RR=\frac{1}{rank_i}</script><h3 id="4-2-MRR-mean-reciprocal-rank"><a href="#4-2-MRR-mean-reciprocal-rank" class="headerlink" title="4.2 MRR(mean reciprocal rank)"></a>4.2 MRR(mean reciprocal rank)</h3><p>多个查询的倒数排名的均值，公式如下：</p><script type="math/tex; mode=display">MRR=\frac{1}{|N|} \sum_{i=1}^{|N|} \frac{1}{rank_i}</script><p>ranki 表示第 i 个查询的第一个相关文档的排名。</p><h3 id="4-3-Cascade-Model-瀑布模型"><a href="#4-3-Cascade-Model-瀑布模型" class="headerlink" title="4.3 Cascade Model(瀑布模型)"></a>4.3 Cascade Model(瀑布模型)</h3><p>点击模型中的瀑布模型，考虑到在同一个检索结果列表中各文档之间的位置依赖关系，假设用户从上至下查看，如果遇到某一检索结果项满意并进行点击，则操作结束；否则跳过该项继续往后查看。第 i 个位置的文档项被点击的概率为：</p><script type="math/tex; mode=display">P(C_i)=r_i \prod_{j=1}^{i-1} (1-r_j)</script><p>其中 ri 表示第 i 个文档被点击的概率，前 i-1 个文档则没有被点击，概率均为 1-rj；</p><h3 id="4-4-ERR-Expected-reciprocal-rank"><a href="#4-4-ERR-Expected-reciprocal-rank" class="headerlink" title="4.4 ERR(Expected reciprocal rank)"></a>4.4 ERR(Expected reciprocal rank)</h3><p>预期的倒数排名，表示用户的需求被满足时停止的位置的倒数的期望，与 RR 计算第一个相关文档的位置倒数不同。<br>首先用户在位置 r 处停止的概率 PPr 计算公式如下：</p><script type="math/tex; mode=display">PP_r=\prod_{i=1}^{r-1}(1-R_i) R_r</script><p>其中 Ri 是关于文档相关度等级的函数，现假设该函数为：</p><script type="math/tex; mode=display">R_i=R(g_i)=\frac{2^g-1}{2^{g_max}}</script><p>当文档是不相关的（g=0），则用户检索到相关文档的概率为0；而当文档极其相关（g=4，如果相关度划分5个等级）时，用户检索到相关文档的概率接近于1。上面公式中的 g 表示文档的相关度，参考 NDCG 中的 rel。</p><p>更通用一点来讲，ERR 不一定是计算用户需求满足时停止的位置的倒数的期望，它可以是基于位置的函数</p><script type="math/tex; mode=display">ERR=\sum_{r=1}^n \varphi(r)P Pr=\sum_{r=1}^n \frac{1}{r} P Pr=\sum_{r=1}^n \frac{1}{r} \prod_{i=1}^{r-1}(1-R_i)R_r</script><p>可以看出，当 φ(r)=1/r 时就是 ERR，当 φ(r)=1/log2(r+1) 就是DCG。</p><p><a href="https://www.cnblogs.com/memento/p/8673309.html" target="_blank" rel="noopener">参考文章:https://www.cnblogs.com/memento/p/8673309.html</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-RP&quot;&gt;&lt;a href=&quot;#1-RP&quot; class=&quot;headerlink&quot; title=&quot;1 RP&quot;&gt;&lt;/a&gt;1 RP&lt;/h2&gt;&lt;p&gt;R（recall）表示召回率、查全率，指查询返回结果中相关文档占所有相关文档的比例；P（precision）表示准确率、精度，指查询返回结果中相关文档占所有查询结果文档的比例。假设有如下的混淆矩阵：&lt;/p&gt;
&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;—-&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Predict P&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Predict N&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Target P&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;TP&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;FN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Target N&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;FP&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;TN&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="算法总结" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="排序" scheme="http://www.xiemingzhao.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="LTR" scheme="http://www.xiemingzhao.com/tags/LTR/"/>
    
  </entry>
  
  <entry>
    <title>Wide &amp; Deep Learning for Recommender Systems</title>
    <link href="http://www.xiemingzhao.com/2019/06/12/Wide%20&amp;%20Deep%20Learning%20for%20Recommender%20Systems--%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.xiemingzhao.com/2019/06/12/Wide &amp; Deep Learning for Recommender Systems--学习笔记/</id>
    <published>2019-06-11T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:45.045Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://scholar.google.com.hk/scholar_url?url=https://dl.acm.org/ft_gateway.cfm%3Fid%3D2988454%26type%3Dpdf&amp;hl=zh-CN&amp;sa=X&amp;scisig=AAGBfm0TVpSA7DpxrGGn23_Zbb27fZpvyQ&amp;nossl=1&amp;oi=scholarr" target="_blank" rel="noopener">原始论文：Wide &amp; Deep Learning for Recommender Systems</a></p><h2 id="推荐系统之Wide-amp-Deep机器学习算法"><a href="#推荐系统之Wide-amp-Deep机器学习算法" class="headerlink" title="推荐系统之Wide &amp; Deep机器学习算法"></a>推荐系统之Wide &amp; Deep机器学习算法</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>不包含非线性特征变换的一般线性模型被广泛地应用在具有稀疏输入的大规模回归和分类问题中。通过一个<em>宽的</em>交叉积特征变换来实现对特征交叉的记忆是很有效和可解释的，而泛化能力需要更多的特征工程工作。考虑少用特征工程，深度神经网络可以更好地起到品泛化的作用，它会从稀疏的特征中学习到那些低维度看不见的密集嵌入。然而，具有嵌入的深度神经网络很容易过度泛化，并在用户-物品交互稀疏和稠密的时候会推荐一些不太相关的项物品。在本文中，我们提出广泛和深度学习——联合训练宽线性模型和深层神经网络——如此来结合记忆模型和泛化模型的好处从而构成更好的推荐系统。我们在Google Play上制作并评估了该系统，它是一个活跃的商业移动应用商店，上面超过10亿活跃用户和超过一百万个应用程序。在线实验结果表明相对于仅用wide模型和deep模型而言，Wide＆Deep显着增加了app的获取。我们也在TensorFlow中开源了我们的实现。</p><p><strong>关键词</strong>  Wide &amp; Deep学习，推荐系统</p><a id="more"></a><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a><strong>1. 介绍</strong></h3><p>一个推荐系统可以被看作是一个搜索排序系统，其中输入的请求是一个用户和上下文信息的集合，输出则是一个物品列表的排序。给定一个请求，推荐系统的任务就是在数据集中找到相关的物品，并且根据一定的目标，例如点击和购买，将所有的项目进行排序。</p><p>推荐系统的一个挑战是类似于一版的搜索排序问题，就是同时实现记忆和泛化的能力。记忆可以被宽泛地定义为学习物品或特征的频繁共现，并且开发历史数据中可用的相关性。另一方面，泛化是基于相关性的传递性和探索从来没有或很少发生在过去的新特征组合。推荐是基于记忆的，通常更具局部性并且与那些用户已经对其产生过行为的物品直接相关。与记忆相比，泛化倾向于改善推荐物品的多样性。在本文中，我们关注Google Play商店中应用程序推荐的问题，但方法应该适用于通用推荐系统。</p><p>对于工业环境中的大规模在线推荐和排序系统，一般的线性模型例如逻辑回归都是被广泛使用的，因为它们是简单，可扩展和可解释的。模型经常是使用one-hot编码的二值化稀疏特征进行训练的。例如，二进制特征“user_installed_app = netflix”，如果用户安装了Netflix那么该特征具有值1。使用通过对稀疏特征进行交叉积变化可以有效地实现记忆功能，例如AND（user_installed_app = netflix，impres-sion_app = pandora），如果用户安装了Netflix后有显示了Pandora，则其值为1。这解释了特征对的共现与目标标签有多么的相关。泛化功能是可以通过使用那些颗粒度较小的特征来添加的，例如AND（user_installed_category = video，impression_category =music），但手动特征工程常常还是需要的。交叉积变化的一个限制是他们没有办法泛化出那些没有出现在训练数据中的请求-物品特征对。</p><p>基于嵌入的模型，例如因式分解机或深度神经网络，可以通过对每个请求和物品特征学习出一个低维的嵌入向量来泛化出那些看不到的请求-物品特征对，如此可以减少特征工程的负担。然而，当底层的请求-物品矩阵是稀疏和高秩的时候，想要学习出一个有效的请求和物品的低维表示是非常困难的，例如具有特定偏好的用户或具有狭隘吸引力的商机物品。在这种情况下它与大多数的查询项对之间都是没有交互的，但密集的嵌入将会导致对所有的查询-物品对都有一个非零预测，因此可以过度泛化从而产生不相关的推荐。另一方面，有交叉积特征变换的线性模型在不用特别多参数的情况下可以记住这种“特殊规则”。</p><p>在本文中，我们提出Wide &amp; Deep学习框架来在同一个模型中同时完成记忆和泛化的任务，如图1所示，它是通过联合训练出一个线性模型和一个神经网络模型。</p><p>这篇文章的主要贡献包括：</p><ul><li>Wide &amp; Deep学习框架是通过联合训练一个有嵌入层的前向神经网络和一个有特征变换的线性模型，如此可以得到一个基于稀疏输入的一般推荐系统模型。</li><li>Wide &amp; Deep推荐系统的实现和评估是在Google Play上完成的，它是一个移动应用程序商店，其上拥有超过十亿的活跃用户和超过一百万的应用程序。</li><li>我们提供了一个开源的实现，它是通过TensorFlow中的一个高级API实现的。</li></ul><p>尽管思想很简单，我们还是证明了Wide &amp; Deep框架极大地提升了移动应用商店的app下载率，并且同时满足训练和高速服务的需求。</p><p><img src="https://i.postimg.cc/Ssdx68zn/relate-papers21-1.jpg" alt="wide&amp;deep-1"></p><p><img src="https://i.postimg.cc/nrLc0zv0/relate-papers21-2.jpg" alt="wide&amp;deep-2"></p><h3 id="2-推荐系统概述"><a href="#2-推荐系统概述" class="headerlink" title="2. 推荐系统概述"></a><strong>2. 推荐系统概述</strong></h3><p>图2显示了app推荐系统的概述。一个查询，可以包括各种用户和用户访问应用商店时会生成的上下文特征。推荐系统返回应用列表（也被称为展示），在这上面用户可以执行一些特定的行为例如点击或购买。这些用户操作，随着查询和展示，都记录在日志中，作为模型的训练数据。</p><p>由于数据库中有超过一百万的应用，在查询服务的潜在要求（经常是O(10)毫秒）的条件下，为每个查询都对所有的应用进行打分是难以实现的。因此，在收到一个查询后的第一步是<em>检索</em>。检索系统返回一个较短的物品列表，这个列表是使用各种特征对请求的最好匹配，通常是机器学习模型和人为定义规则的一个联合。在降低了候选池之后，排序系统会通过它们打出的分数对所有物品进行排序。这个得分经常是$P(y|x)$，它是表示给定特征x后的定于行为标签y的概率，其中x包括用户的特征（例如国家、语言、人口统计学指标），上下文特征（例如设备、一天中的第几个小时、周几），还有展示特征（例如应用年龄、应用的历史统计）。在本文中，我们聚焦于使用Wide &amp; Deep学习框架的排序模型。</p><h3 id="3-Wide-amp-Deep学习"><a href="#3-Wide-amp-Deep学习" class="headerlink" title="3. Wide &amp; Deep学习"></a><strong>3. Wide &amp; Deep学习</strong></h3><p><strong>3.1 Wide部分</strong><br>宽模型部分是一个广义线性模型，形式一般为$y = w^T x+b$，如图1左侧所示。y是预测，$x=[x_1,x_2,…,x_d]$是一个d维特征的向量，$w=[w_1,w_2,…w_d]$是模型参数且b是偏置项。特征集合包含原始输入的特征以及经过转换的特征。一个最终演的变换就是<em>交叉积变换</em>，如下定义：</p><script type="math/tex; mode=display">\phi_k(x)=\prod_{i=1}^d x_i^{c_{ki}} \ , \ c_{ki} \ \in \ \{0,1\}</script><p>其中$c_{ki}$是一个布尔变量，也就是如果第i个特征是第k个变换$\phi_k$的一部分则其取值为1，否则是0。对于二值特征，当且仅当交叉项的组成特征（例如“gender=female” and “language=en”）全部是1的时候交叉积变换（例如“AND(gender=female, language=en)”）才是1，否则就是0。这就获得了二值特征的交叉项，并且往广义线性模型中增加了非线性。</p><p><strong>3.2 Deep部分</strong><br>深模型部分是一个前向神经网络，如图1中右侧所示。对于类别特征，原始输入是特征字符串（例如“language=en”）。每个这种稀疏、高维类别特征都会首先被转换成一个低维并且稠密的实值向量，通常被称为嵌入向量。嵌入层的维度一般在O(10)到O(100)。嵌入向量会被随机的初始化，然后其值会在训练过程中通过最小化最终损失函数来训练。这些低维的稠密嵌入向量会被喂入神经网络前向通过的隐含层中。特别地，每个隐含层的计算是：</p><script type="math/tex; mode=display">a^{l+1} = f(W^{(l)}a^{(l)} + b^{(l)})</script><p>其中l是层数，f是激活函数，经常被设成整数线性单元(ReLUs)。$a^{(l)}, b^{(l)}和W^{(l)}$分别是激活项、偏置项和模型第l层的权重项。</p><p><strong>3.3 Wide &amp; Deep模型的联合训练</strong><br>宽模型部分和深模型部分会被用加权求和联合到一起，然后输出部分会进行对数概率变换后作为预测结果，在这之后一般会喂入一个普通的逻辑损失函数中进行联合训练。注意到<em>联合训练</em>和<em>合并</em>之间是有区别的。合并，一般是每个模型独自分开训练互不干扰，他们的预测结果只在推断的时候才会联合，训练过程中并不会。相反，联合训练会同时优化所有的参数，是通过在训练的过程中汇总获取宽模型和深模型的所有参数进行计算。模型大小的含义：对于模型合并，由于训练是分开的，每个单独的模型大小通常需要比较的大（例如有特别多的特征和变换）从而来得到<br>一个合理准确的起作用的模型合并。相比之下，对于联合训练中的宽模型部分只需要去实现深度模型的弱势部分就可以了，所以它有一个很小量级的交叉积特征变换，而不是一个全量的宽模型。</p><p>Wide &amp; Deep模型的联合训练是通过使用小批量随机优化从输出层同时进行宽模型和深模型的反向梯度传播来完成的。在实验中，我们使用Follow-the-regularized-leader (FTRL)算法和L1正则项作为宽模型部分的优化器，同时AdaGrad作为深度部分的优化器。</p><p>图1中间部分展示了联合模型。属于逻辑回归的问题，模型的预测结果为：</p><script type="math/tex; mode=display">P(Y=1|x)=\sigma(w_{wide}^T [x,\phi (x)] + w_{deep}^T a^{(l_f)} +b)</script><p>其中Y是二值类别标签，$\sigma(\cdot)$是sigmoid函数，$\phi(x)$是原始特征x的交叉积变换，b是偏置项。$w_{wide}$是宽模型权重参数向量，$w_{deep}$是应用在最终激活项$a^{(l_f)}$的的权重参数<br>。</p><h3 id="4-系统实现"><a href="#4-系统实现" class="headerlink" title="4. 系统实现"></a><strong>4. 系统实现</strong></h3><p>应用推荐管道的实现包含三个步骤：数据生成，模型训练，以及模型服务，如图3中所示。</p><p><img src="https://i.postimg.cc/L5047pDR/relate-papers21-3.jpg" alt="wide&amp;deep-3"></p><p><strong>4.1 数据生成</strong><br>在这个步骤，在一个时期的用户和应用展示数据被用来生成训练数据。每个样本对应于一次展示。标签就是应用获取：1代表展示的应用被安装了，否则为0。</p><p>词汇表，是用来将类别特征中的字符串匹配成整数型IDs的，也是在这一步骤中生成的。系统为所有的字符型特征计算IDs的空间，其中特征只计算那些出现次数超过最小次数的。连续型的实值特征会被标准化到[0,1]，方法是将特征值x匹配到该特征的累积分布函数$P(X\leq x)$，分成了$n_q$分位数。第i个分位数标准化后的值是$\frac{i-1}{n_q-1}$。分位数的边界是在数据生成过程中计算的。</p><p><img src="https://i.postimg.cc/BZ2dVshC/relate-papers21-4.jpg" alt="wide&amp;deep-4"></p><p><strong>4.2 模型训练</strong><br>我们在实验中使用的模型结构如图4所示。在训练中，我们的输入层接手输入数据和词汇表，然后用一个标签一起生成稀疏的和密集的特征。宽模型部分由用户安装应用和展示应用做交叉积变换得到。对于模型的深度部分，一个32维的嵌入向量是从每个类别型特征中学到的。我们将所有的嵌入向量串联在一起形成一个密集的特征，这就构成了一个接近1200维的密集向量。串联的向量接着会被喂入3个ReLU网络层，最优通过逻辑层输出单元。</p><p>Wide &amp; Deep模型是在5000亿个样本上训练得到的。每一次一个新的训练数据集到达时，模型需要被再次训练。然而，每次再训练花费的时间都是特别昂贵的计算成本同时新数据更新模型将会产生一定的延迟。为了战胜这个挑战，我们实现一个热启动的系统，它是用前一个模型的嵌入层和线性模型权重参数来初始化本次新模型。</p><p><strong>4.3 模型服务</strong><br>每一次模型被训练完成和确定之后，我们将其加载到模型服务中。对于每次请求，服务会从应用检索系统中接受到一个应用候选集和用户特征来对背个应用进行打分。然后，应用将会根据得分从高到低进行排序，我们将会按照此顺序将应用展示给用户。分数将会通过运行一个Wide &amp; Deep模型的前向推断得到。</p><p>为了在10ms的需求下服务每一次请求，我们使用多线程并行来优化表现，它是通过并行运行小批量实现的而不是在一个但线程中对所有的候选应用进行打分的。</p><h3 id="5-实验结果"><a href="#5-实验结果" class="headerlink" title="5. 实验结果"></a><strong>5. 实验结果</strong></h3><p>为了评估Wide &amp; Deep学习在实际推荐系统中的有效性，我们运行了一个实验并在多方面对系统进行了评估：应用获取和服务表现。</p><p><em>表1：不同模型的离线和在线的效果矩阵。在线的获取Gain值是相对于对照组的。</em></p><div class="table-container"><table><thead><tr><th style="text-align:left">Model</th><th style="text-align:center">Offline AUC</th><th style="text-align:center">Online Acqusition Gain</th></tr></thead><tbody><tr><td style="text-align:left">Wide (control)</td><td style="text-align:center">0.726</td><td style="text-align:center">0%</td></tr><tr><td style="text-align:left">Deep</td><td style="text-align:center">0.722</td><td style="text-align:center">+2.9%</td></tr><tr><td style="text-align:left">Wide &amp; Deep</td><td style="text-align:center">0.728</td><td style="text-align:center">+3.9%</td></tr></tbody></table></div><p><strong>5.1 应用获取</strong><br>我们在一个A/B测试框架中进行了3周的在线实验。对于对照组，随机选择1%的用户并使用之前的排序模型来生成推荐排序，先前的模型是一个高度优化后的仅有宽度逻辑回归的模型，它有很丰富的交叉积特征变换。对于实验组，我们随机选取另1%的用户并用Wide &amp; Deep模型来生成推荐排序，训练数据使用同样的特征集合。如表1中所示，相对于对照组，Wide &amp; Deep提高了主页面上的应用获取率大约+3.9%（统计显著）。结果也和另一1%用户组进行对比，这一组仅仅使用了深度模型结构和相同的特征，同样的Wide &amp; Deep模型有1+%的一个收益（统计显著的）。</p><p>除了线上实验，我们也展示了离线对抗集的AUC。然而Wide &amp; Deep有一个略高的离线AUC，对在线流量的影响更为显着。一个可能的原因是离线数据集的展示和标签是固定的额，而在线系统可以通过混合记忆和泛化来生成新的探索性的推荐，并且可以从新的用户反馈中学习到更多。</p><p><strong>5.2 服务表现</strong><br>在面临我们商业性移动应用商店的时候，高级别流量高吞吐量和低延迟的服务要求是一个挑战。在流量巅峰，我们的推荐服务在每秒内对超过1000万个应用进行打分。在单线程的时候，在一个单批量中对所有候选app进行打分将花费31毫秒。我们使用多线程实现，并将每一批量分成更小的批量，这显著地降低用户端延迟到14毫秒（包括服务高峰期），结果如表2所示。</p><p><em>表2：批量大小和线程个数的服务延迟对比</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">Batch size</th><th style="text-align:center">Number of Threads</th><th style="text-align:center">Serving Latency (ms)</th></tr></thead><tbody><tr><td style="text-align:center">200</td><td style="text-align:center">1</td><td style="text-align:center">31</td></tr><tr><td style="text-align:center">100</td><td style="text-align:center">2</td><td style="text-align:center">17</td></tr><tr><td style="text-align:center">50</td><td style="text-align:center">4</td><td style="text-align:center">4</td></tr></tbody></table></div><h3 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6. 相关工作"></a><strong>6. 相关工作</strong></h3><p>将带有交叉积特征变换的宽线性模型和带有密集嵌入的深度神经网络模型联合到一起的想法是受到前人工作启发的，例如因式分解机这种加入了泛化能力的线性模型，它通过将两个变量之间的交叉项分解成两个变量之间的点积。在本文中，我们通过在嵌入层通过神经网络之间的时候而不是点积来学习更高地非线性交叉项从而达到扩展模型的能力。</p><p>在语言模型中，循环神经网络（RNNs）和带有n-gram特征最大熵模型的联合训练已经被提出来了，通过学习输入层和输出层之间的直接权重能够显著地降低RNN的复杂度（例如隐含层的大小）。在计算机视觉中，深度残差学习已经被用于降低训练深度模型的困难度，并且通过跨越一层或多层的捷径连接达到了提高准确率的效果。带有图模型神经网络的联合训练已经被应用在了从图片中评估人类姿势。在我们提出的这个前向神经网络和线性模型的联合训练的工作中，在稀疏特征和输出单元之间带有直接连接，这是为了通用化带有稀疏输入数据的推荐和排序问题。</p><p>在推荐系统文献中，协同深度学习已经通过结合内容信息的深度学习和评分矩阵的协同过滤被探索了。同样也有很多关于移动应用推荐系统的先前工作，例如将CF用在用户的应用使用记录上的AppJoy。不同于基于CF的或者基于内容方法的这些先前工作，我们的推荐系统是在用户和展示数据上联合训练Wide &amp; Deep模型。</p><h3 id="7-结论"><a href="#7-结论" class="headerlink" title="7. 结论"></a><strong>7. 结论</strong></h3><p>记忆和泛化对于推荐系统来说都很重要。宽线性模型通过使用交叉积特征变换能够有效的基于稀疏特征之间的交叉项，而深度神经网络可以通过低维嵌入层来泛化出那些重要确又看不见的特征交叉项。我们呈现的Wide &amp; Deep学习框架是为了联合这两种模型的各自长处。我们在Google Play这个大规模的商业应用商店上对我们这个框架进行了产品化和评估。在线实验的结果证明了相对于仅用宽和深度模型来说，Wide &amp; Deep模型在应用获取上带来了显著地提升。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://scholar.google.com.hk/scholar_url?url=https://dl.acm.org/ft_gateway.cfm%3Fid%3D2988454%26type%3Dpdf&amp;amp;hl=zh-CN&amp;amp;sa=X&amp;amp;scisig=AAGBfm0TVpSA7DpxrGGn23_Zbb27fZpvyQ&amp;amp;nossl=1&amp;amp;oi=scholarr&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：Wide &amp;amp; Deep Learning for Recommender Systems&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;推荐系统之Wide-amp-Deep机器学习算法&quot;&gt;&lt;a href=&quot;#推荐系统之Wide-amp-Deep机器学习算法&quot; class=&quot;headerlink&quot; title=&quot;推荐系统之Wide &amp;amp; Deep机器学习算法&quot;&gt;&lt;/a&gt;推荐系统之Wide &amp;amp; Deep机器学习算法&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;不包含非线性特征变换的一般线性模型被广泛地应用在具有稀疏输入的大规模回归和分类问题中。通过一个&lt;em&gt;宽的&lt;/em&gt;交叉积特征变换来实现对特征交叉的记忆是很有效和可解释的，而泛化能力需要更多的特征工程工作。考虑少用特征工程，深度神经网络可以更好地起到品泛化的作用，它会从稀疏的特征中学习到那些低维度看不见的密集嵌入。然而，具有嵌入的深度神经网络很容易过度泛化，并在用户-物品交互稀疏和稠密的时候会推荐一些不太相关的项物品。在本文中，我们提出广泛和深度学习——联合训练宽线性模型和深层神经网络——如此来结合记忆模型和泛化模型的好处从而构成更好的推荐系统。我们在Google Play上制作并评估了该系统，它是一个活跃的商业移动应用商店，上面超过10亿活跃用户和超过一百万个应用程序。在线实验结果表明相对于仅用wide模型和deep模型而言，Wide＆Deep显着增加了app的获取。我们也在TensorFlow中开源了我们的实现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键词&lt;/strong&gt;  Wide &amp;amp; Deep学习，推荐系统&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="推荐系统" scheme="http://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Wide &amp; Deep" scheme="http://www.xiemingzhao.com/tags/Wide-Deep/"/>
    
  </entry>
  
  <entry>
    <title>An overview of gradient descent optimization algorithms</title>
    <link href="http://www.xiemingzhao.com/2019/06/11/An%20overview%20of%20gradient%20descent%20optimization%20algorithms--%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.xiemingzhao.com/2019/06/11/An overview of gradient descent optimization algorithms--学习笔记/</id>
    <published>2019-06-10T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:39.370Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://ruder.io/optimizing-gradient-descent/" target="_blank" rel="noopener">原始论文：An overview of gradient descent optimization algorithms</a></p><h2 id="梯度下降优化算法综述"><a href="#梯度下降优化算法综述" class="headerlink" title="梯度下降优化算法综述"></a>梯度下降优化算法综述</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>虽然梯度下降优化算法越来越受欢迎，但通常作为黑盒优化器使用，因此很难对其优点和缺点的进行实际的解释。本文旨在让读者对不同的算法有直观的认识，以帮助读者使用这些算法。在本综述中，我们介绍梯度下降的不同变形形式，总结这些算法面临的挑战，介绍最常用的优化算法，回顾并行和分布式架构，以及调研用于优化梯度下降的其他的策略。</p><h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a><strong>1 引言</strong></h3><p>梯度下降法是最著名的优化算法之一，也是迄今优化神经网络时最常用的方法。同时，在每一个最新的深度学习库中都包含了各种优化的梯度下降法的实现（例如：参见lasagne，caffe和keras的文档）。然而，这些算法通常是作为黑盒优化器使用，因此，很难对其优点和缺点的进行实际的解释。</p><a id="more"></a><p>本文旨在让读者对不同的优化梯度下降的算法有直观的认识，以帮助读者使用这些算法。在第2部分，我们首先介绍梯度下降的不同变形形式。在第3部分，我们将简要总结在训练的过程中所面临的挑战。随后，在第4部分，我们将介绍最常用的优化算法，包括这些算法在解决以上挑战时的动机以及如何得到更新规则的推导形式。在第5部分，我们将简单讨论在并行和分布式环境中优化梯度下降的算法和框架。最后，在第6部分，我们将思考对优化梯度下降有用的一些其他策略。</p><p>梯度下降法是最小化目标函数$J(\theta)$的一种方法，其中，$θ \in \mathbb R^d$为模型参数，梯度下降法利用目标函数关于参数的梯度$\triangledown_{\theta}J(\theta)$的反方向更新参数。学习率$\eta$决定达到最小值或者局部最小值过程中所采用的步长的大小。即，我们沿着目标函数的斜面下降的方向，直到到达谷底。如果你对梯度下降法不熟悉，你可以从<a href="http://cs231n.github.io/optimization-1/" target="_blank" rel="noopener">此处资料</a>找到介绍神经网络优化的材料。</p><h3 id="2-梯度下降法的变形形式"><a href="#2-梯度下降法的变形形式" class="headerlink" title="2 梯度下降法的变形形式"></a><strong>2 梯度下降法的变形形式</strong></h3><p>梯度下降法有3中变形形式，它们之间的区别为我们在计算目标函数的梯度时使用到多少数据。根据数据量的不同，我们在参数更新的精度和更新过程中所需要的时间两个方面做出权衡。</p><h4 id="2-1-批梯度下降法"><a href="#2-1-批梯度下降法" class="headerlink" title="2.1 批梯度下降法"></a><strong>2.1 批梯度下降法</strong></h4><p>Vanilla梯度下降法，又称为批梯度下降法（batch gradient descent），在整个训练数据集上计算损失函数关于参数$\theta$的梯度：</p><script type="math/tex; mode=display">\theta = \theta - \eta \cdot \triangledown_{\theta}J(\theta)</script><p>因为在执行每次更新时，我们需要在整个数据集上计算所有的梯度，所以批梯度下降法的速度会很慢，同时，批梯度下降法无法处理超出内存容量限制的数据集。批梯度下降法同样也不能在线更新模型，即在运行的过程中，不能增加新的样本。</p><p>批梯度下降法的代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(nb_epochs):</span><br><span class="line">    params_grad = evaluate_gradient(loss_function, data, params)</span><br><span class="line">    params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure></p><p>对于给定的迭代次数，首先，我们利用全部数据集计算损失函数关于参数向量params的梯度向量params_grad。注意，最新的深度学习库中提供了自动求导的功能，可以有效地计算关于参数梯度。如果你自己求梯度，那么，梯度检查是一个不错的主意（关于如何正确检查梯度的一些技巧可以参见<a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">此处资料</a>）。</p><p>然后，我们利用梯度的方向和学习率更新参数，学习率决定我们将以多大的步长更新参数。对于凸误差函数，批梯度下降法能够保证收敛到全局最小值，对于非凸函数，则收敛到一个局部最小值。</p><h4 id="2-2-随机梯度下降法"><a href="#2-2-随机梯度下降法" class="headerlink" title="2.2 随机梯度下降法"></a><strong>2.2 随机梯度下降法</strong></h4><p>相反，随机梯度下降法（stochastic gradient descent, SGD）根据每一条训练样本$x^{(i)}$和标签$y^{(i)}$更新参数：</p><script type="math/tex; mode=display">\theta = \theta - \eta \cdot \triangledown_{\theta}J(\theta;x^{(i)};y^{(i)})</script><p>对于大数据集，因为批梯度下降法在每一个参数更新之前，会对相似的样本计算梯度，所以在计算过程中会有冗余。而SGD在每一次更新中只执行一次，从而消除了冗余。因而，通常SGD的运行速度更快，同时，可以用于在线学习。SGD以高方差频繁地更新，导致目标函数出现如图1所示的剧烈波动。</p><p><img src="https://i.postimg.cc/0y9Fzn1Z/optimizer-01.jpg" alt="optimizer-01.jpg"></p><p>与批梯度下降法的收敛会使得损失函数陷入局部最小相比，由于SGD的波动性，一方面，波动性使得SGD可以跳到新的和潜在更好的局部最优。另一方面，这使得最终收敛到特定最小值的过程变得复杂，因为SGD会一直持续波动。然而，已经证明当我们缓慢减小学习率，SGD与批梯度下降法具有相同的收敛行为，对于非凸优化和凸优化，可以分别收敛到局部最小值和全局最小值。与批梯度下降的代码相比，SGD的代码片段仅仅是在对训练样本的遍历和利用每一条样本计算梯度的过程中增加一层循环。注意，如6.1节中的解释，在每一次循环中，我们打乱训练样本。</p><pre><code class="lang-python">for i in range(nb_epochs):    np.random.shuffle(data)    for example in data:        params_grad = evaluate_gradient(loss_function, example, params)        params = params - learning_rate * params_grad</code></pre><h4 id="2-3-小批量梯度下降法"><a href="#2-3-小批量梯度下降法" class="headerlink" title="2.3 小批量梯度下降法"></a><strong>2.3 小批量梯度下降法</strong></h4><p>小批量梯度下降法最终结合了上述两种方法的优点，在每次更新时使用n个小批量训练样本：</p><script type="math/tex; mode=display">\theta = \theta - \eta \cdot \triangledown_{\theta}J(\theta;x^{(i:i+n)};y^{(i:i+n)})</script><p>这种方法，a)减少参数更新的方差，这样可以得到更加稳定的收敛结果；b)可以利用最新的深度学习库中高度优化的矩阵优化方法，高效地求解每个小批量数据的梯度。通常，小批量数据的大小在50到256之间，也可以根据不同的应用有所变化。当训练神经网络模型时，小批量梯度下降法是典型的选择算法，当使用小批量梯度下降法时，也将其称为SGD。注意：在下文的改进的SGD中，为了简单，我们省略了参数$x^{(i:i+n)};y^{(i:i+n)}$。</p><p>在代码中，不是在所有样本上做迭代，我们现在只是在大小为50的小批量数据上做迭代：</p><pre><code class="lang-python">for i in range(nb_epochs):    np.random.shuffle(data)    for batch in get_batches(data, batch_size=50):        params_grad = evaluate_gradient(loss_function, batch, params)        params = params - learning_rate * params_grad</code></pre><h3 id="3-挑战"><a href="#3-挑战" class="headerlink" title="3 挑战"></a><strong>3 挑战</strong></h3><p>虽然Vanilla小批量梯度下降法并不能保证较好的收敛性，但是需要强调的是，这也给我们留下了如下的一些挑战：</p><p>选择一个合适的学习率可能是困难的。学习率太小会导致收敛的速度很慢，学习率太大会妨碍收敛，导致损失函数在最小值附近波动甚至偏离最小值。<br>学习率调整[17]试图在训练的过程中通过例如退火的方法调整学习率，即根据预定义的策略或者当相邻两代之间的下降值小于某个阈值时减小学习率。然而，策略和阈值需要预先设定好，因此无法适应数据集的特点[4]。<br>此外，对所有的参数更新使用同样的学习率。如果数据是稀疏的，同时，特征的频率差异很大时，我们也许不想以同样的学习率更新所有的参数，对于出现次数较少的特征，我们对其执行更大的学习率。<br>高度非凸误差函数普遍出现在神经网络中，在优化这类函数时，另一个关键的挑战是使函数避免陷入无数次优的局部最小值。Dauphin等人[5]指出出现这种困难实际上并不是来自局部最小值，而是来自鞍点，即那些在一个维度上是递增的，而在另一个维度上是递减的。这些鞍点通常被具有相同误差的点包围，因为在任意维度上的梯度都近似为0，所以SGD很难从这些鞍点中逃开。</p><h3 id="4-梯度下降优化算法"><a href="#4-梯度下降优化算法" class="headerlink" title="4 梯度下降优化算法"></a><strong>4 梯度下降优化算法</strong></h3><p>下面，我们将列举一些算法，这些算法被深度学习社区广泛用来处理前面提到的挑战。我们不会讨论在实际中不适合在高维数据集中计算的算法，例如诸如牛顿法的二阶方法。</p><h4 id="4-1-动量法"><a href="#4-1-动量法" class="headerlink" title="4.1 动量法"></a><strong>4.1 动量法</strong></h4><p>SGD很难通过陡谷，即在一个维度上的表面弯曲程度远大于其他维度的区域[19]，这种情况通常出现在局部最优点附近。在这种情况下，SGD摇摆地通过陡谷的斜坡，同时，沿着底部到局部最优点的路径上只是缓慢地前进，这个过程如图2a所示。</p><p><img src="https://i.postimg.cc/FKBBnQdn/optimizer-02.jpg" alt="optimizer-02.jpg"></p><p>如图2b所示，动量法[16]是一种帮助SGD在相关方向上加速并抑制摇摆的一种方法。动量法将历史步长的更新向量的一个分量$\gamma$增加到当前的更新向量中（部分实现中交换了公式中的符号）</p><script type="math/tex; mode=display">v_t = \gamma v_{t-1} + \eta \triangledown_{\theta}J(\theta) \\\theta = \theta - v_t</script><p>动量项$\gamma$通常设置为0.9或者类似的值。</p><p>从本质上说，动量法，就像我们从山上推下一个球，球在滚下来的过程中累积动量，变得越来越快（直到达到终极速度，如果有空气阻力的存在，则$\gamma&lt;1$）。同样的事情也发生在参数的更新过程中：对于在梯度点处具有相同的方向的维度，其动量项增大，对于在梯度点处改变方向的维度，其动量项减小。因此，我们可以得到更快的收敛速度，同时可以减少摇摆。</p><h4 id="4-2-Nesterov加速梯度下降法"><a href="#4-2-Nesterov加速梯度下降法" class="headerlink" title="4.2 Nesterov加速梯度下降法"></a><strong>4.2 Nesterov加速梯度下降法</strong></h4><p>然而，球从山上滚下的时候，盲目地沿着斜率方向，往往并不能令人满意。我们希望有一个智能的球，这个球能够知道它将要去哪，以至于在重新遇到斜率上升时能够知道减速。</p><p>Nesterov加速梯度下降法（Nesterov accelerated gradient，NAG）[13]是一种能够给动量项这样的预知能力的方法。我们知道，我们利用动量项$\gamma v_{t-1}$来更新参数θ。通过计算$\theta - \gamma v_{t-1}$能够告诉我们参数未来位置的一个近似值（梯度并不是完全更新），这也就是告诉我们参数大致将变为多少。通过计算关于参数未来的近似位置的梯度，而不是关于当前的参数$\theta$的梯度，我们可以高效的求解 ：</p><script type="math/tex; mode=display">v_t = \gamma v_{t-1} + \eta \triangledown_{\theta}J(\theta - \gamma v_{t-1}) \\\theta = \theta - v_t</script><p>同时，我们设置动量项$\gamma$大约为0.9。动量法首先计算当前的梯度值（图3中的小的蓝色向量），然后在更新的累积梯度（大的蓝色向量）方向上前进一大步，Nesterov加速梯度下降法NAG首先在先前累积梯度（棕色的向量）方向上前进一大步，计算梯度值，然后做一个修正（绿色的向量）。这个具有预见性的更新防止我们前进得太快，同时增强了算法的响应能力，这一点在很多的任务中对于RNN的性能提升有着重要的意义[2]。</p><p><img src="https://i.postimg.cc/8C5YHC56/optimizer-03.jpg" alt="optimizer-03.jpg"></p><p>对于NAG的直观理解的另一种解释可以参见<a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">此处资料</a>，同时Ilya Sutskever在其博士论文[18]中给出更详细的综述。</p><p>既然我们能够使得我们的更新适应误差函数的斜率以相应地加速SGD，我们同样也想要使得我们的更新能够适应每一个单独参数，以根据每个参数的重要性决定大的或者小的更新。</p><h4 id="4-3-Adagrad"><a href="#4-3-Adagrad" class="headerlink" title="4.3 Adagrad"></a><strong>4.3 Adagrad</strong></h4><p>Adagrad[7]是这样的一种基于梯度的优化算法：让学习率适应参数，对于出现次数较少的特征，我们对其采用更大的学习率，对于出现次数较多的特征，我们对其采用较小的学习率。因此，Adagrad非常适合处理稀疏数据。Dean等人[6]发现Adagrad能够极大提高了SGD的鲁棒性并将其应用于Google的大规模神经网络的训练，其中包含了YouTube视频中的猫的识别。此外，Pennington等人[15]利用Adagrad训练Glove词向量，因为低频词比高频词需要更大的步长。</p><p>前面，我们每次更新所有的参数$\theta$时，每一个参数$\theta_i$都使用的是相同的学习率$\eta$。由于Adagrad在t时刻对每一个参数$\theta_i$使用了不同的学习率，我们首先介绍Adagrad对每一个参数的更新，然后我们对其向量化。为了简洁，令$g_{t,i}$为在t时刻目标函数关于参数$\theta_i$的梯度：</p><script type="math/tex; mode=display">g_{t,i} = \triangledown_{\theta}J(\theta_i)</script><p>在t时刻，对每个参数$\theta_i$的更新过程变为：</p><script type="math/tex; mode=display">\theta_{t+1,i} = \theta_{t,i} - \eta \cdot g_{t,i}</script><p>对于上述的更新规则，在t时刻，基于对$\theta_i$计算过的历史梯度，Adagrad修正了对每一个参数$\theta_i$的学习率：</p><script type="math/tex; mode=display">\theta_{t+1,i} = \theta_{t,i} - \frac{\eta}{\sqrt{G_{t,ii} + \epsilon}} \cdot g_{t,i}</script><p>其中，$G_t \in \mathbb R^{d \times d}$是一个对角矩阵，对角线上的元素i,i是直到t时刻为止，所有关于$\theta_i$的梯度的平方和（Duchi等人[7]将该矩阵作为包含所有先前梯度的外积的完整矩阵的替代，因为即使是对于中等数量的参数d，矩阵的均方根的计算都是不切实际的。），$\是平滑项，用于防止除数为0（通常大约设置为1e−8）。<strong>比较有意思的是，如果没有平方根的操作，算法的效果会变得很差。</strong></p><p>由于$G_t$的对角线上包含了关于所有参数θ的历史梯度的平方和，现在，我们可以通过$G_t$和$g_t$之间的元素向量乘法$\odot$向量化上述的操作：</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \odot g_t</script><p>Adagrad算法的一个主要优点是无需手动调整学习率。在大多数的应用场景中，通常采用常数0.01。</p><p>Adagrad的一个主要缺点是它在分母中累加梯度的平方：由于没增加一个正项，在整个训练过程中，累加的和会持续增长。这会导致学习率变小以至于最终变得无限小，在学习率无限小时，Adagrad算法将无法取得额外的信息。接下来的算法旨在解决这个不足。</p><h4 id="4-4-Adadelta"><a href="#4-4-Adadelta" class="headerlink" title="4.4 Adadelta"></a><strong>4.4 Adadelta</strong></h4><p>Adadelta[21]是Adagrad的一种扩展算法，以处理Adagrad学习速率单调递减的问题。不是计算所有的梯度平方，Adadelta将计算计算历史梯度的窗口大小限制为一个固定值w。</p><p>在Adadelta中，无需存储先前的w个平方梯度，而是将梯度的平方递归地表示成所有历史梯度平方的均值。在t时刻的均值$E[g^2]_t$只取决于先前的均值和当前的梯度（分量$\gamma$类似于动量项）：</p><script type="math/tex; mode=display">E[g^2]_t = \gamma E[g^2]_{t-1} + (1-\gamma)g_t^2</script><p>我们将$\gamma$设置成与动量项相似的值，即0.9左右。为了简单起见，我们利用参数更新向量$\Delta \theta_t$重新表示SGD的更新过程：</p><script type="math/tex; mode=display">\Delta \theta_t = - \eta \cdot g_{t,i} \\\theta_{t+1} = \theta_t + \Delta \theta_t</script><p>我们先前得到的Adagrad参数更新向量变为：</p><script type="math/tex; mode=display">\Delta \theta_t = -\frac{\eta}{\sqrt{G_t +\epsilon}} \odot g_t</script><p>现在，我们简单将对角矩阵$G_t$替换成历史梯度的均值$E[g^2]_t$：</p><script type="math/tex; mode=display">\Delta \theta_t = - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}}g_t</script><p>由于分母仅仅是梯度的均方根（root mean squared，RMS）误差，我们可以简写为：</p><script type="math/tex; mode=display">\Delta \theta_t = - \frac{\eta}{RMS|g|_t}g_t</script><p>作者指出上述更新公式中的每个部分（与SGD，动量法或者Adagrad）并不一致，即更新规则中必须与参数具有相同的假设单位。为了实现这个要求，作者首次定义了另一个指数衰减均值，这次不是梯度平方，而是参数的平方的更新：</p><script type="math/tex; mode=display">E[\Delta \theta^2]_t = \gamma E[\Delta \theta^2]_{t-1} +(1-\gamma) \Delta \theta^2_t</script><p>因此，参数更新的均方根误差为：</p><script type="math/tex; mode=display">RMS[\Delta \theta]_t = \sqrt{E[\Delta \theta^2]_t + \epsilon}</script><p>由于$RMS[\Delta \theta]_t$是未知的，我们利用参数的均方根误差来近似更新。利用$RMS[\Delta \theta]_{t−1}$替换先前的更新规则中的学习率$\eta$，最终得到Adadelta的更新规则：</p><script type="math/tex; mode=display">\Delta \theta_t = - \frac{RMS[\theta]_{t−1}}{RMS|g|_t} g_t \\\theta_{t+1} = \theta_t +\Delta \theta_t</script><p>使用Adadelta算法，我们甚至都无需设置默认的学习率，因为更新规则中已经移除了学习率。</p><h4 id="4-5-RMSprop"><a href="#4-5-RMSprop" class="headerlink" title="4.5 RMSprop"></a><strong>4.5 RMSprop</strong></h4><p>RMSprop是一个未被发表的自适应学习率的算法，该算法由Geoff Hinton在其<a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" target="_blank" rel="noopener">Coursera课堂的课程6e</a>中提出。</p><p>RMSprop和Adadelta在相同的时间里被独立的提出，都起源于对Adagrad的极速递减的学习率问题的求解。实际上，RMSprop是先前我们得到的Adadelta的第一个更新向量的特例：</p><script type="math/tex; mode=display">E[g^2]_t = 0.9 E[g^2]_{t-1} + 0.1 g^2_t \\\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t</script><p>同样，RMSprop将学习率分解成一个平方梯度的指数衰减的平均。Hinton建议将$\gamma$设置为0.9，对于学习率$\eta$，一个好的固定值为0.001。</p><h4 id="4-6-Adam"><a href="#4-6-Adam" class="headerlink" title="4.6 Adam"></a><strong>4.6 Adam</strong></h4><p>自适应矩估计（Adaptive Moment Estimation，Adam）[9]是另一种自适应学习率的算法，Adam对每一个参数都计算自适应的学习率。除了像Adadelta和RMSprop一样存储一个指数衰减的历史平方梯度的平均$v_t$，Adam同时还保存一个历史梯度的指数衰减均值$m_t$，类似于动量：</p><script type="math/tex; mode=display">m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t \\v_t = \beta_2 v_{t-1} + (1-\beta_2) g^2_t</script><p>$m_t$和$v_t$分别是对梯度的一阶矩（均值）和二阶矩（非确定的方差）的估计，正如该算法的名称。当$m_t$和$v_t$初始化为0向量时，Adam的作者发现它们都偏向于0，尤其是在初始化的步骤和当衰减率很小的时候（例如$\beta_1$和$\beta_2$趋向于1）。</p><p>通过计算偏差校正的一阶矩和二阶矩估计来抵消偏差：</p><script type="math/tex; mode=display">\hat m_t = \frac{m_t}{1-\beta_1^t} \\\hat v_t = \frac{v_t}{1-\beta_2^t}</script><p>正如我们在Adadelta和RMSprop中看到的那样，他们利用上述的公式更新参数，由此生成了Adam的更新规则：</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat v_t} + \epsilon} \hat m_t</script><p>作者建议$\beta_1$取默认值为0.9，$\beta_2$为0.999，$\epsilon$为10−8。他们从经验上表明Adam在实际中表现很好，同时，与其他的自适应学习算法相比，其更有优势。</p><h4 id="4-7-算法可视化"><a href="#4-7-算法可视化" class="headerlink" title="4.7 算法可视化"></a><strong>4.7 算法可视化</strong></h4><p>下面两张图给出了上述优化算法的优化行为的直观理解。（还可以看看这里关于Karpathy对相同的图片的描述以及另一个简明关于算法讨论的概述）。</p><p>在图4a中，我们看到不同算法在损失曲面的等高线上走的不同路线。所有的算法都是从同一个点出发并选择不同路径到达最优点。注意：Adagrad，Adadelta和RMSprop能够立即转移到正确的移动方向上并以类似的速度收敛，而动量法和NAG会导致偏离，想像一下球从山上滚下的画面。然而，NAG能够在偏离之后快速修正其路线，因为NAG通过对最优点的预见增强其响应能力。</p><p>图4b中展示了不同算法在鞍点出的行为，鞍点即为一个点在一个维度上的斜率为正，而在其他维度上的斜率为负，正如我们前面提及的，鞍点对SGD的训练造成很大困难。这里注意，SGD，动量法和NAG在鞍点处很难打破对称性，尽管后面两个算法最终设法逃离了鞍点。而Adagrad，RMSprop和Adadelta能够快速想着梯度为负的方向移动，其中Adadelta走在最前面。</p><p><img src="https://i.postimg.cc/dtYSf63v/optimizers-04.gif" alt="optimizers-04.gif"><img src="https://i.postimg.cc/rsSZm0hv/optimizers-05.gif" alt="optimizers-05.gif"></p><p>正如我们所看到的，自适应学习速率的方法，即 Adagrad、 Adadelta、 RMSprop 和Adam，最适合这些场景下最合适，并在这些场景下得到最好的收敛性。</p><h4 id="4-8-选择使用哪种优化算法？"><a href="#4-8-选择使用哪种优化算法？" class="headerlink" title="4.8 选择使用哪种优化算法？"></a><strong>4.8 选择使用哪种优化算法？</strong></h4><p>那么，我们应该选择使用哪种优化算法呢？如果输入数据是稀疏的，选择任一自适应学习率算法可能会得到最好的结果。选用这类算法的另一个好处是无需调整学习率，选用默认值就可能达到最好的结果。</p><p>总的来说，RMSprop是Adagrad的扩展形式，用于处理在Adagrad中急速递减的学习率。RMSprop与Adadelta相同，所不同的是Adadelta在更新规则中使用参数的均方根进行更新。最后，Adam是将偏差校正和动量加入到RMSprop中。在这样的情况下，RMSprop、Adadelta和Adam是很相似的算法并且在相似的环境中性能都不错。Kingma等人[9]指出在优化后期由于梯度变得越来越稀疏，偏差校正能够帮助Adam微弱地胜过RMSprop。综合看来，Adam可能是最佳的选择。</p><p>有趣的是，最近许多论文中采用不带动量的SGD和一种简单的学习率的退火策略。已表明，通常SGD能够找到最小值点，但是比其他优化的SGD花费更多的时间，与其他算法相比，SGD更加依赖鲁棒的初始化和退火策略，同时，SGD可能会陷入鞍点，而不是局部极小值点。因此，如果你关心的是快速收敛和训练一个深层的或者复杂的神经网络，你应该选择一个自适应学习率的方法。</p><h3 id="5-并行和分布式SGD"><a href="#5-并行和分布式SGD" class="headerlink" title="5 并行和分布式SGD"></a><strong>5 并行和分布式SGD</strong></h3><p>当存在大量的大规模数据和廉价的集群时，利用分布式SGD来加速是一个显然的选择。SGD本身有固有的顺序：一步一步，我们进一步进展到最小。SGD提供了良好的收敛性，但SGD的运行缓慢，特别是对于大型数据集。相反，SGD异步运行速度更快，但客户端之间非最理想的通信会导致差的收敛。此外，我们也可以在一台机器上并行SGD，这样就无需大的计算集群。以下是已经提出的优化的并行和分布式的SGD的算法和框架。</p><h4 id="5-1-Hogwild"><a href="#5-1-Hogwild" class="headerlink" title="5.1 Hogwild!"></a><strong>5.1 Hogwild!</strong></h4><p>Niu等人[14]提出称为Hogwild!的更新机制，Hogwild!允许在多个CPU上并行执行SGD更新。在无需对参数加锁的情况下，处理器可以访问共享的内存。这种方法只适用于稀疏的输入数据，因为每一次更新只会修改一部分参数。在这种情况下，该更新策略几乎可以达到一个最优的收敛速率，因为CPU之间不可能重写有用的信息。</p><h4 id="5-2-Downpour-SGD"><a href="#5-2-Downpour-SGD" class="headerlink" title="5.2 Downpour SGD"></a><strong>5.2 Downpour SGD</strong></h4><p>Downpour SGD是SGD的一种异步的变形形式，在Google，Dean等人[6]在他们的DistBelief框架（TensorFlow的前身）中使用了该方法。Downpour SGD在训练集的子集上并行运行多个模型的副本。这些模型将各自的更新发送给一个参数服务器，参数服务器跨越了多台机器。每一台机器负责存储和更新模型的一部分参数。然而，因为副本之间是彼此不互相通信的，即通过共享权重或者更新，因此可能会导致参数发散而不利于收敛。</p><h4 id="5-3-延迟容忍SGD"><a href="#5-3-延迟容忍SGD" class="headerlink" title="5.3 延迟容忍SGD"></a><strong>5.3 延迟容忍SGD</strong></h4><p>通过容忍延迟算法的开发，McMahan和Streeter[11]将AdaGraad扩展成并行的模式，该方法不仅适应于历史梯度，同时适应于更新延迟。该方法已经在实践中被证实是有效的。</p><h4 id="5-4-TensorFlow"><a href="#5-4-TensorFlow" class="headerlink" title="5.4 TensorFlow"></a><strong>5.4 TensorFlow</strong></h4><p>TensorFlow[1]是Google近期开源的框架，该框架用于实现和部署大规模机器学习模型。TensorFlow是基于DistBelief开发，同时TensorFlow已经在内部用来在大量移动设备和大规模分布式系统的执行计算。在2016年4月发布的分布式版本依赖于图计算，图计算即是对每一个设备将图划分成多个子图，同时，通过发送、接收节点对完成节点之间的通信。</p><h4 id="5-5-弹性平均SGD"><a href="#5-5-弹性平均SGD" class="headerlink" title="5.5 弹性平均SGD"></a><strong>5.5 弹性平均SGD</strong></h4><p>Zhang等人[22]提出的弹性平均SGD（Elastic Averaging SGD，EASGD）连接了异步SGD的参数客户端和一个弹性力，即参数服务器存储的一个中心变量。EASGD使得局部变量能够从中心变量震荡得更远，这在理论上使得在参数空间中能够得到更多的探索。经验表明这种增强的探索能力通过发现新的局部最优点，能够提高整体的性能。</p><h3 id="6-优化SGD的其他策略"><a href="#6-优化SGD的其他策略" class="headerlink" title="6 优化SGD的其他策略"></a><strong>6 优化SGD的其他策略</strong></h3><p>最后，我们介绍可以与前面提及到的任一算法配合使用的其他的一些策略，以进一步提高SGD的性能。对于其他的一些常用技巧的概述可以参见[10]。</p><h4 id="6-1-数据集的洗牌和课程学习"><a href="#6-1-数据集的洗牌和课程学习" class="headerlink" title="6.1 数据集的洗牌和课程学习"></a><strong>6.1 数据集的洗牌和课程学习</strong></h4><p>总的来说，我们希望避免向我们的模型中以一定意义的顺序提供训练数据，因为这样会使得优化算法产生偏差。因此，在每一轮迭代后对训练数据洗牌是一个不错的主意。</p><p>另一方面，在很多情况下，我们是逐步解决问题的，而将训练集按照某个有意义的顺序排列会提高模型的性能和SGD的收敛性，如何将训练集建立一个有意义的排列被称为课程学习[3]。</p><p>Zaremba and Sutskever[20]只能使用课程学习训练LSTM来评估简单程序，并表明组合或混合策略比单一的策略更好，通过增加难度来排列示例。</p><h4 id="6-2-批量归一化"><a href="#6-2-批量归一化" class="headerlink" title="6.2 批量归一化"></a><strong>6.2 批量归一化</strong></h4><p>为了便于学习，我们通常用0均值和单位方差初始化我们的参数的初始值来归一化。 随着不断训练，参数得到不同的程度的更新，我们失去了这种归一化，随着网络变得越来越深，这种现象会降低训练速度，且放大参数变化。</p><p>批量归一化[8]在每次小批量数据反向传播之后重新对参数进行0均值单位方差标准化。通过将模型架构的一部分归一化，我们能够使用更高的学习率，更少关注初始化参数。批量归一化还充当正则化的作用，减少（有时甚至消除）Dropout的必要性。</p><h4 id="6-3-Early-stopping"><a href="#6-3-Early-stopping" class="headerlink" title="6.3 Early stopping"></a><strong>6.3 Early stopping</strong></h4><p>如Geoff Hinton所说：“Early Stopping是美丽好免费午餐”（NIPS 2015 Tutorial slides）。你因此必须在训练的过程中时常在验证集上监测误差，在验证集上如果损失函数不再显著地降低，那么应该提前结束训练。</p><h4 id="6-4-梯度噪音"><a href="#6-4-梯度噪音" class="headerlink" title="6.4 梯度噪音"></a><strong>6.4 梯度噪音</strong></h4><p>Neelakantan等人[12]在每个梯度更新中增加满足高斯分布$N(0,\sigma^2_t)$的噪音：</p><script type="math/tex; mode=display">g_{t,i} = g_{t,i} + N(0,\sigma^2_t)</script><p>高斯分布的方差需要根据如下的策略退火：</p><script type="math/tex; mode=display">\sigma_t^2 = \frac{\eta}{(1+t)^\gamma}</script><p>他们指出增加了噪音，使得网络对不好的初始化更加鲁棒，同时对深层的和复杂的网络的训练特别有益。他们猜测增加的噪音使得模型更优机会逃离当前的局部最优点，以发现新的局部最优点，这在更深层的模型中更加常见。</p><h3 id="7-总结"><a href="#7-总结" class="headerlink" title="7 总结"></a><strong>7 总结</strong></h3><p>在这篇博客文章中，我们初步研究了梯度下降的三个变形形式，其中，小批量梯度下降是最受欢迎的。 然后我们研究了最常用于优化SGD的算法：动量法，Nesterov加速梯度，Adagrad，Adadelta，RMSprop，Adam以及不同的优化异步SGD的算法。 最后，我们已经考虑其他一些改善SGD的策略，如洗牌和课程学习，批量归一化和early stopping。</p><p><a href="https://blog.csdn.net/google19890102/article/details/69942970" target="_blank" rel="noopener">参考博文：梯度下降优化算法综述-zhiyong_will</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://ruder.io/optimizing-gradient-descent/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：An overview of gradient descent optimization algorithms&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;梯度下降优化算法综述&quot;&gt;&lt;a href=&quot;#梯度下降优化算法综述&quot; class=&quot;headerlink&quot; title=&quot;梯度下降优化算法综述&quot;&gt;&lt;/a&gt;梯度下降优化算法综述&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;虽然梯度下降优化算法越来越受欢迎，但通常作为黑盒优化器使用，因此很难对其优点和缺点的进行实际的解释。本文旨在让读者对不同的算法有直观的认识，以帮助读者使用这些算法。在本综述中，我们介绍梯度下降的不同变形形式，总结这些算法面临的挑战，介绍最常用的优化算法，回顾并行和分布式架构，以及调研用于优化梯度下降的其他的策略。&lt;/p&gt;
&lt;h3 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;&lt;strong&gt;1 引言&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;梯度下降法是最著名的优化算法之一，也是迄今优化神经网络时最常用的方法。同时，在每一个最新的深度学习库中都包含了各种优化的梯度下降法的实现（例如：参见lasagne，caffe和keras的文档）。然而，这些算法通常是作为黑盒优化器使用，因此，很难对其优点和缺点的进行实际的解释。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法" scheme="http://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="Gradient Descent" scheme="http://www.xiemingzhao.com/tags/Gradient-Descent/"/>
    
      <category term="Optimization" scheme="http://www.xiemingzhao.com/tags/Optimization/"/>
    
  </entry>
  
  <entry>
    <title>XGBoost- A Scalable Tree Boosting System</title>
    <link href="http://www.xiemingzhao.com/2019/06/10/XGBoost-%20A%20Scalable%20Tree%20Boosting%20System--%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.xiemingzhao.com/2019/06/10/XGBoost- A Scalable Tree Boosting System--学习笔记/</id>
    <published>2019-06-09T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:45.468Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://delivery.acm.org/10.1145/2940000/2939785/p785-chen.pdf?" target="_blank" rel="noopener">原始论文：XGBoost: A Scalable Tree Boosting System</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Tree boosting 是一个高效的并且广泛应用的机器学习方法。在本文中，我们会介绍一个可扩展的端到端的 tree boosting 系统，它叫 XGBoost，它被数据科学家广泛地应用，并且在许多机器学习挑战取得了最好的结果。对于稀疏数据我们提出了稀疏性感知算法，以及加权分位数梗概用来近似树模型学习。更重要的是，我们提供了对缓存访问模式，数据压缩和分片的见解来建立一个可扩展的提升树系统。通过综合这些看法， XGBoost 只需要使用比现有系统少得多的资源就可以扩展出超过数十亿的实例。</p><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>大规模机器学习</p><a id="more"></a><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h2><p>机器学习和数据驱动的方法在许多领域变得非常重要。智能垃圾邮件分类器通过从大量垃圾邮件数据和用户反馈中学习来如何保护我们免受垃圾邮件的侵害；广告系统学会将正确的广告放到正确的语境中；欺诈检测系统保护银行免受恶意攻击者的攻击；异常现象检测系统帮助实验物理学家发现引发新物理现象的因素。驱动这些技术成功应用的因素有两个：使用能够发现复杂数据依赖性的有效的（统计）模型，以及能从大型数据集里学习获得偏好模型的可扩展的学习系统。</p><p>在机器学习算法的实践应用中，梯度提升树算法非常卓越。提升树在很多标准分类基准上表现非常出色。LambdaMART是提升树算法的变种，在排序任务中也表现出了不错的效果。XGBoost除了被用作单独的预测器，还被用于实际的广告点击率的问题中。它是集成算法的一种，也经常用于Netfix等竞赛。</p><p>在本文中，我们描述了XGBoost，一种针对提升树的可扩展的机器学习系统。该系统有开源的软件包可用。该系统的影响已经在许多机器学习和数据挖掘任务重得到认可。以机器学习竞赛网站kaggle为例。2015年，kaggle的博客上发布了29个挑战获胜的解决方案，其中17个解决方案用了XGBoost。在这些解决方案中，8个只用了XGBoost来训练模型，而大多数其他解决方案将XGBoost与神经网络进行了结合。第二种常用的方法是深度神经网络，出现在了11个解决方案中。KDDCup2015也证明了该系统的成功，其中前10名的队伍都用了XGBoost。此外，获胜团队表示，集成算法的效果仅仅比XGBoost略优一点。</p><p>这些结果表明，我们的系统在各种问题中表现都非常优异。这些获胜的解决方案涉及到的问题有：商店销量预测；高能物理事件分类；网络文本分类；顾客行为预测；运动检测；广告点击率预测；恶意软件识别；产品分类；风险预测；在线课程辍学率预测；虽然数据分析和特征工程在其中发挥了重要作用，但大家都选择XGBoost算法也是一个事实，这表明了我们的系统和提升树的影响和重要性。</p><p>XGBoost成功的重要因素是它可以扩展到所有场景中。该系统在单台机器上的运行速度比现有流行的解决方案快10倍以上，并可在分布式或内存有限的环境中扩展到数十亿个示例。XGBoost的可扩展性归功于几个重要的系统和算法优化。这些创新包括：一种用于稀疏数据的树学习算法；加权分位数草图能够在近似树学习中处理样本的权重，这在理论上是合理的。并行和分布式计算使得学习速度更快，从而加快了模型的探索。更重要的是，XGBoost利用外核计算，使数据科学家能够在桌面上处理数十亿个示例。最后，更令人兴奋的是，将这些技术结合起来，利用端对端系统以最少的集群资源将其扩展到更大的数据规模。本文主要贡献如下：</p><ul><li>我们设计并构建了一个高度扩展的端对端的提升树系统</li><li>我们提出了一个用于高效运算的理论上正确的加权分位数草图</li><li>我们为并行树模型学习提出了一种新颖的稀疏感知算法</li><li>我们提出了一种有效的缓存感知块结构用于树模型的核外学习</li></ul><p>虽然现在存在一些并行提升树模型的研究工作，但核外计算、缓存感知和稀疏感知学习等方向还尚未有人涉略。更重要的是，结合这些方面的技术构建出的端对端的系统为实际应用提供了一种新的解决方案。这使得数据科学家和研究人员能够构建提升树算法的强大变种。除了这些主要的贡献之外，我们还提出了一个正则化学习的方法。</p><p>本文其余的部分安排如下。第二部分我们回顾了提升树，并介绍了正则化的目标。然后，我们在第三部分介绍分割节点寻找的方法，第四部分是系统设计，包括相关的实验结果，为我们提到的每个优化方法提供量化支持。相关工作放在在第五节讨论。第六部分详细的介绍了端对端的评估。最后，我们在第七部分总结这篇论文。</p><h2 id="2-提升树简介"><a href="#2-提升树简介" class="headerlink" title="2.提升树简介"></a>2.提升树简介</h2><p>我们在这一节中介绍梯度提升树算法。公式推导遵循文献中的梯度提升思想。特别地，其中的二阶方法源自Friedman等人。我们对正则项进行了微小的改进，这在实践中有所帮助。</p><p><img src="https://i.postimg.cc/2ywczj7k/xgb-1.jpg" alt="xgb-1.jpg"></p><h3 id="2-1-正则化学习目标"><a href="#2-1-正则化学习目标" class="headerlink" title="2.1 正则化学习目标"></a>2.1 正则化学习目标</h3><p>对于一个给定的数据集有n个样本和m个特征$\mathcal D={(x_i,y_i)}(|\mathcal D|=n,x_i \in \mathbb R^m,y_i \in \mathbb R)$，树集成算法使用个数为K的加法模型（如图1）来预测输出。</p><script type="math/tex; mode=display">\hat y_i = \phi(x_i) = \sum_{k=1}^k F_k (x_i), f_k \in \mathcal F</script><p>其中$\mathcal F = {f(x) = w_{q(x)}}(q: \mathbb R^m \rightarrow T, w \in \mathbb R^T)$是回归树（也叫做CART）的空间。$q$表示将样本映射到叶节点的树的结构。$T$是每棵树叶子的数量。每个$F_k$对应了独立的树结构$q$和叶权值$w$。与决策树不同，每棵回归树的每个叶子上包含连续的连续值打分，我们用$w_i$表示第$i$个叶子的打分。对于一个给定的例子，我们将使用树中的决策规则（由$q$给出）将其分类到叶子节点中，并通过对相应叶子中的分数求和来计算最终预测（由$w$给出）。为了学习模型中使用的函数集合，我们最小化下面的正则化的项。</p><script type="math/tex; mode=display">\mathcal L(\phi) = \sum_i l(\hat y_i, y_i) + \sum_k \Omega(f_k)</script><script type="math/tex; mode=display">where \Omega(f) = \gamma T + \frac{1}{2} \lambda ||w||^2</script><p>这里$L$是一个可微的凸损失函数，它表示预测$y_i$和目标$y$之间的差值。第二项$\Omega$是惩罚项，惩罚模型的复杂度（即回归树模型）。附加正则化项会有助于使最终学习到的权值更加平滑，避免过拟合。直观地说，带有正则化的目标函数倾向于选择简单的预测模型。类似的正则化技术已被用于正则化贪心森林算法（RGF）模型中。我们的目标函数和相应的学习算法比RGF更简单，更容易实现并行化。当正则化参数被设置为零时，目标函数退化为传统的梯度提升树。</p><h3 id="2-2-梯度提升树"><a href="#2-2-梯度提升树" class="headerlink" title="2.2 梯度提升树"></a>2.2 梯度提升树</h3><p>公式（2）中的树集成模型中包含函数作为参数的情况，不能使用欧氏空间中的传统优化方法来优化。替代的方法是模型以累加的方式训练。形式上,$\hat y_i^{(t)}$是第$t$次迭代中第$i$个实例的预测，我们把$f_t$加到下面的最小化目标中。</p><script type="math/tex; mode=display">\mathcal L^{(t)} = \sum_{t=1}^n l(y_i,\hat y_i^{(t-1)} + f_t(x_i)) + \Omega(f_t)</script><p>这意味着我们根据公式（2）贪婪地将$f_t$加到了目标函数中，这对我们模型提升最大（因为是沿梯度下降的）。一般情况下，二阶近似（泰勒二阶展开近似）可以用于快速优化目标函数。（因为有二阶信息，所以优化起来比一阶速度快。例如，牛顿法就比传统的梯度下降快）。</p><script type="math/tex; mode=display">\mathcal L^{(t)} \simeq \sum_{t=1}^n [l(y_i,\hat y_i^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t)</script><p>其中，$g_i = \partial_{\hat y^{(t-1)}} l(y_i,\hat y_i^{(t-1)})$和$h_i = \partial_{\hat y^{(t-1)}}^2 l(y_i,\hat y_i^{(t-1)})$，分别为损失函数一阶和二阶的梯度值。在第$t$步迭代中，我们可以去掉常数项以简化目标函数。（t步的时候t-1步的损失已经是定值）</p><script type="math/tex; mode=display">\tilde{\mathcal L}^{(t)} \simeq \sum_{t=1}^n [g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t)</script><p>定义$I_j = {i|q(x_i)=j}$为叶子结点j里面的样本，我们可以通过扩展$\Omega$来重写公式（3）：</p><script type="math/tex; mode=display">\tilde{\mathcal L}^{(t)} = \sum_{t=1}^n [g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T w_j^2 \\=\sum_{j=1}^T[(\sum_{i \in I_j} g_i) w_j + \frac{1}{2}(\sum_{i \in I_j} h_i + \lambda) w_j^2] + \gamma T</script><p>对于一个固定的结构$q(x)$，我们可以计算叶子结点$j$的最优权重$w_j^*$：</p><script type="math/tex; mode=display">w_j^* = -\frac{\sum_{i \in I_j} g_i} {\sum_{i \in I_j} h_i + \lambda}</script><p>并通过下式计算相应的最优值：</p><script type="math/tex; mode=display">\tilde{\mathcal{L}}^{(t)}(q)=-\frac{1}{2} \sum_{j=1}^{T} \frac{\left(\sum_{i \in I_{j}} g_{i}\right)^{2}}{\sum_{i \in I_{j}} h_{i}+\lambda}+\gamma T</script><p>公式（6）可以作为一个评估方程去评价一棵树的结构$q$。这个打分就像评估决策树的杂质分数，不同的是它是为了更广泛的目标函数导出的。图2示出了如何计算这个分数。</p><p><img src="https://i.postimg.cc/bNmCWJvL/xgb-2.jpg" alt="xgb-2.jpg"></p><p>通常来说不可能枚举出所有的树结构$q$，而是用贪心算法，从一个叶子开始分裂，反复给树添加分支。假设$I_L$和$I_R$ 是分裂后左右节点中包含的样本集合。使$I＝I_L \cup I_R$，通过下式分裂后会使损失函数降低。</p><script type="math/tex; mode=display">\mathcal{L}_{\text {split}}=\frac{1}{2}\left[\frac{\left(\sum_{i \in I_{L}} g_{i}\right)^{2}}{\sum_{i \in I_{L}} h_{i}+\lambda}+\frac{\left(\sum_{i \in I_{R}} g_{i}\right)^{2}}{\sum_{i \in I_{R}} h_{i}+\lambda}-\frac{\left(\sum_{i \in I} g_{i}\right)^{2}}{\sum_{i \in I} h_{i}+\lambda}\right]-\gamma</script><p>这个公式用于评价候选分裂节点的好坏。</p><h3 id="2-3-收缩和列子采样"><a href="#2-3-收缩和列子采样" class="headerlink" title="2.3 收缩和列子采样"></a>2.3 收缩和列子采样</h3><p>除了在2.1节中使用的正则化项，我们还使用了两种技术来进一步防止过拟合。第一种技术是Friedman引入的收缩。在每一次提升树训练迭代后，在前面乘一个因子$η$来收缩其权重（也就是我们说的学习率，或者叫步长）。与随机优化中的学习率类似，收缩减少了每棵树的影响，并为将来的树模型留出了改进模型的空间。第二种技术上列（特征）子采样。这个技术用于随机森林中，在商业软件TreeNet4中实现，用于梯度增强，但未在现有的开源包中实现。根据用户反馈，使用列子采样可以比传统的行子采样（也支持）更能防止过度采样。列子采样还能加速稍后描述的并行算法。</p><h2 id="3-分裂查找算法"><a href="#3-分裂查找算法" class="headerlink" title="3. 分裂查找算法"></a>3. 分裂查找算法</h2><h3 id="3-1-基准贪婪算法"><a href="#3-1-基准贪婪算法" class="headerlink" title="3.1 基准贪婪算法"></a>3.1 基准贪婪算法</h3><p>树模型学习过程中的一个关键问题是找到最佳分裂节点，如公式（7）所示。为了做到这一点，一个分裂查找算法枚举出了所有特征上的所有可能的分裂节点，我们称之为贪婪算法。大多数现有的单机版本的提升树已经实现了，如scikit-learn、R中的GBM以及XGBoost的单机版本。在Alg.1中给出贪婪算法的详细描述。算法要求列举出所有特征的所有可能的分割点。为了提高效率，算法必须先将特征取值排序，并按顺序访问数据，然后根据公式（7）计算出当前分割点的梯度统计量。</p><p><img src="https://i.postimg.cc/mZN63Vfv/xgb-a1.jpg" alt="xgb-a1.jpg"></p><h3 id="3-2-近似算法"><a href="#3-2-近似算法" class="headerlink" title="3.2 近似算法"></a>3.2 近似算法</h3><p>贪婪算法是非常有效的，因为它贪婪地枚举除了所有可能的分裂点。然而，当数据不能完全读入内存时，这样做就不会很有效率。同样的问题也出现在分布式环境中。为了有效支持这两种环境中的提升树，我们需要一种近似算法。</p><p><img src="https://i.postimg.cc/L5RQKgfQ/xgb-a2.jpg" alt="xgb-a2.jpg"></p><p>我们总结了一个近似框架，类似于在过去的文献中提到的想法「参考文献17、2、22」，如Alg.2描述。总结来说，该算法首先根据特征分布的百分位数提出可能的候选分裂点（具体的准则在3.3中给出）。然后算法将连续特征值映射到候选分割点分割出的箱子中。计算出每个箱子中数据的统计量（这里的统计量指的是公式（7）中的$g$和$h$），然后根据统计量找到最佳的分割点。</p><p>该算法有两种变体，区别为分裂点的准则何时给出。全局选择在树构造的初始阶段要求给出所有候选分裂点，并且在树的所有层中使用相同的分裂节点用于分裂。局部选择在分裂后重新给出分裂候选节点。全局方法比局部方法需要更少的步骤。然而，通常在全局选择中需要更多的候选点，因为在每次分裂后候选节点没有被更新。局部选择在分裂后更新候选节点，并且可能更适合于深度更深的树。图3给出了基于希格斯玻色子数据集的不同算法的比较。我们发现，本地变种确实需要更少的候选人。当给出足够的候选节点，全局变种可以达到与本地变种一样的准确率。（局部选择步骤多的意思就是每分裂一次都需要更新3.3中对应的min(x)和max(x)，相比全局选择来说候选点间隔更细）</p><p>大多数现有的分布式树模型学习的近似算法也遵循这一框架。值得注意的是，直接构造梯度统计量的近似直方图也是可行的。也可以使用分箱策略来代替分位数划分。分位数策略的优点是可分配和可重计算，我们将在下一节中详细说明。从图3中，我们还发现，当设置合理的近似水平，分位数策略可以得到与贪心算法相同的精度。</p><p>我们的系统有效地支持单机版的贪心算法，同时也支持近似算法的本地变种和全球变种的所有设置。用户可以根据需求自由选择。</p><p><img src="https://i.postimg.cc/8PpXZWTj/xgb-3.jpg" alt="xgb-3.jpg"></p><h3 id="3-3-加权分位数梗概"><a href="#3-3-加权分位数梗概" class="headerlink" title="3.3 加权分位数梗概"></a>3.3 加权分位数梗概</h3><p>近似算法中很重要的一步是列出候选的分割点。通常特征的百分位数作为候选分割点的分布会比较均匀。具体来说，设$\mathcal{D}_{k}=\left\{\left(x_{1 k}, h_{1}\right),\left(x_{2 k}, h_{2}\right) \cdots\left(x_{n k}, h_{n}\right)\right\}$表示样本的第$k$个特征的取值和其二阶梯度统计量。我们可以定义一个排序方程$r_{k} : \mathbb{R} \rightarrow[0,+\infty)$：</p><script type="math/tex; mode=display">r_{k}(z)=\frac{1}{\sum_{(x, h) \in \mathcal{D}_{k}} h} \sum_{(x, h) \in \mathcal{D}_{k}, x<z} h</script><p>上式表示样本中第$k$个特征的取值小于$z$的比例（公式表达的是取值小于$z$的二阶梯度统计量的比例）。我们的目标是找到候选的分割节点$\left\{s_{k 1}, s_{k 2}, \cdots s_{k l}\right\}$。</p><script type="math/tex; mode=display">\left|r_{k}\left(s_{k, j}\right)-r_{k}\left(s_{k, j+1}\right)\right|<\epsilon, \quad s_{k 1}=\min_{i} \mathbf{x}_{i k}, s_{k l}=\max_{i} \mathbf{x}_{i k}</script><p>这里$\epsilon$是一个近似因子（就是衡量两者的差距）。直观的说，大概有$\frac{1}{\epsilon}$个分割点（例，如果从0-1之间分割，分割点之间差距小于0.2，那么就是大概有5个分割点）。这里每一个数据点用$h_i$来代表权重。我们来看看为什么$h_i$能代表权重，我们可以把公式（3）重写为：</p><script type="math/tex; mode=display">\sum_{i=1}^{n} \frac{1}{2} h_{i}\left(f_{t}\left(\mathbf{x}_{i}\right)-g_{i} / h_{i}\right)^{2}+\Omega\left(f_{t}\right)+\text {constant}</script><p>这实际上是权值为$h_i$，标签为$g_i/h_i$的加权平方损失。对于大数据集来说，找到满足标准的候选分割点是非常不容易的。当每个实例具有相等的权重时，一个现存的叫分位数草图的算法解决了这个问题。然而，对于加权的数据集没有现存的分位数草图算法。因此，大部分现存的近似算法要么对可能失败的数据的随机子集进行排序，要么使用没有理论保证的启发式算法。</p><p>为了解决这个问题，我们引入了一种新的分布式加权分位数草图算法，该算法可以处理加权数据，并且可以从理论上证明。通常的做法是提出一种支持合并和修建操作的数据结构，每个操作都是可以被证明保持一定准确度的。附录中给出了算法的详细描述以及证明。</p><h3 id="3-4-稀疏性感知分裂查找"><a href="#3-4-稀疏性感知分裂查找" class="headerlink" title="3.4 稀疏性感知分裂查找"></a>3.4 稀疏性感知分裂查找</h3><p>在许多实际问题中，输入$X$稀疏是常见的。稀疏有多个可能的原因导致：<br>1）数据中存在缺失值；<br>2）有些统计数值常常为0；<br>3）特征工程的结果，如one-hot编码。<br>算法对数据中稀疏模式的感知能力是非常重要的。为了做到这一点，我们建议在每个树节点中添加一个默认的方向，如图4所示。当稀疏矩阵$x$中的值丢失时，实例被分类为默认的方向。</p><p><img src="https://i.postimg.cc/VkNTkth3/xgb-4.jpg" alt="xgb-4.jpg"></p><p>在每个分支中有两种默认方向。最优的默认方向是从数据中学习出来的。具体算法在Alg.3显示。关键步骤是只访问非缺失的数据$I_k$。算法将不存在的值视为缺失值并学习默认方向去处理它（这里的不存在的值应该说的是不符合特征意义或者不合理的值）。当非存在的值对应于用户特定说明的值时，可以将枚举结果限制为一致的方案来应用这个算法。</p><p><img src="https://i.postimg.cc/mrv6j5rs/xgb-a3.jpg" alt="xgb-a3.jpg"></p><p>据我们所知，大多数现有的树学习算法要么只对密集数据进行优化，要么需要特定的步骤来处理特殊情况，例如类别编码。XGBoost以统一的方式处理所有稀疏模式。更重要的是，我们的方法利用稀疏性，使得计算的复杂度与输入中的非缺失数据的数量成线性关系。图5显示了稀疏感知算法和一个常规算法在数据集Allstate-10K（此数据集在第6部分描述）上的比较。我们发现稀疏感知算法的运行速度比常规版本快50倍。这证实了稀疏感知算法的重要性。</p><p><img src="https://i.postimg.cc/MprLMT2X/xgb-5.jpg" alt="xgb-5.jpg"></p><h2 id="4-系统设计"><a href="#4-系统设计" class="headerlink" title="4. 系统设计"></a>4. 系统设计</h2><h3 id="4-1-并行学习的列存储"><a href="#4-1-并行学习的列存储" class="headerlink" title="4.1 并行学习的列存储"></a>4.1 并行学习的列存储</h3><p>树学习中最耗时的部分是数据排序。为了减少排序的成本，我们提出将数据存储在内存单元中，称之为block。每个block中的数据每列根据特征取值排序，并以压缩列（CSC）格式储存。这种输入数据布局只需要在训练前计算一次，可以在后续迭代中重复使用。</p><p>在贪婪算法中，我们将整个数据集存储在单个block中，并通过对预排序的数据进行线性扫描来实现分割点搜索。我们集体对所有叶子进行分割查找，这样只需扫描一次block就可以得到所有叶子节点处所有候选分裂节点的统计信息。图6显示了如何将数据集转换成相应格式并使用block结构找到最优分割。</p><p><img src="https://i.postimg.cc/LsYbzp2D/xgb-6.jpg" alt="xgb-6.jpg"></p><p>当使用近似算法时，block结构也非常有用。在这种情况下，可以使用多个block，每个block对应于数据集中的不同的行子集。不同的block可以分布在机器上，或者在非核心设置中存储在磁盘上。使用排序结构，分位数查找步骤在完成排序的列上就变成了线性扫描。这对于在每个分支中频繁更新候选分割点的本地优先算法非常有价值。直方图聚合中的二分搜索也变成了线性时间合并样式算法。</p><p>收集每列统计信息这一步骤可以实现并行化，这也给我们提供了一种寻找分割点的并行算法。还有一点重要的是，列的block结构同样支持列子采样，因为从block结构中选择列子集是非常容易的。</p><p><strong>时间复杂度分析</strong><br>设$d$为树的最大深度，$K$为树的总数。对于贪婪算法，原始稀疏感知算法的时间复杂度为$O(Kd∥x∥_0\log n)$。这里我们使用$||x||_0$来表示训练数据中的非缺失条目的数量。另一方面，在block结构上仅消耗$O(Kd∥x∥_0+∥x∥_0\log n)$。这里$O(x∥_0\log n)$是可以摊销的有一次性预处理成本。该分析表名block结构可以节省额外的logn的复杂度，这在$n$很大时很重要。对于近似算法，基于二分搜索的原始算法的时间复杂度为$O(Kd∥x∥_0\log q)$。这里$q$是数据集中候选分割节点的数量。虽然$q$通常介于32和100之间，但对数因子仍会引入开销。使用block结构，我们可以将之间减少到$O(Kd∥x∥_0+∥x∥_0\log n)$，其中$B$是每个块中的最大行数。我们再次可以在计算中保存额外的$log q$因子。</p><h3 id="4-2-缓存感知访问"><a href="#4-2-缓存感知访问" class="headerlink" title="4.2 缓存感知访问"></a>4.2 缓存感知访问</h3><p>虽然block结构有助于优化分割点查找的时间复杂度，但是算法需要通过行索引间接提取梯度统计量，因为这些值是按特征的顺序访问的，这是一种非连续的内存访问（意思就是按值排序以后指针就乱了）。分割点枚举的简单实现在累积和非连续内存提取之间引入了即时读/写依赖性（参见图8）。当梯度统计信息不适合CPU缓存进而发生缓存未命中时，这会减慢分割点查找的速度。</p><p><img src="https://i.postimg.cc/hPs6ns2L/xgb-8.jpg" alt="xgb-8.jpg"></p><p>对于贪心算法，我们可以通过缓存感知预取算法来缓解这个问题。 具体来说，我们在每个线程中分配一个内部缓冲区，获取梯度统计信息并存入，然后以小批量方式执行累积。预取的操作将直接读/写依赖关系更改为更长的依赖关系，有助于数据行数较大时减少运行开销。图7给出了Higgs和Allstate数据集上缓存感知与非缓存感知算法的比较。我们发现，当数据集很大时，实现缓存感知的贪婪算法的运行速度是朴素版本的两倍。</p><p><img src="https://i.postimg.cc/4dp2SQKh/xgb-7.jpg" alt="xgb-7.jpg"></p><p>对于近似算法，我们通过选择正确的block尺寸来解决问题。 我们将block尺寸定义为block中包含的最大样本数，因为这反映了梯度统计量的高速缓存存储成本。选择过小的block会导致每个线程的工作量很小，并行计算的效率很低。另一方面，过大的block会导致高速缓存未命中现象，因为梯度统计信息不适合CPU高速缓存。良好的block尺寸平衡了这两个因素。 我们在两个数据集上比较了block大小的各种选择，结果如图9所示。该结果验证了我们的讨论，并表明每个块选择$2^{16}$个样本可以平衡缓存资源利用和并行化效率。</p><p><img src="https://i.postimg.cc/15s2b2rR/xgb-9.jpg" alt="xgb-9.jpg"></p><h3 id="4-3-核外计算的块"><a href="#4-3-核外计算的块" class="headerlink" title="4.3 核外计算的块"></a>4.3 核外计算的块</h3><p>我们系统的一个目标是充分利用机器的资源来实现可扩展的学习。 除处理器和内存外，利用磁盘空间处理不适合主内存的数据也很重要。为了实现核外计算，我们将数据分成多个块并将每个块存储在磁盘上。在计算过程中，使用独立的线程将块预取到主存储器缓冲区是非常重要的，因为计算可以因此在磁盘读取的情况下进行。但是，这并不能完全解决问题，因为磁盘读取会占用了大量计算时间。减少开销并增加磁盘IO的吞吐量非常重要。 我们主要使用两种技术来改进核外计算。</p><p><strong>块压缩</strong> 我们使用的第一种技术是块压缩。该块从列方向压缩，并在加载到主存储器时通过独立的线程进行解压。这可以利用解压过程中的一些计算与磁盘读取成本进行交换。我们使用通用的压缩算法来压缩特征值。对于行索引，我们通过块的起始索引开始减去行索引，并使用16位整型来存储每个偏移量。这要求每个块有$2^{16}$个样本，这也被证实是一个好的设置（好的设置指的是$2^{16}$这个数字的设置）。在我们测试的大多数数据集中，我们实现了大约26％到29％的压缩率。</p><p><strong>块分片</strong><br>第二种技术是以另一种方式将数据分成多个磁盘。为每个磁盘分配一个实现预取的线程，并将数据提取到内存缓冲区中。然后，训练线程交替地从每个缓冲区读取数据。当有多个磁盘可用时，这有助于提高磁盘读取的吞吐量。</p><h2 id="5-相关工作"><a href="#5-相关工作" class="headerlink" title="5 . 相关工作"></a>5 . 相关工作</h2><p>我们的系统通过函数的加法模型实现了梯度提升。梯度提升树已成功用于分类，排序，结构化预测以及其他领域。XGBoost采用正则化模型来防止过度拟合，类似于正则化贪心森林，但简化了并行化的目标和算法。列采样是一种从随机森林借鉴来技术，简单且有效。虽然稀疏感知学习在其他类型的模型（如线性模型）中是必不可少的，但很少有关这方面在树模型学习中的研究。本文提出的算法是第一个可以处理各种稀疏模式的统一方法。</p><p>现存有很多树模型并行学习的研究。大多数算法都属于本文所述的近似框架。值得注意的是，还可以按列对数据进行分区并应用贪婪算法。我们的框架也支持这一点，并且可以使用诸如缓存感知预防之类的技术来使这类算法受益。虽然大多数现有的工作都集中在并行化的算法方面，但我们的工作在两个未经探索的方面得到了成果：核外计算和缓存感知学习。这让我们对联合优化系统和算法的有了深刻的理解，并构建了一个端到端系统，可以在非常有限的计算资源下处理大规模问题。在表1中，我们还总结了我们的系统与现存开源系统的对比。</p><p><img src="https://i.postimg.cc/HnCRYhG2/xgb-t1.jpg" alt="xgb-t1.jpg"></p><p>分位数摘要（无权重）是数据库社区中的经典问题。然而，近似提升树算法揭示了一个更普遍的问题——在加权数据上找分位数。据我们所知，本文提出的加权分位数草图是第一个解决该问题的方法。 加权分位数摘要也不是专门针对树模型学习的，可以在将来服务于数据科学和机器学习中的其他应用。</p><h2 id="6-端到端的预估"><a href="#6-端到端的预估" class="headerlink" title="6. 端到端的预估"></a>6. 端到端的预估</h2><h3 id="6-1-系统实现"><a href="#6-1-系统实现" class="headerlink" title="6.1 系统实现"></a>6.1 系统实现</h3><p>我们以开源软件包的形式实现了XGBoost。该软件包是可移植和可重复使用的。它支持各种加权分类和各种阶的目标函数，以及用户定义的目标函数。它对流行的语言都提供支持，例如python，R，Julia，并且与语言特定的数据科学库（如scikit-learn）自然集成。分布式版本构建在rabit库上，用于allreduce。XGBoost的可移植性使其可用于许多生态系统，而不仅仅是绑定在特定平台。分布式XGBoost可以轻松运行在Hadoop，MPI Sun Grid引擎上。最近，我们还在jvm 大数据栈（如Flink和Spark）上实现了分布式XGBoost。分布式版本也已集成到阿里巴巴的天池云平台中。我们相信未来会有更多的整合。</p><h3 id="6-2-数据集和设置"><a href="#6-2-数据集和设置" class="headerlink" title="6.2 数据集和设置"></a>6.2 数据集和设置</h3><p>我们在实验中使用了四个数据集。表2给出了这些数据集的摘要信息。在一些实验中，由于基线较慢，我们使用随机选择的数据子集，或者演示算法在不同大小的数据集下的性能。在这些情况下，我们使用后缀来表示大小。例如，Allstate-10K表示具有10K实例的Allstate数据集的子集。</p><p><img src="https://i.postimg.cc/B6FRGGzb/xgb-t2.jpg" alt="xgb-t2.jpg"></p><p>我们使用的第一个数据集是Allstate保险索赔数据集。任务是根据不同的风险因素预测保险索赔的可能性和成本。在实验中，我们将任务简化为仅预测保险索赔的概率。此数据集用于评估在3.4节中提到的稀疏感知算法。此数据中的大多数稀疏特征都是独热编码。我们随机选择10M样本作为训练集，并将其余部分用作验证集。</p><p>第二个数据集是高能物理学的希格斯玻色子数据集。该数据是使用蒙特卡洛仿真模拟物理现象生成的。它包含21个运动学特征，由加速器中的粒子探测器测量得到。还包含七个额外的粒子派生物理量。任务是分类是否物理现象与希格斯玻色子相对应。我们随机选择10M实例作为训练集，并将其余部分用作验证集。</p><p>第三个数据集是Yahoo! learning to rank比赛数据集，这是learning to rank算法最常用的基准之一。 数据集包含20K网页搜索查询结果，每个查询对应于一个有大约22个文档的列表。任务是根据查询的相关性对文档进行排名。我们在实验中使用官方的训练测试集分割标准。</p><p>最后一个数据集是criteo百万级别的点击日志数据集。我们使用此数据集来评估系统在核外和分布式环境中的扩展性。该数据包含13个数值特征和26个ID特征，其中有用户ID，项目ID和广告商信息ID等。由于树模型更擅长处理连续特征，前十天我们通过计算平均的CTR和ID特征的统计信息对数据预处理，接下来的十天用相应的统计信息替换ID特征，处理完成后就可以作为训练集。预处理后的训练集包含1.7billion个样本，每个样本具有67个特征（13个数值特征，26个平均CTR特征和26个统计特征）。整个数据集的LibSVM格式超过1TB。</p><p>我们将前三个数据集用于单机并行环境中，将最后一个数据集用于分布式和核外计算的环境。所有单机实验均在戴尔PowerEdge R420上进行，配备两个八核Intel Xeon（E5-2470）（2.3GHz）和64GB内存。如果未指定，则所有实验使用机器中的所有可用核心运行。分布式和核外实验的机器配置将在相应的部分中描述。在所有实验中，我们统一设置提升树的最大深度等于8，学习率等于0.1，除非明确指定否则不进行列子采样。当我们将最大深度设置为其他时，我们可以得到相似的结果。</p><h3 id="6-3-分类"><a href="#6-3-分类" class="headerlink" title="6.3 分类"></a>6.3 分类</h3><p>在本节中，我们在Higgs-1M数据集上通过对比其他两种常用的基于贪心算法的提升树，评估基于贪心算法的XGBoost的性能。由于scikit-learn只能处理非稀疏输入，我们选择密集Higgs数据集进行比较。我们在1M的数据子集上运行scikit-learn版本的XGBoost，这样可以在合理的时间内跑完。在比较中，R的GBM使用贪心算法，只扩展树的一个分支，这使它更快但可能导致准确性不足，而scikit-learn和XGBoost都生成完整的树。结果在表3中显示，XGBoost和scikit-learn都比R的GBM表现出更好的性能，而XGBoost的运行速度比scikit-learn快10倍。在实验中，我们还发现列子采样后的结果略差于使用所有特征训练的结果。这可能是因为此数据集中的重要特征很少，贪心算法的精确结果会更好。</p><p><img src="https://i.postimg.cc/wBZnPB0n/xgb-t3.jpg" alt="xgb-t3.jpg"></p><h3 id="6-4-排序学习"><a href="#6-4-排序学习" class="headerlink" title="6.4 排序学习"></a>6.4 排序学习</h3><p>我们接下来评估XGBoost在learning to rank问题上的表现。我们与pGBRT进行比较，pGBRT是以前此类任务中表现最好的系统。XGBoost使用贪心算法，而pGBRT仅支持近似算法。结果显示在表4和图10中。我们发现XGBoost运行速度更快。有趣的是，列采样不仅可以缩短运行时间，还能提高准确性。原因可能是由于子采样有助于防止过拟合，这是许多用户观察出来的。</p><p><img src="https://i.postimg.cc/Z5Kkv2Ws/xgb-10.jpg" alt="xgb-10.jpg"><br><img src="https://i.postimg.cc/Z5fG8H3b/xgb-t4.jpg" alt="xgb-t4.jpg"></p><h3 id="6-5-核外实验"><a href="#6-5-核外实验" class="headerlink" title="6.5 核外实验"></a>6.5 核外实验</h3><p>我们还在核外环境中使用criteo数据评估了我们的系统。我们在一台AWS c3.8xlarge机器上进行了实验（32个vcores，两个320 GB SSD，60 GB RAM）。 结果显示在图11中。我们可以发现压缩将计算速度提高了三倍，并且分成两个磁盘进一步加速了2倍。对于此类实验，非常重要的一点是使大数据集来排空系统文件缓存以实现真正的核外环境。这也是我们所做的。当系统用完文件缓存时，我们可以观察到转折点。要注意的是，最终方法中的转折点不是那么明显。这得益于更大的磁盘吞吐量和更好的计算资源利用率。我们的最终方法能够在一台机器上处理17亿个样本。</p><p><img src="https://i.postimg.cc/c1QP90Y5/xgb-11.jpg" alt="xgb-11.jpg"></p><h3 id="6-6-分布实验"><a href="#6-6-分布实验" class="headerlink" title="6.6 分布实验"></a>6.6 分布实验</h3><p>最后，我们在分布式环境中评估系统。我们在EC2上使用m3.2xlarge机器建立了一个YARN集群，这是集群的非常常见。每台机器包含8个虚拟内核，30GB内存和两个80GB SSD本地磁盘。数据集存储在AWS S3而不是HDFS上，以避免购买持久存储。</p><p><img src="https://i.postimg.cc/8cB3jmNV/xgb-12.jpg" alt="xgb-12.jpg"></p><p>我们首先将我们的系统与两个生产力级别的分布式系统进行比较：Spark MLLib和H2O。我们使用32 m3.2xlarge机器并测试不同输入尺寸的系统的性能。两个基线系统都是内存分析框架，需要将数据存储在RAM中，而XGBoost可以在内存不足时切换到核外设置。结果如图12所示。我们可以发现XGBoost的运行速度比基线系统快。更重要的是，它能够利用核外计算的优势，在给定有限的计算资源的情况下平稳扩展到所有17亿个样本。基线系统仅能够使用给定资源处理数据的子集。该实验显示了将所有系统的改进结合在一起优势。我们还通过改变机器数量来评估XGBoost的缩放属性。结果显示在图13中。随着我们添加更多机器，我们可以发现XGBoost的性能呈线性变化。重要的是，XGBoost只需要四台机器即可处理17亿个数据。这表明系统有可能处理更大的数据。</p><p><img src="https://i.postimg.cc/XvpTQ5cw/xgb-13.jpg" alt="xgb-13.jpg"></p><h2 id="7-结论"><a href="#7-结论" class="headerlink" title="7. 结论"></a>7. 结论</h2><p>在本文中，我们叙述了在构建XGBoost过程中学到的经验（XGBoost是一个可扩展的提升树系统，被数据科学家广泛使用，并在很多问题上有很好的表现）。 我们提出了一种用于处理稀疏数据的新型稀疏感知算法和用于近似学习的理论上合理的加权分位数草图算法。我们的经验表明，缓存访问模式，数据压缩和分片是构建可扩展的端到端系统以实现提升树的基本要素。这些经验也可以应用于其他机器学习系统。通过结合这些经验，XGBoost能够使用最少量的资源解决大规模的实际问题。</p><p><a href="https://blog.csdn.net/zhaojc1995/article/details/89238051" target="_blank" rel="noopener">参考译文：XGBoost原论文阅读翻译-了不起的赵队</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://delivery.acm.org/10.1145/2940000/2939785/p785-chen.pdf?&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：XGBoost: A Scalable Tree Boosting System&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;p&gt;Tree boosting 是一个高效的并且广泛应用的机器学习方法。在本文中，我们会介绍一个可扩展的端到端的 tree boosting 系统，它叫 XGBoost，它被数据科学家广泛地应用，并且在许多机器学习挑战取得了最好的结果。对于稀疏数据我们提出了稀疏性感知算法，以及加权分位数梗概用来近似树模型学习。更重要的是，我们提供了对缓存访问模式，数据压缩和分片的见解来建立一个可扩展的提升树系统。通过综合这些看法， XGBoost 只需要使用比现有系统少得多的资源就可以扩展出超过数十亿的实例。&lt;/p&gt;
&lt;h2 id=&quot;关键词&quot;&gt;&lt;a href=&quot;#关键词&quot; class=&quot;headerlink&quot; title=&quot;关键词&quot;&gt;&lt;/a&gt;关键词&lt;/h2&gt;&lt;p&gt;大规模机器学习&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法" scheme="http://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="XGB" scheme="http://www.xiemingzhao.com/tags/XGB/"/>
    
  </entry>
  
  <entry>
    <title>Understanding LSTM Networks</title>
    <link href="http://www.xiemingzhao.com/2019/05/29/Understanding%20LSTM%20Networks--%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.xiemingzhao.com/2019/05/29/Understanding LSTM Networks--学习笔记/</id>
    <published>2019-05-28T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:44.585Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">原始论文：Understanding LSTM Networks</a></p><h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><p>人类并不是每时每刻都从一片空白的大脑开始他们的思考。在你阅读这篇文章时候，你都是基于自己已经拥有的对先前所见词的理解来推断当前词的真实含义。我们不会将所有的东西都全部丢弃，然后用空白的大脑进行思考。我们的思想拥有持久性。</p><p>传统的神经网络并不能做到这点，看起来也像是一种巨大的弊端。例如，假设你希望对电影中的每个时间点的时间类型进行分类。传统的神经网络应该很难来处理这个问题——使用电影中先前的事件推断后续的事件。</p><p>RNN 解决了这个问题。RNN 是包含循环的网络，允许信息的持久化。</p><a id="more"></a><p><img src="https://i.postimg.cc/Gm0s294H/LSTM-1.png" alt="Recurrent Neural Networks have loops.jpg"></p><p>在上面的示例图中，神经网络的模块，正在读取某个输入 ，并输出一个值。循环可以使得信息可以从当前步传递到下一步。</p><p>这些循环使得 RNN 看起来非常神秘。然而，如果你仔细想想，这样也不比一个正常的神经网络难于理解。RNN 可以被看做是同一神经网络的多次复制，每个神经网络模块会把消息传递给下一个。所以，如果我们将这个循环展开：</p><p><img src="https://i.postimg.cc/G2p4Ny5S/LSTM-2.png" alt="An unrolled recurrent neural network.jpg"></p><p>链式的特征揭示了 RNN 本质上是与序列和列表相关的。他们是对于这类数据的最自然的神经网络架构。</p><p>并且 RNN 也已经被人们应用了！在过去几年中，应用 RNN 在语音识别，语言建模，翻译，图片描述等问题上已经取得一定成功，并且这个列表还在增长。我建议大家参考 Andrej Karpathy 的博客文章——<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">The Unreasonable Effectiveness of Recurrent Neural Networks</a> 来看看更丰富有趣的 RNN 的成功应用。</p><p>而这些成功应用的关键之处就是 LSTM 的使用，这是一种特别的 RNN，比标准的 RNN 在很多的任务上都表现得更好。几乎所有的令人振奋的关于RNN的结果都是通过 LSTM 达到的。这篇博文也会就 LSTM 进行展开。</p><h2 id="长期依赖（Long-Term-Dependencies）问题"><a href="#长期依赖（Long-Term-Dependencies）问题" class="headerlink" title="长期依赖（Long-Term Dependencies）问题"></a>长期依赖（Long-Term Dependencies）问题</h2><p>RNN 的关键点之一就是他们可以用来连接先前的信息到当前的任务上，例如使用过去的视频段来推测对当前段的理解。如果 RNN 可以做到这个，他们就变得非常有用。但是真的可以么？答案是，还有很多依赖因素。</p><p>有时候，我们仅仅需要知道先前的信息来执行当前的任务。例如，我们有一个语言模型用来基于先前的词来预测下一个词。如果我们试着预测 “the clouds are in the sky” 最后的词，我们并不需要任何其他的上下文 —— 因此下一个词很显然就应该是 sky。在这样的场景中，相关的信息和预测的词位置之间的间隔是非常小的，RNN 可以学会使用先前的信息。</p><p><img src="https://i.postimg.cc/Njw5tVnX/LSTM-3.png" alt="不太长的相关信息和位置间隔"></p><p>但是同样会有一些更加复杂的场景。假设我们试着去预测“I grew up in France… I speak fluent French”最后的词。当前的信息建议下一个词可能是一种语言的名字，但是如果我们需要弄清楚是什么语言，我们是需要先前提到的离当前位置很远的 France 的上下文的。这说明相关信息和当前预测位置之间的间隔就肯定变得相当的大。</p><p>不幸的是，在这个间隔不断增大时，RNN 会丧失学习到连接如此远的信息的能力。</p><p><img src="https://i.postimg.cc/bvyrDnpN/LSTM-4.png" alt="相当长的相关信息和位置间隔"></p><p>在理论上，RNN 绝对可以处理这样的 长期依赖 问题。人们可以仔细挑选参数来解决这类问题中的最初级形式，但在实践中，RNN 肯定不能够成功学习到这些知识。<a href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf" target="_blank" rel="noopener">Bengio, et al. (1994)</a>等人对该问题进行了深入的研究，他们发现一些使训练 RNN 变得非常困难的相当根本的原因。<br>然而，幸运的是，LSTM 并没有这个问题！</p><h2 id="LSTM-网络"><a href="#LSTM-网络" class="headerlink" title="LSTM 网络"></a>LSTM 网络</h2><p>Long Short Term 网络—— 一般就叫做 LSTM ——是一种 RNN 特殊的类型，可以学习长期依赖信息。LSTM 由Hochreiter &amp; Schmidhuber (1997)提出，并在近期被Alex Graves进行了改良和推广。在很多问题，LSTM 都取得相当巨大的成功，并得到了广泛的使用。<br>LSTM 通过刻意的设计来避免长期依赖问题。记住长期的信息在实践中是 LSTM 的默认行为，而非需要付出很大代价才能获得的能力！<br>所有 RNN 都具有一种重复神经网络模块的链式的形式。在标准的 RNN 中，这个重复的模块只有一个非常简单的结构，例如一个 tanh 层。</p><p><img src="https://i.postimg.cc/wTN7SHwH/LSTM-5.png" alt="The repeating module in a standard RNN contains a single layer"></p><p>LSTM 同样是这样的结构，但是重复的模块拥有一个不同的结构。不同于 单一神经网络层，这里是有四个，以一种非常特殊的方式进行交互。</p><p><img src="https://i.postimg.cc/gJr04PxC/LSTM-6.png" alt="The repeating module in an LSTM contains four interacting layers."></p><p>不必担心这里的细节。我们会一步一步地剖析 LSTM 解析图。现在，我们先来熟悉一下图中使用的各种元素的图标。</p><p><img src="https://i.postimg.cc/YC1LmkF8/LSTM-7.png" alt="LSTM 中的图标"></p><p>在上面的图例中，每一条黑线传输着一整个向量，从一个节点的输出到其他节点的输入。粉色的圈代表按位 pointwise 的操作，诸如向量的和，而黄色的矩阵就是学习到的神经网络层。合在一起的线表示向量的连接，分开的线表示内容被复制，然后分发到不同的位置。</p><h2 id="LSTM-的核心思想"><a href="#LSTM-的核心思想" class="headerlink" title="LSTM 的核心思想"></a>LSTM 的核心思想</h2><p>LSTM 的关键就是细胞状态，水平线在图上方贯穿运行。</p><p>细胞状态类似于传送带。直接在整个链上运行，只有一些少量的线性交互。信息在上面流传保持不变会很容易。</p><p><img src="https://i.postimg.cc/ZqH9VcVd/LSTM-8.png" alt="LSTM单元"></p><p>LSTM 有通过精心设计的称作为“门”的结构来去除或者增加信息到细胞状态的能力。门是一种让信息选择式通过的方法。他们包含一个 sigmoid 神经网络层和一个按位的乘法操作。</p><p><img src="https://i.postimg.cc/nLpj45Yx/LSTM-9.png" alt="LSTM操作节点"></p><p>Sigmoid 层输出 0 到 1 之间的数值，描述每个部分有多少量可以通过。0 代表“不许任何量通过”，1 就指“允许任意量通过”！</p><p>LSTM 拥有三个门，来保护和控制细胞状态。</p><h2 id="逐步理解-LSTM"><a href="#逐步理解-LSTM" class="headerlink" title="逐步理解 LSTM"></a>逐步理解 LSTM</h2><p>在我们 LSTM 中的第一步是决定我们会从细胞状态中丢弃什么信息。这个决定通过一个称为忘记门层完成。该门会读取 $h_{t-1}$ 和 $x_t$，输出一个在 0 到 1 之间的数值给每个在细胞状态 $C_{t-1}$ 中的数字。1 表示“完全保留”，0 表示“完全舍弃”。<br>让我们回到语言模型的例子中来基于已经看到的预测下一个词。在这个问题中，细胞状态可能包含当前<strong>主语</strong>的性别，因此正确的<strong>代词</strong>可以被选择出来。当我们看到新的<strong>主语</strong>，我们希望忘记旧的<strong>主语</strong>。</p><p><img src="https://i.postimg.cc/d1ShK0MQ/LSTM-10.png" alt="决定丢弃信息"></p><p>下一步是确定什么样的新信息被存放在细胞状态中。这里包含两个部分。第一，sigmoid 层称 “输入门层” 决定什么值我们将要更新。然后，一个 tanh 层创建一个新的候选值向量，$\tilde{C_t}$，会被加入到状态中。下一步，我们会讲这两个信息来产生对状态的更新。</p><p>在我们语言模型的例子中，我们希望增加新的主语的性别到细胞状态中，来替代旧的需要忘记的主语。</p><p><img src="https://i.postimg.cc/2ybVjfmQ/LSTM-11.png" alt="确定更新的信息"></p><p>现在是更新旧细胞状态的时间了，$C_{t-1}$ 更新为 $C_t$。前面的步骤已经决定了将会做什么，我们现在就是实际去完成。</p><p>我们把旧状态与 $f_t$ 相乘，丢弃掉我们确定需要丢弃的信息。接着加上 $i_t * \tilde{C_t}$。这就是新的候选值，根据我们决定更新每个状态的程度进行变化。</p><p>在语言模型的例子中，这就是我们实际根据前面确定的目标，丢弃旧代词的性别信息并添加新的信息的地方。</p><p><img src="https://i.postimg.cc/NF3L5PfW/LSTM-12.png" alt="更新细胞状态"></p><p>最终，我们需要确定输出什么值。这个输出将会基于我们的细胞状态，但是也是一个过滤后的版本。首先，我们运行一个 sigmoid 层来确定细胞状态的哪个部分将输出出去。接着，我们把细胞状态通过 tanh 进行处理（得到一个在 -1 到 1 之间的值）并将它和 sigmoid 门的输出相乘，最终我们仅仅会输出我们确定输出的那部分。</p><p>在语言模型的例子中，因为他就看到了一个 <strong>代词</strong>，可能需要输出与一个<strong>动词</strong> 相关的信息。例如，可能输出是否代词是单数还是负数，这样如果是动词的话，我们也知道动词需要进行的词形变化。</p><p><img src="https://i.postimg.cc/tRwsS7t2/LSTM-13.png" alt="输出信息"></p><h2 id="LSTM-的变体"><a href="#LSTM-的变体" class="headerlink" title="LSTM 的变体"></a>LSTM 的变体</h2><p>我们到目前为止都还在介绍正常的 LSTM。但是不是所有的 LSTM 都长成一个样子的。实际上，几乎所有包含 LSTM 的论文都采用了微小的变体。差异非常小，但是也值得拿出来讲一下。</p><p>其中一个流形的 LSTM 变体，就是由 <a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf" target="_blank" rel="noopener">Gers &amp; Schmidhuber (2000)</a> 提出的，增加了 “peephole connection”。是说，我们让 门层 也会接受细胞状态的输入。</p><p><img src="https://i.postimg.cc/250645Sd/LSTM-14.png" alt="peephole 连接"></p><p>上面的图例中，我们增加了 peephole 到每个门上，但是许多论文会加入部分的 peephole 而非所有都加。</p><p>另一个变体是通过使用 coupled 忘记和输入门。不同于之前是分开确定什么忘记和需要添加什么新的信息，这里是一同做出决定。我们仅仅会当我们将要输入在当前位置时忘记。我们仅仅输入新的值到那些我们已经忘记旧的信息的那些状态 。</p><p><img src="https://i.postimg.cc/MpbXp5kF/LSTM-15.png" alt="coupled 忘记门和输入门"></p><p>另一个改动较大的变体是 Gated Recurrent Unit (GRU)，这是由 <a href="http://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="noopener">Cho, et al. (2014)</a> 提出。它将忘记门和输入门合成了一个单一的 更新门。同样还混合了细胞状态和隐藏状态，和其他一些改动。最终的模型比标准的 LSTM 模型要简单，也是非常流行的变体。</p><p><img src="https://i.postimg.cc/cHjLb5Yr/LSTM-16.png" alt="GRU"></p><p>这里只是部分流行的 LSTM 变体。当然还有很多其他的，如<a href="http://arxiv.org/pdf/1508.03790v2.pdf" target="_blank" rel="noopener">Yao, et al. (2015)</a> 提出的 Depth Gated RNN。还有用一些完全不同的观点来解决长期依赖的问题，如<a href="http://arxiv.org/pdf/1402.3511v1.pdf" target="_blank" rel="noopener">Koutnik, et al. (2014)</a> 提出的 Clockwork RNN。<br>要问哪个变体是最好的？其中的差异性真的重要吗？<a href="http://arxiv.org/pdf/1503.04069.pdf" target="_blank" rel="noopener">Greff, et al. (2015)</a> 给出了流行变体的比较，<strong>结论是他们基本上是一样的</strong>。<a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" target="_blank" rel="noopener">Jozefowicz, et al. (2015)</a> 则在超过 1 万种 RNN 架构上进行了测试，发现一些架构在某些任务上也取得了比 LSTM 更好的结果。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>刚开始，我提到通过 RNN 得到重要的结果。本质上所有这些都可以使用 LSTM 完成。对于大多数任务确实展示了更好的性能！</p><p>由于 LSTM 一般是通过一系列的方程表示的，使得 LSTM 有一点令人费解。然而本文中一步一步地解释让这种困惑消除了不少。</p><p>LSTM 是我们在 RNN 中获得的重要成功。很自然地，我们也会考虑：哪里会有更加重大的突破呢？在研究人员间普遍的观点是：“Yes! 下一步已经有了——那就是注意力！” 这个想法是让 RNN 的每一步都从更加大的信息集中挑选信息。例如，如果你使用 RNN 来产生一个图片的描述，可能会选择图片的一个部分，根据这部分信息来产生输出的词。实际上，Xu, et al.(2015)已经这么做了——如果你希望深入探索注意力可能这就是一个有趣的起点！还有一些使用注意力的相当振奋人心的研究成果，看起来有更多的东西亟待探索……</p><p>注意力也不是 RNN 研究领域中唯一的发展方向。例如，Kalchbrenner, et al. (2015) 提出的 Grid LSTM 看起来也是很有前途。使用生成模型的 RNN，诸如Gregor, et al. (2015) Chung, et al. (2015) 和 Bayer &amp; Osendorfer (2015) 提出的模型同样很有趣。在过去几年中，RNN 的研究已经相当的燃，而研究成果当然也会更加丰富！</p><p><a href="https://www.jianshu.com/p/9dc9f41f0b29#" target="_blank" rel="noopener">参考博文：[译]理解 LSTM 网络-朱小虎</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：Understanding LSTM Networks&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;循环神经网络&quot;&gt;&lt;a href=&quot;#循环神经网络&quot; class=&quot;headerlink&quot; title=&quot;循环神经网络&quot;&gt;&lt;/a&gt;循环神经网络&lt;/h2&gt;&lt;p&gt;人类并不是每时每刻都从一片空白的大脑开始他们的思考。在你阅读这篇文章时候，你都是基于自己已经拥有的对先前所见词的理解来推断当前词的真实含义。我们不会将所有的东西都全部丢弃，然后用空白的大脑进行思考。我们的思想拥有持久性。&lt;/p&gt;
&lt;p&gt;传统的神经网络并不能做到这点，看起来也像是一种巨大的弊端。例如，假设你希望对电影中的每个时间点的时间类型进行分类。传统的神经网络应该很难来处理这个问题——使用电影中先前的事件推断后续的事件。&lt;/p&gt;
&lt;p&gt;RNN 解决了这个问题。RNN 是包含循环的网络，允许信息的持久化。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="http://www.xiemingzhao.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="LSTM" scheme="http://www.xiemingzhao.com/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>Slope One Predictors for Online Rating-Based Collaborative Filtering</title>
    <link href="http://www.xiemingzhao.com/2019/04/19/Slope%20One%20Predictors%20for%20Online%20Rating-Based%20Collaborative%20Filtering--%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.xiemingzhao.com/2019/04/19/Slope One Predictors for Online Rating-Based Collaborative Filtering--学习笔记/</id>
    <published>2019-04-18T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:47.197Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://epubs.siam.org/doi/pdf/10.1137/1.9781611972757.43" target="_blank" rel="noopener">原始论文：Slope One Predictors for Online Rating-Based Collaborative Filtering</a></p><h2 id="Slope-One-基于在线评分的协同过滤算法"><a href="#Slope-One-基于在线评分的协同过滤算法" class="headerlink" title="Slope One: 基于在线评分的协同过滤算法"></a>Slope One: 基于在线评分的协同过滤算法</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>基于评级的协同过滤是预测的程序，即根据用户对其他物品的评分来预测用户会如何评分当前给定的物品。我们提出了三个形式为f（x）= x + b的关于slop one机制的预测模型，预先计算出用户共同评分过的一个物品和另一个物品的评分之间的平均差异。slop one算法是易于实现的，查询效率高，相当准确，同时它们支持在线查询和动态更新，这使它们成为现实系统的良好候选者。建议将基本的SLOPE ONE方案作为协同过滤方案的新参考。通过考虑将用户喜欢和不喜欢的物品从全集中分出来，我们通过较慢的基于记忆的方式实现了结果超过基准EveryMovie和Movielens数据集，同时更好地满足了它对协同过滤应用的需求。</p><p>关键词：协同过滤，推荐工具，电子商务，数据挖掘，知识发现</p><a id="more"></a><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a><strong>1 介绍</strong></h3><p>基于在线评级的协同过滤CF查询由来自单个用户的（物品，评分）对的数组组成。对该查询的响应是一个由用户还没有评分的物品集合构成的预测数组对（物品，评分）。我们旨在提供强大的CF机制，包括：</p><ol><li>易于实现和维持：所有的或者那个数据应该可以有跑一版的工程师很轻松地解读，并且算法应该很容易地被实现和测试；</li><li>即时可更新：新评分的添加应该可以立即改变所有预测;</li><li>查询时效性：查询应该很快，可能以储存为代价;</li><li>对第一个访客的期望很少：很少评分的用户应该也能收到有效的推荐;</li><li>准确无误：算法机制应争先用最准确的方案，除非准确性收益微薄的话，并不总是值得在简单性或可扩展性方面做出重大牺牲。</li></ol><p>我们在本文中的目标不是比较准确性各种CF算法，而是演示Slope One计划同时满足所有五个目标。尽管我们的计划很简单，它们具有可更新性，计算高效性和可扩展性，它们的准确性与放弃某些其他优点的方案相当。</p><p>我们的Slope One算法通过用户的项目之间的“流行度差异”以直观的原理起作用。以成对的方式，我们确定一个物品比另一个更好多少。衡量这种差异的一种方法只是简单地这两个项目的平均评分相减。反过来，给定用户对一个物品的评分后，这种差异可以用来预测另一个用户对其中一个物品的评分。考虑两个用户A和B，两个物品I和J以及图1。用户A给予物品I评分为1，而用户B给予它一个评分为2，而用户A给予物品J评级为1.5。我们观察物品J的评分大于物品I的1.5-1 = 0.5分，因此我们可以预测用户B将给出物品J的评分为：2 + 0.5 = 2.5。我们将用户B称为预测用户和项目J是预测项目。许多这样的差异存在于每个未知评分的训练集，我们取这些差异的平均值。slop one机制在这里呈现了我们选择三种相关的差异方式达到单一预测。</p><p>本文的主要贡献是提出slop one协同过滤预测算法并证明它们具有竞争力，和基于记忆的方案具有几乎相同的准确度，同时更适合CF任务。</p><h3 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a><strong>2 相关工作</strong></h3><p><strong>2.1 基于记忆和基于模型的机制</strong><br>基于记忆的协同过滤算法使用用户间的相似度来进行预测，最经典的就是通过加权平均。<br>所选择的相似性度量决定了预测准确性，并且已经研究了众多替代方案。基于存储器的CF的一些潜在缺点包括可扩展性和对数据稀疏性的敏感性。一般来说，依赖于跨用户相似性的方案在快速在线查询的时候进行预先是不可能的。另一个关键问题是基于记忆的方案必须计算用户之间的相似性，并且衡量标准通常需要一些最小用户数（比如说，至少有100个用户）输入了一些最小个数的评分（比如说至少是20个评分）包括当前用户。我们会将我们的算法和着名的基于内存的方案进行对比，皮尔逊算法。</p><p>CF有许多基于模型的方法。一些基于线性代数（SVD，PCA或Eigenvectors）;或者直接借用来自人工智能的技术，如贝叶斯方法，隐含分类，和神经网络，或聚类。与基于内存的方案相比，基于模型CF算法通常在查询时更快但是可能有昂贵的学习或更新阶段。基于模型方案可以优于基于存储器的方案，当查询速度至关重要时。</p><p>我们会将我们的预测算法与在下面的代数文献中描述的某些类型的预测方法进行比较。因此，我们的预测模型的形式为$f(x)= x + b$，因此名称定为“slope one”，其中b是常数，x是变量代表评分值。对于任何一对物品，我们试图找到从其他物品的评分来预测此物品评分的最佳函数f。这个函数可能对于每个物品对都不一样。 CF机制将加权预测模型产生的诸多预测。在[14]中，作者考虑了成对项目之间的相关性然后导出用户评分的加权平均值作为预测。在他们算法的简单版本中，他们的预测模型形式为$f(x)=x$。在他们的以回归为基础的算法版本中，他们的预测模型形式是$f(x)= ax + b$。在[17]中，作者也采用了预测因子形式$f(x)= ax + b$。基于这两篇论文一个自然延伸的研究，将会考虑这样的预测模型的形式：$f(x)=ax^2 + bx +c$。相反，在这篇文章，我们使用简单的预测模型形式$f(x)= ax + b$。我们也是用最普通的加权方法。可在[14]看到的是，甚至他们的基于回归方程$f(x)= ax + b$的算法依然不能够获得相对于基于记忆算法较大的改进。因此可以得到一个重要的结论就是基于$f(x)= ax + b$形式的预测模型可以与基于记忆的算法机制进行竞争。</p><h3 id="3-CF-算法"><a href="#3-CF-算法" class="headerlink" title="3 CF 算法"></a><strong>3 CF 算法</strong></h3><p>我们提出了三种新的CF方案，并将我们剔除的机制和之前提到的四中算法进行对比：PER USER AVERAGE, BIAS FROM MEAN, ADJUSTED COSINE ITEMBASED,这是一个基于模型的方案，以及PEARSON机制是代表基于记忆的方案。</p><p><strong>3.1 符号</strong><br>我们在算法描述中使用以下符号。来自给定用户的评分，称为<em>评估</em>，表示为一个不完整的数组u，其中$u_i$是该用户给出了物品i的评分。又被用户u评分过的所有物品组成的子集表示成S(u)。训练集中所有评估的集合表示成$\chi$。集合S中的元素个数是card(S)。用户u所有评分的平均评分为$\bar u$。集合$S_i(\chi)$是所有评估$u \in \chi$中包含物品$i(i \in S(u))$组成的集合。给定两个评估u，v，我们定义标量积$(u,v) = \sum_{i \in S(u) \cap S(v)} u_i v_i$。预测，我们写成P(u)，表示每个分量都是对应一个物品预测结果的向量：预测隐含地依赖于训练集$\chi$。</p><p><strong>3.2 基准方案</strong><br>一个最基础的预测算法就是PER USER AVERAGE方案，给定的等式是$P(u)=\bar u$。也就是说，我们预测用户将根据该用户的平均评分对所有内容进行评级。<br>另一个简单的方案称为BIAS FROM MEAN（有时候也称为NON PERSONALIZED)。等式给定为：</p><script type="math/tex; mode=display">P(u)_i = \bar u + \frac{1}{card(S_i(\chi))} \sum_{v \in S_i(\chi)} v_i - \bar v</script><p>也就是说，这个预测是基于用户平均评分再加上训练集中所有用户对该物品的评分与其用户的评分平均值的平均偏差。我们也比较了基于物品的算法并且结果显示效果最好[14]，其中给出了使用以下调整后的余弦相似性度量，当给定两个物品i和j：</p><script type="math/tex; mode=display">sim_{i,j} = \frac{\sum_{u \in S_{i,j}(X)}(u_i-\bar u)(u_j - \bar u)}{\sum_{u \in S_{i,j}(\chi)}(u_i - \bar u)^2 \sum_{u \in S_{i,j}(\chi)}(u_j - \bar u)^2}</script><p>最终预测是由这些度量加权求和得到的：</p><script type="math/tex; mode=display">P(u)_i = \frac{\sum_{j \in S(u)} |sim_{i,j}|(\alpha_{i,j}u_j + \beta_{i,j})}{\sum_{j \in S(u)}|sim_{i,j}}</script><p>其中回归系数$\alpha_{i,j},\beta_{i,j}$是由在i和j固定的条件下最小化$\sum_{u \in S_{i,j}(u)}(\alpha_{i,j} u_j \beta_{i,j} - u_i)^2$</p><p><strong>3.3 参考PEARSON方案</strong><br>因为我们希望证明我们的方案相比于基于记忆的方案的预测能力更具有可比性，但由于意识到这一类的方案有许多种，所以我们选择的是实现其中一个算法作为这类方案的代表。其中最受欢迎和准确的记忆基础算法是PEARSON方案。需要的$\chi$中所有用户的加权总和形式：</p><script type="math/tex; mode=display">P(u)_i = \bar u + \frac{\sum_{v \in S_i(\chi)} \gamma (u,v)(v_i - \bar v)}{\sum_{V \in S_i(\chi)} |\gamma (u,v)|}</script><p>其中$\gamma$是Pearson相关性计算得到的相似性度量：</p><script type="math/tex; mode=display">Corr(u,v) = \frac{<u - \bar u, w - \bar w>}{\sqrt{\sum_{i \in S(u) \cap S(w)} (u_i - \bar u^2) \sum_{i \in S(u) \cap S(w)} (w_i - \bar w)^2}}</script><p>基于[2,8]，我们设定：</p><script type="math/tex; mode=display">\gamma (u,w) = Corr(u,w) |Corr(u,w)|^{\rho - 1}</script><p>其中$\rho = 2.5$，它是样本的权重。此值降低了数据中的噪声：如果相关性是特别高的话，例如0.9，那么经过这层变化后依然可以保持高相关性$(0.9^{2.5} \cong 0.8)$，而当相关性较低的时候例如0.1，那么经过变化后会变得很小$(0.1^{2.5} \cong 0.003)$。论文[2]已经证明了相比于已经存在一些方案，结合样例加权的皮尔逊被证明了在CF算法中更具合理性和准确性。</p><p><img src="https://i.postimg.cc/FztgbNNY/relate-papers7-1.jpg" alt="relate-papers7-1"></p><p><strong>3.4 SLOPE ONE算法</strong><br>slope one算法不仅考虑了评分过当前物品的其他用户的信息，同时还考虑了被当前用户评分过的其他物品的信息。然而，这些算法也是如此依赖于既不属于用户数组也不属于物品数据的数据点（例如，用户A对图1中项目I的评级），但是这些数据仍然是评分预测的重要信息。该方法的大部分优势来自数据没有考虑到的因素。具体来说，只有那些与预测用户评分了一些共同物品并且只有与预测用户拥有的物品评分的用户评分进入slop one的评分预测方案。</p><p>正式的，给定两个评分数组$v_i$和$w_i$，其中$i = 1,…,n$，我们寻找形式为$f(x)=x + b$的最好的预测模型来基于v通过最小化$\sum_i (v_i + b - w_i)^2$预测w。将上式对b进行求导并将导数设置为零，我们可以得到$b = \frac{\sum_i w_i - v_i}{n}$。换句话说，常数b必须选自两个数组间的平均差异。这就可以推导出一下的算法。</p><p>给定训练集$\chi$，以及两个物品j和i以及一些用户对它们的评分$u_j$和$u_i$（其中$u \in S_{j,i}(\chi)$），我们考虑物品i和j之间的平均偏差为：</p><script type="math/tex; mode=display">dev_{j,i} = \sum_{u \in S_{j,i}(\chi)} \frac{u_j - u_i}{card(S_{J,I}(\chi))}</script><p>注意任何不包含对i或j评分$u_i,u_j$的用户评论都不包含在上述的求和中。对称矩阵$dev_{j,i}$可以在新数据尽来的时候快速地计算和更新。</p><p>固定$u_i$的时候，$dev_{j,i} + u_i$即为$u_j$的预测值，一个合理的预测应该对这些预测值进行平均：</p><script type="math/tex; mode=display">P(u)_j = \frac{1}{card(R_j)} {\sum_{i \in R_j} (dev_{j,i} + u_i)}</script><p>其中$R_j = {i|i \in S(u), i \neq j, card(S_{j,i}(\chi)) &gt; 0}$是所有相关的物品集合。有一个近似的方案可以简化预测的计算。对于一个足够密集的数据集，即任意一对物品都有评分数据，也就是，对于几乎所有的i和j都有$card(S_{j,i}(\chi)) &gt; 0$， 大多数时候，当$j \in S(u)$的时候，对于$ j \notin S(u) \ and \ R_j = S(u) -{j}$都有$R_j = S(u)$。由于对于大多数的j有$\bar u = \sum_{i \in S(u)} \frac{u_i}{card(S(u))} \simeq \sum_{i \in R_j} \frac{u_i}{card(R_j}$，我们可以对slop one的预测公式简化成：</p><script type="math/tex; mode=display">P^{S1}(u)_j = \bar u + \frac{1}{card(R_j)} \sum_{i \in R_j} dev_{j,i}</script><p>有趣的是注意到我们实现的SLOPE ONE算法是不依赖于用户是如何评论每个单个物品的，仅仅依赖用户的平均评分以及那些物品被当前用户评分过。</p><p><strong>3.5 加权SLOPE ONE算法</strong><br>虽然加权相对于不常见的评级模式来说是有利于经常出现的评级模式的，我们现在将会考虑另一种特别相关的评级模式。我们通过将预测分为两部分来实现这一目标。使用WEIGHTED SLOPE ONE算法，我们得到一个用户喜欢的物品预测和另一个使用用户不喜欢物品的预测。</p><p>给定一个评分范围，例如0到10，将此范围的中间值5作为阈值看上去是比较合理的，即物品评分大于5认为用户是喜欢的，相反小于5则是不喜欢的。这个方法对于用户评分是均匀分布的时候是特别有效果的。然而，每部电影超过70%的平方根都是大于这个中位数的。因为我们想要支持所有类型的用户，包括平衡，乐观，悲观和双峰用户，我们将用户的平均值应用为用户喜欢和不喜欢的物品之间的阈值。例如，乐观的用户，就是那些评价的每一个物品都是喜欢的用户，那么评分低于其平均评分的都被认为不喜欢这些物品。该阈值确保了这一点我们的算法对于每个用户都有一定数量的喜欢和不喜欢的物品。</p><p>再次参考图1，像往常一样，我们对用户B对J评分的预测是基于其他用户对J和物品I评分的差（例如用户A）这些用户是同时评论过物品I和J的。BI-POLAR SLOPE ONE算法进一步限制了这组评分这是预测性的。首先是物品，只有两个都喜欢的物品评分的或两个都不喜欢的物品的偏差才会被考虑在内。再次对于用户，对同时评论过物品I和J的用户的偏差以及展现出喜欢或者不喜欢物品I的用户会被用来预测物品J。</p><p>将每个用户分成用户喜欢和用户不喜欢有效地使用户数增加一倍。显然，但请注意两极限制刚刚概述了在计算中减少预测评级的总数预测。虽然准确度有所提高对于这种减少的看法可能看似违反了直觉即数据稀疏性始终是一个问题，未能过滤掉那些无关紧要可能证明更有问题的评论。最重要的是，BI-POLAR SLOPE ONE方案无法预测出用户A喜欢物品K而用户B不喜欢物品K这一事实。</p><p>正式的，我们将每一个u的评论分成两个评论物品的集合：$S^{like}(u) = { i \in S(u)|u_i &gt; \bar u}$和$S^{dislike}(u) = { i \in S(u)|u_i &lt;\bar u}$。对于每个物品对i和j，将所有相关评论组成的集合$\chi$分成$S_{ij}^{like}= { u \in \chi|i,j \in S_{like}(u)}$和$S_{i,j}^{dislike} = {u \in \chi| i,j \in S^{dislike}(u)}$。使用这两个集合，我们计算下面的喜欢物品偏差矩阵，类似的不喜欢的物品偏差矩阵就是$dev_{j,i}^{dislike}$：</p><script type="math/tex; mode=display">dev_{j,i}^like = \sum_{u \in S_{j,i}^{like}(\chi)} \frac{u_j - u_i}{card(S_{j,i}^{like}(\chi))}</script><p>物品j的评分预测是基于物品i的评分$p_{j,i}^{like} = dev_{j,i}^{like} + u_i$或者$p_{j,i}^{dislike} = dev_{j,i}^{dislike} + u_i$依赖于i分别属于$S^{like}(u)$还是$S^{dislike}(u)$。</p><p>最终BI-POLAR SLOPE ONE算法可有下式给出：</p><script type="math/tex; mode=display">P^{bpS1}(u)_j = \frac{\sum_{i \in S^{like}(u) - {j}} P_{j,i}^{like} c_{j,i}^{like} + \sum_{i \in S^{dislike}(u) - {j}} p_{j,i}^{dislike} c_{j,i}^{dislike}}{\sum_{i \in S^{like}(u) - {j}} c_{j,i}^{like} + \sum_{i \in S^{dislike}(u) - {j}} c_{j,i}^{dislike}}</script><p>其中权重$c_{j,i}^{like} = card(S_{j,i}^{like})$以及$c_{j,i}^{dislike} = card(S_{j,i}^{dislike})$是类似于一个加权SLOPE ONE算法。</p><h3 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4 实验结果"></a><strong>4 实验结果</strong></h3><p>一个给定的CF算法的有效性是可以被精确测算的。为此，我们使用了All But One Mean Average Error（MAE）[2]。在计算MAE时，我们先后从所有评估中每一次隐藏一个评分剩下的作为测试集，同时预测这个被隐藏的评分，计算我们在预测中犯的错误平均值。给定一个预测模型P以及一个用户的评论u，那么通过评论集合$\chi’$可以得到P的误差率可由下式给到：</p><script type="math/tex; mode=display">MAE = \frac{1}{card(\chi')} \sum_{u \in \chi'} \frac{1}{card(S(u))} \sum_{i \in S(u)} |P(u^{(i)}) - u_i|</script><p>其中$u^{(i)}$是评论集合u，并且其中隐藏了用户对第i个物品的评分。</p><p>我们在由Compaq Research提供EveryMovie数据集以及来自明尼苏达州大学的Grouplens研究小组的Movielens数据上测试我们的方案。数据来自电影评级网站，其中EachMovie评分范围从0.0到1.0，增量为0.2，Movielens的每个电影评分是从1到5的，且增量为1。根据[8,11]，我们使用了足够的评论数据来得到总数为50000个评分数据作为训练集$(\chi)$，和另外一组总数至少100000个评分数据作为测试集$(\chi’)$。当预测结果对给定数据集的评级超出允许范围时，它们会相应地进行更正：一个电影的预测值为1.2，若是范围从0到1则将其看作是预测结果为1。因为Movielens的电影评分范围比MovieMns的每个电影大4倍，那么除以4使结果直接可比。</p><p>不同算法的测试结果汇总在了表1中，它们都是基于同一个数据集以及相同的误差度量得到的。不同的子结果都列在了表格的后面。</p><div class="table-container"><table><thead><tr><th style="text-align:center">Scheme</th><th style="text-align:center">EachMovie</th><th style="text-align:center">Movielens</th></tr></thead><tbody><tr><td style="text-align:center">BI-POLAR SLOPE ONE</td><td style="text-align:center">0.194</td><td style="text-align:center">0.188</td></tr><tr><td style="text-align:center">WEIGHTED SLOPE ONE</td><td style="text-align:center">0.198</td><td style="text-align:center">0.188</td></tr><tr><td style="text-align:center">SLOPE ONE</td><td style="text-align:center">0.200</td><td style="text-align:center">0.188</td></tr><tr><td style="text-align:center">BIAS FROM MEAN</td><td style="text-align:center">0.203</td><td style="text-align:center">0.191</td></tr><tr><td style="text-align:center">ADJUSTED COSINE ITEM-BASED</td><td style="text-align:center">0.209</td><td style="text-align:center">0.198</td></tr><tr><td style="text-align:center">PER USER AVERAGE</td><td style="text-align:center">0.231</td><td style="text-align:center">0.208</td></tr><tr><td style="text-align:center">PEARSON</td><td style="text-align:center">0.194</td><td style="text-align:center">0.190</td></tr></tbody></table></div><p><em>Table 1: All Schemes Compared: All But One Mean Average Error Rates for the EachMovie and Movielens data sets, lower is better.</em></p><p>考虑不同基准方案的测试结果。如期所致，我们发现在本文3.2部分描述的3个基准方案中BIAS FROM MEAN算法表现的最好。然而有趣的是3.4中提到的基础SLOPE ONE方案的准确性比BIAS FROM MEAN还要高。</p><p>在3.5和3.6部分提到的对基础SLOPE ONE进行扩充的算法确实改进了在EachMovie数据集上的准确性。SLOPE ONE算法和WEIGHTED SLOPE ONE之间只存在一点点差距（大概1%）。将不喜欢和喜欢的评论分开的处理能够将结果提高1.5%-2%。</p><p>最后，我们一方面对比了基于记忆的PEARSON方案，另一方面也对比了slope one方案。slope one算法取得了一个相对于PEARSON更具准确性的的结果。这个结果足够支持我们声称的slopeone算法是更合理准确的，尽管他们很简单以及其他理想的特点。</p><h3 id="5-结论"><a href="#5-结论" class="headerlink" title="5 结论"></a><strong>5 结论</strong></h3><p>本文展示了一个易于实现的基于平均评分误差的CF模型，它可以与更多昂贵的基于记忆的方案进行竞争。与目前使用的方案相反，使用我们的方法能够满足5个对抗目标。slope one方案易于实施，动态可更新，在查询时有效，并且对于第一次访问的用户不期望有太多的信息，但相对于其他经常报道的模型依然具有相当的准确性（例如，对于MovieLens，1.90对1.88 MAE）。相比之下，给定一个相对复杂的基于记忆的模型来说slope one算法更为卓越。我们方法的进一步创新是将评论分成不喜欢和喜欢子集，这是一种能够提高准确性的有效技术。希望这里提出的通用型的slope one算法能够给CF算法舍去提供一个有用的参考方案。<br>。<br>请注意，截至2004年11月，WEIGHTED SLOPE ONE是Bell / MSN网站在Disverver.net中使用的协同过滤算法。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://epubs.siam.org/doi/pdf/10.1137/1.9781611972757.43&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：Slope One Predictors for Online Rating-Based Collaborative Filtering&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Slope-One-基于在线评分的协同过滤算法&quot;&gt;&lt;a href=&quot;#Slope-One-基于在线评分的协同过滤算法&quot; class=&quot;headerlink&quot; title=&quot;Slope One: 基于在线评分的协同过滤算法&quot;&gt;&lt;/a&gt;Slope One: 基于在线评分的协同过滤算法&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;基于评级的协同过滤是预测的程序，即根据用户对其他物品的评分来预测用户会如何评分当前给定的物品。我们提出了三个形式为f（x）= x + b的关于slop one机制的预测模型，预先计算出用户共同评分过的一个物品和另一个物品的评分之间的平均差异。slop one算法是易于实现的，查询效率高，相当准确，同时它们支持在线查询和动态更新，这使它们成为现实系统的良好候选者。建议将基本的SLOPE ONE方案作为协同过滤方案的新参考。通过考虑将用户喜欢和不喜欢的物品从全集中分出来，我们通过较慢的基于记忆的方式实现了结果超过基准EveryMovie和Movielens数据集，同时更好地满足了它对协同过滤应用的需求。&lt;/p&gt;
&lt;p&gt;关键词：协同过滤，推荐工具，电子商务，数据挖掘，知识发现&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="CF" scheme="http://www.xiemingzhao.com/tags/CF/"/>
    
  </entry>
  
  <entry>
    <title>Factorization Machines</title>
    <link href="http://www.xiemingzhao.com/2019/04/15/Factorization%20Machines--%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.xiemingzhao.com/2019/04/15/Factorization Machines--学习笔记/</id>
    <published>2019-04-14T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:40.293Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf" target="_blank" rel="noopener">原始论文：Factorization Machines</a></p><h2 id="因式分解机"><a href="#因式分解机" class="headerlink" title="因式分解机"></a>因式分解机</h2><p><strong>摘要</strong>：在本文中，我们介绍了一种因式分解机，这是一种新的模型，结合了SVM的优点，利用了因式分解模型。类似SVM，因式分解机是一种通用的预测器，可以适用于任意的实值特征向量。对比SVM，FMs利用因式分解对变量之间的关系进行建模。因此，FMs可以在大量稀疏特征中进行相互关系的估计。我们展示了，模型的表达式可以在线性时间内求解，FMs可以进行直接的优化。所以，不像非线性的SVM，不需要进行对偶变换，模型的参数可以直接的进行估计，不需要用到支持向量。我们展示了和SVM的关系，以及在稀疏的设置下的参数估计的优势。</p><p>另外，有许多因式分解模型如矩阵分解，并行因子分析如SVD++，PITF，FPMC。这些方法的缺点是通用性不好，只对特殊的输入数据有用。优化方法对于不同的任务也各不相同。我们展示了，FMs通过制定不同的输入就可以模拟这些模型。这就使得FMs非常的易用，甚至可以不需要分解模型的专业知识都可以。</p><a id="more"></a><h3 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h3><p>SVM是机器学习和数据挖掘中最流行的算法之一。然而在协同过滤的场景中，SVM并不重要，最好的模型要么直接使用矩阵的因式分解或者使用因式分解参数。本文中，我们会展示，SVM之所以在这些任务中表现不好，是因为SVM在复杂的非线性的稀疏的核空间中很难找到一个好的分割超平面。而张量分解模型的缺点在于（1）不用应用于标准的预测数据（2）不同的任务需要特殊的模型设计和学习算法。</p><p>在本文中，我们介绍了一个新的预测器，Factorization Machine（FM），是一个像SVM一样的通用的预测模型，但是可以在非常稀疏的数据中估计出可靠的参数。FM对所有变量的相互关系的进行建模（对比SVM的多项式核），但是利用了可因式分解的参数，而不是像SVM一样使用了稠密的参数。我们展示了，模型的表达式可以在线性时间内求解，而且只依赖与线性数量大小的参数。这就允许了直接进行优化和存储模型的参数，而不需要存储任何的训练数据。（SVM是需要存储支持向量的）。非线性的SVM通常使用对偶形式进行求解，而且会使用到支持向量。我们也显示了在协同过滤的业务上FMs比许多很成功的模型如带偏置的MF，SVD++，PITF，FPMC等都好。</p><p>总的来说，我们提出的FM的优点有：<br>1）FMs可以在非常稀疏的数据上进行参数估计。<br>2）FMs的复杂度是线性的，方便优化，不像SVM需要依赖支持向量。我们证明FM可以扩展应用在大数据集上，例如有1亿训练样例的Netflix数据集。<br>3）FMs是通用的预测模型，可以适用于任意的实值的特征向量。与此相反，其他先进的分解模型只在特定输入数据的情况下起作用。我们将通过定义输入数据的特征向量来证明这一点，FM可以模仿其他最先进的模型例如带偏置项的MF，SVD++,PITF以及FPMC模型。</p><h3 id="2、在稀疏数据下进行预测"><a href="#2、在稀疏数据下进行预测" class="headerlink" title="2、在稀疏数据下进行预测"></a>2、在稀疏数据下进行预测</h3><p>大部分的常用的预测任务是估计一个预测的函数$y:\mathbb{R}^n \rightarrow T$，从一个实数向量$x \in \mathbb{R}^n$到目标$T$（如果是回归任务$T=R$，如果是分类任务$T={+，-}$）。在监督学习中，假设有个给定y值的样本训练数据集$D = \{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…\}$。我们也研究了排序的任务，拥有目标值$T=\mathbb{R}$的函数y可以适用于对x向量的评分和排序。评分函数可以通过成对的数据进行训练，当一个样本组合$(x_{(A)},x_{(B)})\in D$表示$x_{(A)}$应该排在$x_{(B)}$的前面。由于成对数据是反对称的，可以直接使用正的实例。</p><p>在本文中，我们要解决的问题是数据的稀疏问题，也就是说在x向量中，大部分的值都是0，只有少部分不是0。让$m(x)$表示特征向量x中非0元素的个数，$\bar m_D$表示所有特征向量$x \in D$的非零元素个数$m(x)$的平均值。高稀疏性的特征在现实世界中是非常常见的，如文本分析和推荐系统中。高稀疏性的一个原因是在处理超多类别变量域的潜在问题。</p><p><strong>例1</strong> 假设我们有个电影评分系统的交互数据。系统记录了用户$u\in U$在特定的时间$t \in R$对电影$i \in I$的评分$r \in {1,2,3,4,5}$.用户U和电影I为：</p><p>$U = \{Alice (A), Bob (B), Charlie (C), . . .\}$<br>$I = \{Titanic (TI),Notting Hill (NH), Star Wars (SW),Star Trek (ST), . . .\}$</p><p>用观察到的数据S表示：<br>$S = \{(A, TI, 2010-1, 5), (A,NH, 2010-2, 3), (A, SW, 2010-4, 1),$<br>      $(B, SW, 2009-5, 4), (B, ST, 2009-8, 5),$<br>      $(C, TI, 2009-9, 1), (C, SW, 2009-12, 5)\}$<br>任务是使用这些数据，估计一个函数$\hat y$，这个函数能够预测一个用户在某个时间对某个电影的评分。</p><p><img src="https://i.postimg.cc/qRd59r8J/relate-papers18-1.jpg" alt="relate-papers18-1.jpg"></p><p>图1展示了一个示例，在这个任务中如何从观测数据S中构建特征向量。在这里，首先$|U|$是一个二值示性变量（蓝色的），它表示一个交互中活跃的用户，总是可以确定的是在一次交互$(u,i,t,r) \in S$中有一个确定的活跃用户。例如，第一行中的Alice($x_A^{(1)} = 1$)。下一个二值示性变量$|I|$（红色的）表示活跃的物品，同样的总是有一个活跃的物品，例如$x_{TI}^{(1)}=1$。图1中的特征向量也包含了用来表示用户曾经评价过的其他物品的表示向量（黄色的）。对于每个用户来说，变量均是被归一化之后的。例如Alice评价过Notting Hill 和 Star Wars。此外，样本还包含一个从2019年一月开始的月份向量（绿色的）来表示时间。最后几列表示用户评价过的最后一个电影，最右边的是当前电影的评分y。在第五部分，我们将展示因式分解机是如何利用输入数据中的特征向量来做到最特殊的顶级的因式分解模型的。</p><p>我们将通过这篇论文用这个示例数据集来证明。然而，请注意FMs是一个像SVMs一样的通用模型，可以应用在任何一个现实中的特征向量，并且对推荐系统没有什么限制。</p><h3 id="3-因式分解机-FM"><a href="#3-因式分解机-FM" class="headerlink" title="3.因式分解机(FM)"></a>3.因式分解机(FM)</h3><p>在这一部分，我们将来介绍因式分解机。我们会详细地讨论模型中的公式推导，并且会展示怎么使用FMs进行多预测任务。</p><p><em>A. 因式分解模型</em><br>1）模型方程：2维的因式分解机模型方程：</p><script type="math/tex; mode=display">\hat y(x):=w_0 + \sum_{i=1}^n w_i x_i + \sum_{i=1}^n \sum_{j=i+1}^n  \langle v_i,v_j \rangle x_i x_j</script><p>公式中的模型参数必须在下面的值域中进行估计：</p><script type="math/tex; mode=display">w_0 \in \mathbb{R}, w \in \mathbb{R}^n, V \in \mathbb{R}^{n \times k}</script><p>其中，$ \langle ·,· \rangle $表示长度为k的点乘，k是一个超参数：</p><script type="math/tex; mode=display">\langle v_i, v_j \rangle  := \sum_{f=1}^kv_{i,f} \cdot v_{j,f}</script><p>V中的行向量$v_i$表示第k个因子的第i个变量。$k \in \mathbb{N}_0^+$是一个产参数定义了因式分解的维度。</p><p>一个2阶的FM能过获取所有的单个特征和配对特征的相互关系：</p><ul><li>$w_0$是全局偏置项。</li><li>$w_i$是模型中的第i个变量的权重。</li><li>$ \hat w_{i,j}:= \langle v_i,v_j \rangle $表示模型中第i个变量和第j个变量之间的交互项。如此就不是用唯一的模型参数$w_{i,j} \in \mathbb{R}$来作为FM模型中因式分解交互项的权重了。在后面我们将看到，当遇到高维且稀疏的数据的时候，这是进行高质量参数估计的关键点。</li></ul><p>2）表达能力：我们知道对于正定矩阵W，存在矩阵V，使得$W=V\cdot V^t$，k足够大。这表明了当k足够大的时候FM能够表示矩阵W中的任何交互项。然而对于稀疏的情况，应该选择一个比较小的k，因为没有足够的数据去预测一个复杂的W。限制k，也就是FM的表达能力，能够提高稀疏情况下的相互关系矩阵的泛化性能。</p><p>3）稀疏情况下的参数估计：在稀疏情况下，通常没有足够的数据进行直接的参数估计。因式分解机可以进行稀疏的估计，甚至在稀疏的情况下可以估计的很好，这是因为它打破了交互项参数和因式分解之间的独立性。总的来说是因为进行了因式分解之后，用来估计一个参数的数据也可以用来估计相关的另一个参数。我们将利用图1中的数据举个例子来更清晰地描述我们的想法。假设我们想估计Alice(A)和Star Trek(ST)交互项的参数来预测目标值y（这里是评分）。很显然，在一个样本中，两个用户$x_A,x_{ST}$的参数不会都是非0数，如果直接进行估计的话，那么A和ST的相互关系参数会估计成0。但是如果使用因式分解将参数分解长$ \langle v_A,v_{ST} \rangle $的话，在这个案例中我们就可以直接进行估计了。</p><p>4）计算量：接下来，我们展示如何让FMs变得实际可用。前面提到的方程（1）的计算复杂度是O(kn2)，因为所有的称为交互项必须倍计算。但是改变一下之后将会使其复杂度降低到线性的。</p><p>引理3.1：因式分解机的计算复杂度可以变成线性的时间复杂度O(kn)。</p><p>证明：由于所有的成对交互项都会做因式分解，于是模型中就没有需要直接利用两个变量进行直接估计的参数。所有成对的交互项可以进行如下的变化：</p><script type="math/tex; mode=display">\begin{align}&\sum_{i=1}^n \sum_{j=i+1}^n  \langle v_i, v_j \rangle x_i x_j\\=&\frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n  \langle v_i, v_j \rangle x_i x_j - \frac{1}{2} \sum_{i=1}^n  \langle v_i, v_i \rangle x_i x_i \\=&\frac{1}{2} (\sum_{i=1}^n \sum_{j=1}^n \sum_{f=1}^k v_{i,f} v_{j,f} x_i x_j - \sum_{i=1}^n \sum_{f=1}^k v_{i,f} v_{i,f} x_i x_i) \\=&\frac{1}{2} \sum_{f=1}^k ((\sum_{i=1}^n v_{i,f} x_i)(\sum_{j=1}^n v_{j,f} x_j)-\sum_{i=1}^n v_{i,f}^2  x_i^2) \\=&\frac{1}{2} \sum_{f=1}^k((\sum_{i=1}^n v_{i,f} x_i)^2 - \sum_{i=1}^n v_{i,f}^2 x_i^2)\end{align}</script><p>以上的公式的结果仅仅有线性的计算复杂度，当k和n固定的时候，计算复杂度就为O(kn)。</p><p>进一步，在稀疏性的条件下，x中的大部分元素值都是0，因此求和就可以只在非0的元素中进行。因此在稀疏数据中因式分解机的计算复杂度就在$O(k\bar m_D)$，例如当$\bar m_D=2$时就是一个经典的推荐系统例如MF算法。</p><p><em>B. 使用因式分解机进行预测</em><br>因式分解机可以用在各种预测任务中：</p><ul><li>回归：直接进行预测，使用最小均方误差进行优化。</li><li>二分类：使用合页损失或者对数几率损失进行优化。</li><li>排序：对预测的分数进行排序，可以通过成对实例的分类损失进行优化。</li></ul><p>在上面所有的情况下，都可以使用L2的正则化来防止过拟合。</p><p><em>C. 因式分解机的学习</em><br>我们已经证明，FMs有一个确定的模型公式使其计算复杂度达到线性的。因此，FMs的参数$（w_0,w , V）$可以通过梯度下降的方式来求解，例如随机梯度下降法(SGD).FM模型的梯度是：</p><script type="math/tex; mode=display">\frac{\partial}{\partial \theta} \hat y(x)  = \begin{cases}1,& if \ \theta \ is \ w_0 \\x_i,& if \ \theta \ is \ w_i \\x_i\sum_{j=1}^n v_{j,f}x_j - v_{j,f}x_i^2,& if \ \theta \ is \ v_{i,f}\end{cases}</script><p>其中，求和项$\sum_{j=1}^n v_{j,f}x_j$是和i无关的，可以事先求出来。总的来说，每个梯度都可以在O(1)时间内求得。对于给个案例(x,y)整体的参数更新的时间为O(kn)，稀疏数据的时候则为O(km(x))。</p><p>我们提供了一个通用的实现，<a href="http://www.libfm.org" target="_blank" rel="noopener">LIBFM</a>，使用SGD，支持元素和配对的loss。</p><p><em>D. d阶的因式分解机</em><br>2阶的因式分解机可以很容易的推广到d阶：</p><script type="math/tex; mode=display">\hat y(x) := w_0 + \sum_{i=1}^n w_i x_i + \sum_{l=2}^d \sum_{i_1=1}^n \cdots \sum_{i_l = i_{l-1} + 1}^n (\prod_{j=1}^l x_{i_j}) (\sum_{f=1}^{k_l} \prod_{j=1}^l v_{i_j, f}^{(l)})</script><p>其中，第l个相互关系参数可以通过PARAFAC模型进行因式分解:</p><script type="math/tex; mode=display">V^{(l)} \in \mathbb{R}^{n \times k_l}, k_l \in \mathbb{N}_0^+</script><p>通过变换，同样可以在线性的时间复杂度上求解，复杂度降为$O(k_d n^d)$。</p><p><em>E. 总结</em><br>FMs的优点：<br>1）可以在稀疏的情况下进行很好的参数估计，特别是可以估计没有观测到的相互关系。<br>2）参数的大小和运算时间都是线性的，可以通过SGD进行参数的更新，可以使用多种loss。</p><h3 id="4、FMs-vs-SVMs"><a href="#4、FMs-vs-SVMs" class="headerlink" title="4、FMs vs. SVMs"></a>4、FMs vs. SVMs</h3><p><em>A. SVM模型</em><br>我们知道SVM可以表示成变换后的特征向量x和参数w的内积的形式:$\hat y(x) =  \langle \phi (x),w \rangle $，其中$\phi$是一个映射将特征空间$\mathbb{R}^n$映射到一个更复杂的空间$\mathcal{F}$。这个映射通常使用核函数来进行：</p><script type="math/tex; mode=display">K:\mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}, K(x,z) =  \langle \phi (x),\phi(z) \rangle</script><p>下面我们通过分析SVMs主要形式来讨论FM和SVM之间的关系。</p><p><em>1）线性核</em>：最简单的核函数就是线性核：$ K_l(x,z):=1 +  \langle x,z \rangle  $，这对应的映射就是$\phi (x) := (1,x_1, \cdots , x_n)$。因此线性核的SVM模型等式可以重写为：</p><script type="math/tex; mode=display">\hat y(x) = w_0 + \sum_{i=1}^n w_i x_i, w_0 \in \mathbb{R}, w \in \mathbb{R}^n</script><p>很明显可以发现线性的SVM模型和FM为1阶的情况完全等效</p><p><em>2）多项式核</em>：多项式的核函数可以让SVM模型去拟合更高维的变量交互项。可以定义：$K(x,z) := ( \langle x,z \rangle  + 1)^d$。例如当多项式为2阶的时候，对应如下的映射：</p><script type="math/tex; mode=display">\phi (x) := (1, \sqrt2 x_1, \cdots , \sqrt2 x_n, x_1^2, \cdots ,x_n^2, \sqrt2 x_1 x_2, \cdots , \sqrt2 x_1 x_n, \sqrt2 x_2 x_3, \cdots, \sqrt2 x_{n-1} x_n)</script><p>因此，多项式核函数的SVM模型等式可以重写为：</p><script type="math/tex; mode=display">\hat y(x) = w_0 + \sqrt2 \sum_{i=1}^n w_i x_i + \sum_{i=1}^n w_{i,i}^{(2)} x_i^2 + \sqrt2 \sum_{i=1}^n \sum_{j = i + 1}^n w_{i,j}^{(2)} x_i x_j</script><p>其中模型的参数是：</p><script type="math/tex; mode=display">w_0 \in \mathbb{R}^n, w \in \mathbb{R}^n, W^{(2)} \in \mathbb{R}^{n \times n} (symmetric matix)</script><p>对比多项式核函数的SVM模型和FM模型，可以发现的一点是两个模型交互项全部上升到了2维。而这主要的差别是参数：SVMs的所有交互项参数之间是相互独立的。相反，对于FMs模型来说所有的交互项参数都是经过因式分解的，因此$ \langle v_i, v_j \rangle  and  \langle v_i, v_l \rangle $依赖于各自交叉共享的参数($v_i$)。</p><p><em>B. 稀疏情况下的参数估计</em><br>我们下面解释一下为什么线性和多项式的SVM在稀疏的情况下表现不好。我们将使用用户和物品的表征向量的数据来证明这个协同过滤的例子。这里，特征向量是稀疏的，并且仅仅两个参数是非0的。</p><p><em>1）线性SVM</em>：对于这种数据x,线性的SVM模型等价于下面的等式：</p><script type="math/tex; mode=display">\hat y(x) = w_0 + w_u + w_i</script><p>因为当且仅当$j = u \ or \ j = i$的时候$x_j = 1$。这个模型对应于一个最基础的协同过滤模型，即只有用户和巫婆的偏置项存在。由于这个模型很简单，因为只有少数的几个参数，所以模型的参数的预测在这种稀疏情况下也会不错。但是预测的质量却不好，见图2。</p><p><img src="https://i.postimg.cc/zG6MFKvR/relate-papers18-2.jpg" alt="relate-papers18-2.jpg"></p><p><em>2）多项式SVM</em>：这种情况下，SVM可以获取高阶的相互关系。在我们的系数数据案例中，$m(x)=2$，这时候SVMs模型的等式等价于：</p><script type="math/tex; mode=display">\hat y(x) = w_0 + \sqrt2 (w_u + w_i) + w_{u,u}^{(2)} + w_{i,i}^{(2)} + \sqrt2 w_{u,i}^{(2)}</script><p>首先，$w_u \ and \ w_{u,u}^{(2)}$代表的是同样的，可以期初其中一个例如后者。现在模型的等式就变成了线性的除了有一个额外的用户交叉项$w_{u,i}^{(2)}$。在经典的协同过滤(FM)问题中，对于每个交叉项参数$w_{u,i}^{(2)}$，训练数据中至少有一个观测样本(u,i)，而在测试数据中的案例$(u’,i’)$就一般不会在训练数据及中再次出现了。这意味着对于所有的测试案例(u,i)的交叉项参数来说，最大边际解是0。因此对于预测测试集的时候，多项式SVM对于二阶的交叉项来说没有任何作用；所以多项式核的SVM模型仅仅依赖于用户和物品偏置项，在效果上并没有比线性的SVM好多少。</p><p>对于SVM模型，估计一个高级的交叉项并不是CF模型中的问题，但是当数据是高稀疏性的时候这个问题就存在了。因为对于一个成对的交叉项$(i,j)$想要得到一个可靠的参数估计$w_{i,j}^{(2)}$的话，必须提供足够多的样例$x \in D,where \ x_i \neq 0 \wedge x_i \neq 0$。只要不同时出现$x_i=0,x_j=0$，这个样例就可以用来进行参数估计。<br>总结一下，只要数据比较稀疏的时候，即没有足够的(i,j)的样例的时候，SVMs模型基本上失效的。</p><p><em>C. 总结</em><br>1）SVM的稠密的参数需要相互关系的直接的观测值，而在稀疏的输入的情况下，这种直接的观测值很少。但是FMs模型就可以在稀疏的情况将进行很好的参数估计。<br>2）FMs可以直接进行学习，非线性的SVM通常在对偶形式进行求解。<br>3）FMs的函数不依赖与训练数据SVM的预测依赖部分训练数据（支持向量）。</p><h3 id="5、FMs-vs-其他的因式分解模型"><a href="#5、FMs-vs-其他的因式分解模型" class="headerlink" title="5、FMs vs. 其他的因式分解模型"></a>5、FMs vs. 其他的因式分解模型</h3><p>有各种各样的分解模型，从m-ary类别变量关系的标准模型（例如MF，PARAFAC）到用于特定数据和任务的专用模型（例如SVD ++，PITF，FPMC）。接下来，我们展示一下FM可以仅仅通过使用正确的输入数据就可以模仿很多其他的因式分解模型（例如特征向量x）。</p><p><em>A.矩阵和张量分解</em><br>矩阵分解（MF）是研究最多的因子分解模型之一。它是分解了在两个分类变量之间的关系（例如U和I）。标准处理分类变量的方法是为每个U和I级别定义二值的指标变量（例如见图1，<br>第一个（蓝色）和第二个（红色）组）：</p><script type="math/tex; mode=display">n:=|U \cup I|, x_j := \delta(j=i \vee j=u)</script><p>使用这个特征向量x的FM模型与矩阵分解模型相同，因为$x_j$仅仅在当前u和i是非0的，所以其他的偏置项和交互项都可以舍去：</p><script type="math/tex; mode=display">\hat y(x)=w_0 + w_u + w_i +  \langle v_u, v_i \rangle</script><p>同样的考虑，当有两个以上的分类变量的时候可以发现存在一样的问题，FM包括了一个嵌套并行因子分析模型（PARAFAC）。</p><p><em>B.SVD++</em><br>对于评分预测任务（即回归）来说，Koren将矩阵分解模型改进成了SVD++模型。FM模型就可以使用下列的输入数据来模拟这个模型（就像图一中的前三组）：</p><script type="math/tex; mode=display">\ n:=|U \cup I \cup L|, \ x_j  = \begin{cases}1,& if \ j=i \vee j=u \\\frac{1}{\sqrt{|N_u|}},& if \ j \in N_u \\0,& else\end{cases}</script><p>其中$N_u$是当前用户曾经评论过的所有电影的集合。一个二维的FM模型将以如下方式处理这个数据集：</p><script type="math/tex; mode=display">\hat y(x) = w_0 + w_u + w_i +  \langle v_u, v_i \rangle  + \frac{1}{\sqrt{|N_u|}} \sum_{l \in N_U}  \langle v_i, v_l \rangle  + \\\frac{1}{\sqrt{|N_u|}}\sum_{l \in N_U}(w_l +  \langle v_u, v_l \rangle  + \frac{1}{\sqrt{|N_u|}}\sum_{l' \in N_u, l'  \rangle  l} \langle v_l, v_l' \rangle )</script><p>其中第一部分（即第一行）就等价于一个SVD++模型。但FM还包含一些额外的用户和电影$N_u$之间的交互项，以及$N_u$中电影对之间的电影$N_u$本身和交互项的基础效应。</p><p><em>C.PITF的标签推荐</em><br>标签预测的问题被定义为对于给定的用户和项目组合来排名标签。这意味着有涉及三个分类域：用户U，项目I和标签T.在关于标签推荐的ECML / PKDD发现挑战中，基于分解成对的交互项的模型（PITF）取得了最好成绩[3]。我们将展示FM如何<br>可以模仿这个模型。一个对于活动用户u，项目i和标签t有二值表示变量的分解机的可以写成以下模型：</p><script type="math/tex; mode=display">n:=|U \cup I \cup L|, x_j := \delta (j = i \vee j = u \vee j = t)\\\Longrightarrow \hat y(x)= w_0 + w_u + w_i +  \langle v_u, v_i \rangle  +  \langle v_u, v_t \rangle  +  \langle v_i, v_t \rangle</script><p>由于该模型用于在相同的用户/项目组合（u，i）内的两个标签$t_A,t_B$之间进行排序的，两者都是始终致力于优化和预测案例$（u,i,t_A）和（u,i,t_B）之间的得分差异。因此对于成对排序的优化，FM模型等价于：</p><script type="math/tex; mode=display">\hat y(x) := w_t +  \langle v_u, v_t \rangle  +  \langle v_i, v_t \rangle</script><p>现在二元指标的原始PITF模型和FM模型几乎是相同的。唯一的区别在于（1）FM模型对t具有偏差项$w_t$，（2）$(u,t)-(i,t)$交叉项的标签之间的分解参数$(v_t)$在FM模型中是共享的，但是又不同于原始PITF模型。除了这个理论分析，图3显示了两种模型实现此任务的可比预测质量的经验分布。</p><p><img src="https://i.postimg.cc/LsPWC5gQ/relate-papers18-3.jpg" alt="relate-papers18-3.jpg"></p><p><em>D.分解个性化的马尔科夫链</em><br>FPMC模型尝试基于用户u的最后一次购买(时间t-1)在线上商店进行商品排序。</p><p>再一次仅仅用特征生成，一个二维的因式分解机可以来近似：</p><script type="math/tex; mode=display">\ n:=|U \cup I \cup L|, \ x_j  = \begin{cases}1,& if \ j=i \vee j=u \\\frac{1}{|B_{t-1}^u|},& if \ j \in B_{t-1}^u \\0,& else\end{cases}</script><p>其中$B_{t}^u \subseteq L$是一个用户u在时间t可购买的所有物品的集合，然后：</p><script type="math/tex; mode=display">\hat y(x) = w_0 + w_u + w_i +  \langle v_u, v_i \rangle  + \frac{1}{|B_{t-1}^u|} \sum_{l \in B_{t-1}^u}  \langle v_i, v_l \rangle  + \\\frac{1}{|B_{t-1}^u|}\sum_{l \in B_{t-1}^u}(w_l +  \langle v_u, v_l \rangle  + \frac{1}{|B_{t-1}^u|}\sum_{l' \in B_{t-1}^u, l'  \rangle  l} \langle v_l, v_l' \rangle )</script><p>就像标签推荐一样，这个模型被用来优化排名（这里是排序物品i），因此只有$(u,i_A,t)$和$(u,i_B,t)$之间的评分存在差异的时候会被用于预测和优化的评断标准中。因此，所有额外的不依赖于i都可以消失，FM模型的等式就相当于：</p><script type="math/tex; mode=display">\hat y(x) = w_i +  \langle v_u, v_i \rangle  + \frac{1}{|B_{t-1}^u|}\sum_{l \in B_{t-1}^u} \langle v_i, v_l \rangle</script><p>现在人们可以看到原始的FPMC模型和FM模型几乎是相同的，仅在附加的偏置项$w_i$中有所不同，以及FM模型中的(u,i)和(i,l)交互项物品的分解参数的共享。</p><p><em>E.总结</em><br>1）标准分解模型，如PARAFAC或MF不是像因式分解机这样的一般预测模型。相反，他们需要特征向量被分成m个部分，每个部分都是精确的一个元素是1，其余元素是0。<br>2）有许多关于专业化因子分解的建议为单个任务设计的模型。我们已经证明了这一点，因式分解机可以模仿许多最成功的分解模型（包括MF，PARAFAC，SVD++，PITF，FPMC）只需通过特征提取即可，这使得FM在实践中很容易应用。</p><h3 id="6、结论"><a href="#6、结论" class="headerlink" title="6、结论"></a>6、结论</h3><p>在这片论文中，我们介绍了因式分解机。FMs融合了SVM模型的泛化能力以及因式分解模型的优势。不同于SVM模型，1)FMs可以在高稀疏的情况下进行参数估计，2)模型等式是线性的并且仅依赖于模型的参数，因此3)它们可以在原始等式中进行优化。FMs模型的解释力相当于多项式SVMs模型。不同于像PARAFAC这种张量因子分解模型，FMs是一个泛化的模型，它可以处理任何实值向量。再者，可以通过在输入特征向量中使用正确的表征来进行简化，FMs相对于其他特别高级的模型来说是更单一且非常简单的，不像那些模型仅仅只能应用在特定的任务重，例如MF, SVD++, PITF和FPMC。</p><p><a href="https://www.jianshu.com/p/a194e05aeb53" target="_blank" rel="noopener">参考博文:点击率预测《Factorization Machines》论文精读-ronghuaiyang</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：Factorization Machines&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;因式分解机&quot;&gt;&lt;a href=&quot;#因式分解机&quot; class=&quot;headerlink&quot; title=&quot;因式分解机&quot;&gt;&lt;/a&gt;因式分解机&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;：在本文中，我们介绍了一种因式分解机，这是一种新的模型，结合了SVM的优点，利用了因式分解模型。类似SVM，因式分解机是一种通用的预测器，可以适用于任意的实值特征向量。对比SVM，FMs利用因式分解对变量之间的关系进行建模。因此，FMs可以在大量稀疏特征中进行相互关系的估计。我们展示了，模型的表达式可以在线性时间内求解，FMs可以进行直接的优化。所以，不像非线性的SVM，不需要进行对偶变换，模型的参数可以直接的进行估计，不需要用到支持向量。我们展示了和SVM的关系，以及在稀疏的设置下的参数估计的优势。&lt;/p&gt;
&lt;p&gt;另外，有许多因式分解模型如矩阵分解，并行因子分析如SVD++，PITF，FPMC。这些方法的缺点是通用性不好，只对特殊的输入数据有用。优化方法对于不同的任务也各不相同。我们展示了，FMs通过制定不同的输入就可以模拟这些模型。这就使得FMs非常的易用，甚至可以不需要分解模型的专业知识都可以。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="FM" scheme="http://www.xiemingzhao.com/tags/FM/"/>
    
  </entry>
  
  <entry>
    <title>Amazon.com Recommendations- Item-to-item collaborative filtering</title>
    <link href="http://www.xiemingzhao.com/2019/04/15/Amazon.com%20Recommendations-%20Item-to-item%20collaborative%20filtering--%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.xiemingzhao.com/2019/04/15/Amazon.com Recommendations- Item-to-item collaborative filtering--学习笔记/</id>
    <published>2019-04-14T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:39.444Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf" target="_blank" rel="noopener">原始论文：Amazon.com Recommendations: Item-to-item collaborative filtering</a></p><h2 id="亚马逊推荐：物到物的协同过滤"><a href="#亚马逊推荐：物到物的协同过滤" class="headerlink" title="亚马逊推荐：物到物的协同过滤"></a>亚马逊推荐：物到物的协同过滤</h2><p>推荐算法因在电子商务网站的应用而广为人知，它们用客户的兴趣爱好作为输入来生成物品的推荐列表。许多应用仅仅用用户明确购买的物品来代表兴趣爱好，dan但其实它们可以用更多的其他特征，包括看过的物品，人口统计下数据，主题兴趣以及最爱的艺术。</p><p>在Amazon.com，我们使用推荐算法为每个客户个性化在线商店。商店根据客户的兴趣从根本上改变，达到给软件工程师显示编程主题和给一位新妈妈展示婴儿玩具。点击率和转化率这两个基于Web和电子邮件的重要测算结果显示了其二者上的广告效果要远远超过横幅广告等非目标内容和畅销书清单。</p><p>电子商务推荐算法经常在不断变化的环境中运行。例如：</p><a id="more"></a><ul><li>一个大的零售商一般会有大量的数据。数以千万计的客户和百万级的不同品类的商品。</li><li>许多应用就需要推荐的结果可以实时返回，不能超过半秒，同时还要保证一定的高质量推荐。</li><li>新用户是基于其仅有的一些购买和产品评分导致拥有极其有限信息的典型案例。</li><li>老用户由于有大量的购买和评分数据使得其拥有大量的信息。</li><li>用户数据是不稳定的：每一次交互都会产生有价值的用户数据，算法必须及时的根据新信息做出反馈。</li></ul><p>一般有三种方法来解决推荐问题：传统的协同过滤，聚类模型，基于搜索的方法。这里，我们用这些方法和我们的算法进行比较，我们的算法称为物到物的协同过滤。不像传统的协同过滤，我们算法的在线大规模计算能力不收用户量和产品量以及产品类别的影响。我们的算法可以实时的生成推荐，并且可以大规模地处理数据集，同时能够生成高质量的推荐。</p><h2 id="推荐算法"><a href="#推荐算法" class="headerlink" title="推荐算法"></a>推荐算法</h2><p>大多数的推荐算法开始都是找一群购买以及评论的产品和推荐目标用户购买过以及评论过的产品有交集的用户。然后从这些相似的用户中聚合出来这些物品，再去除他们已经购买和评论过的物品。这些算法里两个比较流行的版本是协同过滤和聚类模型。其他的算法-包括基于搜索的方法以及我们的物到物的协同过滤，都是集中于找到相似的物品而不是相似的用户。对于每个用户购买和评论过的商品来说，算法尝试去找到相似的物品。然后它聚合出这些相似的物品并推荐它们。</p><h2 id="传统的协同过滤"><a href="#传统的协同过滤" class="headerlink" title="传统的协同过滤"></a>传统的协同过滤</h2><p>一个传统的协同过滤算法将一个用户表示成一个N维的物品向量，N是不用品类的物品数。向量中的元素正的代表用户购买过或者正向评分过的物品，负的代表负向评分的物品。为了补偿那些畅销的产品，该算法通常将用户向量乘以逆频率（对物品有购买或者评分行为的用户数量），使得较不为人知的物品更具有相关性。对于大多数用户来说，这个向量极度稀疏。</p><p>算法基于和目标用户极为相似的一小部分用户产生推荐。有各种各样的方法计算A和B两个用户之间的相似度，普遍采取的方法是两个用户向量之间的cosine角度：</p><script type="math/tex; mode=display">similarity(\vec{A},\vec{B})=\cos(\vec{A},\vec{B})=\frac{\vec{A} \bullet \vec{B}}{||\vec{A}|| \ast ||\vec{B}||}</script><p>从相似用户的物品中选择推荐物品的算法也有很多，一种通用的方法是按照物品被相似用户购买的数量排序。</p><p>使用协同过滤产生推荐计算花费大。最坏的复杂度是O(MN)，其中M是用户数N是产品数，因为对于每个目标用户测试了M个用户以及产品数的上限N。然而，由于用户购买行为的稀疏性，算法最终的花费接近于o(M+N)，因为大部分用户的向量只包含很小数量的物品，不论产品类目有多少。但是有一小部分用户购买和评论了大量的物品质的计算花费时间接近o(N)。因此，算法最终的花费大约为o(M+N)。甚至因此，对于非常大的数据集-例如1000万或更多客户和100万或更多类目产品-算法遇到严重的性能和扩展问题。</p><p>可以通过减小数据规模部分解决计算花费问题。我们可以通过随机抽样客户或丢弃购买少的客户减少M，通过丢弃非常受欢迎或不受欢迎的项目减少N。也可以基于产品类别或主题分类的空间通过分割项目的一个小的、恒定的因素来减少检查的项目数量。降维等技术作为聚类和主成分分析可以大幅减少M或N。</p><p>不幸的是，所有减小数据规模的方法都会降低推荐质量。首先，如果算法近检测一小部分用户样本，那么这些被选中的用户就不会与目标用户那么的相似。第二，品类空间的划分限制了特定产品和主题领域的推荐。第三，如果算法丢弃了最受欢迎或者最不受欢迎的物品，那么它们经永远不会出现在推荐之中，并且仅购买这些物品的客户也得不到这些推荐。将为技术应用于物品空间往往会起到消除低频品类物品的类似效应。降维技术类似于用户分组有效地应用于用户空间，就如我们现在所描述的，这样的聚类也可以降维推荐质量。</p><h2 id="聚类模型"><a href="#聚类模型" class="headerlink" title="聚类模型"></a>聚类模型</h2><p>为了找到那些与目标用户相似的客户，聚类模型将用户分为很多segments，将寻找目标用户相似用户的任务视为一个分类任务。算法目标是将目标用户分配到包含最相似用户的segment中，然后使用segment中用户购买的商品和评分产生推荐。</p><p>通常segments是用聚类模型或者其他无监督的学习算法构建的，虽然有些应用程序使用手动确定segments。使用相似性矩阵，聚类算法将最相似的客户分组一起形成集群或segments。因为对大数据集进行最优聚类是不切实际的，大多数应用程序使用各种形式贪婪的聚类生成算法。通常这些算法从一组初始段开始，且经常会包含一个随机选择的客户。然后他们反复匹配客户到现有的segments中，通常碎玉创建新的或合并现有的segments有一些规定。对于非常大的数据集-特别是那些高数据集维度 - 抽样或降维也是必要的。</p><p>一旦算法生成了segments，就会计算每个用户与每个segments总结向量之间的相似性，然后选择具有最强的相似性segments并根据此对用户进行分类。一些算法将用户分类为多个部分并描述其每个关系的强弱。</p><p>聚类模型相比CF有更好的在线可扩展性和表现，因为聚类算法只将用户和可控制的segments数量进行比较而不是所有用户。复杂花费高的聚类计算是在离线进行的。然而，推荐质量却很低。聚类模型将许多用户分组在一起形成一个segment，将一个用户匹配到一个segment中，然后考虑在这个细分市场中说所有客户的相似客户来产生推荐。由于聚类模型找到的相似客户并不一定是最相似的客户，所以他们产生的推荐并没有太大的相关性。为了提高推荐质量，可以增加类别数量，但这会加大用户在线计算类别的花费。</p><h2 id="基于搜索的模型"><a href="#基于搜索的模型" class="headerlink" title="基于搜索的模型"></a>基于搜索的模型</h2><p>基于搜索或者内容的模型将推荐看作是一个搜索相关物品的问题。给定一些用户的购买和评级的物品，算法会构造搜索查询找到同一作者的其他热门产品，艺术家，导演，以及类似的关键词或<br>主题。如果客户购买了教父DVD收藏，例如，系统可能会推荐其他犯罪剧集，其他马龙白兰度主演的，或其他弗朗西斯福特科波拉导演的电影。</p><p>如果用户只有很少的购买和评分记录，基于搜索的推荐算法可规模化并表现地很好。然而，对于那些有成千上万的购买记录的用户来说，基于一个所有物品的请求来进行推荐是不实际的。算法必须只是用数据集中的一个子集或者汇总数据，这会降低推荐质量。以上例子中，推荐的质量相对较差。推荐结果经常会太宽泛（例如最好卖的电视剧DVD主题）或者太狭隘（例如相同作者的所有书籍）。推荐应该是帮助客户去寻找和发现新的，相关的并且有趣的物品。同一作者的流行作品以及相似主题的类别物品都是不能满足这一目标的。</p><h2 id="物到物的协同过滤"><a href="#物到物的协同过滤" class="headerlink" title="物到物的协同过滤"></a>物到物的协同过滤</h2><p>Amazon.com将推荐作为许多电子邮件活动以及它的大部分网站页面中的营销工具，包括高流量的Amazon.com主页。点击“您的推荐”链接将会引导客户访问一个推荐区域，在这里他们可以通过产品线和主题领域来进行筛选，也可以评价推荐的产品，评价他们以前购买的物品，同时可以看到为什么这些物品被推荐了（如图片1所示）。</p><p>如图2所示，是我们的购物车推荐，根据客户购物车中的物品给他们推荐了一些商品。该功能类似于在超市收银台旁的那些易冲动消费的物品，但我们的冲动项目针对每个客户的。</p><p>亚马逊网站基于他们客户的兴趣广泛地使用推荐算法来个性化他们的网站。由于现存的推荐算法无法扩展到亚马逊网站上数以千万的客户和产品，所以我们开发自己的推荐算法。我们的算法是物到物的协同过滤，可以扩展到巨大的数据集并实时产生高质量的推荐。</p><p><img src="https://i.postimg.cc/g09pWKK0/relate-papers6-1.jpg" alt="图1"><br><img src="https://i.postimg.cc/BnP3kzHy/relate-papers6-2.jpg" alt="图2"></p><h2 id="它是怎么工作的"><a href="#它是怎么工作的" class="headerlink" title="它是怎么工作的"></a>它是怎么工作的</h2><p>物到物的协同过滤并不是对目标用户进行匹配到他们相似的客户，而是对他们购买和评论过的物品匹配到相似的物品，然后聚合这些相似的物品生成推荐列表。</p><p>为了确定地匹配出给定物品的最相似取票，算法通过寻找那些用户会一起购买的物品来建立了一个相似物品表。我们可以构建产品到产品的矩阵通过迭代所有项目对和计算每对的相似性度量。然而，许多产品对没有共同的客户，因此，这种方法效率低下在处理时间和内存使用情况上面。下面的迭代算法提供了一个更好地方法来计算一个商品和其他所有商品之间的相似性。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">For each item in product catalog, I_1</span><br><span class="line">    For each customer C who purchased I_1</span><br><span class="line">        For each item I_2 purchased by</span><br><span class="line">            customer C</span><br><span class="line">            Record that a customer purchased I_1</span><br><span class="line">            and I_2</span><br><span class="line">    For each item I_2</span><br><span class="line">        Compute the similiarity between I_1 and I_2</span><br></pre></td></tr></table></figure></p><p>有各种各样的方法可以计算两者之间的相似性，但一个常见的方法是使用我们之前描述的余弦量度，其中每个向量对应一个物品而不是一个客户，矢量的M维度对应已购买该商品的客户。</p><p>这种相似物品表的离线计算是非常耗时的，O（N2M）为最糟糕的情况。然而，在实践中，它更接近于O（NM），因为大多数客户购买的很少。对购买最畅销主题的客户进行抽样可以进一步减少运行时间，同时会伴随一点质量降低。</p><p>给定一个相似物品表，算法会找到与用户购买的每个项目类似的项目评分，汇总这些项目，然后推荐最受欢迎或相关的项目。这个计算非常快，仅取决于用户购买或评级的商品数量。</p><h2 id="扩展性：比较"><a href="#扩展性：比较" class="headerlink" title="扩展性：比较"></a>扩展性：比较</h2><p>Amazon.com拥有超过2900万客户和数百万品类物品。其他专业零售商拥有相对较大的数据来源。这些数据是一个机会也是一个诅咒，打破了设计算法的背后对于数据集小三个数量级。几乎所有现有的算法都经过了小数据集评估。例如，MovieLens数据set4包含35,000个客户和3,000个项目，并且EveryMovie数据集3包含4,000个客户和1,600项。</p><p>对于非常大的数据集，可扩展的推荐算法必须执行最昂贵的离线计算。如下简要比较显示，现有方法不足：</p><ul><li>传统的协调过滤做很少的甚至没有离线计算，并且它的在线计算的扩展性受到客户和物品数量的限制。算法在大数据集上运行是不现实的，除非它用降维，抽样或者分区等方法，这些都会降低推荐质量。</li><li>聚类模型可以在离线计算中有很大的表现，但是推荐质量相对很差。为了提升它，可以增加聚类中的segments，但是这会使得在线用户的segment分类变得很复杂。</li><li>基于搜索的模型离线建立了关键词，品类和作者指标，但是没能够提供一个又去的目标推荐。他们都很难扩展到那些有大量购买和评论的记录的用户。</li></ul><p>物到物协同过滤扩展性和表现的关键创建一个花费很高的离线计算得到的相似物品表。这个算法的在线部分就是与寻找用户购买和评论过物品的相似物品，其可扩展性与品类大小和总客户数量不相关；仅仅与用户有多少的购买和评论记录有关。因此，即使在很大的数据集上算法也可以运行的很快。由于算法推荐高度相关的相似物品，因此推荐质量是极高的。不像传统的协同过滤，算法也可以在有限的用户数据的条件下表现得很好，可以基于两到三个物品的数据产生高质量的推荐。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>推荐算法通过为每位客户创建个性化的购物体验提供了有效的目标营销形式。对于亚马逊等大型零售商，一个很好的推荐算法可扩展到非常大客户群和产品目录，要求仅仅亚秒处理时间以生成在线推荐，能够对改变用户的数据立即做出反应，并为所有用户提供吸引人的推荐，无论他们的购买和评级物品的数量多少。不像其他的算法，物到物的协同过滤能够迎接这一挑战。</p><p>在未来，我们期待零售业更广泛地应用推荐算法来达到有针对性的营销，在线和离线均是如此。而电子商务企业拥有最简单的个性化工具，技术的转换率提高与传统的大规模方法相比这些方法对于离线的零售商来说也会使其脱颖而出，在用户的邮件邮寄，优惠券和其他形式的客户沟通。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：Amazon.com Recommendations: Item-to-item collaborative filtering&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;亚马逊推荐：物到物的协同过滤&quot;&gt;&lt;a href=&quot;#亚马逊推荐：物到物的协同过滤&quot; class=&quot;headerlink&quot; title=&quot;亚马逊推荐：物到物的协同过滤&quot;&gt;&lt;/a&gt;亚马逊推荐：物到物的协同过滤&lt;/h2&gt;&lt;p&gt;推荐算法因在电子商务网站的应用而广为人知，它们用客户的兴趣爱好作为输入来生成物品的推荐列表。许多应用仅仅用用户明确购买的物品来代表兴趣爱好，dan但其实它们可以用更多的其他特征，包括看过的物品，人口统计下数据，主题兴趣以及最爱的艺术。&lt;/p&gt;
&lt;p&gt;在Amazon.com，我们使用推荐算法为每个客户个性化在线商店。商店根据客户的兴趣从根本上改变，达到给软件工程师显示编程主题和给一位新妈妈展示婴儿玩具。点击率和转化率这两个基于Web和电子邮件的重要测算结果显示了其二者上的广告效果要远远超过横幅广告等非目标内容和畅销书清单。&lt;/p&gt;
&lt;p&gt;电子商务推荐算法经常在不断变化的环境中运行。例如：&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="推荐系统" scheme="http://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="CF" scheme="http://www.xiemingzhao.com/tags/CF/"/>
    
  </entry>
  
  <entry>
    <title>The Learning Behind Gmail Priority Inbox</title>
    <link href="http://www.xiemingzhao.com/2019/03/19/The%20Learning%20Behind%20Gmail%20Priority%20Inbox--%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.xiemingzhao.com/2019/03/19/The Learning Behind Gmail Priority Inbox--学习笔记/</id>
    <published>2019-03-18T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:43.978Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/36955.pdf" target="_blank" rel="noopener">原始论文：The Learning Behind Gmail Priority Inbox</a></p><h2 id="Gmail优先收件箱背后的学习"><a href="#Gmail优先收件箱背后的学习" class="headerlink" title="Gmail优先收件箱背后的学习"></a>Gmail优先收件箱背后的学习</h2><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Gmail的优先收件箱功能是按用户会对邮件进行操作新行为的概率来对邮件进行排名的。因为“重要性”非常个性化的，我们尝试通过学习每个用户统计模型来预测它，并尽可能的频繁地更新模型。本研究报告描述了在线学习的挑战通过数百万个模型，以及采用的解决方案。</p><h2 id="1-Gmail的优先收件箱"><a href="#1-Gmail的优先收件箱" class="headerlink" title="1 Gmail的优先收件箱"></a>1 Gmail的优先收件箱</h2><p>许多Gmail用户每天都会收到数十或数百封邮件。优先收件箱试图缓解这种信息过载，主要通过学习每个用户的重要性统计模型和基于用户对该邮件采取行动的可能性对邮件进行排名来做到。这不是一个新问题[3,4]，但为了要规模性的做到这一点，需要每天对数百万个模型进行实时排名和近线在线更新会使问题复杂化。这种挑战包括在明确的用户标签的情况下来推断没有邮件的重要性;找到处理非静止和含有噪声的训练数据;构建减少培训数据要求的模型;存储和处理每个用户太字节的特征数据;最后，以分布式和容错的方式进行预测。</p><a id="more"></a><p>虽然从Gmail垃圾邮件检测从机器学习的应用中借鉴了想法[6]，但由于用户对什么是重要事项持不同意见，这是需要高度个性化的，因此重要性排名更难。结果这成为了ML在Google上面临的最大且面向用户的应用程序之一。</p><h2 id="2-学习问题"><a href="#2-学习问题" class="headerlink" title="2 学习问题"></a>2 学习问题</h2><h3 id="2-1-特征"><a href="#2-1-特征" class="headerlink" title="2.1 特征"></a>2.1 特征</h3><p>几个类别的特征却包含了成千上百的具体特征。<em>社会特征</em>是基于发送者和接收者之间交互的程度，例如发件人邮件的被收件人阅读的百分比。<em>内容特征</em>尝试识别与收件人在邮件上行为（或无行为）高度相关的标题和最近的术语，例如在该主题中存在最近的术语。在学习之前的预处理步骤中发现了最近的用户术语。<em>路线特征</em>会记录用户的到目前为止与路线的交互，例如，如果用户开始一个帖子。<em>标签功能</em>检查用户用来筛选邮件的标签。我们在排名期间计算特征值，并且我们暂时存储这些值以供以后学习。<em>连续型特征</em>会自动分区为二值特征，通过在特征值的直方图上使用简单的ID3样式算法来实现。</p><h3 id="2-2-重要性矩阵"><a href="#2-2-重要性矩阵" class="headerlink" title="2.2 重要性矩阵"></a>2.2 重要性矩阵</h3><p>优先收件箱的目标就是在没有确切用户标签的条件下进行邮件排序，并且要允许系统达到“开箱即用”的工作效果。真正实地的重要性是基于在邮件发送后用户和其之间的互动。我们的目标是预测在邮件发送后的T秒内用户与邮件产生互动的概率，然后按照此进行邮件排序，我们预测的概率$p=Pr(a\in A,t \in  (T_{min},T_{max})|f,s)$;这里的a是在邮件上的行为，A是贡献重要性的行为集合（例如打开，回复，手动修正），t是邮件发送后和产生行为之间的时间间隔，f是特征的向量，s表示用户有机会能够看到邮件。</p><p>要注意的是$T_{min}$是给用户有机会对新邮件进行操作的必要时间，但是这也收到我们能够多频繁地更新模型的限制。但肯定是小于24小时的。还要注意的是$T_{max}$限定了我们需要考虑进行存储和处理成邮件特征的可得到的资源数据。这是按天进行测算的。一个结论是大于$T_{max}$的时间区间中的用户行为是不会进入训练数据的。总结一下，预测误差是：</p><script type="math/tex; mode=display">e=\left\{\begin{aligned}&0 &if \urcorner{s} \vee t \notin (T_{min},T_{max})\\&1-p &if a \in A \\&z &otherwise\end{aligned}\right.</script><h3 id="2-3-模型"><a href="#2-3-模型" class="headerlink" title="2.3 模型"></a>2.3 模型</h3><p>我们用简单的线性逻辑回归模型来进行规模性的学习和预测。我们有大量的数据可以用来训练一个全局的模型，但是对于具体到单个用户的个性化模型来说就没有充足的数据来进行学习了。我们用一个简单的形式来转换学习方式，那就是将全局模型和用户个性化模型的对数概率和作为最终的预测值。</p><script type="math/tex; mode=display">s=\sum_{i=1}^nf_ig_i+\sum_{i=1}^{n+}</script><script type="math/tex; mode=display">p=\frac{1}{1+exp^{-s}}</script><p>特征的个数用n来表示，我们用了k个没有出现在全局模型中的用户个体特征。全局模型的权重系数g是互相独立地进行更新的，并且当个性化模型更新时其是固定的。因此，个性化模型的权重系数w仅仅代表了这个用户相对于全局模型是有多么的<em>不同</em>。这样的结果使得个性化模型变得更加简洁，因为在有新的特征加入的时候其可以快速地在全局模型的基础上进行迭代。</p><p>在线被动积极性更新[2]的时候，我们使用PA-II回归变体执行来对抗训练集中的高度噪音。每个邮件仅用于更新一次全局模型和更新一次邮件收件人的模型，例如第i个用户模型权重的更新是</p><script type="math/tex; mode=display">w_{i}\leftarrow w_{i}+f_{i}\frac{sgn(e)max(|e|-\epsilon,0)}{||f||^2+\frac{1}2C}</script><p>其中e是误差，C是正则化参数，用于调整更新的“激进性”，并且$\epsilon$是铰链损失容差，或“被动”的程度。在实践中，我们通过控制C来调整每封邮件代表我们对标签的信任度，例如用户的手动校正会给出更高的值C.用户模型的C值也高于全局模型，新用户模型的C值更高仍然是为了促进初始学习。</p><h3 id="2-4-分类排序"><a href="#2-4-分类排序" class="headerlink" title="2.4 分类排序"></a>2.4 分类排序</h3><p>我们确定s的每个用户阈值，以将每个邮件分类为重要或不重要。我们把这个问题当成排名而不是分类，因为快速调整阈值对于用户感知的表现是至关重要的。想要通过算法方式设定一个阈值从而使得每个用户都有效是很困难的。打开邮件是我们的重要性矩阵中很强烈的信号（第2.2节），但很多用户会打开特别多的邮件这就说明他们只是“感兴趣”而不是表名这个邮件对他们“很重要”。此外，与垃圾邮件分类不同，用户不同意假阳性与假阴性的成本。我们的经验显示了巨大的用户对重要邮件量的偏好之间的差异，这些偏好无法与他们的行为相关联。因此，我们需要用户进行一些手动干预来调整其阈值。当一个用户以一致的方向标记消息，我们对他们的阈值执行一个实时增量。</p><h2 id="3-产品"><a href="#3-产品" class="headerlink" title="3 产品"></a>3 产品</h2><p>将学习扩展到数百万用户与为单个用户调整算法一样困难。储藏和服务模型，以及收集邮件训练数据，我们广泛使用大数据表[1]，其中将分布式文件系统的功能与数据库相结合。</p><h3 id="3-1-预测时间"><a href="#3-1-预测时间" class="headerlink" title="3.1 预测时间"></a>3.1 预测时间</h3><p>优先收件箱以远远超过单台计算机容量的速率对邮件进行排名。要通过处理用户的Gmail帐户的数据中心来预测是很困难的，因此我们必须能够对来自任何数据中心的用户进行打分，且不会延迟邮件传递。大数表用于全局复制并为专门的排名任务来服务模型。特征提取和打分后，另一个大数表用来记录那些用于学习的特征。</p><p>通过维护每个用户的记录：message-id，将数据记录到大数表可以实现邮件功能与后续用户操作的实时合并。因此，模型更新所需的所有数据都是位于同一记录中。如果我们要将所有功能和操作附加到磁盘上的文件中，当它们发生的时候，那就需要数百台机器花费数小时进行聚合和排序用户日志。大数表在许多应用程序中共享这些资源并提供实时记录合并，使数据在全球范围内可用，以便在几分钟内完成学习。</p><h3 id="3-2-学习"><a href="#3-2-学习" class="headerlink" title="3.2 学习"></a>3.2 学习</h3><p>分片学习在概念上很简单。每个核心负责更新一小部分用户模型。面临的挑战是以保持核心繁忙的速度通过网络提供数据。 大数表通过提供对已排序用户：message-id记录的全局访问来完成大量此工作。简单地获取用户模型，为每个消息记录执行更新，然后回写模型是很诱人的。不幸的是，有数百万用户通过网络对单个模型读写的被惩罚为禁止的。有必要进行批量用户模型读写，将许多模型尽可能加载进入RAM。为了提高效率，大数表以近似方式执行批量读取密钥顺序，允许跨持有数据的服务器的并行性。由于消息是由user：message-id键控的，消息可能偶尔不在用户订单中。</p><p>为了评估我们的隐式指标，我们需要知道用户上次在Gmail中处于活动状态。我们不能够确定这一点，直到所有user：message-id记录都被读取，因为它们不是暂时的订阅。这需要两次通过大数表中保存电子邮件数据的每个用户模型的分片。其中第一次通过是计算用户分片上的最后一个动作时间和其他统计信息。大部分需要传输的数据很小，因此第一次传递很快。第二遍扫描所有消息特征数据，执行更新。最后，所有已更改的用户模型都是批量写回到大数表的。因此，每个可用核心按用户ID前缀和该分数给予一小部分用户进一步划分为用户分片，其中所有模型可以同时保存在RAM中（图2）。最终结果是，在非高峰非专用类似桌面机器的条件下，我们可以在每个核心每秒处理35个用户。一些用户有数千个更新，有些用户有一个。这是一个重要的通过24/7专用任务实现真正在线学习的资源节约。</p><h3 id="3-3-数据保护"><a href="#3-3-数据保护" class="headerlink" title="3.3 数据保护"></a>3.3 数据保护</h3><p>所有的用户数据均在谷歌隐私政策条件下进行分析和存储，从消息中提取出的特征数据在训练后就会被删除。为了调试和优化，团队成员仅仅会用他们自己的账户进行特征和统计模型的测试。</p><h2 id="4-结果"><a href="#4-结果" class="headerlink" title="4 结果"></a>4 结果</h2><p>图3展示了一个经典的全局模型的对数概率分的柱状图，其中绿色的表示重要的消息，红色的则表示不重要的。这表示了逻辑回归具有多少的平滑排序功能。每个桶底包含了一个根据对数概率曲线从重要到不重要的比例。</p><p>基于我们隐含的重要性定义，相比于对照组我们的准确度$(tp+tn)/message$接近于$80\pm5\%$。显示偏差导致活跃的优先性收件箱用户的准确度提高2或3％。这个数字比看上去要好。由于阈值调整，我们的假阴性率是假阳性率的3到4倍。用户阅读他们承认并不重要的邮件，因此很多我们的错误否定从用户的角度却应该是正确分类。这说明了确定隐含重要性的困难，数据集中的噪声水平以及评估用户感知质量的挑战。来自用户的手动标记是有价值的，因为它们提供了重要性的真实评估，尽管它们主要来自分类错误并因此具有偏差。从一组160k这样的标记我们计算出仅应用全局的模型与个性化模型和嘉善够个性化阈值的个性化模型间的区别（表1）。趋势是增加个性化可以显着减少错误。</p><p>最终目标是帮助Gmail用户。我们分析了有和没有优先收件箱的条件下Google员工在电子邮件上花费的时间。对收到类似邮件量的Google员工进行取平均值，优先收件箱用户（约2000名用户）整体阅读邮件的时间减少了6％，阅读不重要的邮件时间减少了13％。他们也更有信心批量存档或删除电子邮件。</p><p><img src="https://i.postimg.cc/j2TPvzDn/relate-papers2-1.jpg" alt="relate_papers2-1"></p><p><img src="https://i.postimg.cc/2yxvtVWc/relate-papers2-2.jpg" alt="relate_papers2-2"></p><p><img src="https://i.postimg.cc/CMCj562G/relate-papers2-3.jpg" alt="relate_papers2-3"></p><div class="table-container"><table><thead><tr><th>Combination</th><th style="text-align:center">Error</th></tr></thead><tbody><tr><td>Global model</td><td style="text-align:center">45%</td></tr><tr><td>User models</td><td style="text-align:center">38%</td></tr><tr><td>User models &amp; thresholds</td><td style="text-align:center">31%</td></tr></tbody></table></div><p><em>Table 1: Error rates on user marked mail</em></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/36955.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：The Learning Behind Gmail Priority Inbox&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Gmail优先收件箱背后的学习&quot;&gt;&lt;a href=&quot;#Gmail优先收件箱背后的学习&quot; class=&quot;headerlink&quot; title=&quot;Gmail优先收件箱背后的学习&quot;&gt;&lt;/a&gt;Gmail优先收件箱背后的学习&lt;/h2&gt;&lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;p&gt;Gmail的优先收件箱功能是按用户会对邮件进行操作新行为的概率来对邮件进行排名的。因为“重要性”非常个性化的，我们尝试通过学习每个用户统计模型来预测它，并尽可能的频繁地更新模型。本研究报告描述了在线学习的挑战通过数百万个模型，以及采用的解决方案。&lt;/p&gt;
&lt;h2 id=&quot;1-Gmail的优先收件箱&quot;&gt;&lt;a href=&quot;#1-Gmail的优先收件箱&quot; class=&quot;headerlink&quot; title=&quot;1 Gmail的优先收件箱&quot;&gt;&lt;/a&gt;1 Gmail的优先收件箱&lt;/h2&gt;&lt;p&gt;许多Gmail用户每天都会收到数十或数百封邮件。优先收件箱试图缓解这种信息过载，主要通过学习每个用户的重要性统计模型和基于用户对该邮件采取行动的可能性对邮件进行排名来做到。这不是一个新问题[3,4]，但为了要规模性的做到这一点，需要每天对数百万个模型进行实时排名和近线在线更新会使问题复杂化。这种挑战包括在明确的用户标签的情况下来推断没有邮件的重要性;找到处理非静止和含有噪声的训练数据;构建减少培训数据要求的模型;存储和处理每个用户太字节的特征数据;最后，以分布式和容错的方式进行预测。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="排序" scheme="http://www.xiemingzhao.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>Bag of Tricks for Efficient Text Classification</title>
    <link href="http://www.xiemingzhao.com/2019/03/17/Bag%20of%20Tricks%20for%20Efficient%20Text%20Classification--%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.xiemingzhao.com/2019/03/17/Bag of Tricks for Efficient Text Classification--学习笔记/</id>
    <published>2019-03-16T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:40.045Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1607.01759v2.pdf" target="_blank" rel="noopener">原始论文：Bag of Tricks for Efficient Text Classification</a></p><h2 id="有效的文本分类技巧"><a href="#有效的文本分类技巧" class="headerlink" title="有效的文本分类技巧"></a>有效的文本分类技巧</h2><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本文提出了一种简单而有效的文本分类和表示学习方法。 我们的实验表明，我们的快速文本分类器fastText在准确性方面通常与深度学习分类器保持一致，并且在训练和评估中速度快很多。 我们可以在不到10分钟的时间内使用标准的多核CPU对超过10亿个单词进行快速文本训练，并在不到一分钟的时间内对312K类中的50万个句子进行分类。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>建立良好的文本分类表示是许多应用程序的重要任务，如Web搜索，信息检索，排序和文档分类。 最近，基于神经网络的模型在计算句子表示方面越来越受欢迎。 虽然这些模型在实践中取得了非常好的表现，但是在训练和测试时间，它们往往相对较慢，限制了它们在非常大的数据集上的使用。</p><a id="more"></a><p>与此同时，简单的线性模型也显示出令人印象深刻的性能，同时计算效率非常高。 他们通常学习单词级别的表示，后来组合起来形成句子表示。 在这项工作中，我们提出了这些模型的扩展，以直接学习句子表示。 我们通过引入其他统计数据（如使用n-gram包）来显示，我们减少了线性和深度模型之间精度的差距，同时速度提高了许多个数量级。</p><p>我们的工作与标准线性文本分类器密切相关。 与Wang和Manning类似，我们的动机是探索由用于学习无监督词表示的模型启发的简单基线。 与Le和Mikolov不同的是，我们的方法在测试时不需要复杂的推理，使得其学习表示很容易在不同问题上重复使用。 我们在两个不同的任务中评估模型的质量，即标签预测和情感分析。</p><h2 id="2-模型架构"><a href="#2-模型架构" class="headerlink" title="2 模型架构"></a>2 模型架构</h2><p>句子分类的简单而有效的基线是将句子表示为词袋（BoW）并训练线性分类器，例如逻辑回归或支持向量机。 但是，线性分类器不能在特征和类之间共享参数，可能会限制泛化。 这个问题的常见解决方案是将线性分类器分解成低秩矩阵或使用多层神经网络。在神经网络的情况下，信息通过隐藏层共享。</p><p><img src="https://i.postimg.cc/QtxNVkXX/Model-architecture-of-fast-Text.jpg" alt="Model architecture of fastText.jpg"></p><p>图1显示了一个带有1个隐藏层的简单模型。 第一个权重矩阵可以看作是一个句子单词的查找表。 词表示被平均为文本表示，然后反馈给线性分类器。 这种结构类似于Mikolov等人的cbow模型，其中中间的单词被标签取代。 该模型将一系列单词作为输入，并在预定义的类上生成概率分布。 我们使用softmax函数来计算这些概率。对于N篇文档，我们最小化下面的负的似然值：</p><script type="math/tex; mode=display">-\frac{1}{N}\sum_{n=1}^{N}y_nlog(f(BAx_n))</script><p>训练这样的模型本质上与word2vec相似，也就是说，我们使用随机梯度下降和反向传播以及线性衰减的学习速率。 我们的模型在多个CPU上异步训练。</p><h3 id="2-1-分层softmax"><a href="#2-1-分层softmax" class="headerlink" title="2.1 分层softmax"></a>2.1 分层softmax</h3><p>当目标数量很大时，计算线性分类器的计算量很大。 更准确地说，计算复杂度为O（Kd）O（Kd），其中K是目标的数量，d是隐藏层的维数。 为了改善我们的运行时间，我们使用基于霍夫曼编码树的分层softmax。 在训练期间，计算复杂度降至O（dlog2（K））O（dlog2（K））。 在这棵树上，目标是树叶。</p><p>当搜索最可能的类别时，分层softmax在测试时间也是有利的。 每个节点都与从根节点到该节点的路径概率相关联。 如果节点与父节点n1，…，nl处于深度l + 1，则其概率为</p><script type="math/tex; mode=display">P(n_{l+1}) = \prod_{i=1}^lP(n_i)</script><p>这意味着节点的概率总是低于其父节点的概率。 通过深度遍历探索树并跟踪叶子之间的最大概率允许我们丢弃与较小概率相关的任何分支。 在实践中，我们观察到在测试时O（dlog2（K））O（dlog2（K））的复杂度降低。 这种方法进一步扩展到以O（log（T））O（log（T））为代价，使用二进制堆计算T-top目标。</p><h3 id="2-2-N-gram特征"><a href="#2-2-N-gram特征" class="headerlink" title="2.2 N-gram特征"></a>2.2 N-gram特征</h3><p>单词包对于词序是不变的，但考虑到这个顺序通常在计算上非常昂贵。 相反，我们使用一袋n-gram作为附加功能来捕获有关本地词序的部分信息。 这在实践中非常高效，同时实现了与明确使用订单的方法类似的结果。</p><p>如果我们只使用bigrams，则使用与Mikolov和10M bin相同的哈希函数，否则我们使用哈希函数保持n-gram的快速和高效内存映射。</p><h2 id="3-实验"><a href="#3-实验" class="headerlink" title="3 实验"></a>3 实验</h2><p>我们用两个不同的任务来评估fastText算法。首先，我们拿它跟现有的文本分类算法在情感分析的问题中进行比较。然后，我们再在大规模输出空间的标签预测数据及来评估算法的性能。我们的算法虽然基于Vowpal Wabbit资料集的工具化生效，但是可以发现我们特定的工具要至少快2-5倍。</p><h3 id="3-1-情绪分析"><a href="#3-1-情绪分析" class="headerlink" title="3.1 情绪分析"></a>3.1 情绪分析</h3><p>数据集和基线 我们使用Zhang等人的相同的8个数据集和评估协议。我们报告Zhang等人的N-gram和TFI-DF基线以及Zhang和LeCun的字符级卷积模型（char-CNN）和 Conneau等人的非常深的卷积网络（VDCNN）。我们还与Tang等人的评估协议进行了比较。 我们报告他们的主要基线以及基于递归网络（Conv-GRNN和LSTM-GRNN）的两种方法。</p><p><strong>结果</strong> 我们在表1中给出了结果。我们使用10个隐藏单元并运行5个纪元的fastText，并在{0.05,0.1,0.25,0.5}的验证集上选择了一个学习率。 在这项任务中，添加bigram信息将使性能提高1 - 4％。 总体而言，我们的准确度略好于char-CNN，稍差于VDCNN。 请注意，我们可以通过使用更多的n-gram来稍微提高精度，例如，搜狗的性能上升到97.1％。 最后，表1表明我们的方法与Tang等人提出的方法相比是有竞争力的。</p><p><img src="https://i.postimg.cc/RCYCVH2B/Table-1-Test-accuracy-on-sentiment-datasets.jpg" alt="Test accuracy% on sentiment datasets.jpg"><br>表1：情绪数据集的测试准确度[％]。 所有数据集都使用相同的参数运行FastText。 它有10个隐藏的单位，我们评估它有没有bigrams。 对于VDCNN和char-CNN，我们显示没有数据增加的最佳报告数字。</p><p><img src="https://i.postimg.cc/C59wv3b1/Table-2-Training-time-for-a-single-epoch-on-sentiment-analysis-d.jpg" alt="Table 2 Training time for a single epoch on sentiment analysis.jpg"><br>表3：与Tang等人的比较。在验证集上选择超参数。</p><p>我们调整验证集上的超参数，并观察使用多达5个导联的n-grams 达到最佳性能。 与Tang等人不同，fastText不使用预先训练的词嵌入，这可以解释1％的差异。</p><p>训练时间 char-CNN和VDCNN都使用NVIDIA Tesla K40 GPU进行培训，而我们的模型则使用20个线程在CPU上进行培训。 表2显示使用卷积的方法比fastText慢几个数量级。 </p><p><img src="https://i.postimg.cc/FRWrSdR0/Table-3-Comparision-with-Tang-et-al-2015.jpg" alt="Table 3 Comparision with Tang et al. (2015).jpg"><br>表2：与char-CNN和VDCNN相比，情绪分析数据集的训练时间。 我们报告整个培训时间，除了char-CNN，我们报告每个时间。</p><p>请注意，对于char-CNN，我们报告每个时期的时间，同时报告其他方法的整体训练时间。 虽然使用更新的CUDA实现的卷积可以使char-CNN的速度提高10倍，但fastText只需不到一分钟的时间就可以训练这些数据集。 与基于CNN的方法相比，我们的加速比随着数据集的大小而增加，至少达到15,000倍的加速。</p><h3 id="3-2-标签预测"><a href="#3-2-标签预测" class="headerlink" title="3.2 标签预测"></a>3.2 标签预测</h3><p><strong>数据集和基线</strong><br>为了测试我们方法的可伸缩性，对YFCC100M数据集进行了进一步评估，该数据集由几乎100M的带有字幕，标题和标签的图像组成。我们专注于根据标题和标题预测标签（我们不使用图像）。我们删除少于100次的字词和标签，并将数据分成训练，验证和测试集。该训练集包含91,188,648个样本。验证有930,497个样本和测试集543,424个样本。词汇大小为297,141，并且有312,116个标签。我们将发布一个脚本来重新创建这个数据集，以便我们的数据可以被复制。</p><p>我们考虑预测最频繁标签的基于频率的基线。我们还将它与标签预测模型Tagspace进行了比较，标签预测模型与我们的标签预测模型相似，但基于Weston等人的Wsabie模型。虽然使用卷积描述了标签空间模型，但我们认为线性版本具有可比较的性能，更快。</p><p><strong>结果和训练时间</strong>  </p><p><img src="https://i.postimg.cc/90DWYmRK/Table-5-Prec-1-on-the-test-set-for-tag-prediction.jpg" alt="Table 5 Prec@1 on the test set for tag prediction.jpg"><br>表5：YFCC100M上用于标记预测的测试集上的Prec @ 1。 我们还会报告训练时间和测试时间。 测试时间是单线程的报告，而两种模式的训练使用20个线程。</p><p>表5给出了fastText和基线的比较。我们运行5个周期的fastText，并将它与Tagspace的两种尺寸的隐藏层（即50和200）进行比较。两种模型都实现了与隐藏层相似的性能，但增加了巨大值使我们在精度上有了显着提升。 在测试时间，Tagspace需要计算所有类别的分数，这使得它相对较慢，而当类别数量很多（此处超过300K）时，我们的快速推理会显着提高速度。 总体而言，获得质量更好的模型的速度要快一个数量级。 测试阶段的加速更加重要（600倍加速）。表4显示了一些定性的例子。 </p><p><img src="https://i.postimg.cc/xTbfkdSb/Table-4-Examples-from-the-validation-set-of-YFCC100-M-dataset.jpg" alt="Table 4 Examples from the validation set of YFCC100M dataset.jpg"></p><p>表4：使用具有200个隐藏单元和两个bigrams的fastText获取的YFCC100M数据集验证集的示例。 我们展示了一些正确和不正确的标签预测。</p><p>FastText学习将标题中的单词与他们的主题标签相关联，例如“christmas”与“＃christmas”。 它还捕捉单词之间的简单关系，如“snowfall”和“#snow”。 最后，使用bigrams还可以捕捉诸如“twin cities”和“#minneapolis”之类的关系。</p><h2 id="4-讨论和结论"><a href="#4-讨论和结论" class="headerlink" title="4 讨论和结论"></a>4 讨论和结论</h2><p>在这项工作中，我们开发了fastText，它扩展了word2vec来处理句子和文档分类。 与来自word2vec的无监督训练的单词向量不同，我们的单词特征可以平均在一起形成好的句子表示。 在几项任务中，我们获得的性能与最近提出的深度学习方法相媲美，同时观察到了大幅度的加速。 尽管深层神经网络在理论上比浅层模型具有更高的表征能力，但是如何分析简单的文本分类问题（如情感分析）是否正确评估它们并不明确。 我们将发布我们的代码，以便研究团体可以轻松构建我们的工作。</p><h2 id="一些收获"><a href="#一些收获" class="headerlink" title="一些收获"></a>一些收获</h2><p>FastText词向量与word2vec对比<br><strong>FastText= word2vec中 cbow + h-softmax的灵活使用</strong><br>灵活体现在两个方面： </p><blockquote><ol><li>模型的输出层：word2vec的输出层，对应的是每一个term，计算某term的概率最大；而fasttext的输出层对应的是 分类的label。不过不管输出层对应的是什么内容，起对应的vector都不会被保留和使用； </li><li>模型的输入层：word2vec的输出层，是 context window 内的term；而fasttext 对应的整个sentence的内容，包括term，也包括 n-gram的内容；</li></ol></blockquote><p><strong>两者本质的不同，体现在h-softmax的使用：</strong></p><blockquote><p>Wordvec的目的是得到词向量，embedding层 到 input层的 共享权重矩阵 就是 词向量矩阵，输出层对应的 h-softmax 也会生成一系列的向量，但最终都被抛弃，不会使用。<br>fasttext则充分利用了h-softmax的分类功能，遍历分类树的所有叶节点，找到概率最大的label（一个或者N个）</p></blockquote><p><a href="https://blog.csdn.net/u011239443/article/details/80076720" target="_blank" rel="noopener">参考博文：论文阅读：《Bag of Tricks for Efficient Text Classification-卓寿杰_SoulJoy</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1607.01759v2.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：Bag of Tricks for Efficient Text Classification&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;有效的文本分类技巧&quot;&gt;&lt;a href=&quot;#有效的文本分类技巧&quot; class=&quot;headerlink&quot; title=&quot;有效的文本分类技巧&quot;&gt;&lt;/a&gt;有效的文本分类技巧&lt;/h2&gt;&lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;p&gt;本文提出了一种简单而有效的文本分类和表示学习方法。 我们的实验表明，我们的快速文本分类器fastText在准确性方面通常与深度学习分类器保持一致，并且在训练和评估中速度快很多。 我们可以在不到10分钟的时间内使用标准的多核CPU对超过10亿个单词进行快速文本训练，并在不到一分钟的时间内对312K类中的50万个句子进行分类。&lt;/p&gt;
&lt;h2 id=&quot;1-介绍&quot;&gt;&lt;a href=&quot;#1-介绍&quot; class=&quot;headerlink&quot; title=&quot;1 介绍&quot;&gt;&lt;/a&gt;1 介绍&lt;/h2&gt;&lt;p&gt;建立良好的文本分类表示是许多应用程序的重要任务，如Web搜索，信息检索，排序和文档分类。 最近，基于神经网络的模型在计算句子表示方面越来越受欢迎。 虽然这些模型在实践中取得了非常好的表现，但是在训练和测试时间，它们往往相对较慢，限制了它们在非常大的数据集上的使用。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Classification" scheme="http://www.xiemingzhao.com/tags/Classification/"/>
    
      <category term="Bag of Tricks" scheme="http://www.xiemingzhao.com/tags/Bag-of-Tricks/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统三十六式--读书笔记（35-38 产品&amp;团队&amp;参考阅读）</title>
    <link href="http://www.xiemingzhao.com/2018/11/12/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F--%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%8835-38%20%E4%BA%A7%E5%93%81&amp;%E5%9B%A2%E9%98%9F&amp;%E5%8F%82%E8%80%83%E9%98%85%E8%AF%BB%EF%BC%89/"/>
    <id>http://www.xiemingzhao.com/2018/11/12/推荐系统三十六式--读书笔记（35-38 产品&amp;团队&amp;参考阅读）/</id>
    <published>2018-11-11T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:43.213Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://time.geekbang.org/column/intro/74" target="_blank" rel="noopener">参考原作：推荐系统三十六式-刑无刀</a></p><h2 id="35-【产品篇】推荐系统在互联网产品商业链条中的地位"><a href="#35-【产品篇】推荐系统在互联网产品商业链条中的地位" class="headerlink" title="35.【产品篇】推荐系统在互联网产品商业链条中的地位"></a>35.【产品篇】推荐系统在互联网产品商业链条中的地位</h2><p>在商业世界里，就应该带一点“功利”的眼光看待推荐系统，但功利地看待推荐系统之前，要认识到推荐系统在商业链条中到底是个什么样的角色和作用。</p><h3 id="推荐系统的作用"><a href="#推荐系统的作用" class="headerlink" title="推荐系统的作用"></a><strong>推荐系统的作用</strong></h3><p>商业社会中亘古不变的关系是供求关系，供求关系的背后是交换。无论是实体经济还是虚拟经济，都是基于这个原理。供求关系动态变化，当供给小于需求时，就产生了稀缺，有了稀缺，就有了商业。</p><p>推荐系统处理的是信息，它的主要作用是在信息生产方和信息消费方搭建起桥梁。所以推荐系统是信息经济中的一个装置。信息经济中，看上去供求方是信息生产者，需求方是注意力提供者。这里似乎猝不及防地就引出了“注意力”这个词。</p><p>所以，无论推荐系统服务的是什么样的产品，这些产品属于资讯，社交，电商，游戏等不同的形式，它们最终得到真金白银的手段不一样，也就是所谓的商业模式各有不同，但是它们都有一个关键步骤就是：<strong>获得用户的注意力。</strong>用户产生行为就是付出注意力的表现，也因此信息流产品都在看谁家的阅读时间长，那都是白花花的注意力啊。信息经济其实就是注意力经济，而推荐系统就是留住注意力的重要手段。</p><a id="more"></a><p>注意力有个特点：总量有限。随着信息越来越丰富，注意力越来越稀缺。</p><blockquote><p>首先，在门户时代，信息稀缺，注意力丰富，用户主动找信息。<br>其次，在搜索时代，信息已经丰富，但搜索的工具属性和使用场景单一，导致它并不会侵蚀用户的注意力，所以依然是用户主动找信息。<br>最后，在移动互联网普及之后，信息已经泛滥到很大程度，智能手机变成身体的一个器官，丰富的注意力被信息源以推荐的方式逐渐侵蚀，注意力从丰富变成稀缺。</p></blockquote><p>但是，注意力本身有价值高低之分。资讯阅读类注意力量大，但是便宜，电商、游戏类注意力贵重，但数量上不如资讯阅读类。这个注意力价值，一般在行业里被粗略称呼为用户价值，实际上这应该是注意力价值。</p><p>综合看，三个时代的信息和注意力关系如下图所示:<br><a href="https://postimg.cc/gnzSW7t7" target="_blank" rel="noopener"><img src="https://i.postimg.cc/BQDdx9TJ/image.jpg" alt="信息和注意力.jpg"></a><br>在推荐系统的帮助下，注意力变成了稀缺方，信息源在打着灯笼到处寻找注意力，其实商品不再是信息，商品就是注意力，信息源变成了这些注意力的消费方。</p><p>有限的注意力在推荐系统的帮助下，聚到了平台上，平台方需要像电力一样把这些注意力储存起来，储存起来的注意力就是平台方最有价值的资产。储存这些注意力的并不是电池板，而是产品，而推荐系统是一种注意力储存设备型号，这就是推荐系统在商业链条中的角色和地位。</p><p>如何定量地定义注意力？直观地看，注意力的存在会导致平台上内容被消耗。因此，我个人把注意力定义为：内容被消耗的加速度与平台内容复杂度的乘积。：</p><script type="math/tex; mode=display">attention = A \times C</script><p>解释一下这个公式：</p><blockquote><ol><li>C 是内容复杂程度，因为不好量化，可以理解为内容被消耗光所需的时间。比如论文网站和鸡汤文网站，要读完两者，难度显然不同，表现为消耗时间不同，再比如，卖奢侈品电商网站和卖地摊货的电商网站，要买光所有商品，花费的钱需要时间去累积，也表现在消耗时间不同。</li><li>A 是内容消耗的加速度，为什么是加速度，而不是速度呢？因为这里衡量的注意力并不只是内容消费者的注意力，还有内容创作者的注意力，是两者合并后的结果。如果用户的注意力和内容创作者倾注的注意力相同，就表现为每天消耗的内容数量一样，加速度为 0，整个平台上没有多余的注意力剩下，没有多余的注意力剩下，就无法销售注意力。</li><li>内容消耗的加速度，还与参加消耗的用户数量有关，用户数量越多，每天消耗越多，用户数量指数增加，则消耗的加速度就不为 0，平台方就有了多余的注意力。</li></ol></blockquote><p>针对这个注意力定义框架制定一些提升平台剩余注意力的策略，及负面影响。</p><blockquote><ol><li>内容创作适当少倾注注意力，这样的结果是，用户消耗会快，但难度也会减少，总注意力会受到制衡；</li><li>提升内容难度，这意味着创作者也要倾注更多注意力，有可能用户方消耗不了，加速度变成负数；</li><li>提高单用户消耗加速度，这就是推荐系统的作用，给用户推荐他更愿意消耗的内容；</li><li>提高用户数，或者说提高活跃用户数。</li></ol></blockquote><p>定义了注意力之后，就能看清楚推荐系统在提升平台注意力的作用，也就能看清楚推荐系统的价值。</p><h3 id="推荐系统的成本"><a href="#推荐系统的成本" class="headerlink" title="推荐系统的成本"></a><strong>推荐系统的成本</strong></h3><p>既然是商业，那么就会考虑成本，虽然只考虑成本是非常浅薄的商业思维；但是这不重要，如果你是公司或者团队负责人，想清楚你的成本，你就会掂量一下是不是要去把“个性化”或者“算法”的标签贴给自己的产品。</p><p><strong>如果你是从业者，清楚成本你就会有危机感，你不会觉得老板不懂，所以就不把成本放在眼里，而是会时刻提醒自己，一切成本，他都是知道的，包括你本身。这并非危言耸听，时代赐予的红利会消失，创造的价值覆盖了成本才能挺过来。</strong></p><p>大致来说，打造一个推荐系统的成本分布在这几个地方：</p><blockquote><ol><li>团队成本；</li><li>硬件成本；</li><li>机会成本。</li></ol></blockquote><h4 id="1-团队成本"><a href="#1-团队成本" class="headerlink" title="1. 团队成本"></a><strong>1. 团队成本</strong></h4><p>团队成本包含团队组建的成本和团队维护的成本。一个推荐系统的团队至少要包含以下几类全职的人。</p><ul><li><p>算法工程师<br>承担了数据科学家和程序员的双重工作，以数据科学为主，并兼具工程能力，在国外一般叫做机器学习工程师。团队里的这类人，由于市场长期供不应求，所以招募成本很高。比如要在各大招聘网站去投放广告，不断和人 social 混脸熟，高昂的猎头费用，转化率极低。招募这部分人，如果只是靠在朋友圈发个招聘文案，可以说是 0 可能会招到人。招募成本高，人员本身的成本也高，由于时代红利存在，整体薪资水平水涨船高，在无法真实分辨出每个人实际价值前，也只能付出这部分人才试错成本。</p></li><li><p>软件工程师<br>如果把推荐系统分为引擎和算法的话，那么软件工程师承担的责任比算法工程师更大，因为算法可以用一些开箱即用的开源工具暂时顶上去；而没有引擎，算法则就没有了用武之地。软件工程师由于市场存量高于算法工程师，所以招募时稍微好一点，但是请注意是好一点，实际上，要找到好的软件工程师，该付出的成本一个都不少。<br>团队成本占据了推荐系统成本的大头，老板们也容易在这一部分产生焦虑，不要这样的团队，生怕自己的产品被市场抛弃，维护这样一个团队呢，那真是“玩儿得特大”。</p></li></ul><p>其实不只是推荐系统，对于技术团队，有一个错误的认识被无数前辈警醒过，那就是：短期高估，长期低估。团队维护的成本除了实打实的薪资支出，还有文化建设成本。工程师们都号称需要宽容自由的环境，形式上看就像是花钱请了一群野马，这也是成本，或者说风险。因为真正优秀的工程师才会在宽松环境下创造出远大于成本的价值，而普通工程师有可能在宽松自由的环境下逐渐废掉。给团队维护一个宽松自由的环境，就需要有一些非常明确地验收工程师成果的机制，这种技术文化建设也不是一朝一夕的事情，需要付出很大的精力。</p><h4 id="2-硬件成本"><a href="#2-硬件成本" class="headerlink" title="2. 硬件成本"></a><strong>2. 硬件成本</strong></h4><p>推荐系统是数据贪婪型。为了获得更多的数据，需要非常高配置的硬件支持，这是由于：</p><blockquote><ol><li>要存储更多的数据；</li><li>要更安全保存数据；</li><li>要更快响应用户，才能留住用户；</li><li>要更好的开发环境，才能提高工程师开发效率，要知道工程师的时间成本最高。</li></ol></blockquote><p>等等这些理由都告诉我们：推荐系统是数据贪婪型，而推荐系统工程师是硬件贪婪型。当然，幸运的是有摩尔定律，硬件成本在逐年下降，配置却在逐年提高，所以硬件成本比起团队成本，只是毛毛雨啦。有了团队，不要在硬件上节省，节省的是非常有限的硬件成本，浪费的是非常昂贵的团队成本。</p><h4 id="3-机会成本"><a href="#3-机会成本" class="headerlink" title="3. 机会成本"></a><strong>3. 机会成本</strong></h4><p>这个就是非常玄学了，并且也不好评估，如果有平行时空存在，倒是可以给这个做个 ABTest。</p><p>所谓机会成本就是：可能推荐系统并没有帮助产品创造什么价值，反而把很多资源投入在这上面，白白浪费了市场窗口期。在信息流大火的今天，大家觉得个性化咨询阅读天然成立，然而仅仅在十年前，许多做个性化阅读的产品投入巨大，到今天可以说尸骨无存。如果当年他们不用推荐系统做，而是老老实实用人工编辑的方式做，也许有不一样的结果。这个就是机会成本。直白地讲，机会成本就是那句毒鸡汤的正经说法：选择大于努力。</p><hr><h2 id="36-【产品篇】说说信息流的前世今生"><a href="#36-【产品篇】说说信息流的前世今生" class="headerlink" title="36.【产品篇】说说信息流的前世今生"></a>36.【产品篇】说说信息流的前世今生</h2><p>信息流，就是 Feed，包括社交动态信息流，也有图文资讯信息流，短视频信息流。</p><p>推荐系统是一种注意力存储器，注意力是信息经济时代的稀缺商品，广告商向平台方购买注意力，平台方把存储的注意力分一点给广告商，然后通过推荐系统收集更多注意力补充回来。在今天，最厉害的注意力存储器就是信息流，尤其是个性化信息流，也叫做兴趣 Feed，这也是推荐系统的一种。</p><h3 id="前世今生"><a href="#前世今生" class="headerlink" title="前世今生"></a><strong>前世今生</strong></h3><p>说信息流，就不得不提到 NewsFeed。2004 年，Facebook 问世，2006 年，信息流鼻祖 NewsFeed 横空出世，经过十多年，NewsFeed 已经是日收入几千万美金的现金大牛。</p><p>在 NewsFeed 上线前，经历过两个抗议阶段:</p><ul><li>第一个是把新鲜事公布出来，原先的新鲜事被大家认为是隐私，在时间线中呈现出来被好友看见不妥，而事实是，每个人在意的除了自己的隐私被公布，更在意的是朋友的八卦，数据表明新鲜事被公布后，用户活跃度大幅上涨。</li><li>第二个就是 NewsFeed 上线，用户广泛抗议，原来按照时间先后顺序阅读新鲜事，现在却按照重要程度阅读，非常不习惯，然而数据表明，用户互动行为再一次大幅度提高。</li></ul><p>这些年来，NewsFeed 有数不清的改进，甚至每天线上会同时部署很多算法版本进行 AB 测试。后来的故事大家都知道了，Facebook 上市，股价逐年上涨。</p><p>NewsFeed 的成功，验证了几个常识：</p><blockquote><ol><li>数据驱动比舆论驱动靠谱，别听人们嘴上是怎么说的，只看人们是如何行动的；</li><li>窥探隐私，向群体靠拢，害怕孤单是普遍人性，把新鲜事公开这件事验证了这一点；</li><li>注意力非常有限，用推荐系统的方法更好地储存注意力，基于兴趣的信息流验证了这一点。</li></ol></blockquote><p>后来，Twitter，微博，Instagram，老牌的时间线信息流方式如今都换成了按照兴趣筛选内容，原因都是信息泛滥，用户错过的信息量越来越多，注意力耗散很多，无法将耗散的注意力变现成了这些平台最大的痛。</p><h3 id="配套设施"><a href="#配套设施" class="headerlink" title="配套设施"></a><strong>配套设施</strong></h3><p>信息流是一个低衰减的注意力存储器，但是光有信息流是不完整的，最大的问题可能有两个：</p><blockquote><ol><li>内容源不足，无法形成信息过载，注意力就不会稀缺，注意力是无法待价而沽的商品；</li><li>在注意力变成稀缺的事物后，存储的注意力无法变现，反哺平台自身。</li></ol></blockquote><p>针对这两个问题，完整的信息流产品还需要配套设施。以 NewsFeed 为例，讲讲信息流的配套设施。</p><h4 id="1-内容源"><a href="#1-内容源" class="headerlink" title="1. 内容源"></a><strong>1. 内容源</strong></h4><p>内容源是注意力的重要间接影响因素。“内容哪里来”是信息流要不断思考的问题，对于 NewsFeed 来说，就是社交关系上的人发布新鲜事。NewsFeed 存在的前提是要依赖用户建立大量的社交联系，这样才会出现信息过载，因此 NewsFeed 的一个重要的配套设施就是“你可能感兴趣的人”推荐系统。这是一个我们在产品形式上比较熟悉的推荐系统，它是一套大规模矩阵分解算法，在前面的专栏已经专门讲过，这套推荐系统希望用户和用户，用户和 App、公共主页等都建立起大量的连接。</p><p>建立起连接，相当于变相地增加了内容源，这些用户发布的新鲜事，App 产生的内容，公共主页发布的帖子，都会通过这些连接流进用户的个人信息流。社交信息流中，内容源依赖于社交关系的数量。而图文资讯信息流，则更多依赖爬虫技术，“不生产内容，只是内容的搬运工”。依赖爬虫的信息流内容源，质量非常不可控，会有涉黄、涉政、涉暴力等敏感内容，甄别工作量非常巨大，而且一旦控制不好就是社会事件，代价惨重</p><p>内容源是信息流的一种重要基础设施，要想尽办法建设好。内容源应该考虑下面几种。</p><blockquote><ol><li>质量：虽然群体喜欢消费低质量的内容，便宜商品，但是一旦出现敏感内容，不合格的商品等，代价还是很高昂。</li><li>多样性：信息只有多样了才有信息量，有了多样性才能满足更多的用户，才能在存储海量注意力时不衰减。</li><li>数量：数量自不必说，推荐系统解决信息过载问题，没有信息过载问题怎么办呢？就是先制造信息过载问题，要制造信息过载，信息的数量就要有保障。</li></ol></blockquote><h4 id="2-广告系统"><a href="#2-广告系统" class="headerlink" title="2. 广告系统"></a><strong>2. 广告系统</strong></h4><p>NewsFeed 还有另一个配套设施，也是它为什么每天能吸金几千万刀的原因：那就是广告系统。Facebook 的广告形态多样。</p><blockquote><ol><li>Suggested Page (你可能喜欢的公众页)</li><li>Page Post (公众号帖子推广)</li><li>Suggested App (你可能喜欢的应用)</li><li>Video Ads (视频广告)</li></ol></blockquote><p>广告主花钱购买信息流存储的注意力，俗称信息流变现。实际上就是信息流产品供应注意力，广告主消费注意力。注意这枚硬币的另一面：广告主供应的什么，用户是否消费了，则是另外一套看待角度。</p><p>以前，Facebook 鼓励商业机构花钱投广告增加粉丝，彼时的 NewsFeed 算法允许随意发广告，看上去就是公共主页发布了新鲜事。这一阶段对应着增加用户和内容源之间的连接阶段，是一个非常必要的步骤。看上去广告主增加了自己的粉丝，用户增加了内容源，而本质上则是让注意力买主先看到他种草的商品，这个阶段只让广告主每天摸摸自己种草的商品，并不是真的给他。</p><p>直到后来，平台方开始严格限制商业广告与普通用户触达，不只是 Facebook，任何的信息流平台，在广告主吸引了足够粉丝之后，都会果断限制广告无节制地触达用户。种草的商品突然提价，广告主就只能剁手买买买，这就是广告系统了。</p><p>跟据某个专门做 NewsFeed 推广的公司追踪结果，1000 个公共主页的 50000 条内容以原生方式触达用户的比例，从 2012 年 16% 降低到了 2014 年的 6.51%，降了一倍还多。当然也可能是因为用户平均关注的公共主页增多了，而本质上的原因就是，注意力市场开市了。</p><p>在注意力这边，存储注意力要做的事就是基于兴趣筛选信息流，重新排序展示，这样的好处就是用户不会错过自己感兴趣的，而本质上就是留住注意力，不要衰减。在注意力购买方这边，通过广告系统，大家去购买自己看中的注意力。信息流，看上去就是这么一个简单的商业逻辑。广告主这边一开始和信息流平台方有非常甜蜜的日子，直到要花钱购买自己帮忙存储的注意力时，就会有怨言了。</p><p>曾经就有广告主对 Facebook 抗议道：那你干脆不要干涉 NewsFeed 排序啊，按时间线自然展示，用户错过就错过，大家都公平。对此 Facebook 的解释则是：数据显示，重排序后的 NewsFeed 可以让用户阅读积极性提高很多。这句话的意思是：这样做才能存储注意力啊。</p><p>关于到底要不要重排序的争吵，我们要看清楚，双方都是商业机构：一边是要消费注意力，一边在销售注意力。<br>这本身就是买卖嘛，不要谈什么情怀，商业社会永远是逐利的，逐利的手段就是制造信息不对称，并且在制造过程中不断提高效率和降低成本。显然，“大家一起穷，完全拼人品”的时间线，不符合基本商业逻辑，信息流才符合商业逻辑。世界上最遥远的距离就是：手握大把粉丝，却不能随心所欲地曝光自己的产品。</p><p>具体信息流会怎么发展，我们无法预测，但是可以肯定的有三点：</p><blockquote><ol><li>信息流是推荐系统在商业上最成功的应用；</li><li>完全依赖数据驱动的信息流会面临黑天鹅事件，所以人和算法协同进化的信息流会是最有生命力的；</li><li>数量上，注意力已被大厂囤在自己了手中，那么下一步要关注的是注意力的质量，这是信息流平台方的商品，毕竟广告主购买了注意力后，发现是地摊货，生意也不会长久的。</li></ol></blockquote><hr><h2 id="37-【团队篇】组建推荐团队及工程师的学习路径"><a href="#37-【团队篇】组建推荐团队及工程师的学习路径" class="headerlink" title="37.【团队篇】组建推荐团队及工程师的学习路径"></a>37.【团队篇】组建推荐团队及工程师的学习路径</h2><h3 id="团队组建"><a href="#团队组建" class="headerlink" title="团队组建"></a><strong>团队组建</strong></h3><p>我们先定义团队的角色，这里既然是组建“有下限团队”，当然按照能省则省的原则。</p><blockquote><ol><li>算法工程师，承担的是数据科学家和机器学习工程师的双重职责，主要职责是清洗数据，训练离线推荐模型，开发算法接口，评估指标。</li><li>软件开发工程师，承担算法之外的开发任务，例如数据库的搭建维护，API 接口的开发，日志的收集，在线系统的高可用等，当然“有下限的团队”可以适当简陋些，不用考虑高性能。</li><li>其他非技术角色，如果是“有下限团队”的话，这一项也可以省略，如果涉及了跨部门合作，或者你不幸被老板提出各种“推得不准”的伪 Bug，那么你就需要一个这样的角色去充当工程师港湾，来阻挡外界的风雨。</li></ol></blockquote><p>关于算法工程师，最低配需要 2 位，一位三年左右经验的算法工程师负责数据分析，数据清洗，推荐模型训练，评估和上线，外带一位三年以下经验的初级工程师，从中辅助分担琐碎工作。</p><p>为什么说有经验的算法工程师一位就够了，假如你使用矩阵分解作为推荐系统第一版核心算法，那么推荐使用 Quora 开源的 QMF 工具。它能在一台 32 核、244G、640G 固态硬盘的服务器上用 20 分钟完成 10 亿非零元素，千万用户和物品的矩阵分解。工具简单易用，一个有经验的工程师足够让其运转起来。</p><p>那么核心问题就是，一台机器是不是撑得起你老板的野心？我认为，撑得起，具体的估算如下。根据前文中对注意力的定义：内容消耗的加速度乘以内容的消耗难度。当注意力为正数时，是上马推荐系统的好时机。因为这说明平台方已经有了注意力的原始积累，只需要加上推荐系统将它保存下来并加以扩大即可。那么组建的这个“有下限团队”最低要求就是能留住当前的注意力。</p><p>注意力为正时，每天的用户消耗内容数量应该是指数级别，比如$f(a,t)=t^a(a&gt;=2)$。其中t是时间，a大于2时才会有正的注意力。因为它的二阶导数为:$a(a-1)t^(a-2)$。</p><p>每天的内容消耗量，其实就是用户产生的行为数据条数，至少是正比关系，这里从简考虑，认为<br>二者等同。假如 a=2，t 的单位是天。那么在 t 天后，累计产生的日志数量是：</p><script type="math/tex; mode=display">\sum_{i=1}^Ti^2 = \frac{T(T+1)(2T+1)}{6}</script><p>现在看看，如果你公司使用的服务器和 Quora 评测 QMF 时所用服务器一样的配置，用单机运行 QMF，极限是撑多久？我简单列个方程:</p><script type="math/tex; mode=display">\frac{T(T+1)(2T+1)}{6}=6000000000</script><p>方程右边就是 QMF 评测时处理的 60 亿非零元素。解这个一元三次方程，得到唯一的实数解是<br>1441.75 天，也就是 3.9 年。那么为什么明明一位算法工程师就可以，还要外带一位，这主要是考虑，团队人才应该有梯度和备份。</p><p>关于软件开发工程师，至少需要四位，是的，要证明的是需要两位，还有两位是为了人才梯度和冗余备份。分工是这样的。</p><blockquote><ol><li>推荐服务输出，一位三年及以上经验的后端开发工程师，外带一位三年以下的初级工程师。负责调用推荐 RPC 服务，开发必要的过滤逻辑，填充详细字段等；</li><li>反馈数据收集和管理，一位三年以上经验的运维工程师，外带一位三年以下的初级工程师，负责回收用户反馈数据，统一存储日志数据。</li></ol></blockquote><p>以上就是一个最低配推荐系统团队的配置。当然，如果能复用现有团队的部门工程师，则灵活处理。上面的估算也只是一个示例。</p><h3 id="个人成长"><a href="#个人成长" class="headerlink" title="个人成长"></a><strong>个人成长</strong></h3><p>下面来说说，工程师个人该如何学习和成长的问题。<br>推荐系统工程师和一般意义的软件工程师相比，看上去无需像 IOS 或者 Android 工程师写大量的代码；也无需像研究院的研究员那样，非得憋出漂亮的数学模型才能工作；更无需像数据分析师绘制出漂亮的图表。那推荐系统工程师的定位是什么呢？<br>实际上，这里说的几个“看上去无需”，并不是降低了推荐系统工程师的要求，而是提高了要求。因为你得具备三个核心素质：</p><blockquote><ol><li>有较强的工程能力，能快速交付高效率少 Bug 的算法实现，虽然项目中不一定要写非常大量的代码；</li><li>有较强的理论基础，能看懂最新的论文，虽然不一定要原创出漂亮的数学模型；</li><li>有很好的可视化思维，能将不直观的数据规律直观地呈现出来，向非工程师解释清楚问题所在，原理所在。</li></ol></blockquote><p>首先，虽然世人目光都聚焦在高大上的推荐算法上，然而算法模块确实是容易标准化的，开源算法实现一般也能满足中小厂的第一版所需，而实现整个推荐系统的路径却不可复制，这个实现路径就是工程。可以说，是工程能力决定了推荐系统的上限。如何提高工程能力，无他，就是反复刻意练习。</p><p>但是对于入行不同年限的人来说，提高的办法则各不相同。对于在校生，一个比较好的办法是，将看到的任何算法知识、论文或者图书，都亲手转换成代码，一个简单的算法，从你看懂到你无 Bug 地实现出来，其实还有很远的距离，在实现完成后，去阅读对应的热门开源应用，阅读它的实现方法，对照自己的，总结差距。</p><p>对于刚工作的新人，这时候你已经有一定的工程基础，并且没有太多的整块时间，那么就要好好把握工作中的项目实战。避免重复造轮子的前提是知道有轮子，并且知道轮子好在哪，这要求你熟读现有轮子的各种，对它性能、实现方法了如指掌，如此才能在不重复造轮子的基础上安心实施拿来主义，并且可以进一步将轮子按照实际使用的所需问题进行改良。</p><p>对于工作一定年限的人，这时候你已经熟知各种轮子极其弊端，也能改进了，那么在业务逐渐增长后，需要考虑将系统中部分模块中所使用的开源加上补丁，整体升级为自研系统。这个开发可以从一些风险不高的模块着手，逐渐锻炼。</p><p>上述三个大的阶段，比较粗略。但是核心思想就是：爱动手，爱思考，爱阅读，爱总结。</p><p>第二，是理论基础。对于一个从事推荐系统的工程师来说，一定需要有数理基础。高等数学、概率统计、线性代数这些大学基础课一定还在自己心中，没有还给老师。<br>如果不幸还给老师，你需要重新捡起来，因为整个机器学习都是建立在高等数学基础上的。另外，有一个学科我个人认为很重要，甚至成为人生的指南，那就是信息论。信息论用量化方式确定了什么是信息，很多算法问题也因此可以从通信角度考虑。</p><p>第三，是数据可视化思维，在做数据分析和清洗工作时，需要想办法直观地呈现出来，在工具层面，掌握一些常用的绘图工具就很有必要了。Python 中的 Matplotlib，R 语言中的 ggplot2，Linux 命令里面的 Gnuplot，Windows 里的 Excel 等等都是非常常用的绘图工具。</p><p>掌握工具并不难，还需要有 show 的冲动，直观方式呈现出数据规律不但对自己优化算法和系统有非常大的作用，还可以与合作伙伴快速达成任务共识，节省沟通成本。这三个能力，建立起来的难度逐渐增加，需要持之以恒，与《卖油翁》那句著名的“无他，但手熟尔”，规律相同。</p><p>除此之外，还有一些非典型工程师的加分项。</p><blockquote><ol><li>学习能力：虽然缓慢，但是科学一直在突破边界，技术更是日新月异地升级了一代又一代，而文化的进化则远远快于人类基因的进化，这些变化，都要求你我要有不断学习的意识，还要有会学习的能力。</li><li>沟通能力：在一些中大型厂，一些数据资源分散在不同部门，在技术之外需要去整合这些资源，这需要沟通能力。</li><li>表达能力：能把一件事情讲清楚，最直接的好处是在团队内部减少无效的沟通，提高工作效率。</li></ol></blockquote><hr><h2 id="38-推荐系统的参考阅读"><a href="#38-推荐系统的参考阅读" class="headerlink" title="38.推荐系统的参考阅读"></a>38.推荐系统的参考阅读</h2><p>这些资料分成这么几个类型。</p><blockquote><ol><li>论文：以论文形式发表的，期刊数据库中可以下载到。</li><li>网络文章：就是在网上自由流传的内容或者博客，为了方便阅读，我将它们保存为 PDF 格式。</li><li>演示文稿：就是作者曾公开演讲过的内容，相对来说不是那么严谨，但是更容易理解。</li><li>书：推荐系统相关的书较少，我在专栏中参考过的书只有一本（附件中不提供书的电子文档）。</li></ol></blockquote><h3 id="原理篇"><a href="#原理篇" class="headerlink" title="原理篇"></a><strong>原理篇</strong></h3><h3 id="1-内容推荐"><a href="#1-内容推荐" class="headerlink" title="1. 内容推荐"></a><strong>1. 内容推荐</strong></h3><p>题目：Bag of Tricks for Efficient Text Classification<br>类型：论文  作者：Facebook<br>说明：Facebook 开源的文本处理工具 fastText 背后原理。可以训练词嵌入向量，文本多分类，效率和线性模型一样，效果和深度学习一样，值得拥有。</p><p>题目：The Learning Behind Gmail Priority Inbox<br>类型：论文  作者：Google<br>说明：介绍了一种基于文本和行为给用户建模的思路，是信息流推荐的早期探索，Gmail 智能邮箱背后的原理。</p><p>题目：Recommender Systems Handbook(第三章，第九章)<br>类型：书  作者：Francesco Ricci等<br>说明：这本书收录了推荐系统很多经典论文，话题涵盖非常广，第三章专门讲内容推荐的基本原理，第九章是一个具体的基于内容推荐系统的案例。</p><p>题目：文本上的算法<br>类型：网络文章 (网络免费版，已有成书《文本上的算法: 深入浅出自然语言处理》，内容更丰富)  作者：路彦雄<br>说明：介绍了文本挖掘中常用的算法，及基础概念。内容涉及概率论，信息论，文本分类，聚类，深度学习，推荐系统等。   </p><p>题目：LDA 数学八卦<br>类型：网络文章  作者：Rickjin(@靳志辉) 说明：由浅入深地讲解 LDA 原理，对于实际 LDA 工具的使用有非常大的帮助。</p><h3 id="2-近邻推荐"><a href="#2-近邻推荐" class="headerlink" title="2. 近邻推荐"></a><strong>2. 近邻推荐</strong></h3><p>题目：Amazon.com recommendations: item-to-item collaborative filtering<br>类型：论文  作者：Amazon<br>说明：介绍 Amazon 的推荐系统原理，主要是介绍 Item-Based 协同过滤算法。</p><p>题目：Slope One Predictors for Online Rating-Based Collaborative Filtering<br>类型：论文  作者：Daniel Lemire 等<br>说明：Slope One 算法。</p><p>题目：Item-Based Collaborative Filtering Recommendation Algorithms<br>类型：论文作者：Badrul Sarwar 等<br>说明：GroupLens 的研究团队对比了不同的 Item-to-Item 的推荐算法。</p><p>题目：Collaborative Recommendations Using Item-to-Item Similarity Mappings<br>类型：专利  作者：Amazon<br>说明：是的，Amazon 申请了 Item-Based 算法的专利，所以如果在美上市企业，小心用这个算法。</p><p>题目：Recommender Systems Handbook（第 4 章）<br>类型：书  作者：Francesco Ricci 等<br>说明：第四章综述性地讲了近邻推荐，也就是基础协同过滤算法。</p><h3 id="3-矩阵分解"><a href="#3-矩阵分解" class="headerlink" title="3. 矩阵分解"></a><strong>3. 矩阵分解</strong></h3><p>题目：Matrix Factorization and Collaborative Filtering<br>类型：演示文稿  作者：Daryl Lim<br>说明：从 PCA 这种传统的数据降维方法讲起，综述了矩阵分解和协同过滤算法。矩阵分解也是一种降维方法。</p><p>题目：Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model<br>类型：论文  作者：Yehuda Koren<br>说明：把矩阵分解和近邻模型融合在一起。</p><p>题目：BPR- Bayesian Personalized Ranking from Implicit Feedback<br>类型：论文  作者：Steffen Rendle 等<br>说明：更关注推荐结果的排序好坏，而不是评分预测精度，那么 BPR 模型可能是首选，本篇是出处。</p><p>题目：Collaborative Filtering for Implicit Feedback Datasets<br>类型：论文  作者：Yifan Hu 等<br>说明：不同于通常矩阵分解处理的都是评分数据这样的显式反馈，本文介绍一种处理点击等隐式反馈数据的矩阵分解模型。</p><p>题目：Matrix Factorization Techniques For Recommender Systems<br>类型：论文  作者：Yehuda Koren 等<br>说明：本文是大神 Yehuda Koren 对矩阵分解在推荐系统中的应用做的一个普及性介绍，值得一读。</p><p>题目：The BellKor Solution to the Netflix Grand Prize<br>类型：论文  作者：Yehuda Koren<br>说明：也是一篇综述，或者说教程，针对 Netflix Prize 的。</p><h3 id="4-模型融合"><a href="#4-模型融合" class="headerlink" title="4. 模型融合"></a><strong>4. 模型融合</strong></h3><p>题目：Adaptive Bound Optimization for Online Convex Optimization<br>类型：论文  作者：Google<br>说明：FTRL 是 CTR 预估常用的优化算法，本文介绍 FTRL 算法原理。</p><p>题目：在线最优化求解<br>类型：网络文章  作者：冯扬<br>说明：是对 FTRL 的通俗版解说。</p><p>题目：Ad Click Prediction: a View from the Trenches<br>类型：论文  作者：Google<br>说明：FTRL 工程实现解读。</p><p>题目：Factorization Machines<br>类型：论文  作者：Steffen Rendle<br>说明：提出 FM 模型的论文，FM 用于 CTR 预估。</p><p>题目：Field-aware Factorization Machines for CTR Prediction<br>类型：论文  作者：Yuchin Juan<br>说明：FFM 模型，用于 CTR 预估。</p><p>题目：Practical Lessons from Predicting Clicks on Ads at Facebook<br>类型：论文<br>说明：提出了 LR + GBDT 的 CTR 预估模型。</p><p>题目：Wide &amp; Deep Learning for Recommender Systems<br>类型：论文  作者：Google<br>说明：提出融合深度和宽度模型的Wide&amp;Deep 模型，用于 CTR 预估。</p><h3 id="5-Bandit-算法"><a href="#5-Bandit-算法" class="headerlink" title="5.Bandit 算法"></a><strong>5.Bandit 算法</strong></h3><p>题目：Introduction to Bandits- Algorithms and Theory Part 1- Bandits with small sets of actions<br>类型：演示文稿  作者：Jean-Yves Audibert 等<br>说明：介绍 bandit 算法概念，理论和算法，这部分主要针对小的选项候选集。</p><p>题目：Introduction to Bandits- Algorithms and Theory Part 2- Bandits with large sets of actions<br>类型：演示文稿  作者：Jean-Yves Audibert 等<br>说明：介绍 Bandit 算法概念，理论和算法，这部分主要针对较大的选项候选集。</p><p>题目：A Contextual-Bandit Approach to Personalized News Article Recommendation<br>类型：论文  作者：Yahoo<br>说明：Linucb 的原始论文，考虑上下文的 Bandit 算法。</p><p>题目：Collaborative Filtering Bandits<br>类型：论文  作者：Shuai Li 等<br>说明：Bandit 算法与协同过滤结合，提出 COFIBA 算法。</p><h3 id="6-深度学习"><a href="#6-深度学习" class="headerlink" title="6. 深度学习"></a><strong>6. 深度学习</strong></h3><p>题目：Deep Neural Networks for YouTube Recommendations<br>类型：论文  作者：Google<br>说明：介绍 YouTube 视频推荐系统在深度神经网络上的尝试。能从中看到 wide&amp;deep 模型的影子。</p><p>题目：Efficient Estimation of Word Representations in Vector Space<br>类型：论文  作者：Google<br>说明：Word2Vec 的作者在这篇文章中提出了一种词嵌入向量学习方法，也就是把开源工具包 Word2Vec 背后的模型详细介绍了一次。理论上很简单，更多是一些工程技巧的分享。 Word2Vec 给推荐系统带来了一种新的隐因子向量学习方法，深陷评分预测泥潭的矩阵分解被开拓了思路。</p><p>题目：Item2Vec: Neural Item Embedding for Collaborative Filtering<br>类型：论文  作者：Microsoft<br>说明：这篇就是借鉴了 word2vec 在语言建模中的思路，为推荐系统的行为建模，从中为物品学习嵌入向量。</p><p>题目：Learning Representations of Text using Neural Networks<br>类型：演示文稿  作者：Google<br>说明：理解为 word2vec 作者写一个教程。</p><p>题目：Long Short-Term Memory<br>类型：论文  作者：Sepp Hochreiter 等<br>说明：可以用来为序列建模的 LSTM，实际上在 1997 年就发表论文了，只是在十几年后才大火。</p><p>题目：An Empirical Exploration of Recurrent Network Architectures<br>类型：论文  作者：Google<br>说明：Google 在 RNN 模型使用上的经验分享。</p><p>题目：Recurrent Neural Networks for Collaborative Filtering<br>类型：网络文章  作者：Erik Bernhardsson<br>说明：这是 Erik Bernhardsson 在 Spotify 期间所做的尝试，用 RNN 自动构建音乐播单。Erik<br>Bernhardsson 还有一项开源项目 Annoy，用于稠密向量的近邻搜索，在推荐系统中也用得较多。</p><h3 id="7-其他实用算法"><a href="#7-其他实用算法" class="headerlink" title="7. 其他实用算法"></a><strong>7. 其他实用算法</strong></h3><p>题目：Detecting Near-Duplicates for Web Crawling<br>类型：论文  作者：Google<br>说明：在这篇论文中提出了 simhash 算法，用于大规模网页去重。</p><p>题目：Weighted random sampling with a reservoir<br>类型：论文  作者：Pavlos S. Efraimidis<br>说明：对流式数据的加权采样。</p><p>题目：Weighted Sampling Without Replacement from Data Streams<br>类型：论文  作者：Vladimir Braverman 等<br>说明：介绍了两种对流式数据的加权采样。</p><h3 id="工程篇"><a href="#工程篇" class="headerlink" title="工程篇"></a><strong>工程篇</strong></h3><h3 id="1-常见架构"><a href="#1-常见架构" class="headerlink" title="1. 常见架构"></a><strong>1. 常见架构</strong></h3><p>题目：Activity Feeds Architecture<br>类型：演示文稿  作者：Etsy<br>说明：本文非常详细地介绍了社交动态信息流的架构设计细节。</p><p>题目：Atom Activity Streams 1.0<br>类型：规范文档  作者：Activity Streams Working Group<br>说明：这是一份动态信息流数据模型的协议规范文档，由 Activity Streams Working Group 共同发出，这个组织包含 Google 和 Microsoft。</p><p>题目：Beyond the 5 stars（Netflix Recommendations）<br>类型：网络文章  作者：Netflix<br>说明：Netflix 详细宏观上介绍了自家推荐系统的产品形态，不只是比赛中的评分预测那么简单的。</p><p>题目：System Architectures for Personalization and Recommendation<br>类型：网络文章  作者：Netflix<br>说明：Netflix 推荐系统的架构介绍。</p><p>题目：Information Seeking-Convergence of Search, Recommendations and Advertising<br>类型：论文  作者：H Garcia-Molina 等<br>说明：探讨搜索、推荐、广告三者架构统一。</p><h3 id="2-关键模块"><a href="#2-关键模块" class="headerlink" title="2. 关键模块"></a><strong>2. 关键模块</strong></h3><p>题目：Overlapping Experiment Infrastructure- More, Better, Faster Experimentation<br>类型：论文  作者：Google<br>说明：ABTest 实验平台的扛鼎之作，Google 出品，值得拥有。</p><p>题目：TencentRec：Real-time Stream Recommendation in Practice<br>类型：论文  作者：腾讯<br>说明：介绍了腾讯内部的实时推荐系统架构。   </p><p>题目：Personalization at Spotify using Cassandra<br>类型：网络文章  作者：Spotify<br>说明：介绍了 Spotify 在推荐系统所用到的数据存储中间件。</p><h3 id="3-效果保证"><a href="#3-效果保证" class="headerlink" title="3. 效果保证"></a><strong>3. 效果保证</strong></h3><p>题目：Tutorial on Robustness of Recommender Systems<br>类型：演示文稿  作者：Neil Hurley<br>说明：本文非常详细讨论了对推荐系统的攻击和防护，并有实验模拟。</p><p>题目：Recommender Systems Handbook(第八章)<br>类型：书  作者：Francesco Ricci 等<br>说明：该书第八章介绍了能见到的几乎所有推荐系统评价指标，只是实际上用不到这么多指标。</p><p>其他书目</p><blockquote><ol><li>Pattern Recognization and Machine Learning（机器学习基础，有此一本足够了）。</li><li>推荐系统实践（国内唯一一本非翻译的推荐系统书籍，入门必选）。</li><li>信号与噪声（介绍贝叶斯统计的一本科普书）。</li><li>复杂（推荐系统面对的是复杂网络，了解复杂系统和复杂网络的特点，有助于开脑洞）。</li><li>信息简史（既然是信息经济，当然要读一本关于信息的历史）。</li></ol></blockquote><hr><script type="math/tex; mode=display">r_i = \bar r + (r_i - \bar r)*min(1,\frac{n_i}{\bar n})</script><p>其中$r_i$是第i个产品的平滑后的评分，$\bar r$是当前产品簇的平均分（这里可用其他统计量，比如分位数，具体看各自项目的效果），$r_i$是第i个产品原始评分，$n_i$是第i个产品的评分人数，$\bar n$是当前产品簇的平均评分人数（这里也可用其他统计量，具体看效果）。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/column/intro/74&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考原作：推荐系统三十六式-刑无刀&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;35-【产品篇】推荐系统在互联网产品商业链条中的地位&quot;&gt;&lt;a href=&quot;#35-【产品篇】推荐系统在互联网产品商业链条中的地位&quot; class=&quot;headerlink&quot; title=&quot;35.【产品篇】推荐系统在互联网产品商业链条中的地位&quot;&gt;&lt;/a&gt;35.【产品篇】推荐系统在互联网产品商业链条中的地位&lt;/h2&gt;&lt;p&gt;在商业世界里，就应该带一点“功利”的眼光看待推荐系统，但功利地看待推荐系统之前，要认识到推荐系统在商业链条中到底是个什么样的角色和作用。&lt;/p&gt;
&lt;h3 id=&quot;推荐系统的作用&quot;&gt;&lt;a href=&quot;#推荐系统的作用&quot; class=&quot;headerlink&quot; title=&quot;推荐系统的作用&quot;&gt;&lt;/a&gt;&lt;strong&gt;推荐系统的作用&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;商业社会中亘古不变的关系是供求关系，供求关系的背后是交换。无论是实体经济还是虚拟经济，都是基于这个原理。供求关系动态变化，当供给小于需求时，就产生了稀缺，有了稀缺，就有了商业。&lt;/p&gt;
&lt;p&gt;推荐系统处理的是信息，它的主要作用是在信息生产方和信息消费方搭建起桥梁。所以推荐系统是信息经济中的一个装置。信息经济中，看上去供求方是信息生产者，需求方是注意力提供者。这里似乎猝不及防地就引出了“注意力”这个词。&lt;/p&gt;
&lt;p&gt;所以，无论推荐系统服务的是什么样的产品，这些产品属于资讯，社交，电商，游戏等不同的形式，它们最终得到真金白银的手段不一样，也就是所谓的商业模式各有不同，但是它们都有一个关键步骤就是：&lt;strong&gt;获得用户的注意力。&lt;/strong&gt;用户产生行为就是付出注意力的表现，也因此信息流产品都在看谁家的阅读时间长，那都是白花花的注意力啊。信息经济其实就是注意力经济，而推荐系统就是留住注意力的重要手段。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="推荐系统三十六式" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法" scheme="http://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="推荐" scheme="http://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统三十六式--学习笔记（32-34 效果保证&amp;开源工具）</title>
    <link href="http://www.xiemingzhao.com/2018/11/11/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F--%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%8832-34%20%E6%95%88%E6%9E%9C%E4%BF%9D%E8%AF%81&amp;%E5%BC%80%E6%BA%90%E5%B7%A5%E5%85%B7%EF%BC%89/"/>
    <id>http://www.xiemingzhao.com/2018/11/11/推荐系统三十六式--读书笔记（32-34 效果保证&amp;开源工具）/</id>
    <published>2018-11-10T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:42.823Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://time.geekbang.org/column/intro/74" target="_blank" rel="noopener">参考原作：推荐系统三十六式-刑无刀</a></p><h2 id="32-【效果保证】推荐系统的测试方法及常用指标介绍"><a href="#32-【效果保证】推荐系统的测试方法及常用指标介绍" class="headerlink" title="32.【效果保证】推荐系统的测试方法及常用指标介绍"></a>32.【效果保证】推荐系统的测试方法及常用指标介绍</h2><h3 id="为什么要关注指标"><a href="#为什么要关注指标" class="headerlink" title="为什么要关注指标"></a><strong>为什么要关注指标</strong></h3><p>面对推荐系统这样一个有诸多复杂因素联动起作用的系统，要时时刻刻知道它好不好，健不健康，你同样需要掌握一些测试方法和检测指标。</p><h3 id="推荐系统的测试方法"><a href="#推荐系统的测试方法" class="headerlink" title="推荐系统的测试方法"></a><strong>推荐系统的测试方法</strong></h3><p>需要有不确定性思维，但是这绝不是帮你在老板那里开脱的说辞。推荐系统也需要测试，只是它不同于传统的功能测试。传统软件的功能测试，功能的响应是有预期的，点击一个加关注按钮，应该有什么响应，是被产品文档明确规定的；也因此在开发功能的时候，可以同步写出测试用例来。</p><p>这非常明白，在功能开发时，你做了任何改动，只要跑一下测试用例，逻辑对不对就一目了然了。反观推荐系统就没那么容易了，你什么都没动，可能两次推荐的结果都有可能不一样，而且很可能这个不一样也是你自己或者你老板要求的。</p><a id="more"></a><p>那么推荐系统要怎么测试呢？与其说推荐系统没有确定性的预期响应，不如说推荐系统的响应维度更高。因为确定性的功能响应像是一个点，而推荐系统的响应则是高维空间中的一个区域，而不是一个点。那么是不是推荐系统不需要单元测试了呢？显然也不是。</p><p>归纳起来，推荐系统的测试方法有四种：<strong>业务规则扫描、离线模拟测试、在线对比测试、用户访谈。</strong></p><h4 id="1-业务规则扫描"><a href="#1-业务规则扫描" class="headerlink" title="1. 业务规则扫描"></a><strong>1. 业务规则扫描</strong></h4><p>首先，业务规则扫描本质上就是传统软件的功能测试。确定的业务规则会对应有确定的规则，这些规则就可以翻译成单元测试，像是运行单元测试那样，对推荐系统逐一扫描业务规则。</p><p>通常这些业务规则对测试的要求也有“软的”和“硬的”两种。前者会对业务规则违反情况做一个基线规定，比如触发几率小于万分之一，在扫描测试时统计触发次数，只要统计触发几率不超过基线，就算是合格。而硬的规则，就是一票否决，例如一些业务黑名单，简直就是高压线，测试时碰不得，碰了就是 Bug，就要想办法修正。</p><p>除了业务规则，还有一些容易被人忽视的地方，比如绝大多数推荐模型都涉及了数学计算，而数学计算中也有一些潜在的规则不能违反。比如除数不能为0，比如计算机的浮点数精度有限，经过一些指数运算后可能就出现预期之外的结果，还可能一些连续相乘的计算要防止出现0的乘数，类似这些在计算中的潜在业务规则，也需要扫描测试。</p><h4 id="2-离线模拟测试"><a href="#2-离线模拟测试" class="headerlink" title="2. 离线模拟测试"></a><strong>2. 离线模拟测试</strong></h4><p>其次，就是在离线模拟测试。这是一种军事演习式的测试。模拟测试当然无法代替真实数据，但是也能暴露一些问题。通常做法是先收集业务数据，也就是根据业务场景特点，构造用户访问推荐接口的参数。这些参数要尽量还原当时场景，然后拿这些参数数据去实时访问推荐推荐，产生推荐结果日志，收集这些结果日志并计算评测指标，就是离线模拟测试。</p><p>显然，离线模拟测试是失真的测试，并且评测指标也有限，因为并不能得到用户真实及时的反馈。但是仍然有参考意义。这些模拟得到的日志可以统称为曝光日志，它可以评测一些非效果类指标，例如推荐覆盖率，推荐失效率，推荐多样性等。</p><p>那是不是离线模拟测试就对效果一无所知、无法模拟呢？也并不是，有一种办法是，利用历史真实日志构造用户访问参数，得到带评测接口的结果日志后，结合对应的真实反馈，可以定性评测效果对比。</p><p>比如，可以评测推荐结果的 TopK 的准确率，或者排序效果 AUC。这些模型效果类指标，虽然不能代表终关注的商业指标，但是两者之间一般存在一定的相关性。通常来说 TopK 准确率高，或者 AUC 高于 0.5 越多，对应的商业指标就会越好，这是一个基本假设。通过离线模拟评测每一天的模型效果指标，同时计算当天真实的商业指标，可以绘制出两者之间的散点图，从而回归出一个简单的模型，用离线模型效果预估上线后真实商业指标。</p><h4 id="3-在线对比测试"><a href="#3-在线对比测试" class="headerlink" title="3. 在线对比测试"></a><strong>3. 在线对比测试</strong></h4><p>第三种测试方法就是真正的实战了，那就是 ABTest，即在线对比测试，分流量做真实的评测。这需要一个支持流量正交切分的 ABTest 框架，在前面的文中已经讲到过。ABTest 在样本充分的前提下，基本上可以定性新的推荐系统是否比老的推荐系统更加优秀。</p><h4 id="4-用户访谈"><a href="#4-用户访谈" class="headerlink" title="4. 用户访谈"></a><strong>4. 用户访谈</strong></h4><p>后一种测试方法就是用户访谈，或者说用户调查。前面三种测试方法，背后的思想是数据驱动。然而正如我在本文开篇时所说，数据测量的是系统外在表现，并不反映系统原理，而且数据指标是人设计的，是存在主观性和片面性的，人的认知广度和深度各有不同。</p><p>因此，除了要紧紧团结在“数据驱动”这个核心思想周围，还需要深入用户，对用户做直接的交流，对用户访谈，更重要的意义不是评测推荐系统，而是评测推荐系统的指标，设计是否合理，是否其高低反映了你预先的设定。</p><p>除此之外，通过前面三种测试方法如果得知系统表现不好，那么结合直接真实的用户调查和访谈，可以为系统优化找到真实原因。这种方法类比一下就是：维修下水道时，你需要钻进下水道。</p><h3 id="常用指标"><a href="#常用指标" class="headerlink" title="常用指标"></a><strong>常用指标</strong></h3><p>推荐系统有很多指标。你之前如果阅读过一些介绍推荐系统指标的文献或书籍，想必会对繁多的指标望而却步，总之就是各种率。<strong>实际上所有指标就是在回答两个问题：系统有多好，还能好多久？这两个问题恰恰就是推荐系统里面一个老大难问题的反映：探索利用问题。</strong></p><p>系统有多好？这就是想问问：对数据利用得彻底吗？还能好多久？这个问题就是想问问：能探索出用户新的兴趣吗？这样就能继续开采利用了。也好比在职场中看一个人，除了看他现在的经验和解决问题能力有多强，还要看他学习能力有多强，毕竟世界是变化的，朝阳也会变成夕阳。</p><p>下面分别说说这两类指标有哪些。</p><h4 id="1-系统有多好？"><a href="#1-系统有多好？" class="headerlink" title="1. 系统有多好？"></a><strong>1. 系统有多好？</strong></h4><p>检测系统到底有多好，其实，也有两类，一类是深度类，一类是广度类。</p><p>把数据看做是一座矿山，推荐系统是一个开采这座矿山的器械，“系统有多好”这个问题就是在关心开采得好不好，所以其实就看现有矿山上开采得深不深，开采得到不到位。广度类指标就是指在矿山上打满了钻井，而不仅仅盯着一处打钻井。<br>深度类指标，就是看推荐系统在它的本职工作上做得如何。还记得推荐系统的本职工作是什么吗？就是预测用户和物品之间的连接，预测的方法又有评分预测和行为预测。因此深度类指标就指在检测系统在这两个工作上是否做得到位，有针对离线模型的指标，也有在线的指标，下面分别说一说。</p><ul><li>评分准确度。通常就是均方根误差 RMSE，或者其他误差类指标，反映预测评分效果的好坏。在讲协同过滤时已经详细说过这个指标。这里不再赘述。</li><li>排序。检测推荐系统排序能力非常重要，因为把用户偏爱的物品放在前面是推荐系统的天职。<br>由于推荐系统输出结果是非常个人化的，除了用户本人，其他人都很难替他回答哪个好哪个不好，所以通常评价推荐系统排序效果很少采用搜索引擎排序指标，例如 MAP，MRR，NDCG。搜索引擎评价搜索结果和查询相关性，具有很强的客观属性，可以他人代替评价。推荐系统评价排序通常采用 AUC。也在前面介绍 BPR 模型时，专门讲到过。</li><li>分类准确率。这个指标也是针对行为预测的，而行为预测就是分类问题，所以评价准确度就很自然。<br>在推荐系统中，评价准确度略微特殊，一般评价 TopK 准确率，与之对应还有 TopK 召回率，这里的 K 和实际推荐系统场景有关，就是实际每次推荐系统需要输出几个结果。</li></ul><p>opK 准确度计算方式如下：<br>如果日志中用户有 A、B 两个物品有正反馈行为，推荐系统推出一个物品列表，长度为 K，这个列表中就有可能包含 A、B 两个物品中的一个或多个，下面这个表格就说明了 TopK 准确率和 TopK 召回率的含义:</p><div class="table-container"><table><thead><tr><th style="text-align:center">K</th><th style="text-align:center">推荐输出</th><th style="text-align:center">包含用户反馈物品数</th><th style="text-align:center">TopK准确率</th><th style="text-align:center">TopK召回率</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">A</td><td style="text-align:center">1</td><td style="text-align:center">100%</td><td style="text-align:center">100%</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">A,C</td><td style="text-align:center">1</td><td style="text-align:center">50%</td><td style="text-align:center">50%</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">A,C,D</td><td style="text-align:center">1</td><td style="text-align:center">33%</td><td style="text-align:center">50%</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">A,C,D,E</td><td style="text-align:center">1</td><td style="text-align:center">25%</td><td style="text-align:center">50%</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">A,B,C,D</td><td style="text-align:center">1</td><td style="text-align:center">50%</td><td style="text-align:center">100%</td></tr></tbody></table></div><p>这三个指标，比较直观地反映了推荐系统在“预测”这件事上对数据开采的深度，实际上由于模型不同，还可以有不同的指标，也可以自己设计指标，这里不再赘述。但这三个指标也属于比较初期的指标，距离终商业指标还有一定的距离。</p><p>通常检测推荐系统的商业指标有：点击率，转化率。其实把用户从打开你的应用或者网站开始，到最终完成一个消费，中间要经历数个步骤，也是大家常说的漏斗转化过程。推荐系统如果在其中某个环节起作用，那么就要衡量那个环节的转化率，这个相比前面三个指标，更加接近真实效果。</p><p>除了比例类的商业指标，还要关注绝对量的商业指标，常见的有：社交关系数量，用户停留时长，GMV（成交金额），关注绝对数量，除了因为它才是真正商业目标，还有一个原因，是要看推荐系统是否和别的系统之间存在零和博弈情况。假如推荐系统导流效果提升，搜索引擎导流下降，从整个平台来看，因为整个平台的商业目标并没有那么成绩喜人，也需要警惕。</p><ul><li>覆盖率</li></ul><p>这项指标就是看推荐系统在多少用户身上开采成功了，覆盖率又细分为 UV 覆盖率和 PV 覆盖率。UV 覆盖率计算方法是:</p><script type="math/tex; mode=display">COV_uv = \frac{N_{l>c}}{N_{uv}}</script><p>解释一下，首先要定义有效推荐，就是推荐结果列表长度保证在 C 个之上，独立访问的用户去<br>重就是 UV，有效推荐覆盖的独立去重用户数除以独立用户数就是 UV 覆盖率。PV 覆盖率计算<br>方法类似，唯一区别就是计算时分子分母不去重:</p><script type="math/tex; mode=display">COV_pv = \frac{N_{l>c}^*}{N_{uv}^*}</script><ul><li>失效率</li></ul><p>失效率指标衡量推荐不出结果的情况。也分为 UV 失效率和 PV 失效率。UV 失效率计算方法是：</p><script type="math/tex; mode=display">LOST_{uv} = \frac{N_{l=0}}{N_{uv}}</script><p>分子是推荐结果列表长度为 0 覆盖的独立用户数，分母依然是去重后的独立访问用户数。PV 失<br>效率也一样，区别是不去重:</p><script type="math/tex; mode=display">LOST_{pv} = \frac{N_{l=0}^*}{N_{pv}^*}</script><ul><li>新颖性</li></ul><p>对于用户来说，“总是看到你这张老脸”会让他们审美疲劳，所以对用户来说，推荐的物品要有一定的新颖性。直观理解就是用户没见过。所以新颖性需要讲粒度，物品粒度、标签粒度、主题粒度、分类粒度等等。每个粒度上评价用户没见过的物品比例。对于物品级别的新颖性，更多是靠直接过滤保证，前面章节已经专门讲到了对应的过滤算法。</p><ul><li>更新率</li></ul><p>检测推荐结果更新程度。如果推荐列表每天几乎一样，显然不可取，尤其是新闻资讯类，要求每次刷新都不一样，对更新率要求更高。更新率可以有很多衡量方式，有一种是衡量每个推荐周期和上个周期相比，推荐列表中不同物品的比例。这个周期，可以是每次刷新，也可以是每天。</p><script type="math/tex; mode=display">UPDATE = \frac{\Delta N_{diff}}{N_{last}}</script><h4 id="2-还能好多久？"><a href="#2-还能好多久？" class="headerlink" title="2. 还能好多久？"></a><strong>2. 还能好多久？</strong></h4><p>也就是系统是否健康。在推荐系统中，需要数据不断更新，这样系统才是一个活系统，用户兴趣客观上会变迁，数据源客观上也是会用光的一天，所以推荐系统如果不能应对这两个变化，就好不了太久。</p><p>衡量推荐系统是否健康的指标常用的有三个。</p><ul><li>个性化。</li></ul><p>虽然说到推荐系统时，言必称个性化，但实际上能做到真正个性化很难，那要求用户每个人都独立思考、爱好明确、不受群体影响。但是个性化程度的确能够反映推荐系统的健康程度，如前面提到的公式：</p><script type="math/tex; mode=display">\frac{\Delta connection}{\Delta user \times \Delta item}</script><p>如果没有个性化，那么分子上增加的连接数，其实是不受分母上增加的物品数影响的，因为所有人都只消费那少数几个物品，那么你其实不需要推荐系统。个性化如何检测呢？有一个直观的方法，取一天的日志，计算用户推荐列表的平均相似度，如果<br>用户量较大，对用户抽样。</p><ul><li>基尼系数。</li></ul><p>基尼系数衡量推荐系统的马太效应，反向衡量推荐的个性化程度。把物品按照累计推荐次数排序，排在位置 i 的物品，其推荐次数占总次数为$p_i$ 。那么基尼系数为：</p><script type="math/tex; mode=display">Gini = \frac{1}{n}\sum_{i=1}^np_i * (2i-n-i)</script><p>看这个公式可以知道，如果推荐次数越不平均，那么基尼系数就越趋近于 1。</p><ul><li>多样性</li></ul><p>多样性不但要在推荐服务吐出结果时需要做一定的保证，也要通过日志做监测。多样性可能会损失一些效果指标，但是从长远上来看，对推荐系统所在平台是有利的。多样的推荐结果也会让产品显得生机勃勃，提升品牌形象。多样性衡量方式通常要依赖维度体系选择，例如常见的是在类别维度上衡量推荐结果的多样性。方法是下面这样的:</p><script type="math/tex; mode=display">Div = \frac{\sum_{i=1}^n-p_i*log(p_i)}{n*log(n)}</script><p>多样性衡量实际上在衡量各个类别在推荐时的熵，一共有 n 个类别，分母是各个类别最均匀，都得到一样的推荐次数情况下对应的熵。分子则是实际各个类别得到的推荐次数， 是类别 i 被推荐次数占总推荐次数的比例，计算它的熵。两者求比值是为了在类别数增加和减少时，可以互相比较。</p><p>这种计算多样性是一个整体的评价，还可以具体评价每次推荐的多样性，每个用户的多样性，也就是 PV 多样性和 UV 多样性。</p><hr><h2 id="33-【效果保证】道高一尺魔高一丈：推荐系统的攻防"><a href="#33-【效果保证】道高一尺魔高一丈：推荐系统的攻防" class="headerlink" title="33.【效果保证】道高一尺魔高一丈：推荐系统的攻防"></a>33.【效果保证】道高一尺魔高一丈：推荐系统的攻防</h2><p>推荐系统是某一方流量诸侯的运转规则，那么就不能不考虑到在其诸侯封地之内会有刁民闹事、钻营规则的漏洞，从而达到自己的目的。</p><h3 id="攻和防"><a href="#攻和防" class="headerlink" title="攻和防"></a><strong>攻和防</strong></h3><p>用行话说，就是推荐系统也会受到攻击，推荐系统也是一种软件，只要是软件，就一定有安全问题，推荐系统也不能免俗。如果推荐系统非常脆弱，容易受到攻击，那么推荐系统就不是为平台利益而运转，而是为攻击者利益而运转，推荐系统不过是个傀儡，前面讲到的那么多酷炫的算法也就成了摆设。</p><p>让前面讲到的所有算法、架构起到它该起的作用；让那些指标数据反映真实的效果，这两件事都很重要。推荐系统如果被攻击也就需要被防护。</p><h3 id="攻击"><a href="#攻击" class="headerlink" title="攻击"></a><strong>攻击</strong></h3><p>知己知彼，百战不殆。要更好地守护你的推荐系统，就需要先了解别人会怎么攻击你的推荐系统。在推荐系统攻防研究领域，被研究得最为彻底的就是针对协同过滤的攻防。</p><p>因为一方面是协同过滤本身就应用广泛，另一方面是针对协同过滤的攻击容易生效。<br>为什么呢？一方面是协同过滤本身就应用广泛，另一方面是针对协同过滤的攻击容易生效。</p><p>我们先概略认识一下推荐系统的攻击是怎么回事，然后再认识一下攻击怎么做。有人对身为流量控制器的推荐系统攻击，并不是他吃饱了没事做，来帮你测试系统，根据“无利不起早”这条社会公理，攻击方一定是想扶持或者打压某些物品，从而获得他想要的个人利益。攻击方要扶持一个物品，就想要推荐算法在计算他的评分时给出高分，想要打压一个物品，就要反之行事。不论目的是扶持还是打压，都需要先达到操纵选民的目的，你知道的，协同过滤，无论是基于物品还是基于用户，都是群体智慧，也就是说需要有投票过程。</p><p>所以攻击协同过滤，核心问题在于如何操纵选民。选民有两种，一种是用户，一种是物品，前者是基于用户的协同过滤所需要的，后者是基于物品的协同过滤所需要的。现在，从一个简单例子开始来思考，如何攻击基于用户的协同过滤算法。</p><p>我们先回顾一下它的原理，首先计算出用户之间的相似度，在给一个用户计算推荐结果时，让相似的用户集体决策，其背后的思想也很直接：人以群分，与你口味相似的人给你推荐的结果你会喜欢。</p><p>那么攻击任务就是，要让自己扶持的物品在推荐算法决定是否要推荐给一个用户时，得到高分。方法就是操纵选民，这里的选民就是和被欺骗用户相似的用户，被欺骗用户肯定是吃瓜群众，也是攻击方的利益攫取，所以不会成为被操纵的选民。通常的手段就是，批量制造假用户资料，并装作是与被欺骗用户兴趣相投的人。这叫做托攻击或者 Shilling Attacks，托也就是水军，名字很形象有没有？具体怎么制造这批选民呢？</p><p>首先，攻击者会注册一批用户，这部分用户就是攻击者可以操纵的选民，然后让这批用户去做出和被欺骗用户一样的历史评分行为。被欺骗的用户打高分的物品，这批水军也打高分，这样一来就可以在计算用户相似度时，这一批新注册的用户都和那个用户有较高的相似度，从而就变成了参与推荐算法计算时的选民，也就可以给扶持的物品打高分或者给打压的物品打低分。</p><p>只不过，针对一个吃瓜群众做这些事情显然是一个不划算的事情，所以攻击者会先找到目标用户群体，针对目标用户群体来做这些事，这样一来就可以把扶持的物品推荐给这个群体，让打压的物品从这个群体面前消失。攻击者在伪造用户兴趣时，除了要做出和被欺骗用户相似的历史行为之外，还要做出掩人耳目的行为，以防止被平台发现，所以还会给一些无关的物品打分。至此，一个简单的攻击过程完成了。</p><p>总结一下，攻击手段包含这些元素。</p><blockquote><ol><li>目标物品，就是攻击方要扶持或者打压的那个物品。</li><li>助攻物品，就是用来构造假的相似用户所需要的物品。</li><li>陪跑物品，就是用来掩饰造假的物品。</li></ol></blockquote><p>三类物品构成一个靶子，靶心是攻击者要拿下的，层层包围，示意如下。<br><a href="https://postimg.cc/K3NkJ6ct" target="_blank" rel="noopener"><img src="https://i.postimg.cc/NLh6ftWC/image.jpg" alt="协同过滤攻击.jpg"></a><br>其中，根据对最外环物品的评分构造方法不同，可以把攻击分为两种：</p><blockquote><ol><li>随机攻击。<br>随机攻击就是在上面示意图中，构造最外环“陪跑物品”评分时，采用随机打分方式生成。随机打分就是用全局平均分构造一个正态分布，给无关物品打分时，用这个正态分布产生一个随机分值。</li><li>平均分攻击。<br>平均分攻击也是用在最外环物品中，给他们打每个物品的平均分。需要先统计出被打分物品的平均分，然后攻击方给这个物品也打上平均分。</li></ol></blockquote><p>前面举例的这种攻击手段，需要先找到一批被欺骗用户，然后逐一为它们构造相似用户，最后才能如愿地实现扶持或打压目标物品。于是就有更为狡猾的攻击办法，这里举两种，<strong>一种是热门攻击，还有一种是分段攻击。</strong></p><p>热门攻击就是攻击者会想办法让目标物品和热门物品扯上关系。这样做有事半功倍的效果，热门物品有个特点是：评分用户多。如果和它扯上关系，那就找到了一个数量较大的群体，攻击的影响也会巨大。和热门物品扯上关系最常用的就是，使用假用户同时给热门物品和目标物品评上高分，这是针对扶持目标物品的做法，如果要打压，则给热门评高分，给目标物品最低分，陪跑物品就采用随机评分的方式。</p><p>热门攻击，若干年前在某电商网站真实发生过，攻击者想让自己的图书得到更多推荐，于是大量同时购买畅销书以及那本想得到推荐的图书，最后在畅销书页面的相关推荐中就推出了那本书，攻击者目的达成。</p><p>热门攻击有两个“优势”。</p><blockquote><ol><li>如果是扶持目标物品，则经过热门攻击后，基于物品的协同过滤算法会把目标物品计算为热门物品的相似物品，上述实际案例就是如此；</li><li>基于用户的协同过滤算法，也会把消费过多个热门物品的用户计算为假用户的相似用户，从而为这些用户推荐出目标物品。</li></ol></blockquote><p>热门攻击有时候并不是攻击者有意发起的，而是一种群体现象，例如粉丝出征，消费者集体维权，都可能产生出热门攻击的效果。</p><p>分段攻击就是想办法把目标物品引入到某个群体中，做法就是攻击者先圈定好用户群体，再列出这个群体肯定喜欢的物品集合，然后同时用假用户给目标物品和这批物品集合评分，做法类似热门攻击。<br>最后的攻击效果就是：如果扶持目标物品，那么这个被圈定的用户群体会看见，如果打压，那么目标物品就会在这群人面前消失。</p><h3 id="防护"><a href="#防护" class="headerlink" title="防护"></a><strong>防护</strong></h3><p>上述这些攻击手段，核心都是操纵选民，手段是构造假用户兴趣，因此你自然会想到，防护的手段核心就是识别出被操纵的选民，这是当然的，但是并不仅仅如此，防护手段按照层级，可以分为下面几种。</p><ul><li><p>平台级。<br>这一层属于在推荐系统之外的防护手段，一面是提高批量注册用户的成本，从攻击者的第一步遏制，比如弹验证码，另一方面是产品教育用户积极参与，并提供真实的反馈，让推荐系统所用的数据真实性比例越高，越不容易被攻击，这是最根本的。</p></li><li><p>数据级。<br>数据级别防护重点是从数据中识别出哪些数据是假的，哪些用户是被操纵的选民，一旦识别出来就将这些数据删除。做法通常是采用机器学习思路，标注一批假用户或假反馈数据，训练分类器，在线上识别出反馈，将其延后或者排除在推荐计算之外，通常要和反垃圾系统紧密结合。或者对用户数据聚类，假用户产生的数据一定有着和正常用户不一样的分布，因为它目标明确，所以无监督的办法可以 找出假用户群体来，一旦确认可以删除整个群体，可以采用的有主成分分析等做法。</p></li><li><p>算法级。<br>算法级别就是在推荐算法设计时，要根据情况做一些改进和选择。一般来说基于用户的协同过滤更容易受到攻击，因此需要对基于用户的协同过滤做改进。</p></li></ul><p>改进方向包括下面几种：</p><blockquote><p>引入用户质量，限制对于低质量的用户参与计算，或者限制新用户参与计算；<br>限制每个用户的投票权重，即在计算用户相似度时引入较重的平滑因子，使得用户之间的相似度不容易出现过高的值，也就是变相使得投票时参与用户更多一些，提高攻击者的成本。<br>除此之外，采用多种推荐算法最后再走模型融合之路也是一种提高推荐系统健壮性的有效做法。</p></blockquote><p>将上述三个层级的防护表示如下图更清楚些，核心要保护推荐结果符合平台方的利益:<br><a href="https://postimg.cc/0K8dkdbd" target="_blank" rel="noopener"><img src="https://i.postimg.cc/prj0Bsv7/image.jpg" alt="三层级防护.jpg"></a></p><hr><h2 id="34-【开源工具】和推荐系统有关的开源工具及框架介绍"><a href="#34-【开源工具】和推荐系统有关的开源工具及框架介绍" class="headerlink" title="34.【开源工具】和推荐系统有关的开源工具及框架介绍"></a>34.【开源工具】和推荐系统有关的开源工具及框架介绍</h2><h3 id="轮子不要重复造"><a href="#轮子不要重复造" class="headerlink" title="轮子不要重复造"></a><strong>轮子不要重复造</strong></h3><p>但是事实上你没必要这样做也不应该这样做。大厂研发力量雄厚，业务场景复杂，数据量大，自己从挖地基开始研发自己的推荐系统则是非常常见的，然而中小厂职工们则要避免重复造轮子。<br>这是因为下面的原因。</p><blockquote><ol><li>中小企业，或者刚刚起步的推荐系统，要达成的效果往往是基准线，通用的和开源的已经能够满足；</li><li>开源的轮子有社区贡献，经过若干年的检验后，大概率上已经好于你自己从零开始写一个同样功能的轮子；</li><li>对于没有那么多研发力量的厂来说，时间还是第一位的，先做出来，这是第一要义。</li></ol></blockquote><p>既然要避免重复造轮子，就要知道有哪些轮子。有别于介绍一个笼统而大全的“推荐系统”轮子，我更倾向于把粒度和焦点再缩小一下，介于最底层的编程语言 API 和大而全的”推荐系统”之间.选择开源项目时要优先选择自己熟悉的编程语言、还要选有大公司背书的，毕竟基础技术过硬且容易形成社区、除此之外要考虑在实际项目中成功实施过的公司、最后还要有活跃的社区氛围。</p><h3 id="内容分析"><a href="#内容分析" class="headerlink" title="内容分析"></a><strong>内容分析</strong></h3><p>基于内容的推荐，主要工作集中在处理文本，或者把数据视为文本去处理。文本分析相关的工作就是将非结构化的文本转换为结构化。</p><blockquote><p>主要的工作就是三类。</p><ol><li>主题模型；</li><li>词嵌入；</li><li>文本分类。</li></ol></blockquote><p>以做这三类工作的开源工具有下面的几种:</p><div class="table-container"><table><thead><tr><th style="text-align:center">开源项目名</th><th style="text-align:center">用途</th><th style="text-align:center">接口语言</th><th style="text-align:center">单机/分布式</th><th style="text-align:center">支持方</th></tr></thead><tbody><tr><td style="text-align:center">LightLDA</td><td style="text-align:center">主题模型</td><td style="text-align:center">C++</td><td style="text-align:center">分布式</td><td style="text-align:center">Microsoft</td></tr><tr><td style="text-align:center">gensim</td><td style="text-align:center">主题模型，词嵌入</td><td style="text-align:center">Python</td><td style="text-align:center">单机多线程</td><td style="text-align:center">adimrehurek.com</td></tr><tr><td style="text-align:center">plda</td><td style="text-align:center">主题模型</td><td style="text-align:center">C++</td><td style="text-align:center">单机多线程/分布式</td><td style="text-align:center">Google</td></tr><tr><td style="text-align:center">DMWE</td><td style="text-align:center">词嵌入</td><td style="text-align:center">C++</td><td style="text-align:center">分布式</td><td style="text-align:center">Microsoft</td></tr><tr><td style="text-align:center">tensorflow-word2vec</td><td style="text-align:center">词嵌入</td><td style="text-align:center">Python</td><td style="text-align:center">分布式或单机</td><td style="text-align:center">Google</td></tr><tr><td style="text-align:center">FastText</td><td style="text-align:center">词嵌入</td><td style="text-align:center">C++/Python</td><td style="text-align:center">单机多线程</td><td style="text-align:center">Facebook</td></tr><tr><td style="text-align:center">liblinear</td><td style="text-align:center">文本分类</td><td style="text-align:center">C++,Java,Python</td><td style="text-align:center">单机</td><td style="text-align:center">台湾大学</td></tr></tbody></table></div><p>这其中 FastText 的词嵌入和 Word2vec 的词嵌入是一样的，但 FastText 还提供分类功能，这个分类非常有优势，效果几乎等同于 CNN，但效率却和线性模型一样，在实际项目中久经考验。LightLDA 和 DMWE 都是微软开源的机器学习工具包。</p><h3 id="协同过滤和矩阵分解"><a href="#协同过滤和矩阵分解" class="headerlink" title="协同过滤和矩阵分解"></a><strong>协同过滤和矩阵分解</strong></h3><p>基于用户、基于物品的协同过滤，矩阵分解，都依赖对用户物品关系矩阵的利用，这里面常常要涉及的工作有下面几种：</p><blockquote><ol><li>KNN 相似度计算；</li><li>SVD 矩阵分解；</li><li>SVD++ 矩阵分解；</li><li>ALS 矩阵分解；</li><li>BPR 矩阵分解；</li><li>低维稠密向量近邻搜索。</li></ol></blockquote><p>可以做这些工作的开源工具有下面几种:</p><div class="table-container"><table><thead><tr><th style="text-align:center">开源项目名</th><th style="text-align:center">用途</th><th style="text-align:center">接口语言</th><th style="text-align:center">单机/分布式</th><th style="text-align:center">支持方</th></tr></thead><tbody><tr><td style="text-align:center">kgraph</td><td style="text-align:center">KNN相似度计算和搜索</td><td style="text-align:center">C++,Python</td><td style="text-align:center">单机/多线程</td><td style="text-align:center">aaalgo(Wei Dong)</td></tr><tr><td style="text-align:center">annoy</td><td style="text-align:center">稠密低维向量的KNN相似搜索</td><td style="text-align:center">C++,Python</td><td style="text-align:center">单机多线程</td><td style="text-align:center">Spotify</td></tr><tr><td style="text-align:center">faiss</td><td style="text-align:center">稠密低维向量的KNN相似搜索，聚类</td><td style="text-align:center">C++,Python</td><td style="text-align:center">单机多线程，支持GPU加速</td><td style="text-align:center">Facebook</td></tr><tr><td style="text-align:center">nmslib</td><td style="text-align:center">稠密低维向量的KNN相似搜索</td><td style="text-align:center">C++,Python</td><td style="text-align:center">单机</td><td style="text-align:center">nmslib</td></tr><tr><td style="text-align:center">Spark.RowMatrix.columnSimilarities</td><td style="text-align:center">基于用户/基于物品协同过滤</td><td style="text-align:center">Scala,Java,Python</td><td style="text-align:center">单机多线程，分布式</td><td style="text-align:center">Twitter</td></tr><tr><td style="text-align:center">lightfm</td><td style="text-align:center">SVD矩阵分解,SVD++矩阵分解，BPR矩阵分解</td><td style="text-align:center">Python</td><td style="text-align:center">单机多线程</td><td style="text-align:center">lyst</td></tr><tr><td style="text-align:center">implicit</td><td style="text-align:center">基于用户/物品的协同过滤，ALS矩阵分解，BPR矩阵分解</td><td style="text-align:center">Python</td><td style="text-align:center">单机多线程，支持GPU加速</td><td style="text-align:center">benfraderickson.com</td></tr><tr><td style="text-align:center">QMF</td><td style="text-align:center">加权矩阵分解，BPR矩阵分解</td><td style="text-align:center">C++,Python</td><td style="text-align:center">单机多线程</td><td style="text-align:center">Quora</td></tr></tbody></table></div><p>这里面的工作通常是这样：基础协同过滤算法，通过计算矩阵的行相似和列相似得到推荐结果。矩阵分解，得到用户和物品的隐因子向量，是低维稠密向量，进一步以用户的低维稠密向量在物品的向量中搜索得到近邻结果，作为推荐结果，因此需要专门针对低维稠密向量的近邻搜索。<strong>同样，除非数据量达到一定程度，比如过亿用户以上，否则你要慎重选择分布式版本，非常不划算。</strong></p><h3 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a><strong>模型融合</strong></h3><p>模型融合这部分，有线性模型、梯度提升树模型。</p><div class="table-container"><table><thead><tr><th style="text-align:center">开源项目名</th><th style="text-align:center">用途</th><th style="text-align:center">接口语言</th><th style="text-align:center">单机/分布式</th><th style="text-align:center">支持方</th></tr></thead><tbody><tr><td style="text-align:center">LightGBM</td><td style="text-align:center">GBDT等树模型</td><td style="text-align:center">C++</td><td style="text-align:center">分布式</td><td style="text-align:center">Microsoft</td></tr><tr><td style="text-align:center">XGBoost</td><td style="text-align:center">GBDT等树模型</td><td style="text-align:center">C++,Python,R</td><td style="text-align:center">单机多线程，分布式</td><td style="text-align:center">Distributed (Deep) Machine Learning Community</td></tr><tr><td style="text-align:center">Tensoeflow_wide and deep</td><td style="text-align:center">Wide&amp;Deep模型</td><td style="text-align:center">Python</td><td style="text-align:center">单机多线程，分布式</td><td style="text-align:center">Google</td></tr><tr><td style="text-align:center">LibFFM</td><td style="text-align:center">因子分解机，厂敏感的因子分解机</td><td style="text-align:center">C++,Python</td><td style="text-align:center">单机</td><td style="text-align:center">台湾大学</td></tr><tr><td style="text-align:center">vowpal_wabbit</td><td style="text-align:center">线性模型</td><td style="text-align:center">C++,Python,Java,C#等</td><td style="text-align:center">单机多线程</td><td style="text-align:center">Microsoft</td></tr></tbody></table></div><p>线性模型复杂在模型训练部分，这部分可以离线批量进行，而线上预测部分则比较简单，可以用开源的接口，也可以自己实现。</p><h3 id="其他工具"><a href="#其他工具" class="headerlink" title="其他工具"></a><strong>其他工具</strong></h3><p>Bandit 算法比较简单，自己实现不难，这里不再单独列举。至于深度学习部分，则主要基于 TensorFlow 完成。存储、接口相关开源项目和其他互联网服务开发一样，也在对应章节文章列出，这里不再单独列出了。</p><h3 id="完整推荐系统"><a href="#完整推荐系统" class="headerlink" title="完整推荐系统"></a><strong>完整推荐系统</strong></h3><p>这里也梳理一下有哪些完整的推荐系统开源项目，可以作为学习和借鉴。<strong>所谓完整的推荐系统是指：包含推荐算法实现、存储、接口</strong>。</p><p>|开源项目名| 说明 | 开发语言 |<br>| ：—-： | ：—-： | ：—-：|<br>| PredictionIO | 基于Spark(算法)、HBase(存储)、Spray(接口)开发 | Scala |<br>| recommendationRaccoon | 以协同过滤为核心算法的推荐系统，Redis作为存储 | Node.js |<br>| easyrec | 存储采用MySQL，接口基于Tomcat | Java |<br>| hapiger | 存储采用PostgreSQL，接口采用Hapi.js框架 | Node.js |</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>你可能注意到了，这里的推荐系统算法部分以 Python 和 C++ 为主，甚至一些 Python 项目，底层也都是用 C++ 开发而成。因此在算法领域，以 Python 和 C++ 作为开发语言会有比较宽泛的选择范围。</p><p>倾向于选择各个模块的开源项目，再将其组合集成为自己的推荐系统。这样做的好处是有下面几种。</p><blockquote><ol><li>单个模块开源项目容易入手，学习成本低，性能好；</li><li>自己组合后更容易诊断问题，不需要的不用开发；</li><li>单个模块的性能和效果更有保证。</li></ol></blockquote><p><a href="https://postimg.cc/y3RmT1kx" target="_blank" rel="noopener"><img src="https://i.postimg.cc/HnZ6djmw/image.jpg" alt="效果保证&amp;开源工具.jpg"></a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/column/intro/74&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考原作：推荐系统三十六式-刑无刀&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;32-【效果保证】推荐系统的测试方法及常用指标介绍&quot;&gt;&lt;a href=&quot;#32-【效果保证】推荐系统的测试方法及常用指标介绍&quot; class=&quot;headerlink&quot; title=&quot;32.【效果保证】推荐系统的测试方法及常用指标介绍&quot;&gt;&lt;/a&gt;32.【效果保证】推荐系统的测试方法及常用指标介绍&lt;/h2&gt;&lt;h3 id=&quot;为什么要关注指标&quot;&gt;&lt;a href=&quot;#为什么要关注指标&quot; class=&quot;headerlink&quot; title=&quot;为什么要关注指标&quot;&gt;&lt;/a&gt;&lt;strong&gt;为什么要关注指标&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;面对推荐系统这样一个有诸多复杂因素联动起作用的系统，要时时刻刻知道它好不好，健不健康，你同样需要掌握一些测试方法和检测指标。&lt;/p&gt;
&lt;h3 id=&quot;推荐系统的测试方法&quot;&gt;&lt;a href=&quot;#推荐系统的测试方法&quot; class=&quot;headerlink&quot; title=&quot;推荐系统的测试方法&quot;&gt;&lt;/a&gt;&lt;strong&gt;推荐系统的测试方法&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;需要有不确定性思维，但是这绝不是帮你在老板那里开脱的说辞。推荐系统也需要测试，只是它不同于传统的功能测试。传统软件的功能测试，功能的响应是有预期的，点击一个加关注按钮，应该有什么响应，是被产品文档明确规定的；也因此在开发功能的时候，可以同步写出测试用例来。&lt;/p&gt;
&lt;p&gt;这非常明白，在功能开发时，你做了任何改动，只要跑一下测试用例，逻辑对不对就一目了然了。反观推荐系统就没那么容易了，你什么都没动，可能两次推荐的结果都有可能不一样，而且很可能这个不一样也是你自己或者你老板要求的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="推荐系统三十六式" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法" scheme="http://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="推荐" scheme="http://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统三十六式--学习笔记（28-31 关键模块）</title>
    <link href="http://www.xiemingzhao.com/2018/11/10/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F--%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%8828-31%20%E5%85%B3%E9%94%AE%E6%A8%A1%E5%9D%97%EF%BC%89/"/>
    <id>http://www.xiemingzhao.com/2018/11/10/推荐系统三十六式--读书笔记（28-31 关键模块）/</id>
    <published>2018-11-09T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:43.011Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://time.geekbang.org/column/intro/74" target="_blank" rel="noopener">参考原作：推荐系统三十六式-刑无刀</a></p><h2 id="28-【关键模块】巧妇难为无米之炊：数据采集关键要素"><a href="#28-【关键模块】巧妇难为无米之炊：数据采集关键要素" class="headerlink" title="28.【关键模块】巧妇难为无米之炊：数据采集关键要素"></a>28.【关键模块】巧妇难为无米之炊：数据采集关键要素</h2><h3 id="日志和数据"><a href="#日志和数据" class="headerlink" title="日志和数据"></a><strong>日志和数据</strong></h3><p>数据驱动这个概念也是最近几年才开始流行起来的，在古典互联网时代，设计和开发产品完全侧重于功能易用和设计精巧上，并且整体驱动力受限于产品负责人的个人眼光，这属于是一种感性的把握，也因此对积累数据这件事就不是很重视。</p><p>关于数据采集，按照用途分类又有三种：</p><ul><li>报表统计</li><li>数据分析</li><li>机器学习</li></ul><a id="more"></a><p>最基本的数据收集，是为了统计一些核心的产品指标，例如次日留存，七日留存等，一方面是为了监控产品的健康状况，另一方面是为了对外秀肌肉，这一类数据使用非常浅层，对数据的采集要求也不高。</p><p>第二种就是比较常见的数据采集需求所在了。在前面第一种用途基础上，不但需要知道产品是否健康，还需要知道为什么健康、为什么不健康，做对了什么事、做错了什么事，要从数据中去找到根本的原因。最后要产出的是比较简明清晰直观的结论，这是数据分析师综合自己的智慧加工出来的，是有人产出的。它主要用于指导产品设计、指导商业推广、指导开发方式。走到这一步的数据采集，已经是实打实的数据驱动产品了。</p><p>第三种，就是收集数据为了机器学习应用，或者更广泛地说人工智能应用。那么机器学习应用，主要在消化数据的角色是算法、是计算机，而不是人。</p><h3 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a><strong>数据采集</strong></h3><p>推荐系统收集日志需要考虑：日志的数据模型，收集哪些日志，用什么工具收集，收集的日志怎么存储。</p><h4 id="1-数据模型"><a href="#1-数据模型" class="headerlink" title="1. 数据模型"></a><strong>1. 数据模型</strong></h4><p>所谓数据模型，其实就是把数据归类。产品越负责，业务线越多，产生的日志就越复杂。数据模型帮助梳理日志、归类存储，以方便在使用时获取。你可以回顾一下在前面讲过的推荐算法，这些推荐算法形形色色，但是他们所需要的数据可以概括为两个字：矩阵。</p><div class="table-container"><table><thead><tr><th style="text-align:center">矩阵</th><th style="text-align:center">行</th><th style="text-align:center">列</th><th style="text-align:center">数据类型</th></tr></thead><tbody><tr><td style="text-align:center">人，属性矩阵</td><td style="text-align:center">用户ID</td><td style="text-align:center">属性</td><td style="text-align:center">User Profile</td></tr><tr><td style="text-align:center">物，属性矩阵</td><td style="text-align:center">物品ID</td><td style="text-align:center">属性</td><td style="text-align:center">Item Profile</td></tr><tr><td style="text-align:center">人，人 矩阵</td><td style="text-align:center">用户ID</td><td style="text-align:center">用户ID</td><td style="text-align:center">Relation</td></tr><tr><td style="text-align:center">人，物矩阵</td><td style="text-align:center">用户ID</td><td style="text-align:center">物品ID</td><td style="text-align:center">Event</td></tr></tbody></table></div><p>基于这个分析，可以给要收集的数据归纳成下面几种。</p><div class="table-container"><table><thead><tr><th style="text-align:center">模型</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:center">User Profile</td><td style="text-align:left">用户属性数据</td></tr><tr><td style="text-align:center">Item Profile</td><td style="text-align:left">物品属性数据</td></tr><tr><td style="text-align:center">Event</td><td style="text-align:left">时间数据，即用户发生的所有行为和动作，比如曝光，浏览，点击，收藏，购买</td></tr><tr><td style="text-align:center">Relation</td><td style="text-align:left">关系数据，这类数据不是每个产品都有的，社交网站会有社交关系，就属于用户之间的关系数据</td></tr></tbody></table></div><p>有了数据模型，就可以很好地去梳理现有的日志，看看每一种日志属于哪一种。并且，在一个新产品上线之初，该如何为将来的推荐系统记录日志也比较清楚了。这个数据模型当然不能概括全部数据，但是用来构建一个推荐系统就绰绰有余了。接下来就是去收集数据了。</p><h4 id="2-数据在哪？"><a href="#2-数据在哪？" class="headerlink" title="2. 数据在哪？"></a><strong>2. 数据在哪？</strong></h4><p>收集的数据主要来自两种，一种是业务运转必须要存储的记录，例如用户注册资料，如果不在数据库中记录，产品就无法正常运转。另一种就是在用户使用产品时顺便记录下来的，这叫做埋点。第一种数据源来自业务数据库，通常都是结构化存储，MySQL。</p><p>第二种数据需要埋点，埋点又有几种不同方法(按照技术手段分):</p><ul><li><p>第一种，SDK 埋点。</p><blockquote><p>这个是最经典古老的埋点方法，就是在开发自己的 App 或者网站时，嵌入第三方统计的 SDK，App 如友盟等，网站如 Google Analytics 等。<br>SDK 在要收集的数据发生点被调用，将数据发送到第三方统计，第三方统计得到数据后再进一步分析展示。<br>这种数据收集方式对推荐系统的意义不大，因为得不到原始的数据而只是得到统计结果，我们可以将其做一些改动，或者自己仿造做一些开发内部数据采集 SDK，从而能够收集到鲜活的数据。</p></blockquote></li><li><p>第二种，可视化埋点。</p><blockquote><p>可视化埋点在 SDK 埋点基础上做了进一步工作，埋点工作通过可视化配置的方式完成，一般是在 App 端或者网站端嵌入可视化埋点套件的 SDK，然后再管理端接收前端传回的应用控件树，通过点选和配置，指令前端收集那些事件数据。业界有开源方案实现可参考，如 Mixpanel。</p></blockquote></li><li><p>第三种，无埋点。</p><blockquote><p>所谓无埋点不是不埋点收集数据，而是尽可能多自动收集所有数据，但是使用方按照自己的需求去使用部分数据。SDK 埋点就是复杂度高，一旦埋点有错，需要更新客户端版本，可视化埋点的不足就是：收集数据不能收集到非界面数据，例如收集了点击事件，也仅仅能收集一个点击事件，却不能把更详细的数据一并返回。</p></blockquote></li></ul><p>按照收集数据的位置分，又分为<strong>前端埋点和后端埋点</strong>:<br>举个例子，要收集用户的点击事件，前端埋点就是在用户点击时，除了响应他的点击请求，还同时发送一条数据给数据采集方。后端埋点就不一样了，由于用户的点击需要和后端交互，后端收到这个点击请求时就会在服务端打印一条业务日志，所以数据采集就采集这条业务日志即可。<br><strong>国内如神测数据等公司，将这些工作已经做得很傻瓜化了，大大减轻了埋点数据采集的困扰。</strong></p><p>对于推荐系统来说，所需要的数据基本上都可以从后端收集，采集成本较低，但是有两个要求：要求所有的事件都需要和后端交互，要求所有业务响应都要有日志记录。这样才能做到在后端收集日志。</p><blockquote><p>后端收集业务日志好处很多，比如下面几种。</p><ol><li>实时性。由于业务响应是实时的，所以日志打印也是实时的，因此可以做到实时收集。</li><li>可及时更新。由于日志记录都发生在后端，所以需要更新时可以及时更新，而不用重新发布客户端版本。</li><li>开发简单。不需要单独维护一套 SDK。</li></ol></blockquote><p>归纳一下，Event 类别的数据从后端各个业务服务器产生的日志来，Item 和 User 类型数据，从业务数据库来，还有一类特殊的数据就是 Relation 类别，也从业务数据库来。</p><h4 id="3-元素有哪些？"><a href="#3-元素有哪些？" class="headerlink" title="3. 元素有哪些？"></a><strong>3. 元素有哪些？</strong></h4><p>后端收集事件数据需要业务服务器打印日志,大致需要包含下面的几类元素:</p><ol><li>用户 ID，唯一标识用户身份。</li><li>物品 ID，唯一标识物品。这个粒度在某些场景中需要注意，例如电商，物品的 ID 就不是真正要去区别物和物之间的不同，而是指同一类试题，例如一本书《岛上书店》，库存有很多本，并不需要区别库存很多本之间的不同，而是区别《岛上书店》和《白夜行》之间的不同。</li><li>事件名称，每一个行为一个名字。</li><li>事件发生时间，时间非常重要。</li></ol><blockquote><p>以上是基本的内容，下面再来说说加分项。（这些有时候很重要，特别是某些时变的属性，例如机票价格）</p><ol><li>事件发生时的设备信息和地理位置信息等等；</li><li>从什么事件而来；</li><li>从什么页面而来；</li><li>事件发生时用户的相关属性；</li><li>事件发生时物品的相关属性。</li></ol></blockquote><p>把日志记录想象成一个 Live 快照，内容越丰富就越能还原当时的场景。</p><h4 id="4-怎么收集？"><a href="#4-怎么收集？" class="headerlink" title="4. 怎么收集？"></a><strong>4. 怎么收集？</strong></h4><p>一个典型的数据采集架构如下图所示：<br><a href="https://postimg.cc/KKndChx6" target="_blank" rel="noopener"><img src="https://i.postimg.cc/d0XwkJXV/image.jpg" alt="数据采集架构.jpg"></a><br>下面描述一下这个图。最左边就是数据源，有两部分，一个是来自非常稳定的网络服务器日志， NGINX 或者 Apache 产生的日志。</p><p>因为有一类埋点，在 PC 互联网时代，有一种事件数据收集方式是，放一个一像素的图片在某个要采集数据的位置。这个图片被点击时，向服务端发送一个不做什么事情的请求，只是为了在服务端的网络服务器那里产生一条系统日志。 这类日志用 Logstash 收集。</p><p>左边另外的数据源就是业务服务器，这类服务器会处理具体场景的具体业务，甚至推荐系统本身也是一个业务服务器。这类服务器有各自不同的日志记录方式，例如 Java 是 Log4j，Python 是 Logging 等等，还有<br>RPC 服务。这些业务服务器通常会分布在多台机器上，产生的日志需要用 Flume 汇总。</p><p>Kafka 是一个分布式消息队列，按照 Topic 组织队列，订阅消费模式，可以横向水平扩展，非常适合作为日志清洗计算层和日志收集之间的缓冲区。所以一般日志收集后，不论是 Logstash 还是 Flume，都会发送到 Kafka 中指定的 Topic 中。在 Kafka 后端一般是一个流计算框架，上面有不同的计算任务去消费 Kafka 的数据 Topic，流计算框架实时地处理完采集到的数据，会送往分布式的文件系统中永久存储，一般是 HDFS。</p><p>日志的时间属性非常重要。因为在 HDFS 中存储日志时，为了后续抽取方便快速，一般要把日志按照日期分区。当然，在存储时，按照前面介绍的数据模型分不同的库表存储也能够方便在后续构建推荐模型时准备数据。</p><h4 id="5-质量检验"><a href="#5-质量检验" class="headerlink" title="5. 质量检验"></a><strong>5. 质量检验</strong></h4><p>数据采集，日志收集还需要对采集到的数据质量做监控。关注数据质量，大致需要关注下面几个内容。</p><ol><li>是否完整？事件数据至少要有用户 ID、物品 ID、事件名称三元素才算完整，才有意义。</li><li>是否一致？一致是一个广泛的概念。数据就是事实，同一个事实的不同方面会表现成不同数据，这些数据需要互相佐证，逻辑自洽。</li><li>是否正确？该记录的数据一定是取自对应的数据源，这个标准不能满足则应该属于 Bug 级别，记录了错误的数据。</li><li>是否及时？虽然一些客户端埋点数据，为了降低网络消耗，会积攒一定时间打包上传数据，但是数据的及时性直接关系到数据质量。由于推荐系统所需的数据通常会都来自后端埋点，所以及时性还可以保证。</li></ol><hr><h2 id="29-【关键模块】让你的推荐系统反应更快：实时推荐"><a href="#29-【关键模块】让你的推荐系统反应更快：实时推荐" class="headerlink" title="29.【关键模块】让你的推荐系统反应更快：实时推荐"></a>29.【关键模块】让你的推荐系统反应更快：实时推荐</h2><p>推荐系统从业者所追求的三个要素：捕捉兴趣要更快，指标要更高，系统要更健壮。</p><h3 id="为什么要实时"><a href="#为什么要实时" class="headerlink" title="为什么要实时"></a><strong>为什么要实时</strong></h3><p>一个连接从建立开始，其连接的强度就开始衰减，直到最后。用户和物品之间产生的连接，不论轻如点击，还是重如购买，都有推荐的黄金时间。在这个黄金时间，捕捉到用户的兴趣并且给与响应，可能就更容易留住用户。在业界，大家为了高大上，不会说“更快”的推荐系统，而是会说“实时”推荐系统。</p><p>实时推荐，实际上有三个层次：</p><ul><li>第一层，“给得及时”，也就是服务的实时响应。<br>这个是基本的要求，一旦一个推荐系统上线后，在互联网的场景下，没有让用户等个一天一夜的情况，基本上慢的服务接口整个下来响应时间也超过秒级。达到第一层不能成为实时推荐，但是没达到就是不合格。</li><li>第二层，“用得及时”，就是特征的实时更新。<br>例如用户刚刚购买了一个新的商品，这个行为事件，立即更新到用户历史行为中，参与到下一次协同过滤推荐结果的召回中。做到这个层次，已经有实时推荐的意思了，常见的效果就是在经过几轮交互之后，用户的首页推荐会有所变化。这一层次的操作影响范围只是当前用户。</li><li>第三层，“改得及时”，就是模型的实时更新。<br>还是刚才这个例子，用户刚刚购买了一个新的商品，那需要实时地去更新这个商品和所有该用户购买的其他商品之间的相似度，因为这些商品对应的共同购买用户数增加了，商品相似度就是一种推荐模型，所以它的改变影响的是全局推荐。</li></ul><h3 id="实时推荐"><a href="#实时推荐" class="headerlink" title="实时推荐"></a><strong>实时推荐</strong></h3><h4 id="1-架构概览"><a href="#1-架构概览" class="headerlink" title="1. 架构概览"></a><strong>1. 架构概览</strong></h4><p>按照前面的分析，一个处在第三层次的实时推荐，需要满足三个条件：</p><blockquote><ol><li>数据实时进来</li><li>数据实时计算</li><li>结果实时更新</li></ol></blockquote><p>一个基本的实时推荐框图:<br><a href="https://postimg.cc/sQnsF1p6" target="_blank" rel="noopener"><img src="https://i.postimg.cc/PJHxwwNj/image.jpg" alt="实时推荐框架.jpg"></a><br>前端服务负责和用户之间直接交互，不论是采集用户行为数据，还是给出推荐服务返回结果。用户行为数据经过实时的消息队列发布，然后由一个流计算平台消费这些实时数据，一方面清洗后直接入库，另一方面就是参与到实时推荐中，并将实时计算的结果更新到推荐数据库，供推荐服务实时使用。</p><h3 id="2-实时数据"><a href="#2-实时数据" class="headerlink" title="2. 实时数据"></a><strong>2. 实时数据</strong></h3><p>实时流数据的接入，在上一篇专栏中已经讲到过，需要一个实时的消息队列，开源解决方案Kafka 已经是非常成熟的选项。<br><a href="https://postimg.cc/0zB9Hz0V" target="_blank" rel="noopener"><img src="https://i.postimg.cc/5txjyvYW/kafka.jpg" alt="kafka.jpg"></a><br>Kafka 以生产者消费者的模式吞吐数据，这些数据以主题的方式组织在一起，每一个主题的数据会被分为多块，消费者各自去消费，互不影响，Kafka 也不会因为某个消费者消费了而删除数据。</p><p>每一个消费者各自保存状态信息：所消费数据在 Kafka 某个主题某个分块下的偏移位置。也因此任意时刻、任意消费者，只要自己愿意，可以从 Kafka 任意位置开始消费数据，一遍消费，对应的偏移量顺序往前移动。示意图如下:<br><a href="https://postimg.cc/PvTH8Yd5" target="_blank" rel="noopener"><img src="https://i.postimg.cc/1XN32rTw/kafka.jpg" alt="kafka偏移量.jpg"></a></p><p>一个生产者可以看做一个数据源，生产者决定数据源放进哪个主题中，甚至通过一些算法决定数据如何落进哪个分块里。示意图如下：<br><a href="https://postimg.cc/237b9xbT" target="_blank" rel="noopener"><img src="https://i.postimg.cc/CMWG1PFy/kafka.jpg" alt="kafka数据源.jpg"></a><br>因此，Kafka 的生产者和消费者在自己的项目中实现时都非常简单，就是往某个主题写数据，以及从某个主题读数据。</p><h4 id="3-流计算"><a href="#3-流计算" class="headerlink" title="3. 流计算"></a><strong>3. 流计算</strong></h4><p>整个实时推荐建立在流计算平台上。常见的流计算平台有 Twitter 开源的 Storm，“Yahoo！”开源的 S4，还有 Spark 中的 Streaming。<br>Storm 使用者越来越多，社区越来越繁荣，并且相比 Streaming 的 MiniBatch 模式，Storm 才是真正的流计算。另新的流计算框架 FLink 表现强劲，高吞吐低延迟，也很不错。</p><p>Storm 是一个流计算框架，它有以下几个元素。</p><blockquote><ol><li>Spout，意思是喷嘴，水龙头，接入一个数据流，然后以喷嘴的形式把数据喷洒出去。</li><li>Bolt，意思是螺栓，像是两段水管的连接处，两端可以接入喷嘴，也可以接入另一个螺栓，数据流就进入了下一个处理环节。</li><li>Tuple，意思是元组，就是流在水管中的水。</li><li>Topology，意思是拓扑结构，螺栓和喷嘴，以及之间的数据水管，一起组成了一个有向无环图，这就是一个拓扑结构。</li></ol></blockquote><p><strong>注意，Storm 规定了这些基本的元素，也是你在 Storm 平台上编程时需要实现的，但不用关心水管在哪，水管由 Storm 提供，你只用实现自己需要的水龙头和水管连接的螺栓即可。</strong></p><p>因此，其编程模型也非常简单。举一个简单的例子，看看如何用 Storm 实现流计算？假如有一个字符串构成的数据流，这个数据流恰好也是 Kafka 中的一个主题，正在源源不断地在接入。要用 Storm 实现一个流计算统计每一个字符的频率。你首先需要实现一个 Spout，也就是给数据流加装一个水龙头，这个水龙头那一端就是一个 Kafka 的消费者，从 Kafka 中不断取出字符串数据，这头就喷出来，然后再实现 Bolt，也就是螺栓。当有字符串数据流进来时，把他们拆成不同的字符，并以（字符，1）这样的方式变成新的数据流发射出去，    后就是去把相同字符的数据流聚合起来，相加就得到了字符的频率。</p><p>实际上，如果你知道 MapReduce 过程的话，你会发现虽然 Storm 重新取了名字，仍然可以按照 MapReduce 来理解。 Storm 的模型示意如下：<br><a href="https://postimg.cc/tZXysFqC" target="_blank" rel="noopener"><img src="https://i.postimg.cc/XJ5vDgtF/storm.jpg" alt="storm.jpg"></a><br>Storm 中要运行实时推荐系统的所有计算和统计任务，比如有下面几种：</p><blockquote><ol><li>清洗数据；</li><li>合并用户的历史行为；</li><li>重新更新物品相似度；</li><li>在线更新机器学习模型；</li><li>更新推荐结果。</li></ol></blockquote><h4 id="4-算法实时化"><a href="#4-算法实时化" class="headerlink" title="4. 算法实时化"></a><strong>4. 算法实时化</strong></h4><p>我在前面的文章里面，已经介绍过基于物品的协同过滤原理。下面我以基于物品的协同过滤算法为主线，来讲解一下如何实现实时推荐，其他算法你可以举一反三改造。主要是两个计算，第一个是计算物品之间的相似度。</p><script type="math/tex; mode=display">sim(i,j) = \frac{co_users(item_i,item_j)}{\sqrt{count_users(item_i)}\sqrt{count_users(item_j)}}</script><p>计算了物品和物品之间的相似度之后，用另一个公式来计算推荐分数：</p><script type="math/tex; mode=display">rec(u,i)=\frac{\sum_{j \in N_i}sim(i,j)r_{uj}}{\sum_{j \in N_i} sim(i,j)}</script><p>要做到前面说的第三层次实时推荐，首先就是要做到增量更新物品之间的相似度。相似度计算分成三部分：</p><blockquote><ol><li>分子上的“物品对”，共同评分用户数；</li><li>分母上左边是物品 i 的评价用户数；</li><li>分母上右边是物品 j 的评价用户数。</li></ol></blockquote><p>所以更新计算相似度就要更新三部分，实际上一种相似度增量更新策略是在收到一条用户评分事件数据时，然后取出这个用户的历史评分物品列表，因为所有的历史评分物品现在和这个新评分物品之间，就要增加一个共同评分了。</p><p>并且，这个新物品本身，也要给自己一个评分用户数。更新完三个后，就实时更新所有这些“物品对”的相似度了。转换成 Storm 的编程模型，你需要实现：</p><blockquote><ol><li>Spout：消费实时消息队列中的用户评分事件数据，并发射成（UserID , ItemID_i）这样的Tuple;</li><li>Bolt1：接的是源头 Spout，输入了 UserID 和 ItemID_i，读出用户历史评分 Item 列表， 遍历这些 ItemID_j，逐一发射成 ((Item_i, Item_j), 1) 和 ((Item_j, Item_i), 1)，并将 Item_i 加进历史评分列表中；</li><li>Bolt2：接的是源头 Spout，输入了 UserID 和 ItemID_i，发射成 (ItemID_i, 1)；</li><li>Bolt3：接 Bolt1，更新相似度所需的分子</li><li>Bolt4：接 Bolt2，更新物品自己的评分用户数把这个过程表示成公式就是：<script type="math/tex; mode=display">sim(i,j) = \frac{co_users(item_i,item_j)+\Delta co_users}{\sqrt{count_users(item_i) +\Delta count_users(i)}\sqrt{count_users(item_j) + \Delta count_users(j)}}</script></li></ol></blockquote><p>另外，还有实时更新推荐结果，也是作为 Storm 的一个 Bolt 存在，接到用户行为数据，重新更新推荐结果，写回推荐结果数据中。</p><h4 id="5-效率提升"><a href="#5-效率提升" class="headerlink" title="5. 效率提升"></a><strong>5. 效率提升</strong></h4><p>上面展示了一个基于物品的协同过滤算法在实时推荐中的计算过程，那么随之而来的一些问题也需要解决。比如当用户历史行为数据有很多时，或者物品对是热门物品时，相似度实时更新就有些挑战了。对此可以有如下应对办法：剪枝，加窗，采样，缓存。</p><p>所谓剪枝就是，并不是需要对每一个“物品对”都做增量计算。两个物品之间的相似度，每更新一次得到的新相似度，可以看成一个随机变量，那么这个随机变量就有一个期望值，一旦物品之间的相似度可以以较高的置信度确认，它已经在期望值附近小幅度波动了，也就没必要再去更新了。</p><p>甚至如果进一步确定是一个比较小的相似度，或者可以直接干掉这个物品对，不被更新，也不参与计算。那么问题就来了，怎么确定什么时候可以不再更新这个物品对的相似度了呢？这时候要用到一个不等式：Hoeffding 不等式。</p><p>Hoeffding 不等式适用于有界的随机变量。相似度明显是有界的，最大值是 1，最小值是 0。所以可以用这个不等式，Hoeffding 不等式是这样一个统计法则：<strong>随机变量的真实期望值不会超过$\hat x + \epsilon$ 的概率是概率$1-\delta$</strong>，其中 的值是这样算的：</p><script type="math/tex; mode=display">\epsilon = \sqrt{\frac{ln(\frac{1}{\delta})}{2n}}</script><p>公式中： 是历次更新得到的相似度平均值，n 是更新过的次数。这样一来，你选定$\delta$和$\epsilon$之后就知道更新多少次之后就可以放心大胆地使用了。</p><p>举例：这里设置$\delta = 0.05$</p><div class="table-container"><table><thead><tr><th style="text-align:center">与真实相似度误差</th><th style="text-align:center">最少更新次数</th></tr></thead><tbody><tr><td style="text-align:center">0.1</td><td style="text-align:center">150</td></tr><tr><td style="text-align:center">0.05</td><td style="text-align:center">600</td></tr><tr><td style="text-align:center">0.01</td><td style="text-align:center">14979</td></tr></tbody></table></div><p>也就是在前面讲到的更新相似度的 Bolt 中，如果发现一个物品对的更新次数已经达到最少更新次数，则可以不再更新，并且，如果此时相似度小于设定阈值，就可以斩钉截铁地说：这两个物品不相似，以后不用再参与推荐计算了。</p><p>这就是一项基于统计的剪枝方法，除此之外还有<strong>加窗、采样、合并三种常规办法。</strong></p><ul><li>首先，关于加窗。用户的兴趣会衰减，请你不要怀疑这一点，因为这是这篇文章的基本假设和出发点。用户兴趣衰减，那么一个直接的推论就是，比较久远的用户历史行为数据所起的作用应该小一些。所以，另一个剪枝技术就是：滑窗。设定一个时间窗口，时间窗口内的历史行为数据参与实时计算，窗口外的不再参与实时计算。<blockquote><p>这个窗口有两种办法：</p></blockquote></li></ul><ol><li>近 K 次会话。用户如果反复来访问产品，每次访问是一次会话，那么实时计算时只保留近 K 次会话信息。</li><li>近 K 条行为记录。不管访问多少次，只保留最近 K 条历史行为事件，参与到实时推荐中。<br><strong>两种滑窗方法都可以有效保证实时计算的效率，同时不会明显降低推荐效果。</strong></li></ol><ul><li><p>关于采样。当你的推荐系统遇到热门的物品或者异常活跃的用户，或者有时候就只是突然一个热点爆发了。</p><blockquote><p>它们会在短时间产生大量的数据，除了前面的剪枝方法，还可以对这种短时间大量出现的数据采样，采样手段有很多，可以均匀采样，也可以加权采样，这在前面的专栏里已经详细介绍过方法。</p></blockquote></li><li><p>关于合并计算。在前面介绍的增量计算中，是假设收到每一个用户行为事件时都要去更新相似度和推荐结果，如果在突然大量涌入行为数据时，可以不必每一条来了都去更新，而是可以在数据流的上游做一定的合并。</p><blockquote><p>相似度计算公式的分子分母两部分都可以这样做，等合并若干事件数据之后，再送入下游去更新<br>相似度和推荐结果。</p></blockquote></li></ul><p>最后，提高实时推荐的效率，甚至不只是推荐系统，在任何互联网应用的后端，缓存都是提高效<br>率必不可少的部分。可以根据实际情况，对于高频访问的物品或者用户增加缓存，</p><blockquote><p>这可能包括：</p><ol><li>活跃用户的历史行为数据；</li><li>热门物品的特征数据；</li><li>热门物品的相似物品列表。</li></ol></blockquote><p>缓存系统一般采用 Memcached 或者 Redis 集群。缓存有个问题就是，数据的一致性可能比较<br>难保证，毕竟它和真正的业务数据库之间要保持时时刻刻同步也是一项挑战。</p><hr><h2 id="30-【关键模块】让数据驱动落地，你需要一个实验平台"><a href="#30-【关键模块】让数据驱动落地，你需要一个实验平台" class="headerlink" title="30.【关键模块】让数据驱动落地，你需要一个实验平台"></a>30.【关键模块】让数据驱动落地，你需要一个实验平台</h2><h3 id="数据驱动和实验平台"><a href="#数据驱动和实验平台" class="headerlink" title="数据驱动和实验平台"></a><strong>数据驱动和实验平台</strong></h3><p>要做到数据驱动，就要做到两点：第一点是数据，第二点是驱动。要做到驱动，需要一个 AB 实验平台。数据驱动的重点是做对比实验，通过对比，让模型、策略、设计等不同创意和智慧结晶新陈代谢，不断迭代更新。对比实验也常常被大家叫做 ABTest。</p><blockquote><p>要讨论实验平台，先要认识实验本身。互联网实验，需要三个要素。</p><ol><li>流量：流量就是用户的访问，也是实验的样本来源。</li><li>参数：参数就是各种组合，也是用户访问后，从触发互联网产品这个大函数，到最后返回结果给用户，中间所走的路径。</li><li>结果：实验的全过程都有日志记录，通过这些日志才能分析出实验结果，是否成功，是否显著。</li></ol></blockquote><p>实验要观察的结果就是一个随机变量，这个变量有一个期望值，要积累很多样本才能说观察到的实验结果比较接近期望值了，或者要观察一定时期才能说对照实验之间有区别或者没区别。因为只有明显有区别并且区别项好，才能被进一步推上全线。</p><p>在设计一个实验之初，实验设计人员总是需要考虑下面这些问题。</p><blockquote><ol><li>实验的起止时间。这涉及到样本的数量，关系到统计效果的显著性，也涉及能否取出时间因素的影响。</li><li>实验的流量大小。这也涉及了样本的数量，关系到统计效果的显著性。</li><li>流量的分配方式。每一个流量在为其选择参数分支时，希望是不带任何偏见的，也就是均匀采样，通常按照 UUID 或者 Cookie 随机取样。</li><li>流量的分配条件。还有一些实验需要针对某个流量的子集，例如只对重庆地区的用户测试，推荐时要不要把火锅做额外的提升加权。</li><li>流量如何无偏置。这是流量分配最大的问题，也是最难的问题。<br>同时只做一个实验时，这个问题不明显，但是要同时做多个实验，那么如何避免前面的实验给后面的实验带来影响，这个影响就是流量偏置，意思是在前面实验的流量分配中，有一种潜在的因素在影响流量分配，这个潜在的因素不易被人察觉，潜在的因素如果会影响实验结果，那么处在这个实验后面获得流量的实验，就很难得到客观的结论。</li></ol></blockquote><p>Google 公司的实验平台已经成为行业争相学习的对象，所以今天我会以 Google 的实验平台为主要对象，深入浅出地介绍一个重叠实验平台的方方面面。</p><h3 id="重叠实验架构"><a href="#重叠实验架构" class="headerlink" title="重叠实验架构"></a><strong>重叠实验架构</strong></h3><p>所谓重叠实验，就是一个流量从进入产品服务，到最后返回结果呈现给用户，中间设置了好几个检查站，每个检查站都在测试某些东西，这样同时做多组实验就是重叠实验。</p><p>面说了，重叠实验最大的问题是怎么避免流量偏置。为此，需要引入三个概念。</p><blockquote><ol><li>域：是流量的一个大的划分，最上层的流量进来时首先是划分域。</li><li>层：是系统参数的一个子集，一层实验是对一个参数子集的测试。</li><li>桶：实验组和对照组就在这些桶中。</li></ol></blockquote><p>层和域可以互相嵌套。意思是对流量划分，例如划分出 50%，这 50% 的流量是一个域，这个域里面有多个实验层，每一个实验层里面还可以继续嵌套域，也就是可以进步划分这 50% 的流量。下面这两个图示意了有域划分和没有域划分的两种情况：<br><a href="https://postimg.cc/1nfHyYkG" target="_blank" rel="noopener"><img src="https://i.postimg.cc/HxtP4q3h/image.jpg" alt="实验域的划分.jpg"></a><br>图中左边是一个三层实验，但是并没有没有划分域。第一层实验要测试 UI 相关，第二层要测试推荐结果，第三层要测试在推荐结果插入广告的结果。</p><p>三层互不影响。图中的右边则添加了域划分，也就是不再是全部流量都参与实验中，而是被分走了一部分到左边域中。剩下的流量和左边的实验一样。</p><p>这里要理解一点，为什么多层实验能做到重叠而不带来流量偏置呢？<br>这就需要说桶的概念。还是上面示意图中的左图，假如这个实验平台每一层都是均匀随机分成 5 个桶，在实际的实验平台上，可能是上千个桶，这里只是为了举例。示意图如下：<br><a href="https://postimg.cc/3W2G2TFy" target="_blank" rel="noopener"><img src="https://i.postimg.cc/fWrvnW3v/image.jpg" alt="流量偏置.jpg"></a></p><p>这是一个划分域的三层实验。每一层分成 5 个桶，一个流量来了，在第一层，有统一的随机分流算法，将 Cookie 或者 UUID 加上第一层 ID，均匀散列成一个整数，再把这个整数对 5 取模，于是一个流量就随机地进入了 5 个桶之一。</p><p>每一个桶均匀得到 20% 的流量。每一个桶里面已经决定好了为你展示什么样的 UI，流量继续往下走。每一个桶的流量接着依然面对随机进入下一层实验的 5 个桶之一，原来每个桶的 20% 流量都被均分成 5 份，每个桶都有 4% 的流量进入到第二层的每个桶。</p><p>这样一来，第二层每个桶实际上得到的依然是总流量的 20%，而且上一层实验带来的影响被均匀地分散在了这一层的每一个桶中，也就是可以认为上一层实验对这一层没有影响。同样的，第三层实验也是这样。</p><p>关于分层实验，有几点需要注意：</p><blockquote><ol><li>每一层分桶时，不是只对 Cookie 或者 UUID 散列取模，而是加上了层 ID，是为了让层和层之间分桶相互独立；</li><li>Cookie 或者 UUID 散列成整数时，考虑用均匀的散列算法，如 MD5。</li><li>取模要一致，为了用户体验，虽然是分桶实验，但是同一个用户在同一个位置每次感受不一致，会有损用户体验。</li></ol></blockquote><p>Google 的重叠实验架构还有一个特殊的实验层，叫做发布层，优先于所有其他的实验层，它拥有全部流量。这个层中的实验，通常是已经通过了 ABtest 准备全量发布了。示意图如下：<br><a href="https://postimg.cc/hQKt9HKx" target="_blank" rel="noopener"><img src="https://i.postimg.cc/d3yZKYXW/image.jpg" alt="image.jpg"></a><br>前面举例所说的对用户身份 ID 做散列的流量分配方式，只是其中一种，还有三种流量分配方式，一共四种：</p><blockquote><ol><li>Cookie+ 层 ID 取模；</li><li>完全随机；</li><li>用户 ID+ 层 ID 取模；</li><li>Cookie+ 日期取模。</li></ol></blockquote><p>在实验中，得到流量后还可以增加流量条件，比如按照流量地域，决定要不要对其实验，如果不符合条件，则这个流量不会再参与后面的实验，这样避免引入偏置，那么这个流量会被回收，也就是使用默认参数返回结果。</p><p>在 Google 的架构中，由于层和域还可以嵌套，所以在进入某个层时，可能会遇到一个嵌套域，这时候需要按照域划分方式继续下沉，直到遇到实验或者被作为回收流量返回。整个实验平台，工作的示意图如下所示：<br><a href="https://postimg.cc/GHcQXQKx" target="_blank" rel="noopener"><img src="https://i.postimg.cc/hPm5PZ76/google.jpg" alt="google实验平台.jpg"></a><br>说明如下：</p><blockquote><ol><li>图中涉及了判断的地方，虚线表示判断为假，实线表示判断为真。</li><li>从最顶端开始，不断遍历域、层、桶，最终输出一个队列 Re，其中记录对每一个系统参数子集如何处理，取实验配置的参数还是使用默认参数，其中无偏流量表示使用默认参数，也就是在那一层不参与实验，流量被回收。</li><li>拿到 Re 就得到了全部的实验，在去调用对应的服务。</li></ol></blockquote><h3 id="统计效果"><a href="#统计效果" class="headerlink" title="统计效果"></a><strong>统计效果</strong></h3><p>除了分层实验平台之外，还存在另一个问题，每一个实验需要累计获得多少流量才能得到实验结论呢？这涉及了一点统计学知识。实验得到的流量不够，可以说实验的结论没有统计意义，也就浪费了这些流量，而实验在已经具有统计意义之后，如果还占用流量做测试，则也是在浪费流量。<br>如何确定实验规模呢？Google 给出了如下公式：</p><script type="math/tex; mode=display">N>=10.5(\frac{s}{\theta})^2</script><p>公式中：</p><ol><li>$s$是实验指标的标准差。</li><li>$\theta$是希望检测的敏感度，比如想检测到 2% 的 CTR 变化。<br>上面这个公式计算出来的实验规模，表示以 90% 的概率相信结果的显著性，也就是有 90% 的统计功效。如想改变此值，则可以查找对应的显著性水平对应的参数，修改10.5。</li></ol><h3 id="对比实验的弊端"><a href="#对比实验的弊端" class="headerlink" title="对比实验的弊端"></a><strong>对比实验的弊端</strong></h3><p>AB 测试实验平台，是产品要做到数据驱动必不可少的东西，但是这种流量划分的实验方式也有自己的弊端，列举如下：</p><blockquote><ol><li>落入实验组的流量，在实验期间，可能要冒着一定的风险得到不好的用户体验，在实验结束之前，这部分流量以 100% 的概率面对这不确定性；</li><li>要得得到较高统计功效的话，就需要较长时间的测试，如果急于看到结果全面上线来说有点不能接收；</li><li>下线的实验组如果不被人想起，就不再有机会得到测试。</li></ol></blockquote><p>诸如此类弊端，也可以考虑在实验平台中用 Bandit 算法替代流量划分的方式，通过 Bandit 算法选择不同的参数组合、策略，动态实时地根据用户表现给出选择策略，一定程度上可以避免上面列举的弊端。</p><hr><h2 id="31-【关键模块】-推荐系统服务化、存储选型及API设计"><a href="#31-【关键模块】-推荐系统服务化、存储选型及API设计" class="headerlink" title="31.【关键模块】 推荐系统服务化、存储选型及API设计"></a>31.【关键模块】 推荐系统服务化、存储选型及API设计</h2><h3 id="服务化是最后一步"><a href="#服务化是最后一步" class="headerlink" title="服务化是最后一步"></a><strong>服务化是最后一步</strong></h3><p>提供一个在线服务，需要两个关键元素：数据库和 API。</p><h3 id="存储"><a href="#存储" class="headerlink" title="存储"></a><strong>存储</strong></h3><p>这里讲到的存储，专指近线或者在线部分所用的数据库，并不包括离线分析时所涉及的业务数据库或者日志数据库。推荐系统在离线阶段会得到一些关键结果，这些关键结果需要存进数据库，供近线阶段做实时和准实时的更新，最终会在在线阶段直接使用。</p><p>首先来看一下，离线阶段会产生哪些数据。按照用途来分，归纳起来一共就有三类:</p><blockquote><ol><li>特征。特征数据会是最多的，所谓用户画像，物品画像，这些都是特征数据，更新并不频繁。</li><li>模型。尤其是机器学习模型，这类数据的特点是它们大都是键值对，更新比较频繁。</li><li>结果。就是一些推荐方法在离线阶段批量计算出推荐结果后，供最后融合时召回使用。任何一个数据都可以直接做推荐结果，如协同过滤结果。</li></ol></blockquote><p>如果把整个推荐系统笼统地看成一个大模型的话，它依赖的特征是由各种特征工程得到的，这些线下的特征工程和样本数据共同得到模型数据，这些模型在线上使用时，需要让线上的特征和线下的特征一致，因此需要把线下挖掘的特征放到线上去。</p><p>特征数据有两种，一种是稀疏的，一种是稠密的，稀疏的特征常见就是文本类特征，用户标签之类的，稠密的特征则是各种隐因子模型的产出参数。</p><p><strong>特征数据又常常要以两种形态存在：一种是正排，一种是倒排</strong>。正排就是以用户 ID 或者物品 ID 作为主键查询，倒排则是以特征作为主键查询。</p><p>在需要拼凑出样本的特征向量时，如线下从日志中得到曝光和点击样本后，还需要把对应的用户 ID 和物品 ID 展开成各自的特征向量，再送入学习算法中得到最终模型，这个时候就需要正排了。另一种是在需要召回候选集时，如已知用户的个人标签，要用个人标签召回新闻，那么久就需要提前准备好标签对新闻的倒排索引。</p><p>这两种形态的特征数据，需要用不同的数据库存储。正排需要用列式数据库存储，倒排索引需要用 KV 数据库存储。前者最典型的就是 HBase 和 Cassandra，后者就是 Redis 或 Memcached。</p><p>另外，对于稠密特征向量，例如各种隐因子向量，Embedding 向量，可以考虑文件存储，采用内存映射的方式，会更加高效地读取和使用。</p><p>模型数据也是一类重要的数据，模型数据又分为机器学习模型和非机器学习模型。机器学习模型与预测函数紧密相关。模型训练阶段，如果是超大规模的参数数量，业界一般采用分布式参数服务器，对于达到超大规模参数的场景在中小公司不常见，可以不用牛刀。而是采用更加灵活的 PMML 文件作为模型的存储方式，PMML 是一种模型文件协议，其中定义模型的参数和预测函数。</p><p>非机器学习模型，则不太好定义，有一个非常典型的是相似度矩阵，物品相似度，用户相似度，在离线阶段通过用户行为协同矩阵计算得到的。相似度矩阵之所以算作模型，因为，它是用来对用户或者物品历史评分加权的，这些历史评分就是特征，所以相似度应该看做模型数据。</p><p>最后，是预先计算出来的推荐结果，或者叫候选集，这类数据通常是 ID 类，召回方式是用户 ID 和策略算法名称。这种列表类的数据一般也是采用高效的 KV(Key-Value) 数据库存储，如 Redis。</p><p>另外，还要介绍一个特殊的数据存储工具：ElasticSearch。这原本是一个构建在开源搜索引擎 Lucene 基础上的分布式搜索引擎，也常用于日志存储和分析，但由于它良好的接口设计，扩展性和尚可的性能，也常常被采用来做推荐系统的简单第一版，直接承担了存储和计算的任务。</p><h4 id="1-列式数据库"><a href="#1-列式数据库" class="headerlink" title="1. 列式数据库"></a><strong>1. 列式数据库</strong></h4><p>所谓列式数据库，是和行式数据库相对应的，这里不讨论数据库的原理，但是可以有一个简单的比喻来理解这两种数据库。你把数据都想象成为矩阵，行是一条一条的记录，例如一个物品是一行，列是记录的各个字段，例如 ID 是一列，名称是一列，类似等等。</p><p>当我们在说行和列的时候，其实是在大脑中有一个抽象的想象，把数据想象成了二维矩阵，但是实际上，数据在计算机中，管你是行式还是列式，都要以一个一维序列的方式存在内存里或者磁盘上。那么有意思的就来了，是按照列的方式把数据变成一维呢，还是按照行的方式把数据变成一维呢，这就是列式数据库和行式数据库的区别。当然实际上数据库比这复杂多了，这只是一个简单形象的说明，有助于你去理解数据的存储方式。</p><p>列式数据库有个列族的概念，可以对应于关系型数据库中的表，还有一个键空间的概念，对应于关系型数据库中的数据库。<br>众所周知，列式数据库适合批量写入和批量查询，因此常常在推荐系统中有广泛应用。列式数据库当推 Cassandra 和 HBase，两者都受 Google 的 BigTable 影响，但区别是：Cassandra 是一个去中心化的分布式数据库，而 HBase 则是一个有 Master 节点的分布式存储。</p><p>Cassandra 在数据库的 CAP 理论中可以平滑权衡，而 HBase 则是强一致性，并且 Cassandra 读写性能优于 HBase，因此 Cassandra 更适合推荐系统，毕竟推荐系统不是业务逻辑导向的，对强一致性要求不那么强烈。</p><p>Cassandra 的数据模型组织形式如下图所示：<br><a href="https://postimg.cc/VJ24ct15" target="_blank" rel="noopener"><img src="https://i.postimg.cc/bvw5k0B0/Cassandra.jpg" alt="Cassandra.jpg"></a></p><h4 id="2-键值数据库"><a href="#2-键值数据库" class="headerlink" title="2. 键值数据库"></a><strong>2. 键值数据库</strong></h4><p>除了列式数据库外，还有一种存储模式，就是键值对内存数据库，这当然首推 Redis。Redis 你可以简单理解成是一个网络版的 HashMap，但是它存储的值类型比较丰富，有字符串、列表、有序列表、集合、二进制位。并且，Redis 的数据放在了内存中，所以都是闪电般的速度来读取。</p><p>在推荐系统的以下场景中常常见到 Redis 的身影：</p><blockquote><ol><li>消息队列，List 类型的存储可以满足这一需求；</li><li>优先队列，比如兴趣排序后的信息流，或者相关物品，对此 sorted set 类型的存储可以满足这一需求；</li><li>模型参数，这是典型的键值对来满足。</li></ol></blockquote><p>另外，Redis 被人诟病的就是不太高可用，对此已经有一些集群方案，有官方的和非官方的，可以试着加强下 Redis 的高可用。</p><h4 id="3-非数据库"><a href="#3-非数据库" class="headerlink" title="3. 非数据库"></a><strong>3. 非数据库</strong></h4><p>除了数据库外，在推荐系统中还会用到一些非主流但常用的存储方式。第一个就是虚拟内存映射，称为 MMAP，这可以看成是一个简陋版的数据库，其原理就是把磁盘上的文件映射到内存中，以解决数据太大不能读入内存，但又想随机读取的矛盾需求。比如你训练的词嵌入向量，或者隐因子模型，当特别大时，可以二进制存在文件中，然后采用虚拟内存映射方式读取。</p><p>另外一个就是 PMML 文件，专门用于保存数据挖掘和部分机器学习模型参数及决策函数的。当模型参数还不足以称之为海量时，PMML 是一个很好的部署方法，可以让线上服务在做预测时并不依赖离线时的编程语言，以 PMML 协议保存离线训练结果就好。</p><h3 id="API"><a href="#API" class="headerlink" title="API"></a><strong>API</strong></h3><p>除了存储，推荐系统作为一个服务，应该以良好的接口和上有服务之间交互，因此要设计良好的 API。<br><strong>API 有两大类，一类数据录入，另一类是推荐服务</strong>。数据录入 API，可以用于数据采集的埋点，或者其他数据录入。</p><div class="table-container"><table><thead><tr><th style="text-align:center">接口</th><th style="text-align:center">用途</th><th style="text-align:center">基本输入参数</th><th style="text-align:center">备注</th></tr></thead><tbody><tr><td style="text-align:center">/Users</td><td style="text-align:center">录入用户信息</td><td style="text-align:center">userid,attribute,value</td><td style="text-align:center">可以接受任意多的属性和值</td></tr><tr><td style="text-align:center">/Item</td><td style="text-align:center">录入物品信息</td><td style="text-align:center">itemid,attribute,value</td><td style="text-align:center">和用户接口类似</td></tr><tr><td style="text-align:center">/Relation</td><td style="text-align:center">录入一个关系数据</td><td style="text-align:center">from,to,weight</td><td style="text-align:center">参考关系数据的存储模型</td></tr><tr><td style="text-align:center">/Event</td><td style="text-align:center">录入事件</td><td style="text-align:center">userid,itemid,eventname,timestamp</td><td style="text-align:center">参考时间数据的存储模型</td></tr></tbody></table></div><p>推荐服务的 API 按照推荐场景来设计，则是一种比较常见的方式。</p><h4 id="1-猜你喜欢接口："><a href="#1-猜你喜欢接口：" class="headerlink" title="1. 猜你喜欢接口："></a><strong>1. 猜你喜欢接口：</strong></h4><p>/Recommend 输入：</p><ul><li>UserID – 个性化推荐的前提 </li><li>PageID – 推荐的页面 ID，关系到一些业务策略 </li><li>FromPage – 从什么页面来 </li><li>PositionID – 页面中的推荐位 ID </li><li>Size – 请求的推荐数量 </li><li>Offset – 偏移量，这是用于翻页的<br>输出：</li><li>Items – 推荐列表，通常是数组形式，每一个物品除了有 ID，还有展示所需的各类元素 </li><li>Recommend_id – 唯一 ID 标识每一次调用，也叫做曝光 ID，标识每一次曝光，用于推荐后追踪推荐效果的，很重要 </li><li>Size – 本次推荐数量 </li><li>Page —— 用于翻页的</li></ul><h4 id="2-相关推荐接口："><a href="#2-相关推荐接口：" class="headerlink" title="2. 相关推荐接口："></a><strong>2. 相关推荐接口：</strong></h4><p>/Relative 输入：</p><ul><li>UserID – 个性化推荐的前提 </li><li>PageID – 推荐的页面 ID，关系到一些业务策略 </li><li>FromPage – 从什么页面来 </li><li>PositionID – 页面中的推荐位 ID </li><li>ItemID – 需要知道正在浏览哪个物品导致推荐相关物品 </li><li>Size – 请求的推荐数量 </li><li>Offset – 偏移量，这是用于翻页的输出：</li><li>Items – 推荐列表，通常是数组形式，每一个物品除了有 ID，还有展示所需的各类元素 </li><li>Recommend_ID – 唯一 ID 标识每一次调用，也叫做曝光 ID，标识每一次曝光，用于推荐后追踪推荐效果的，很重要 </li><li>Size – 本次推荐数量 </li><li>Page —— 用于翻页的</li></ul><h4 id="3-热门排行榜接口："><a href="#3-热门排行榜接口：" class="headerlink" title="3. 热门排行榜接口："></a><strong>3. 热门排行榜接口：</strong></h4><p>/Relative 输入：</p><ul><li>UserID – 个性化推荐的前提 </li><li>PageID – 推荐的页面 ID，关系到一些业务策略 </li><li>FromPage – 从什么页面来 </li><li>PositionID – 页面中的推荐位 ID </li><li>Size – 请求的推荐数量 </li><li>Offset – 偏移量，这是用于翻页的输出：</li><li>Items – 推荐列表，通常是数组形式，每一个物品除了有 ID，还有展示所需的各类元素 </li><li>Recommend_id – 唯一 ID 标识每一次调用，也叫做曝光 ID，标识每一次曝光，用于推荐后追踪推荐效果的，很重要 </li><li>Size – 本次推荐的数量  * Page —— 用于翻页的</li></ul><p>相信你看到了吧，实际上这些接口都很类似。</p><p><a href="https://postimg.cc/K4YTJzSW" target="_blank" rel="noopener"><img src="https://i.postimg.cc/WpG7pF9s/image.jpg" alt="关键模块.jpg"></a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/column/intro/74&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考原作：推荐系统三十六式-刑无刀&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;28-【关键模块】巧妇难为无米之炊：数据采集关键要素&quot;&gt;&lt;a href=&quot;#28-【关键模块】巧妇难为无米之炊：数据采集关键要素&quot; class=&quot;headerlink&quot; title=&quot;28.【关键模块】巧妇难为无米之炊：数据采集关键要素&quot;&gt;&lt;/a&gt;28.【关键模块】巧妇难为无米之炊：数据采集关键要素&lt;/h2&gt;&lt;h3 id=&quot;日志和数据&quot;&gt;&lt;a href=&quot;#日志和数据&quot; class=&quot;headerlink&quot; title=&quot;日志和数据&quot;&gt;&lt;/a&gt;&lt;strong&gt;日志和数据&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;数据驱动这个概念也是最近几年才开始流行起来的，在古典互联网时代，设计和开发产品完全侧重于功能易用和设计精巧上，并且整体驱动力受限于产品负责人的个人眼光，这属于是一种感性的把握，也因此对积累数据这件事就不是很重视。&lt;/p&gt;
&lt;p&gt;关于数据采集，按照用途分类又有三种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;报表统计&lt;/li&gt;
&lt;li&gt;数据分析&lt;/li&gt;
&lt;li&gt;机器学习&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="推荐系统三十六式" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法" scheme="http://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="推荐" scheme="http://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统三十六式--学习笔记（25-27 常见架构）</title>
    <link href="http://www.xiemingzhao.com/2018/11/09/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F--%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%8825-27%20%E5%B8%B8%E8%A7%81%E6%9E%B6%E6%9E%84%EF%BC%89/"/>
    <id>http://www.xiemingzhao.com/2018/11/09/推荐系统三十六式--读书笔记（25-27 常见架构）/</id>
    <published>2018-11-08T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:43.394Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://time.geekbang.org/column/intro/74" target="_blank" rel="noopener">参考原作：推荐系统三十六式-刑无刀</a></p><h2 id="25-【常见架构】典型的信息流架构是什么样的"><a href="#25-【常见架构】典型的信息流架构是什么样的" class="headerlink" title="25.【常见架构】典型的信息流架构是什么样的"></a>25.【常见架构】典型的信息流架构是什么样的</h2><p>在工程实践的部分中，我首先介绍的内容是当今最热门的信息流架构。信息流是推荐系统应用中的当红炸子鸡，它表现形式有很多：社交网络的动态信息流、新闻阅读的图文信息流、短视频信息流等等。</p><h3 id="究竟。整体框架"><a href="#究竟。整体框架" class="headerlink" title="究竟。整体框架"></a><strong>究竟。整体框架</strong></h3><p>信息流，通常也叫作 feed，这个英文词也很有意思，就是“喂”给用户的意思。传统的信息流产品知识简单按照时间排序，而被推荐系统接管后的信息流逐渐成为主流，按照兴趣排序，也叫作“兴趣 feed”。所以我们通常提到信息流，或者兴趣 feed，其实都是在说同一个话题。</p><blockquote><p>温馨提示一下：如果要搜索 feed 相关的技术文章，你应该用“Activity Stream”作为关键词去搜，而不应该只用“feed”搜索，Activity Stream 之于 feed，就好比多潘立酮之于吗丁啉，前者是行话，后者是通俗说法。</p></blockquote><p>要实现一个信息流，整体逻辑上是比较清楚的。可以划分为两个子问题。</p><ol><li>如何实现一个按照时间顺序排序的信息流系统？</li><li>如何给信息流内容按照兴趣重排序？</li></ol><a id="more"></a><p><a href="https://postimg.cc/DSVsnXrt" target="_blank" rel="noopener"><img src="https://i.postimg.cc/wjMk557T/image.jpg" alt="image.jpg"></a><br>这张架构图划分成几个大的模块：<strong>日志收集、内容发布、机器学习、信息流服务、监控。</strong><br>这里分别介绍一下：</p><blockquote><ol><li>日志收集，是所有排序训练的数据来源，要收集的最核心数据就是用户在信息流上产生的行为，用于机器学习更新排序模型；</li><li>内容发布，就是用推或者拉的模式把信息流的内容从源头发布到受众端；</li><li>机器学习，从收集的用户行为日志中训练模型，然后为每一个用户即将收到的信息流内容提供打分服务；</li><li>信息流服务，为信息流的展示前端提供 Rest API；</li><li>监控，这是系统的运维标配，保证系统的安全和稳定等。</li></ol></blockquote><h3 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a><strong>数据模型</strong></h3><p>信息流的基本数据有三个：<strong>用户（User）、内容（Activity）和关系（Connection）。</strong> 用户不用说，就是区别不同用户的身份 ID，现在来说一说其他的两种。</p><h4 id="1-内容即-Activity"><a href="#1-内容即-Activity" class="headerlink" title="1.内容即 Activity"></a><strong>1.内容即 Activity</strong></h4><p>用于表达 Activity 的元素有相应的规范，叫作 Atom，你可以参考它并结合产品需求，定义出自己的信息流数据模型来。<br>根据 Atom 规范的定义，一条 Activity 包含的元素有：Time、Actor、Verb、Object、Target、Title、Summary。下面详细解释一下这些元素。</p><blockquote><ol><li>Time：即“Activity 发生的时间”。</li><li>Actor：即“Activity 由谁发出的”。通常 Actor 就是用户 ID，但是我们也可以扩展到其他拟人化物体上，如关注的一个“店铺”，收藏的一部“电影”，或者用户喜欢的一个标签或者分类。也就是和用户建立连接的另一端。</li><li>Verb：动词，就是连接的名字，比如“Follow”“Like”等，也可以是隐含的连接，如挖掘出的用户兴趣词和用户之间这种潜规则。</li><li>Object：即动作作用到最主要的对象，只能有一个，比如一个人赞过的一张照片，店铺上新的一件商品，一个分类下一篇新的文章。</li><li>Target：动作的最终目标，与 verb 有关，可以没有。它对应英语中介词 to 后接的事物，比如“John saved a movie to his wishlist”（John 保存了一部电影到清单里），这里电影就是 Object，而清单就是 Target。</li><li>Title：这个是 Activity 的标题，用自然语言描述，用于展示给用户。</li><li>Summary：通常是一小段 HTML 代码，是对这个 Activity 的描述，还可能包含类似缩略图这样的可视化元素，可以理解为 Activity 的视图，不是必须的。</li></ol></blockquote><p>除了上面的字段外，还有一个隐藏的 ID，用于唯一标识一个 Activity。社交电商 Etsy 在介绍他们的信息流系统时，还创造性地给 Activity 增加了 Owner 属性，同一个 Activity 可以属于不同的用户，相当于考虑了方向。</p><h4 id="2-关系即连接"><a href="#2-关系即连接" class="headerlink" title="2. 关系即连接"></a><strong>2. 关系即连接</strong></h4><p>互联网产品里处处皆连接，有强有弱，好友关系、关注关系等社交是较强的连接，还有点赞、收藏、评论、浏览，这些动作都可以认为是用户和另一个对象之间建立了连接。有了连接，就有信息流的传递和发布。<br>定义一个连接的元素有下面几种。</p><blockquote><ol><li>From：连接的发起方。</li><li>To：被连接方。</li><li>Type/Name：就是 Atom 模型中的 Verb，即连接的类型：关注、加好友、点赞、浏览、评论，等等。</li><li>Affinity：连接的强弱。</li></ol></blockquote><p>如果把建立一个连接视为一个 Activity 模型的话，From 就对应 Activity 中的 Actor，To 就对应 Activity 中的 Object。连接的发起从 From 到 To，内容的流动从 To 到 From。Connection 和 Activity 是相互加强的，这是蛋和鸡的关系：有了 Activity，就会产生 Connection，有了 Connection，就可以“喂”（feed）给你更多的 Activity。</p><p>在数据存储上可以选择的工具有下面的几种：<br>Activity 存储可以采用 MySQL、Redis、Cassandra 等； Connection 存储可以采用<br>MySQL； User 存储可以采用 MySQL。</p><h3 id="内容发布"><a href="#内容发布" class="headerlink" title="内容发布"></a><strong>内容发布</strong></h3><p>用户登录或者刷新后，信息流是怎么产生的呢？我们把内容出现在受众的信息流中这个过程称为 Fan-out，直觉上是这样实现的：</p><ol><li>获取用户所有连接的终点（如好友、关注对象、兴趣标签）；</li><li>获取这些连接终点（关注对象）产生的新内容（Activity）；</li><li>按照某个指标排序后输出。<br>上面这个步骤别看简单，在一个小型的社交网络上，通常很有效，而且 Twitter 早期也是这么做的。这就是江湖行话说的“拉”模式（Fan-out-on-load），即：<strong>信息流是在用户登录或者刷新后实时产生的</strong>。<br>这里有一个示意图:<br><a href="https://postimg.cc/jnyYyPBp" target="_blank" rel="noopener"><img src="https://i.postimg.cc/NFzGqxDj/fan-out.jpg" alt="fan-out.jpg"></a></li></ol><p>拉模式就是当用户访问时，信息流服务才会去相应的发布源拉取内容到自己的 feed 区来，这是一个阻塞同步的过程。“拉”模式的好处也显而易见，主要有下面两种。</p><ol><li>实现简单直接：一行 SQL 语句就搞定了。</li><li>实时：内容产生了，受众只要刷新就看得见。</li></ol><p>但是也有很大的不足：</p><ol><li>随着连接数的增加，这个操作的复杂度指数级增加；</li><li>内存中要保留每个人产生的内容；</li><li>服务很难做到高可用。</li></ol><p>与“拉”模式对应，还有一个“推”模式（Fan-out-on-write），如下图所示：<br><a href="https://postimg.cc/F1vYnpHk" target="_blank" rel="noopener"><img src="https://i.postimg.cc/qBh2qZfw/fan-out-on-write.jpg" alt="fan-out-on-write.jpg"></a><br>当一个 Actor 产生了一条 Activity 后，不管受众在不在线，刷没刷新，都会立即将这条内容推送给相应的用户（即和这个 Actor 建立了连接的人），系统为每一个用户单独开辟一个信息流存储区域，用于接收推送的内容。如此一来，当用户登录后，系统只需要读取他自己的信息流即可。</p><p>“推”模式的好处显而易见：<br>在用户访问自己的信息流时，几乎没有任何复杂的查询操作，所以服务可用性较高。</p><p>“推”模式也有一些不足：</p><ol><li>大量的写操作：每一个粉丝都要写一次。</li><li>大量的冗余存储：每一条内容都要存储 N 份（受众数量）。</li><li>非实时：一条内容产生后，有一定的延迟才会到达受众信息流中。</li><li>无法解决新用户的信息流产生问题。</li></ol><p>既然两者各有优劣，那么实际上就应该将两者结合起来，一种简单的结合方案是全局的：</p><ol><li>对于活跃度高的用户，使用推模式，每次他们刷新时不用等待太久，而且内容页相对多一些；</li><li>对于活跃度没有那么高的用户，使用拉模式，当他们登录时才拉取最新的内容；</li><li>对于热门的内容生产者，缓存其最新的 N 条内容，用于不同场景下的拉取。</li></ol><p>还有一种结合方案是分用户的，这是 Etsy 的设计方案：</p><blockquote><ol><li>如果受众用户与内容产生用户之间的亲密度高，则优先推送，因为更可能被这个受众所感兴趣；</li><li>如果受众用户与内容产生用户之间的亲密度低，则推迟推送或者不推送；</li><li>也不是完全遵循亲密度顺序，而是采用与之相关的概率。</li></ol></blockquote><p><strong>在中小型的社交网络上，采用纯推模式就够用了，结合的方案可以等业务发展到一定规模后再考虑。</strong></p><p>对于信息流的产生和存储可以选择的工具有：</p><ul><li>用户信息流的存储可以采用 Redis 等 KV 数据库, 使用 uid 作为 key。</li><li>信息流推送的任务队列可以采用 Celery 等成熟框架。</li></ul><p>信息流排序信息流的排序，要避免陷入两个误区：</p><ol><li>没有目标；</li><li>人工量化。<blockquote><p>“没有目标”意思就是说，设计排序算法之前，一定要先弄清楚为什么要对时间序重排？希望达到什么目标？只有先确定目标，才能检验和优化算法。<br>“人工量化”，也就是我们通常见到的产品同学或者运营同学要求对某个因素加权、降权。这样做很不明智，主要是不能很好地持续优化。</p></blockquote></li></ol><p>目前信息流采用机器学习排序，以提升类似互动率，停留时长等指标，这已经成为共识。比如说提高互动率则需要下面几个内容:<br>首先，定义好互动行为包括哪些，比如点赞、转发、评论、查看详情等；<br>其次，区分好正向互动和负向互动，比如隐藏某条内容、点击不感兴趣等是负向的互动。</p><p>基本上到这里就可以设计成一个典型的二分类监督学习问题了，能产生概率输出的二分类算法都可以用在这里，比如贝叶斯、最大熵、逻辑回归等。互联网常用的是逻辑回归（Logistic Regression），谁用谁知道，用过的都说好；也有 Facebook 等大厂采用了逻辑回归加梯度提升树模型（又称 GBDT）来对信息流排序，效果显著。</p><p>如今大厂都已经转向深度学习了，但我还是建议小厂或者刚起步的信息流先采用线性模型。<br>对于线性模型，一个重要的工作就是特征工程。<strong>信息流的特征有三类：</strong></p><blockquote><ol><li>用户特征，包括用户人口统计学属性、用户兴趣标签、活跃程度等；</li><li>内容特征，一条内容本身可以根据其属性提取文本、图像、音频等特征，并且可以利用主题模型提取更抽象的特征。</li><li>其他特征，比如刷新时间、所处页面等。</li></ol></blockquote><p><strong>排序模型在实际使用时，通常做成 RPC（远程过程调用协议） 服务，以供发布信息流时调用。</strong></p><h3 id="数据管道"><a href="#数据管道" class="headerlink" title="数据管道"></a><strong>数据管道</strong></h3><p>这个管道中要使用的相关数据可能有：</p><blockquote><ol><li>互动行为数据，用于记录每一个用户在信息流上的反馈行为；</li><li>曝光内容，每一条曝光要有唯一的 ID，曝光的内容仅记录 ID 即可；</li><li>互动行为与曝光的映射关系，每条互动数据要对应到一条曝光数据；</li><li>用户画像内容，即用户画像，提供用户特征，具体请见我在第 4、5、6 三篇中的内容；</li><li>信息流的内容分析数据，提供内容特征，即物品画像。</li></ol></blockquote><p>对于一个从零开始的信息流，没必要做到在线实时更新排序算法的参数，所以数据的管道可以分成三块：</p><ol><li>生成训练样本，可离线；</li><li>排序模型训练，可离线；</li><li>模型服务化，实时服务；像 Pinterest 早期的管道也差不多就是这样。</li></ol><p>在离线训练优化模型时，关注模型的 AUC 是否有提升，线上 AB 测试时关注具体的产品目标是否有提升，比如互动率等，同时还要根据产品具体形态关注一些辅助指标。<br>另外，互动数据相比全部曝光数据，数量会小得多，所以在生成训练数据时需要对负样本（展示了却没有产生互动的样本）进行采样，采样比例也是一个可以优化的参数。<br>固定算法和特征后，在 0.1~0.9 之间遍历对比实验，选择最佳的正负比例即可。经验比例在 2:3 左右，即负样本略大于正样本，你可以用这个比例做启发式搜索。</p><hr><h2 id="26-【常见架构】Netflix个性化推荐架构"><a href="#26-【常见架构】Netflix个性化推荐架构" class="headerlink" title="26.【常见架构】Netflix个性化推荐架构"></a>26.【常见架构】Netflix个性化推荐架构</h2><p>工程落地很重要，虽然影响是否用户产品的因素有很多很多，但是能否流畅地给用户提供服务是一个最基本的标准。</p><h3 id="架构的重要性"><a href="#架构的重要性" class="headerlink" title="架构的重要性"></a><strong>架构的重要性</strong></h3><p>推荐系统向来是一个锦上添花的东西，因此传统的观点是推荐系统更加注重线下的模型效果，而非线上的服务质量。但是你也知道，时至今日，推荐系统不再只是锦上添花，而是承担了产品的核心功能。因此，对推荐系统架构的要求也高了很多：</p><ol><li>实时响应请求；</li><li>及时、准确、全面记录用户反馈；</li><li>可以优雅降级；</li><li>快速实验多种策略。</li></ol><p>一种更符合经典推荐系统的架构，这就是著名的流媒体Netflix 的推荐系统架构。</p><h3 id="经典架构"><a href="#经典架构" class="headerlink" title="经典架构"></a><strong>经典架构</strong></h3><p><a href="https://postimg.cc/RqxfTxYc" target="_blank" rel="noopener"><img src="https://i.postimg.cc/ryKJM8CY/Netflix.jpg" alt="Netflix.jpg"></a><br><strong>先整体看一下这个架构，一共分成三层：在线、近线、离线。</strong></p><p>可以这样定义这三个层级：</p><ol><li>离线：不用实时数据，不提供实时服务；</li><li>近线：使用实时数据，不保证实时服务；</li><li>在线：使用实时数据，要保证实时服务。</li></ol><h4 id="1-数据流"><a href="#1-数据流" class="headerlink" title="1. 数据流"></a><strong>1. 数据流</strong></h4><p>用户在产品 UI 上使用产品，消费展示的内容，产生行为事件数据，实时地被收集走，一边进入分布式的文件系统中存储，供离线阶段使用，另一边流向近线层的消息队列，供近线阶段的流计算使用。</p><p>离线存储的全量数据被抽取出来，组成离线计算所需的训练数据，这些训练数据被一个管理数据生成和发布的组件统一管理，要使用数据的下游，比如模型训练会在离线数据生成时得到这个组件的通知，从而开始训练，训练得到的模型用于进一步为用户计算推荐结果。</p><p>离线阶段的推荐结果或者模型在近线阶段被更新，进一步在在线阶段被直接使用，产生最终的推荐结果，呈现给用户。</p><h4 id="2-在线层"><a href="#2-在线层" class="headerlink" title="2. 在线层"></a><strong>2. 在线层</strong></h4><p>在线层的触发时机是当用户发出请求，也就是用户进入一个推荐场景，推荐位等着展示推荐结果时，这个时候需要承担责任就是在线层。在线层就是实时响应用户请求。简单说，在线层的特点就是<strong>“使用实时数据，要保证实时服务”。</strong></p><p>在线层的优势有：</p><ol><li>直接首次接触到大多数最新数据；</li><li>对用户请求时的上下文了如指掌；</li><li>只需计算必须的信息，不需要考虑所有的信息。</li></ol><p>在线层也有严格的制约：</p><ol><li>严格的服务响应时间，不能超时，或者让用户等太久；</li><li>服务要保证可用性，稳定性；</li><li>传输的数据有限。</li></ol><p>在线层常常展现出的形式就是 Rest API 形式，后端则通常是 RPC 服务内部互相调用，以用户 ID、场景信息去请求，通常就在 ms 响应时间内返回 Json 形式的推荐结果。那么哪些计算逻辑适合放在在线层呢？</p><blockquote><ol><li>简单的算法逻辑；</li><li>模型的预测阶段；</li><li>商业目标相关的过滤或者调权逻辑；</li><li>场景有关的一些逻辑；</li><li>互动性强的一些算法。</li></ol></blockquote><p>在线阶段要处理的对象一般是已经预处理后的推荐结果，是少量物品集合。比如说当用户访问一个物品详情页，需要做相关推荐，那么在线阶段给在线服务的 Rest API 传入用户身份以及当前的物品 ID，实时地取出物品 ID 对应的相关物品 ID，再根据用户信息对这些物品 ID 做一些重拍和过滤，就可以输出了，整个过程都是在 ms 级别完成。如果发生意外，比如说这个物品 ID 就没有相关的物品，那么这时候服务就需要降级，但是不能低于最低要求，这里的最低要求就是必须要返回东西，这就降级为取出热门排行榜返回。这就是服务的可用性。</p><h4 id="3-离线层"><a href="#3-离线层" class="headerlink" title="3. 离线层"></a><strong>3. 离线层</strong></h4><p>讲完在线层，再来看看离线层。离线层就是躲在推荐系统的大后方，批量、周期性地执行一些计算任务。其特点是<strong>“不用实时数据，不提供实时服务”。</strong><br>离线层的示意图如下：<br><a href="https://postimg.cc/68qGQW7N" target="_blank" rel="noopener"><img src="https://i.postimg.cc/DwdQBmnm/image.jpg" alt="offline.jpg"></a><br>离线阶段主要面对的数据源就是 Hadoop，实质上是 HDFS。收集到的所有日志都存在这里面，是一个全量的数据中心。通过 Pig 或者 Hive 等工具，从全量日志中按照算法要求抽取出不同的数据，再加上其他数据变成了不同算法所需的数据源。</p><p>如果这种数据源比较多时，就需要有专门的工具统一管理起来，这个管理上要求：</p><ol><li>数据准备好之后及时通知相关方，也就是要有订阅发布的模式；</li><li>能够满足下游不同的存储系统；</li><li>完整的监控体系，并且监控过程对于数据使用方是透明的。</li></ol><p>在 Netflix 内部，承担这个管理任务的工具叫做 Hermes，类似 Kafka，但是又有不同的内部工具。<br><strong>离线阶段的任务主要是两类：模型训练和推荐结果计算。</strong></p><p>离线阶段有以下这么几个好处：</p><ol><li>可以处理最大的数据量；</li><li>可进行批量处理和计算；</li><li>不用有响应时间等要求。当然坏处也是明显的：</li></ol><p>同样的有几点短处：</p><ol><li>无法及时响应前端需求；</li><li>面对的数据较静态，无法及时反应用户的兴趣变化。</li></ol><p>大多数推荐算法，实际上都是在离线阶段产生推荐结果的。离线阶段的推荐计算和模型训练，<strong>如果要用分布式框架，通常可以选择 Spark</strong> 等。</p><h4 id="4-近线层"><a href="#4-近线层" class="headerlink" title="4. 近线层"></a><strong>4. 近线层</strong></h4><p>最后，来讲讲近线层。近线层的特点是<strong>“使用实时数据，不保证实时服务”</strong>。</p><p>虽然这看上去蛮不讲理，但实际上这是一个非常重要的一层，它结合了离线层和在线层的好处，摒弃了两者的不足。近线层，也叫做<strong>准实时层</strong>，所谓“准实时”，就是接近实时，但不是真的实时。</p><p>从前面的架构图中也可以看出，这一层的数据来源是实时的行为事件队列，但是计算的结果并不是沿着输入数据的方向原路返回，而是进入了在线数据库中，得到用户真正发起请求时，再提供服务。</p><p>一个典型的近线计算任务是这样的：从事件队列中获取最新的一个或少许几个用户反馈行为，首先将这些用户已经反馈过的物品从离线推荐结果中剔除，进一步，用这几个反馈行为作为样本，以小批量梯度下降的优化方法去更新融合模型的参数。</p><p>这两个计算任务都不会也不需要立即对用户做出响应，也不必须在下一次用户请求时就产生效果，就是说当用户实时请求时，不需要去等待近线任务的最新结果，因为两者是异步的。</p><p>近线计算任务一个核心的组件就是流计算，因为它要处理的实时数据流。常用的流计算框架有<strong>Storm，Spark Streaming，FLink 等</strong>，Netflix 采用的内部流计算框架 Manhattan，这和Storm 类似。略有区别的是 Spark Streaming，实际上并不是实时流计算，而是小批量计算。</p><h3 id="简化架构"><a href="#简化架构" class="headerlink" title="简化架构"></a><strong>简化架构</strong></h3><p>Netflix 是为全球多个国家同时提供在线服务的，因此推荐系统的架构略微复杂。倘若你现在刚刚接手一个新产品，要从 0 开始搭建一个推荐系统，那么可以以 Netflix 的架构作为蓝本，做一定的简化：<br><a href="https://postimg.cc/jwHD1C1y" target="_blank" rel="noopener"><img src="https://i.postimg.cc/vBj5cVL2/Netflix.jpg" alt="Netflix简化.jpg"></a><br>关键简化有两点：</p><ol><li>完全舍弃掉近线层；</li><li>避免使用分布式系统。</li></ol><p>在一个新产品的场景下， 当数据量还没有那么大时，使用分布式存储或者计算框架，非常不划算。如果性能不足，请升级单机配置。根据经验，一个几千万用户，几十万到百万的物品的协同过滤或者矩阵分解，如果充分发挥单机的性能，综合效率会远远优于在 Spark 上运行。</p><p><a href="https://postimg.cc/c6JW2rPZ" target="_blank" rel="noopener"><img src="https://i.postimg.cc/59BtHz3H/Netflix.jpg" alt="Netflix.jpg"></a><br>以上就是对这个架构的宏观总结对比。如前所说，其实架构都是进化出来的，你千万不必在一开始就追求完美的架构，满足最低要求就好。</p><hr><h2 id="27-【常见架构】总览推荐架构和搜索、广告的关系"><a href="#27-【常见架构】总览推荐架构和搜索、广告的关系" class="headerlink" title="27.【常见架构】总览推荐架构和搜索、广告的关系"></a>27.【常见架构】总览推荐架构和搜索、广告的关系</h2><h3 id="三种信息获取方式"><a href="#三种信息获取方式" class="headerlink" title="三种信息获取方式"></a><strong>三种信息获取方式</strong></h3><p>当用户想要从浩如烟海的网页中，找到对自己有用的信息，首选当然是搜索引擎，这是属于“已知的未知”需求，剩下的“未知的已知”和“未知的未知”则需要推荐系统去满足，只是推荐系统常常会出现画蛇添足去满足“已知的已知”这样的伪需求。<br>另外介于两者之间，还有一种商业化解决信息触达问题，就是广告系统。在线广告从条幅广告，到搜索广告再到社交精准广告，也逐渐形成了一个理念就是：把广告当成一种有用的信息去找到最需要它的人。</p><h3 id="三者对比"><a href="#三者对比" class="headerlink" title="三者对比"></a><strong>三者对比</strong></h3><p>搜索，推荐和广告本质上都在解决信息过载的问题，各自解决的手段、目标不相同，各自诞生在产品生命周期不同阶段，以至于系统实现也不尽相同。我们从几个维度对比一下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">-</th><th style="text-align:center">搜索</th><th style="text-align:center">推荐</th><th style="text-align:center">广告</th></tr></thead><tbody><tr><td style="text-align:center">信息送达方式</td><td style="text-align:center">拉</td><td style="text-align:center">推和拉</td><td style="text-align:center">推</td></tr><tr><td style="text-align:center">关注点</td><td style="text-align:center">内容消费方</td><td style="text-align:center">内容生产方消费方</td><td style="text-align:center">内容生产方</td></tr><tr><td style="text-align:center">是否期待惊喜</td><td style="text-align:center">否</td><td style="text-align:center">是</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">是否需要集体智慧</td><td style="text-align:center">可能</td><td style="text-align:center">可能</td><td style="text-align:center">需要</td></tr><tr><td style="text-align:center">是否需要query</td><td style="text-align:center">需要</td><td style="text-align:center">可能</td><td style="text-align:center">可能</td></tr><tr><td style="text-align:center">是否依赖上下文</td><td style="text-align:center">可能</td><td style="text-align:center">可能</td><td style="text-align:center">可能</td></tr></tbody></table></div><ul><li>搜索更关注内容消费者，搜索要解决的是精确快速找到想要的结果，最重要的目标是降低延迟和提高相关性。搜索引擎是一个效率工具，希望用户找到信息越快越好，而不是希望用户沉迷在搜索引擎中。</li><li>传统的推荐系统大都是起一个“锦上添花”的作用，一般很少会将其作为核心功能来承载产品。希望用户消费内容，消费越多越好。可以给用户制造惊喜。</li><li>基于内容的推荐，本质上就是一个小的搜索引擎。例如使用用户的兴趣标签召回推荐结果，就需要先对推荐候选池按照兴趣标签建立倒排索引，从而检索出候选集。</li><li>广告是一个很特殊的存在，前面也说了，搜索和推荐都是为人找信息，而广告是为信息找人。但它在形式上又像推荐，总是“不请自来”，在技术实现上又兼有推荐和搜索两者特点。</li></ul><h3 id="架构抽象"><a href="#架构抽象" class="headerlink" title="架构抽象"></a><strong>架构抽象</strong></h3><p>我们抽象一下三者的需求共性：本质上都是在匹配，匹配用户的兴趣和需求（看成 context），但匹配的目标，条件和策略不尽相同。示意图如下：<br><a href="https://postimg.cc/R3QcjX8s" target="_blank" rel="noopener"><img src="https://i.postimg.cc/8CxtfYbS/image.jpg" alt="搜索&amp;推荐&amp;广告.jpg"></a></p><p><strong>我们再进一步抽象下去，又可以分为三步：过滤候选、排序候选、个性化输出。</strong></p><h4 id="1-过滤候选"><a href="#1-过滤候选" class="headerlink" title="1. 过滤候选"></a><strong>1. 过滤候选</strong></h4><p>从查询关键字中解析得到查询意图，以及结构化的搜索条件，再用结构化的查询条件从倒排索引中检索出排序候选。与之相似的是广告系统，搜索广告也是查询关键字去检索候选广告，而联盟广告则是拿着用户标签去需求方获取广告候选。</p><p>在推荐系统中，一再强调有挖掘、召回和排序三个阶段，其中的召回阶段就是过滤候选阶段，基于内容的就和搜索一样，用标签检索候选，协同过滤则检索出相似物品来，等等。</p><p>一种离线阶段的推荐算法对应一种召回策略，为了保证高效地召回，都要建立相应的索引，这样一来，是不是搜索、广告和推荐都离不开过滤候选这一步，而过滤候选就离不开建立索引。</p><h4 id="2-排序候选"><a href="#2-排序候选" class="headerlink" title="2. 排序候选"></a><strong>2. 排序候选</strong></h4><p>候选排序这一步，对于三者来说，主要区别在于排序的目标和约束。搜索的排序目标是高相关性，无论 BM25 为代表的传统排序模型，还是以 Learn to Rank 为代表的机器学习排序皆是如此，把<strong>用户每次在搜索上花费的时间是不是更少（而不是更多）来衡量搜索的效果</strong>。</p><p>通常推荐系统用 CTR 预估来融合召回策略得到的候选集，如果做得深入，还需要考虑探索利用问题。附加的约束则是千变万化。电商中，当天买过的当天就不能再推了，新闻推荐里，重复的新闻不能再推了。某些场景需要推荐搭配，某些场景需要推荐相似，TopN 推荐还需要考虑多样性，序列推荐要考虑前序和后续等等。</p><p>广告系统的排序更多是从经济学角度去看，CPC 广告的排序方式是结合预估 CTR、出价、广告质量三者一起考虑。同时还要考虑很多别的因素，尤其是商业因素，平台方的要求，广告主的要求等等，是一个纯动态的博弈。</p><h4 id="3-个性化输出"><a href="#3-个性化输出" class="headerlink" title="3.个性化输出"></a><strong>3.个性化输出</strong></h4><p>个性化只是推荐系统的衡量指标之一而已，个性化的前提也一定是信息够丰富够垂直才行。搜索的个性化需求相对来说松弛一些，常见的是利用地域等人口统计学体现个性化，而且对于歧义较少的查询关键字，搜索如果太个性化既没意义又有风险。</p><h4 id="4-三者的协同"><a href="#4-三者的协同" class="headerlink" title="4.三者的协同"></a><strong>4.三者的协同</strong></h4><p>有一部分搜索需求是无法用搜索相关性满足的，比如“一个人的夜晚听什么歌”这样的 query，这就需要推荐系统去满足，交互形式可能是眼下大热的聊天机器人，也可能是流推荐等等。如果能够识别出这样的搜索请求，其实更应该交给推荐系统来响应，这类是看似搜索请求，实际上则是漫无目的。</p><p><strong>推荐系统总体上滞后于用户的即时需求，再强大的推荐系统，也要有搜索引擎来与之配合。</strong></p><ul><li>一方面，搜索因为能够满足用户的主动寻找需求，所以能够化解一些推荐不力不及时的尴尬。</li><li>另一方面，搜索可以积累用户兴趣数据；当二者结合起来考虑时，可以避免“搜什么推什么”的窘境，整个系统能够综合考虑哪些是即时快速需求，哪些是长期兴趣。</li></ul><p>广告系统，在技术上和搜索跟推荐并无本质差异，差异在意图不同，功能不同。对用户的信息需求满足，搜索和推荐离真正得到满足之间总是有一定的鸿沟，要么是信息不足，要么是信息过载，这些鸿沟可以利用经济手段进行调配，这就是广告系统。</p><p><a href="https://postimg.cc/R6WZc0c7" target="_blank" rel="noopener"><img src="https://i.postimg.cc/XJ8B6Gqz/image.jpg" alt="常见架构.jpg"></a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/column/intro/74&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考原作：推荐系统三十六式-刑无刀&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;25-【常见架构】典型的信息流架构是什么样的&quot;&gt;&lt;a href=&quot;#25-【常见架构】典型的信息流架构是什么样的&quot; class=&quot;headerlink&quot; title=&quot;25.【常见架构】典型的信息流架构是什么样的&quot;&gt;&lt;/a&gt;25.【常见架构】典型的信息流架构是什么样的&lt;/h2&gt;&lt;p&gt;在工程实践的部分中，我首先介绍的内容是当今最热门的信息流架构。信息流是推荐系统应用中的当红炸子鸡，它表现形式有很多：社交网络的动态信息流、新闻阅读的图文信息流、短视频信息流等等。&lt;/p&gt;
&lt;h3 id=&quot;究竟。整体框架&quot;&gt;&lt;a href=&quot;#究竟。整体框架&quot; class=&quot;headerlink&quot; title=&quot;究竟。整体框架&quot;&gt;&lt;/a&gt;&lt;strong&gt;究竟。整体框架&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;信息流，通常也叫作 feed，这个英文词也很有意思，就是“喂”给用户的意思。传统的信息流产品知识简单按照时间排序，而被推荐系统接管后的信息流逐渐成为主流，按照兴趣排序，也叫作“兴趣 feed”。所以我们通常提到信息流，或者兴趣 feed，其实都是在说同一个话题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;温馨提示一下：如果要搜索 feed 相关的技术文章，你应该用“Activity Stream”作为关键词去搜，而不应该只用“feed”搜索，Activity Stream 之于 feed，就好比多潘立酮之于吗丁啉，前者是行话，后者是通俗说法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;要实现一个信息流，整体逻辑上是比较清楚的。可以划分为两个子问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何实现一个按照时间顺序排序的信息流系统？&lt;/li&gt;
&lt;li&gt;如何给信息流内容按照兴趣重排序？&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="推荐系统三十六式" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法" scheme="http://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="推荐" scheme="http://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统三十六式--学习笔记（22-24 其他应用算法）</title>
    <link href="http://www.xiemingzhao.com/2018/11/08/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F--%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%8822-24%20%E5%85%B6%E4%BB%96%E5%BA%94%E7%94%A8%E7%AE%97%E6%B3%95%EF%BC%89/"/>
    <id>http://www.xiemingzhao.com/2018/11/08/推荐系统三十六式--读书笔记（22-24 其他应用算法）/</id>
    <published>2018-11-07T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:42.085Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://time.geekbang.org/column/intro/74" target="_blank" rel="noopener">参考原作：推荐系统三十六式-刑无刀</a></p><h2 id="22-【其他应用算法】构建一个科学的排行榜体系"><a href="#22-【其他应用算法】构建一个科学的排行榜体系" class="headerlink" title="22.【其他应用算法】构建一个科学的排行榜体系"></a>22.【其他应用算法】构建一个科学的排行榜体系</h2><h3 id="为什么要排行榜"><a href="#为什么要排行榜" class="headerlink" title="为什么要排行榜"></a><strong>为什么要排行榜</strong></h3><p>排行榜，又名热门榜，听上去似乎是一个很常见的东西，原来它也算是推荐算法的一员？是的，它不但是，并且非常重要，有诸多作用：</p><blockquote><ol><li>排行榜可以作为解决新用户冷启动问题的推荐策略。这个不难理解，当一个新用户刚注册时，可以把    近产品中热门的物品推荐给他。</li><li>排行榜可以作为老用户的兴趣发现方式。即使是老用户，也可以在享受个性化推荐的同时去浏览热门的物品，从中看看哪些感兴趣，哪些不感兴趣，这些行为都是补充或者更新用户兴趣的数据来源。</li><li>排行榜本身就是一个降级的推荐系统。推荐系统本身是一个软件，因此也会有出现问题的时候，也会有推荐不出来的时候，这个时候考虑到服务的可用性，用排行榜作为一种兜底策略，可以避免推荐位开天窗。</li></ol></blockquote><a id="more"></a><h3 id="排行榜算法"><a href="#排行榜算法" class="headerlink" title="排行榜算法"></a><strong>排行榜算法</strong></h3><p>简单的排行榜，就是直接统计某种指标，按照大小去排序。在社交网站上，按照点赞数、转发数、评论数去排序，这是一种常见、朴素的排行榜。类似的做法还有在电商网站上按照销量去排序。</p><p>此类算法不靠谱的原因主要有：</p><ol><li>非常容易被攻击，也就是被刷榜；</li><li>马太效应一直存在，除非强制替换，否则一些破了纪录的物品会一直占据在榜单中；</li><li>不能反映出排行榜随着时间的变化，这一点和马太效应有关。</li></ol><p>针对这些弊端，可以设计相应的措施：</p><h4 id="1-考虑时间因素"><a href="#1-考虑时间因素" class="headerlink" title="1.考虑时间因素"></a><strong>1.考虑时间因素</strong></h4><p>接下来，我要把用户给物品贡献的行为看做是用户在投票，这个很容易理解，好像热门的东西都是大多数人投票民主选举出来的。排行榜中的物品，你可以想象它们每一个都是炙手可热的，都有一定的温度，那么这个温度按照热力学定律来讲，随着时间推移就一定会耗散到周围，温度就会下降。或者，把排行榜想象成一个梯子，每个物品都在奋力往上爬，他们的动力来自用户的手动投票，物品本身都要承受一定的重力，会从梯子上掉下来，用户投票可以抵挡部分重力，投票数不及时或者不够，排行榜上的物品就会掉下来。</p><p>把这个规律反映在排行榜分数计算公式中，就比简单统计数量，再强制按照天更新要科学得多。Hacker News 计算帖子的热度就用到了这个思想，它们的做法用公式表达是下面这个样子：</p><script type="math/tex; mode=display">\frac{P-1}{(T+2)^G}</script><p>公式中三个字母分别代表如下意义：</p><blockquote><ol><li>P：得票数，去掉帖子作者自己投票。</li><li>T：帖子距离现在的小时数，加上帖子发布到被转帖至 Hacker News 的平均时长。</li><li>G：帖子热度的重力因子。</li></ol></blockquote><p>其中，重力因子的选择根据情况而定，重力因子越大，帖子的热度衰减越快，不同的重力因子对比如下图所示:<br><a href="https://postimg.cc/CzYSNFjT" target="_blank" rel="noopener"><img src="https://i.postimg.cc/wTRM9MMv/image.png" alt="重力因子衰减.png"></a><br>可以看到，重力因子越大，衰减越快。<br>再看一下，相同重力因子选择的情形下，不同的得票数的对比。<br><a href="https://postimg.cc/68bKtnFt" target="_blank" rel="noopener"><img src="https://i.postimg.cc/GpdmPjQ8/2.png" alt="重力因子衰减2.png"></a><br>这这个示意图可以看到，这个公式仍然能够反映出相同时间的帖子之间的相对热度差别。</p><p>另一个考虑时间因素的排行榜算法是牛顿冷却定律。物品受关注度如同温度一样，不输入能量的话它会自然冷却，而且物体的冷却速度和其当前温度与环境温度之差成正比。将这一定律表述为公式就是下面的样子：</p><script type="math/tex; mode=display">T(t) = H + Ce^{-\alpha t}</script><p>公式中字母的意义如下。</p><blockquote><p>H：为环境维度，可以认为是平均票数，比如电商中的平均销量，由于不影响排序，可以不<br>使用。<br>C：为净剩票数，即时刻 t 物品已经得到的票数，也就是那个最朴素的统计量，比如商品的销<br>量。<br>t：为物品存在时间，一般以小时为单位。<br>$\alpha$：是冷却系数，反映物品自然冷却的快慢。</p></blockquote><p>问题来了，这个反映物品自然冷却快慢的 α 该如何确定呢？有一个更直观的办法。假如一个物品在时间过去 B 个单位后，因为增加了 A 个投票数，而保持了热门程度不变，那这样的话 α 应该是多少呢？简单把这个描述列成方程就是下面的样子:</p><script type="math/tex; mode=display">Ce^{-\alpha t} = (C+A)e^{- \alpha (t + B)}</script><p>用这个公式加上自己产品的要求来确定 alpha 就容易得多，假如按照 B = 24，也就是过一天来看，来举几个例子:</p><div class="table-container"><table><thead><tr><th style="text-align:center">直观解释</th><th style="text-align:center">A/C</th><th style="text-align:center">alpha</th></tr></thead><tbody><tr><td style="text-align:center">投票数翻倍</td><td style="text-align:center">1</td><td style="text-align:center">0.03</td></tr><tr><td style="text-align:center">投票数增加两倍</td><td style="text-align:center">2</td><td style="text-align:center">0.05</td></tr><tr><td style="text-align:center">投票数增加三倍</td><td style="text-align:center">3</td><td style="text-align:center">0.06</td></tr><tr><td style="text-align:center">投票数增加三百倍</td><td style="text-align:center">300</td><td style="text-align:center">0.24</td></tr></tbody></table></div><h4 id="2-考虑三种投票"><a href="#2-考虑三种投票" class="headerlink" title="2. 考虑三种投票"></a><strong>2. 考虑三种投票</strong></h4><p>前面的热度计算方法，只考虑用户投票和用户弃权两种，虽然这种情况很常见，但是还有一些产品会存在运行用户投反对票的情形，比如问答网站中对答案的投票，既可以赞成，又可以反对。</p><p>在这样的情形下，一般这样来考虑：</p><ul><li>同样多的总票数，支持赞成票多的，因为这符合平台的长期利益；</li><li>同样多的赞成票数，支持    有价值的，同样这符合平台长期利益。</li></ul><p>以国外某著名程序员问答网站度热门问题的热度计算公式为例：</p><script type="math/tex; mode=display">\frac{(log_{10} Qviews) \times 4 + \frac {Qanswers \times Qscore}{5} + \sum_i Ascore_i}{(\frac{Qage}{2} + \frac{Qupdated}{2} + 1)^{1.5}}</script><blockquote><p>其中的元素意义如下：<br>Qviews: 问题的浏览次数。<br>Ascore：答案的得分。<br>Qage: 问题发布距离当前的时间。<br>Qupdated: 问题    后一次修改距离当前的时间。</p></blockquote><p>这个问题热门程度计算方式，也考虑了时间因素。分母反映了问题的陈旧程度，修改问题可以让问题不要衰老过快。分子有三部分构成：</p><ul><li>左边是问题的浏览量，反映了问题的受关注程度；</li><li>中间是问题的回答量和问题本身的质量分数的乘积，高质量、回答多的问题占优势；</li><li>右边是答案的总质量分。</li></ul><h4 id="3-考虑好评的平均程度"><a href="#3-考虑好评的平均程度" class="headerlink" title="3. 考虑好评的平均程度"></a><strong>3. 考虑好评的平均程度</strong></h4><p>前面两种排行榜分数计算法，都是以用户投票的绝对数量作为核心的，那么换个思路来看，从比例来看也是可以的。这也是一些点评网站常常采纳的模式，比如电影点评网站通常会有一个Top250，这也是一种排行榜，以好评比例作为核心来计算排行榜分数。下面来看看这种排行榜。</p><p>一个经典的好评率估算公式，叫做<strong>威尔逊区间</strong>，它这样估算物品的好评率：</p><script type="math/tex; mode=display">\frac{\hat p + \frac{1}{2n} z_{1-\frac {\alpha}{2}}^2 \pm z_{1-\frac {\alpha}{2}} \sqrt{\frac {\hat p(1-\hat p)}{n} + \frac {z_{1-\frac {\alpha}{2}}^2}{4n^2}}} {1 + \frac {1}{n}z_{1-\frac {\alpha}{2}}^2}</script><p>实际上，你照着公式中所需的元素去统计就可以计算出排行榜了。我解释一下这个公式中所需的元素，你就可以照着去搬砖了，可以不必理解其中的原理:</p><ul><li>$\hat p$ 就是好评率，比如一百个点评的商品，99 个给了好评，那么这个值就是 0.99 </li><li>$z_{1-\frac {\alpha}{2}}$ 是一个置信水平为 alpha Z 统计量，这个查表就可以得到。</li></ul><p>威尔逊区间考虑了评价的样本数，样本不足时，置信区间很宽，样本很足时，置信区间很窄。那么这个统计量有哪些应用呢，比如说下面的几个情况。</p><ol><li>多大比例的人们会采取某种行为？</li><li>多大比例的人认为这是一个 Spam？</li><li>多大比例的人认为这是一个“值得推荐的”物品呢？</li></ol><p>当你为每一个物品都计算一个威尔逊区间后，你可以采用前面讲到的 Bandit 算法，类似 UCB 的方式取出物品，构建成一个略带变化的排行榜。后，为你呈上某电影点评网站为电影排行榜计算分数的公式，它是另一种对好评率的应用，针对评分类型数据的排行榜:</p><script type="math/tex; mode=display">\frac {v}{v + m}R + \frac {m}{v + m}C</script><p>这个排行榜计算公式，也有一个响当当的名字，叫做<strong>“贝叶斯平均”</strong>。其中的元素意义描述如下：</p><blockquote><p>R，物品的平均得分，这个很简单，有多少人评分，把他们评分加起来除以人数就是了；<br>v，参与为这个物品评分的人数；<br>m，全局平均每个物品的评分人数；<br>C，全局平均每个物品的平均得分；</p></blockquote><p>别看这个公式简单，它反映了这么几个思想在里面：</p><ol><li>如果物品没多少人为它投票，也就是评价人数不足，那么 v 就很小，m 就很大，公式左边就很小，右边就很大，于是总分算出来很接近右边部分，也就是接近全局平均分 C；</li><li>如果物品投票人数很多，那么 v 很大，m 很小，分数就接近它自己的平均分 R。</li></ol><p>这个公式的好处是：所有的物品，不论有多少人为它评分，都可以统一地计算出一个合理的平均分数，它已经被国内外电影评分网站采纳在自己的排行榜体系中，当然，它们肯定各自都有根据实际情况的修改。</p><hr><h2 id="23-【其他应用算法】实用的加权采样算法"><a href="#23-【其他应用算法】实用的加权采样算法" class="headerlink" title="23.【其他应用算法】实用的加权采样算法"></a>23.【其他应用算法】实用的加权采样算法</h2><h3 id="一些场景"><a href="#一些场景" class="headerlink" title="一些场景"></a><strong>一些场景</strong></h3><p>想象一个场景：你经过辛辛苦苦抓数据，清洗数据，收集用户行为，目的就是给用户计算兴趣标签。这时候你可能会遇到一个两难的问题：如果给用户计算出兴趣标签的权重了，那应该保留多少标签呢？</p><p>这时候，你需要的一个简单的加权采样算法，每次召回时并不使用全部用户标签，而是按照权重采样一部分标签来使用，这样做的好处当然很明显：</p><ol><li>大大减少召回时的计算复杂度；</li><li>可以保留更多的用户标签；</li><li>每次召回计算时还能有所变化；</li><li>虽然有变化，但是依然受标签的权重相对大小约束。</li></ol><p>加权采样的应用不只这一个地方，比如在热门排行榜展示时，也可以用加权采样，而不仅仅按照排行榜分数顺序展示，采用加权采样的展示方法，会让排行榜每次刷新都略有变化，人民群众也会更加喜闻乐见。</p><h3 id="加权采样"><a href="#加权采样" class="headerlink" title="加权采样"></a><strong>加权采样</strong></h3><p>加权采样有两种情况，一种是能够已知全部样本的个数。这需要遍历整个样本，比如说用户标签采样输出，那么每次采样时仍然需要遍历所有的标签，来依次决定每一个标签输出的概率。另一种是不知道总量样本是多大，或者总量很大，以至于你不愿意全部遍历之后再输出采样结果，这样的数据就是数据流，对应的就是<strong>流采样。</strong></p><h4 id="1-有限数据集"><a href="#1-有限数据集" class="headerlink" title="1.有限数据集"></a><strong>1.有限数据集</strong></h4><p>等概率采样的方法非常简单，任意编程语言中都有伪随机数实现。现在假设你有用户标签若干，每一个标签都有个权重 w，权重高低反映了用户对这个标签的感兴趣程度高低。你希望每次输出一部分标签用于召回推荐候选集，每次输出时都不一样，但是又能反映用户标签的权重，输出的概率和权重成正比。这时候你需要一个公式：</p><script type="math/tex; mode=display">S_i = R^{\frac{1}{w_i}}</script><blockquote><p>解释一下这个公式：</p><ol><li>$w_i$ 是每个样本的权重，比如用户标签权重；</li><li>R 是遍历每个样本时产生的 0 到 1 之间的随机数；</li><li>$S_i$ 就是每个样本的采样分数</li></ol></blockquote><p>还有另一种加权采样方法，是利用指数分布。</p><script type="math/tex; mode=display">f(x,\lambda) = \left\{ \begin{array}{ll}\lambda e^{-\lambda x} & \textrm{$x>0$}\\0 & \textrm{$x<=0$}\\\end{array} \right.</script><p>指数分布的参数 $\lambda$，它的倒数，$\frac{1}{\lambda}$就是事件发生时间间隔的期望。把指数分布的这个意义放进标签中来考虑，标签的权重其实反映一个直觉：权重越大的标签，用户消费它就越频繁，也就是间隔时间就会短。</p><p>所以根据这个原理，就有另一个加权采样的办法：为每一个标签构造一个指数分布随机数，这个指数分布的参数 Lambda 就是标签权重，然后用这个指数分布的产生一个随机数，再输出随机数最大的 k 个标签作为采样结果。</p><h4 id="2-无限数据集"><a href="#2-无限数据集" class="headerlink" title="2. 无限数据集"></a><strong>2. 无限数据集</strong></h4><p>上面的两种采样都是针对有限数据集的，也就是采样之前都要遍历一遍所有样本。那么如果面对的数据集无限大，或者不知道多大时，该怎么做加权采样呢？这就要讲到另一个采样算法了，名字叫<strong>蓄水池采样</strong>（也叫蓄水池抽样）。</p><p>蓄水池采样可以用在推荐系统的哪些地方呢？比如可以再模型融合之后加一层蓄水池抽样，或者在召回阶段加一层蓄水池采样，这样在不影响整个推荐流程和转化概率的前提下，降低计算复杂度和提升推荐多样性。或者，在线阶段要使用用户的反馈行为做实时推荐，对于不同的用户，活跃程度不同，产生的反馈行为数量不同，你也可以用蓄水池采样，为每个用户取出固定数量的行为用于更新推荐结果。下面，先讲蓄水池采样，再讲加权蓄水池采样。</p><p>假如有一个数据集合，一共有 n 条，要从中采样取出 k 个，那么每个样本被选中的概率就是。蓄水池采样的做法是：</p><blockquote><ol><li>直接先取出前 k 个样本留着，这 k 个就是随时准备最终要输出的；</li><li>从第 k+1 个开始，每个都以$\frac{k}{n}$的概率去替换那留着的 k 个样本中的一个。</li></ol></blockquote><p>这个过程，随时可以取用那个 k 个集合作为输出结果，任意时刻，当总样本遍历了 n 个时，他们的概率都是$\frac{k}{n}$ 。这就是蓄水池采样，蓄水池采样，顾名思义，k 个元素的样本集合就是个蓄水池，是任意时刻的采样结果，可以随时取用。</p><p>实际上更需要的是加权蓄水池采样。加权蓄水池采样利用的依然是在前面说的第一种加权采样方法，只不过结合了蓄水池采样的思想。要从大数据集中采样 k 个，其具体做法是这样的：</p><blockquote><ol><li>为每一个样本生成一个分数，分数还是用这个公式$S_i = R^{\frac {1}{w_i}}$ ;</li><li>如果结果不足 k 个，直接保存到结果中；</li><li>如果结果中已经有 k 个了，如果 $S_i$ 比已有的结果里最小那个分数大，就替换它。</li></ol></blockquote><hr><h2 id="24-【其他应用算法】推荐候选池的去重策略"><a href="#24-【其他应用算法】推荐候选池的去重策略" class="headerlink" title="24.【其他应用算法】推荐候选池的去重策略"></a>24.【其他应用算法】推荐候选池的去重策略</h2><h3 id="去重是刚需"><a href="#去重是刚需" class="headerlink" title="去重是刚需"></a><strong>去重是刚需</strong></h3><p>主要是在两个地方：一个是内容源去重，另一个是不重复给用户推荐。</p><p>先说说内容源的去重，这部分以前几年的图文信息流推荐为典型的例子。<br>如果一个平台自己不生产内容，只是做内容搬运和聚合分发，那么从大量第三方的内容生产处抓取内容，就难免遇到相似甚至重复的内容。这就需要对内容做一个重复检测了。</p><p>对内容做重复检测，直观的思路是分词，然后提取关键词，再两两计算词向量之间的距离，距离小于一定阈值后就判定为重复。然而，这对于海量内容，比如几千万以上的内容来说简直就是灾难。其实，内容源去重并不是仅在推荐系统中才首次出现，这早在搜索引擎时代就是一个刚需了，搜索引擎把整个互联网的网页都下载到自己的服务器上，这时，重复冗余的内容就需要被检测出来。</p><p>另一个需求是在内容阅读类推荐场景下，给用户推荐的内容不要重复，推荐过的内容就不再出现在推荐候选集中。在你刷一个信息流产品时，不断看到重复的内容，想必不是使用感很好的一件事。因为以抓取作为主要内容来源的信息流产品，不同于社交网站上用户自发产生内容，除非遇到用户恶意发送，否则后者是不容易重复的。</p><h3 id="Simhash"><a href="#Simhash" class="headerlink" title="Simhash"></a><strong>Simhash</strong></h3><p>内容重复检测，是搜索引擎公司    先遇到的，所以 Google 在 07 年公开了他们内部的内容重复检测算法，这个算法简单有效，甚至造福了今天的信息流推荐产品。</p><p>我们直接将原始的内容映射为一个短字符串，这个短字符串就是原始内容的指纹，虽然不是绝对保证和原始内容一一映射，但是不同内容能得到相同指纹的概率非常小。只是这种信息指纹的方法有个非常明显的坏处就是，哪怕原始内容改一个字，得到的信息指纹就会截然不同。此处有点像MD5码一样。</p><p>但我们希望的是只要主要内容不变，就算一些不太重要的词句不同，也仍然可以得到相近甚至相同的指纹。这才能更加灵活地进行内容重复检测。是否有这样的算法？有，就是 Simhash。核心思想也是为每个内容生成一个整数表示的指纹，然后用这个指纹去做重复或者相似的检测。下面这个示意图说明了 Simhash 如何把一个原始内容表示成一个整数指纹：<br><a href="https://postimg.cc/BXmtb1fh" target="_blank" rel="noopener"><img src="https://i.postimg.cc/W1vZ9MWP/Simhash.jpg" alt="Simhash.jpg"></a></p><blockquote><ol><li>首先，对原始内容分词，并且计算每个词的权重；</li><li>对每个词哈希成一个整数，并且把这个整数对应的二进制序列中的 0 变成 -1，1 还是 1，得到一个 1 和 -1 组成的向量；</li><li>把每个词哈希后的向量乘以词的权重，得到一个新的加权向量；</li><li>把每个词的加权向量相加，得到一个最终向量，这个向量中每个元素有正有负；</li><li>把最终这个向量中元素为正的替换成 1，为负的替换成 0，这个向量变成一个二进制位序列，也就是    终变成了一个整数。</li></ol></blockquote><p>最终这个整数就代表了原始的内容。这个 Simhash 奇妙在哪呢？<br>看这个示意图中，我故意加了一个不太重要的词“了”，它的权重是 1，对应的加权向量元素不是 1 就是 -1，在上述的第四步中，如果这个词对应的向量缺少了，其实根本不影响最终得到那个整数，因为它很难改变最终向量元素的正负。这就是为什么那些不太重要的词不影响内容之间的重复检测。</p><p><strong>Simhash 为每一个内容生成一个整数指纹，其中的关键是把每个词哈希成一个整数，这一步常常采用 Jenkins 算法。</strong></p><p>这里简单示意的整数只有 8 个二进制位，实际上可能需要 64 个二进制位的整数，甚至范围更大。得到每个内容的 Simhash 指纹后，可以两两计算汉明距离，比较二进制位不同个数，其实就是计算两个指纹的异或，异或结果中如果包含 3 个以下的 1，则认为两条内容重复。为了高效，也可以直接认为指纹相同才重复，视情况而定。</p><h3 id="Bloomfilter"><a href="#Bloomfilter" class="headerlink" title="Bloomfilter"></a><strong>Bloomfilter</strong></h3><p>除了内容重复检测，还有一个需求是防止已经推荐的内容被重复推荐。这个刚需和上述内容重复相比，    大的不同就是过滤对象不同，<strong>上述 Simhash 过滤对象是内容本身，而这里则一般是内容的 ID。</strong></p><p>内容的 ID 一般是用一个 UUID 表示，是一个不太长的字符串或者整数。对于这类形如模式串的去重，显然可以用单独专门的数据库来保存，为了高效，甚至可以为它建上索引。但对于用户量巨大的情况下，这个做法对存储的消耗则不可小看。实际上，解决这类看一个字符串在不在一个集合中的问题，有一个有点老但很好用的做法，就是 Bloomfilter，有时候也被称为布隆过滤器。</p><p>布隆过滤器的原理也要用到哈希函数。<strong>它包含两部分：一个很长的二进制位向量，和一系列哈希函数。</strong></p><p>Bloomfilter 是一个很巧妙的设计，它先把原始要查询的集合映射到一个长度为 m 的二进制位向量上去，它映射的方法是：</p><blockquote><ol><li>设计 n 个互相独立的哈希函数，准备一个长度为 m 的二进制向量，最开始全是 0；</li><li>每个哈希函数把集合内的元素映射为一个不超过 m 的正整数 k，m 就是二进制向量的长度；</li><li>把这个二进制向量中的第 k 个位置设置为 1；也就是一个元素会在二进制向量中对应 n 个位置为 1。</li></ol></blockquote><p>示意图如下：<br><a href="https://postimg.cc/gwQZJL89" target="_blank" rel="noopener"><img src="https://i.postimg.cc/76YMKgLL/Bloomfilter.jpg" alt="Bloomfilter.jpg"></a><br>这个示意图中，原始的模式串经过三个互相独立的哈希函数，映射到 8 位二进制向量中的三个位置了。原始的模式串集合经过这样的处理后，就得到一个很大的二进制向量。在应用阶段时，假如来了一个模式串 s，需要查询是否在这个集合中，也需要经过同样的上述步骤。每个哈希函数对这个模式串 s 哈希后都得到一个整数，看看这个整数在二进制向量中所指示的位置是不是 1，如果每个哈希函数所指示的位置都是 1，就说明模式串 s 已经在集合中了。</p><p>需要说明的是，Bloomfilter 也并不是百分之百保证的，有很小的概率把原本不存在集合中的模式串判断为存在。这样就会造成那些明明还没有推荐给用户的内容 ID 就再也不会推荐给用户了，当然，这个小概率是可以承受的。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>在推荐系统中，虽然我们十分关心推荐匹配的效果，但是别忘了，对原始内容的挖掘和清洗往往更加重要。这其中就包括对重复内容的检测。两种去重策略都是牺牲一点误伤的概率换得大幅度的效率提升，具体的做法都是要借助哈希函数。只是哈希函数的结果在两个算法中有不同的处理手段，Simhash 是加权，Bloomfilter 则是用来做寻址。</p><p><a href="https://postimg.cc/vcKgX624" target="_blank" rel="noopener"><img src="https://i.postimg.cc/wjqXqXhQ/image.jpg" alt="其他应用算法.jpg"></a></p><blockquote><p>精选留言：</p><blockquote><p>Counting Bloom Filter支持删除操作，除了已有的二进制向量，向量的每一位对应一个整数计数器。每当增加一个元素时，哈希函数映射到的二进制向量对应的整数计数器加一，删除时减一。有了这个操作可以增加，查找和删除集合里的元素。</p><p>业界一般是不对布隆过滤器剔除元素，原因是剔除已有元素有可能导致整体数据错误。想到一种方法：使用一个同样长度的向量，记录对于位置1的个数，剔除是先hash6映射，对于1的位置，个数大于的话不变，等于1的话设为0；不过，缺点是这个向量占空间，存储成稀疏向量吧</p></blockquote></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/column/intro/74&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考原作：推荐系统三十六式-刑无刀&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;22-【其他应用算法】构建一个科学的排行榜体系&quot;&gt;&lt;a href=&quot;#22-【其他应用算法】构建一个科学的排行榜体系&quot; class=&quot;headerlink&quot; title=&quot;22.【其他应用算法】构建一个科学的排行榜体系&quot;&gt;&lt;/a&gt;22.【其他应用算法】构建一个科学的排行榜体系&lt;/h2&gt;&lt;h3 id=&quot;为什么要排行榜&quot;&gt;&lt;a href=&quot;#为什么要排行榜&quot; class=&quot;headerlink&quot; title=&quot;为什么要排行榜&quot;&gt;&lt;/a&gt;&lt;strong&gt;为什么要排行榜&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;排行榜，又名热门榜，听上去似乎是一个很常见的东西，原来它也算是推荐算法的一员？是的，它不但是，并且非常重要，有诸多作用：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;排行榜可以作为解决新用户冷启动问题的推荐策略。这个不难理解，当一个新用户刚注册时，可以把    近产品中热门的物品推荐给他。&lt;/li&gt;
&lt;li&gt;排行榜可以作为老用户的兴趣发现方式。即使是老用户，也可以在享受个性化推荐的同时去浏览热门的物品，从中看看哪些感兴趣，哪些不感兴趣，这些行为都是补充或者更新用户兴趣的数据来源。&lt;/li&gt;
&lt;li&gt;排行榜本身就是一个降级的推荐系统。推荐系统本身是一个软件，因此也会有出现问题的时候，也会有推荐不出来的时候，这个时候考虑到服务的可用性，用排行榜作为一种兜底策略，可以避免推荐位开天窗。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="推荐系统三十六式" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法" scheme="http://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="推荐" scheme="http://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统三十六式--学习笔记（20-21 深度学习）</title>
    <link href="http://www.xiemingzhao.com/2018/11/07/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F--%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%8820-21%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%89/"/>
    <id>http://www.xiemingzhao.com/2018/11/07/推荐系统三十六式--读书笔记（20-21 深度学习）/</id>
    <published>2018-11-06T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:41.918Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://time.geekbang.org/column/intro/74" target="_blank" rel="noopener">参考原作：推荐系统三十六式-刑无刀</a></p><h2 id="20-【深度学习】深度学习在推荐系统中的应用有哪些"><a href="#20-【深度学习】深度学习在推荐系统中的应用有哪些" class="headerlink" title="20.【深度学习】深度学习在推荐系统中的应用有哪些"></a>20.【深度学习】深度学习在推荐系统中的应用有哪些</h2><h3 id="深度学习与推荐系统"><a href="#深度学习与推荐系统" class="headerlink" title="深度学习与推荐系统"></a><strong>深度学习与推荐系统</strong></h3><p>在矩阵分解中，原始的矩阵表示每个用户的向量是物品，表示每个物品的向量是用户，两者向量的维度都特别高不说，还特别稀疏，分解后用户向量和物品向量不但维度变得特别小，而且变稠密了。业界还把这个稠密的向量叫做<strong>隐因子，意图直观说明它的物理意义：用户背后的偏好因子，物品背后的主题因子。</strong></p><p>实际上，你完全可以把矩阵分解看成是一种浅层神经网络，只有一层，它的示意图如下。<br><a href="https://postimg.cc/dDQMyM50" target="_blank" rel="noopener"><img src="https://i.postimg.cc/tRW98pPF/image.jpg" alt="矩阵分解隐因子.jpg"></a><br>这个示意图表示了一个用户 Ui，评分过的物品有 I2 和 I4，分解后的矩阵隐因子数量是 2，用户 Ui 的隐因子向量就是 [w1, w2]，物品 I2 的隐因子向量是 [w3, w5]，物品 I4 的隐因子向量是 [w4, w6]。可以把矩阵分解看成是一个拥有一个隐藏层的神经网络，得到的隐因子向量就是神经网络的连接权重参数。</p><a id="more"></a><p>深度学习是对事物的某些本质属性的挖掘，有两个好处：</p><ul><li>可以更加高效且真实地反映出事物本身的样子。对比一下，一张图片用原始的像素点表示，不但占用空间大，而且还不能反应图片更高级的特征，如线条、明暗、色彩，而后者则可以通过一系列的卷积网络学习(CNN)而得。</li><li>可以更加高效真实地反映出用户和物品之间的连接。对比一下，以用户历史点击过的物品作为向量表示用户兴趣；用这些物品背后隐藏的因子表示用户兴趣，显然后者更高效更真实，因为它还考虑了物品本身的相似性，这些信息都压缩到隐因子向量中了，同时再得到物品的隐因子向量，就可以更加直接平滑地算出用户对物品的偏好程度。</li></ul><p>这两个好处，正是深度学习可以帮助推荐系统的地方。<strong>第一个叫做 Embedding，就是嵌入，第二个叫做 Predicting，就是预测。</strong> 其实两者在前面的内容都已经有涉及了，矩阵分解得到的隐因子向量就是一种 Embedding， Word2vec 也是一种 Embedding，Wide&amp;Deep 则是用来预测的。关于第二种，具体来说有几个方向：深度神经网络的 CTR 预估，深度协同过滤，对时间序列的深度模型。</p><h3 id="各种-2vec"><a href="#各种-2vec" class="headerlink" title="各种 2vec"></a><strong>各种 2vec</strong></h3><p>首先还是在文本领域，从 Word2vec 到 Sentence2vec，再到 Doc2vec。简单介绍一下 Word2vec。你知道，Word2Vec 最终是每个词都得到一个稠密向量，十分类似矩阵分解得到的隐因子向量，得到这个向量有两个训练方法。先说第一个方法，想象你拿着一个滑动窗口，在一篇文档中从左往右滑动，每一次都有 N 个词在这个窗口内，每移动一下，产生 N-1 条样本。</p><p>每条样本都是用窗口内一个词去预测窗口正中央那个词，明明窗口内是 N 个词，为什么只有 N- 1 条样本呢？因为正中央那个词不用预测它本身啊。这 N-1 条样本的输入特征是词的嵌入向量，预测标签是窗口那个词。示意图如下所示:<br><a href="https://postimg.cc/yJftHjZT" target="_blank" rel="noopener"><img src="https://i.postimg.cc/9MVhyNXs/word2vec.jpg" alt="word2vec.jpg"></a><br>图中把 N-1 个样本放在一起示意的，无法看出隐藏层，实际上，输入时每个词可以用 One-hot 方式表示成一个向量，这个向量长度是整个词表的长度，并且只有当前词位置是 1，其他都是 0。</p><p>隐藏层的神经元个数就是最终得到嵌入向量的维度数，最终得到的嵌入向量元素值，实际上就是输入层和隐藏层的连接权重。示意图如下:<br><a href="https://postimg.cc/3dHLzVqT" target="_blank" rel="noopener"><img src="https://i.postimg.cc/J4s9HWcG/word2vec.jpg" alt="word2vec模型图.jpg"></a><br>至于 Word2vec 的第二种训练方法，则是把上述的 N-1 条样本颠倒顺序，用窗口中央的词预测周围的词，只是把输入和输出换个位置，一样可以训练得到嵌入向量。这就是两大经典训练方法，<strong>CBOW和Skip-Gram。</strong></p><p>既然词可以表示成一个稠密向量干这干那，那不如来个 Sentence2vec，把一个句子表示成一个嵌入向量，通常是把其包含的词嵌入向量加起来就完事了。</p><p>而 Doc2vec 则略微一点点不同，说明一点，多个句子构成一个段落，所以这里的 Doc 其实就是段落。Doc2vec 在窗口滑动过程中构建 N-1 条样本时，还增加一条样本，就是段落 ID 预测中央那个词，相当于窗口滑动一次得到 N 条样本。一个段落中有多少个滑动窗口，就得到多少条关于段落 ID 的样本，相当于这个段落中，段落 ID 在共享嵌入向量。段落 ID 像个特殊的词一样，也得到属于自己的嵌入向量，也就是 Doc2vec。<br><a href="https://postimg.cc/0KC7TW6k" target="_blank" rel="noopener"><img src="https://i.postimg.cc/Y058mTMW/DOC2vec.jpg" alt="DOC2vec.jpg"></a></p><p>那么对于Product2vec就是照着词嵌入的做法来，把用户按照时间先后顺序加入到购物车的商品，看成一个一个的词，一个购物车中所有的商品就是一个文档；于是照猫画虎学出每个商品的嵌入向量，用于去做相关物品的推荐，或者作为基础特征加入到其他推荐排序模型中使用。类似的，如果是应用商场的 App 推荐，也可以依计行事，把用户的下载序列看成文档，学习每个 App 的嵌入向量。</p><p>各种 2vec 的做法其实还不算深度学习，毕竟隐藏层才一层而已。如果要用更深的模型学习嵌入向量，就是深度学习中的 AutoEncoder，自动编码器。</p><p>从输入数据逐层降维，相当于是一个对原始数据的编码过程，到最低维度那一层后开始逐层增加神经元，相当于是一个解码过程，解码输出要和原始数据越接近越好，相当于在大幅度压缩原始特征空间的前提下，压缩损失越小越好。<br><a href="https://postimg.cc/sGpqWrMV" target="_blank" rel="noopener"><img src="https://i.postimg.cc/Fzq42FmJ/Autoencode.jpg" alt="Autoencode.jpg"></a></p><h3 id="YouTube-视频推荐"><a href="#YouTube-视频推荐" class="headerlink" title="YouTube 视频推荐"></a><strong>YouTube 视频推荐</strong></h3><p>首先，Youtube 把推荐的预测任务看成是一个多分类，这个和之前常规的推荐系统要么预测行为要么预测评分的做法不太一样，而是把候选物品当成多个类别，预测用户下一个会观看哪个视频。</p><script type="math/tex; mode=display">P(w_t = i|U,C) = \frac{e^{v_iu}}{\sum_{j \in V}e^{v_iu}}</script><p>这个公式中 U 是用户 C 是场景，输入时视频的嵌入向量和用户的嵌入向量。这里就涉及了先要使用深度神经网络，从用户历史反馈行为和场景信息中学习物品和用户的嵌入向量。整个推荐排序模型示意图如下:</p><p>原文可以参考:<a href="https://www.researchgate.net/publication/307573656_Deep_Neural_Networks_for_YouTube_Recommendations" target="_blank" rel="noopener">Deep Neural Networks for YouTube Recommendations</a><br><a href="https://postimg.cc/FfdPc462" target="_blank" rel="noopener"><img src="https://i.postimg.cc/FKGwMFVs/You-Tube.png" alt="YouTube.png"></a></p><blockquote><ol><li>根据观看历史把视频变成了嵌入向量，然后平均后作为输入特征之一，这个和前面的<br>Product2vec 的思路一致，把观看历史看成文档，观看的视频看成词。</li><li>搜索 Query 也变成了嵌入向量，平均之后作为输入特征之二。</li><li>人口统计学信息统统都嵌入了。</li><li>还加入视频的年龄信息，也就是在预测时，视频上传多久了。</li><li>所有这些不同的嵌入向量拼接成一个大的输入向量，经过深度神经网络，在输出层以<br>Softmax 作为输出函数，预测下一个观看视频。</li></ol></blockquote><p>在模型训练时，以 Softmax 作为输出层，但是在实际线上预测服务时，由于模型关心相对顺序，所以并不需要真的去计算 Softmax，而是拿着用户的特征向量做近似的近邻搜索，只生成最相近的一些推荐结果。整个推荐系统非常好理解，也比较好落地，所有的模型都可以通过 TensorFlow 快速实现。</p><hr><h2 id="【深度学习】用RNN构建个性化音乐播单"><a href="#【深度学习】用RNN构建个性化音乐播单" class="headerlink" title="【深度学习】用RNN构建个性化音乐播单"></a><strong>【深度学习】用RNN构建个性化音乐播单</strong></h2><p>前面讲到的绝大多数推荐算法，也都没有考虑“用户在产品上作出任何行为”都是有时间先后的。有一些矩阵分解算法考虑了时间属性，比如 Time-SVD；但是，这种做法只是把时间作为一个独立特征加入到模型中，仍然没有给时间一个正确的处理方式。</p><h3 id="时间的重要性"><a href="#时间的重要性" class="headerlink" title="时间的重要性"></a><strong>时间的重要性</strong></h3><p>绝大数推荐算法都忽略操作的先后顺序，为什么要采取这样简化的做法呢？因为一方面的确也能取得不错的效果，另一方面是深度学习和推荐系统还迟迟没有相见。在深度学习大火之后，对时间序列建模被提上议事日程，业界有很多尝试，今天以 Spotify 的音乐推荐为例，介绍循环神经网络在推荐系统中的应用。</p><h3 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a><strong>循环神经网络</strong></h3><p>循环神经网络，也常被简称为 RNN，是一种特殊的神经网络。再回顾一下神经网络的结构，示意图如下：<br><a href="https://postimg.cc/m1gRTkdv" target="_blank" rel="noopener"><img src="https://i.postimg.cc/zvnfSRTG/NN.jpg" alt="NN.jpg"></a><br>普通神经网络有三个部分，输入层 x，隐藏层 h，输出层 o，深度神经网络的区别就是隐藏层数量有很多，具体多少算深，这个可没有定论，有几层的，也有上百层的。</p><p>把输入层和隐藏层之间的关系表示成公式后就是：</p><script type="math/tex; mode=display">h = F(Wx)</script><p>就是输入层 x 经过连接参数线性加权后，再有激活函数 F 变换成非线性输出给输出层。<br>在输出层就是：</p><script type="math/tex; mode=display">O = \phi (Vh)</script><p>隐藏层输出经过输出层的网络连接参数线性加权后，再由输出函数变换成最终输出，比如分类任务就是 Softmax 函数。</p><p><strong>循环神经网络和普通神经网络的区别就在于：普通神经网络的隐藏层参数只有输入 x 决定，因为当神经网络在面对一条样本时，这条样本是孤立的，不考虑前一个样本是什么，循环神经网络的隐藏层不只是受输入 x 影响，还受上一个时刻的隐藏层参数影响。</strong></p><p>循环神经网络表示成示意图如下：<br><a href="https://postimg.cc/PNXdWVtS" target="_blank" rel="noopener"><img src="https://i.postimg.cc/zDW3144Y/RNN.jpg" alt="RNN.jpg"></a><br>解释一下这个示意图。在时刻 t，输入是 xt，而隐藏层的输出不再是只有输入层 $x_t$，还有时刻 t-1 的隐藏层输出 $h_{t-1}$，表示成公式就是：</p><script type="math/tex; mode=display">h_t = F(Wx_t + Uh_{t-1})</script><p>对比这个公式和前面普通神经网络的隐藏层输出，就是在激活函数的输入处多了一个 $Uh_{t-1}$ 。别小看多这一个小东西，它背后的意义非凡。那么上一个时刻得到的隐藏层，就是对时间序列上一个时刻的信息压缩，让它参与到这一个时刻的隐藏层建设上来，物理意义就是认为现在这个时刻的信息不只和现在的输入有关，还和上一个时刻的状态有关。这是时间序列本来的意义，也就是循环神经网络的意义。</p><h3 id="播单生成"><a href="#播单生成" class="headerlink" title="播单生成"></a><strong>播单生成</strong></h3><p>在网络音乐推荐中，尤其是各类 FM 类 App，提倡的是一直听下去,一首歌接着一首歌地播下去，就很适合这些场景。</p><blockquote><p>通常要做到这样的效果，有这么几种做法。</p><ol><li>电台音乐 DJ 手工编排播单，然后一直播放下去，传统广播电台都是这样的。</li><li>用非时序数据离线计算出推荐集合，然后按照分数顺序逐一输出。</li><li>利用循环神经网络，把音乐播单的生成看成是歌曲时间序列的生成，每一首歌的得到不但受用户当前的特征影响，还受上一首歌影响。</li></ol></blockquote><p>Spotify 采用了第三种办法，下面我就详细讲解这个推荐算法。</p><h4 id="1-数据"><a href="#1-数据" class="headerlink" title="1. 数据"></a><strong>1. 数据</strong></h4><p>个性化的播单生成，不再是推荐一个一个独立的音乐，而是推荐一个序列给用户。所用的数据就是已有播单，或者用户的会话信息。其中用户会话信息的意思就是，当一个用户在 App 上所做的一系列操作。把这些数据，看成一个一个的文档，每一个音乐文件就是一个一个的词。听完什么再听什么，就像是语言中的词和词的关系。</p><h4 id="2-建模"><a href="#2-建模" class="headerlink" title="2.建模"></a><strong>2.建模</strong></h4><p>你可以把播单生成看成由若干步骤组成，每一步吐出一个音乐来。这个吐出音乐的动作实际上是一个多分类问题，类别数目就是总共可以选择的音乐数目，如果有 100 万首歌可以选择，那么就是一个 100 万分类任务。这个分类任务计算输入是当前神经网络的隐藏状态，然后每一首歌都得到一个线性加权值，再由 Softmax 函数为每一首歌计算得到一个概率。表示如下：</p><script type="math/tex; mode=display">p(o_{yi}|h_t) = \frac {e^{v_ih}}{\sum_{j \in M}e^{v_jh}}</script><p>假如隐藏层有 k 个神经元，也就是说 h 是一个 k 维向量，输出层有 m 首歌可选，所以是一个 One-hot 编码的向量，也就是说一个 m 维向量，只有真正输出那首歌 i 是 1，其他都是 0，那么输出层就有 k 乘以 m 个未知参数。</p><p>再往前，计算隐藏层神经元输出时，不但用到输入层的信息，在这里，输入层也是一首歌，也有 m 首歌可以选择，所以输入向量仍然是一个 One-hot 编码的向量。除此之外，每一个隐藏层神经元还依赖上一个时刻自己的输出值，隐藏层神经元是 k 个，一个 k 维向量。按照隐藏层计算公式就是下面的样子:</p><script type="math/tex; mode=display">h_t = F(Wx_t + Uh_{t-1})</script><p>W 就是一个 m 乘以 k 的参数矩阵，U 就是一个 k 乘以 k 的参数矩阵。</p><blockquote><p>如此一来，循环神经网络在预测时的计算过程就是：</p><ul><li>当用户听完一首歌，要预测下一首歌该推荐什么时，输入就是一个 One-hot 编码的 m 维度向量，用 m 乘以 k 形状的输入层参数矩阵，乘以这个 m 向量，然后用隐藏层之间的 k 乘 k 参数矩阵，去乘以上一个隐藏状态向量，两者都得到一个 k 维向量，相加后经过非线性激活函数，比如 ReLU，这样就得到当前时刻的隐藏层输出值。</li><li>再用当前时刻的隐藏层输出值，经过 k 乘以 m 形状的输出层参数矩阵，得到一个 m 维向量，<br>再用 Softmax 把这个 m 维向量归一化成概率值，就是对下一首歌的预测，可以挑选最大概率的若干首歌作为输出，或者直接输出概率最高的那首歌直接播放。</li></ul></blockquote><p>这个计算过程示意图如下：<br><a href="https://postimg.cc/xcYYfsZv" target="_blank" rel="noopener"><img src="https://i.postimg.cc/8PfCb9B0/image.jpg" alt="Spotify.jpg"></a></p><blockquote><p>一个播单生成模型的参数就是这么三大块。</p><ol><li>连接输入和隐藏之间的矩阵 $W_{m \times k}$；</li><li>连接上一个隐藏状态和当前隐藏状态的矩阵： $U_{k \times k}$；</li><li>连接隐藏层和输出层的矩阵 $V_{k \times m}$。</li></ol></blockquote><p>得到了这些参数，就得到了播单推荐模型，怎么得到呢？这里就再简要讲一下神经网络的参数如何训练得到。</p><ol><li>初始化参数；</li><li>用当前的参数预测样本的类别概率；</li><li>用预测的概率计算交叉熵；</li><li>用交叉熵计算参数的梯度；</li><li>用学习步长和梯度更新参数；</li><li>迭代上述过程直到满足设置的条件。</li></ol><p>神经网络中的误差方向传播，实际上就是链式求导法则，因为要更新参数，就需要计算参数在当前取值时的梯度，要计算梯度就要求导，要求导就要从交叉熵函数开始，先对输出层参数求导计算梯度，更新输出层参数，接着链式下去，对输入层参数求导计算梯度，更新输入层参数。交叉熵是模型的目标函数，训练模型的目的就是要最小化它，也就是“误差反向传播”的“误差”。</p><p><a href="https://postimg.cc/H8twyYC4" target="_blank" rel="noopener"><img src="https://i.postimg.cc/7hFmjhsc/image.jpg" alt="深度学习.jpg"></a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/column/intro/74&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考原作：推荐系统三十六式-刑无刀&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;20-【深度学习】深度学习在推荐系统中的应用有哪些&quot;&gt;&lt;a href=&quot;#20-【深度学习】深度学习在推荐系统中的应用有哪些&quot; class=&quot;headerlink&quot; title=&quot;20.【深度学习】深度学习在推荐系统中的应用有哪些&quot;&gt;&lt;/a&gt;20.【深度学习】深度学习在推荐系统中的应用有哪些&lt;/h2&gt;&lt;h3 id=&quot;深度学习与推荐系统&quot;&gt;&lt;a href=&quot;#深度学习与推荐系统&quot; class=&quot;headerlink&quot; title=&quot;深度学习与推荐系统&quot;&gt;&lt;/a&gt;&lt;strong&gt;深度学习与推荐系统&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;在矩阵分解中，原始的矩阵表示每个用户的向量是物品，表示每个物品的向量是用户，两者向量的维度都特别高不说，还特别稀疏，分解后用户向量和物品向量不但维度变得特别小，而且变稠密了。业界还把这个稠密的向量叫做&lt;strong&gt;隐因子，意图直观说明它的物理意义：用户背后的偏好因子，物品背后的主题因子。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;实际上，你完全可以把矩阵分解看成是一种浅层神经网络，只有一层，它的示意图如下。&lt;br&gt;&lt;a href=&quot;https://postimg.cc/dDQMyM50&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img src=&quot;https://i.postimg.cc/tRW98pPF/image.jpg&quot; alt=&quot;矩阵分解隐因子.jpg&quot;&gt;&lt;/a&gt;&lt;br&gt;这个示意图表示了一个用户 Ui，评分过的物品有 I2 和 I4，分解后的矩阵隐因子数量是 2，用户 Ui 的隐因子向量就是 [w1, w2]，物品 I2 的隐因子向量是 [w3, w5]，物品 I4 的隐因子向量是 [w4, w6]。可以把矩阵分解看成是一个拥有一个隐藏层的神经网络，得到的隐因子向量就是神经网络的连接权重参数。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="推荐系统三十六式" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法" scheme="http://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="推荐" scheme="http://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统三十六式--学习笔记（17-19 MAB问题）</title>
    <link href="http://www.xiemingzhao.com/2018/11/06/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F--%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%8817-19%20MAB%E9%97%AE%E9%A2%98%EF%BC%89/"/>
    <id>http://www.xiemingzhao.com/2018/11/06/推荐系统三十六式--读书笔记（17-19 MAB问题）/</id>
    <published>2018-11-05T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:41.440Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://time.geekbang.org/column/intro/74" target="_blank" rel="noopener">参考原作：推荐系统三十六式-刑无刀</a></p><h2 id="17-【MAB问题】简单却有效的Bandit算法"><a href="#17-【MAB问题】简单却有效的Bandit算法" class="headerlink" title="17.【MAB问题】简单却有效的Bandit算法"></a>17.【MAB问题】简单却有效的Bandit算法</h2><h3 id="推荐就是选择"><a href="#推荐就是选择" class="headerlink" title="推荐就是选择"></a><strong>推荐就是选择</strong></h3><p>选择的困难在于不知道选择的后果，而且一旦错了就没有机会再来一次。在推荐系统中就对应了少了一次成功展示的机会。选择时不再聚焦到具体每个选项，而是去选择类别，这样压力是不是就小了很多？比如说，把推荐选择具体物品，上升到选择策略。如果后台算法中有三种策略：按照内容相似推荐，按照相似好友推荐，按照热门推荐。每次选择一种策略，确定了策略后，再选择策略中的物品，这样两个步骤。<strong>于是有了 Bandit 算法。</strong></p><h3 id="MAB-问题"><a href="#MAB-问题" class="headerlink" title="MAB 问题"></a><strong>MAB 问题</strong></h3><p>Bandit 算法来源于人民群众喜闻乐见的赌博学，它要解决的问题是这样的。</p><p>一个赌徒，要去摇老虎机，走进赌场一看，一排老虎机，外表一模一样，但是每个老虎机吐钱的概率可不一样，他不知道每个老虎机吐钱的概率分布是什么，那么想最大化收益该怎么整？</p><a id="more"></a><blockquote><p>这就是多臂赌博机问题 (Multi-armed bandit problem, K-armed bandit problem, MAB)，简称 MAB 问题。有很多相似问题都属于 <strong>MAB 问题</strong>。</p><ol><li>假设一个用户对不同类别的内容感兴趣程度不同，当推荐系统初次见到这个用户时，怎么快速地知道他对每类内容的感兴趣程度？这也是推荐系统常常面对的冷启动问题。</li><li>假设系统中有若干广告库存物料，该给每个用户展示哪个广告，才能获得最大的点击收益，是不是每次都挑收益最好那个呢？</li><li>算法工程师又设计出了新的策略或者模型，如何既能知道它和旧模型相比谁更靠谱又对风险可控呢？</li></ol></blockquote><p>推荐系统里面有两个顽疾，一个是冷启动，一个是探索利用问题，后者又称为 EE 问题：Exploit－Explore 问题。针对这两个顽疾，Bandit 算法可以入药。</p><h3 id="Bandit-算法"><a href="#Bandit-算法" class="headerlink" title="Bandit 算法"></a><strong>Bandit 算法</strong></h3><p>Bandit 算法并不是指一个算法，而是一类算法。首先，来定义一下，如何衡量选择的好坏？Bandit 算法的思想是：看看选择会带来多少遗憾，遗憾越少越好。在 MAB 问题里，用来量化选择好坏的指标就是累计遗憾，计算公式如下所示。</p><script type="math/tex; mode=display">\begin{align}R_T &= \sum_{i=1}^T(w_{opt}-w_{B(i)})\\&= Tw^*-\sum_{i=1}^Tw_{B(i)}\end{align}</script><p><strong>公式有两部分构成：一个是遗憾，一个是累积。求和符号内部就表示每次选择的遗憾多少。</strong></p><p>$W_{opt}$ 就表示，每次都运气好，选择了最好的选择，该得到多少收益，WBi 就表示每一次实际选择得到的收益，两者之差就是“遗憾”的量化，在 T 次选择后，就有了累积遗憾。</p><p>在这个公式中：为了简化 MAB 问题，每个臂的收益不是 0，就是 1，也就是伯努利收益。这个公式可以用来对比不同 Bandit 算法的效果：对同样的多臂问题，用不同的 Bandit 算法模拟试验相同次数，比比看哪个 Bandit 算法的累积遗憾增长得慢，那就是效果较好的算法。</p><p>Bandit 算法的套路就是：小心翼翼地试，越确定某个选择好，就多选择它，越确定某个选择差，就越来越少选择它。</p><p>如果某个选择实验次数较少，导致不确定好坏，那么就多给一些被选择机会，直到确定了它是金子还是石头。简单说就是，把选择的机会给“确定好的”和“还不确定的”。</p><blockquote><p>Bandit 算法中有几个关键元素：臂，回报，环境。</p><blockquote><ol><li>臂：是每次选择的候选项，好比就是老虎机，有几个选项就有几个臂；</li><li>回报：就是选择一个臂之后得到的奖励，好比选择一个老虎机之后吐出来的金币；</li><li>环境：就是决定每个臂不同的那些因素，统称为环境。</li></ol></blockquote><p>将这个几个关键元素对应到推荐系统中来。</p><blockquote><ol><li>臂：每次推荐要选择候选池，可能是具体物品，也可能是推荐策略，也可能是物品类别；</li><li>回报：用户是否对推荐结果喜欢，喜欢了就是正面的回报，没有买账就是负面回报或者零回报；</li><li>环境：推荐系统面临的这个用户就是不可捉摸的环境。</li></ol></blockquote></blockquote><h4 id="1-汤普森采样算法"><a href="#1-汤普森采样算法" class="headerlink" title="1. 汤普森采样算法"></a><strong>1. 汤普森采样算法</strong></h4><p>原理：假设每个臂是否产生收益，起决定作用的是背后有一个概率分布，产生收益的概率为 p。每个臂背后绑定了一个概率分布；每次做选择时，让每个臂的概率分布各自独立产生一个随机数，按照这个随机数排序，输出产生最大随机数那个臂对应的物品。</p><p><a href="https://postimg.cc/1g7XXD8z" target="_blank" rel="noopener"><img src="https://i.postimg.cc/xCnzsRYL/beta.png" alt="beta.png"></a></p><p>假设每个臂背后的概率分布是上图所示的beta分布，a 和 b 两个参数决定了分布的形状和位置：</p><ul><li>当 a+b 值越大，分布曲线就越窄，分布就越集中，这样的结果就是产生的随机数会容易靠近中心位置；</li><li>当 a/(a+b) 的值越大，分布的中心位置越靠近 1，反之就越靠近 0，这样产生的随机数也相应第更容易靠近 1 或者 0。</li></ul><blockquote><p>贝塔分布的这两个特点，可以把它分成三种情况：</p><ol><li>曲线很窄，而且靠近 1；</li><li>曲线很窄，而且靠近 0；</li><li>曲线很宽。</li></ol></blockquote><p>把贝塔分布的 a 参数看成是推荐后得到用户点击的次数，把分布的 b 参数看成是没有得到用户点击的次数。按照这个对应，再来叙述一下汤普森采样的过程。</p><ol><li>取出每一个候选对应的参数 a 和 b；</li><li>为每个候选用 a 和 b 作为参数，用贝塔分布产生一个随机数；</li><li>按照随机数排序，输出最大值对应的候选；</li><li>观察用户反馈，如果用户点击则将对应候选的 a 加 1，否则 b 加 1；<br><strong>注意，实际上在推荐系统中，要为每一个用户都保存一套参数，比如候选有 m 个，用户有 n 个，那么就要保存 2mn 个参数。</strong></li></ol><blockquote><p>有效性的原因：</p><ol><li>如果一个候选被选中的次数很多，也就是 a+b 很大了，它的分布会很窄，换句话说这个候选的收益已经非常确定了，用它产生随机数，基本上就在中心位置附近，接近平均收益。</li><li>如果一个候选不但 a+b 很大，即分布很窄，而且 a/(a+b) 也很大，接近 1，那就确定这是个好的候选项，平均收益很好，每次选择很占优势，就进入利用阶段，反之则几乎再无出头之日。</li><li>如果一个候选的 a+b 很小，分布很宽，也就是没有被选择太多次，说明这个候选是好是坏还不太确定，那么用它产生随机数就有可能得到一个较大的随机数，在排序时被优先输出，这就起到了前面说的探索作用。</li></ol></blockquote><p>用 Python 实现汤普森采样就一行：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> pymc</span><br><span class="line">choice = numpy.argmax(pymc.rbeta(<span class="number">1</span> + self.wins, <span class="number">1</span> + self.trials - self.wins))</span><br></pre></td></tr></table></figure></p><h4 id="2-UCB-算法"><a href="#2-UCB-算法" class="headerlink" title="2.UCB 算法"></a><strong>2.UCB 算法</strong></h4><p>第二个常用的 Bandit 算法就是 UCB 算法，UCB 算法全称是 Upper Confidence Bound，即置信区间上界。它也为每个臂评分，每次选择评分最高的候选臂输出，每次输出后观察用户反馈，回来更新候选臂的参数。每个臂的评分公式为:</p><script type="math/tex; mode=display">\bar x_j(t)+\sqrt{\frac{2ln t}{T_{j,t}}}</script><p>公式有两部分，加号前面是这个候选臂到目前的平均收益，反应了它的效果，后面的叫做 Bonus，本质上是均值的标准差，反应了候选臂效果的不确定性，就是置信区间的上边界。t 是目前的总选择次数，$T_{jt}$ 是每个臂被选择次数。</p><p>思想：</p><ul><li>以每个候选的平均收益为基准线进行选择；</li><li>对于被选择次数不足的给予照顾；</li><li>选择倾向的是那些确定收益较好的候选。</li></ul><p>&nbsp;</p><h4 id="3-Epsilon-贪婪算法"><a href="#3-Epsilon-贪婪算法" class="headerlink" title="3. Epsilon 贪婪算法"></a><strong>3. Epsilon 贪婪算法</strong></h4><p>朴素的一个算法，简单有效，类似于模拟退火。具体步骤：</p><ol><li>先选一个 (0,1) 之间较小的数，叫做 Epsilon，也是这个算法名字来历。</li><li>每次以概率 Epsilon 做一件事：所有候选臂中随机选一个，以 1-Epsilon 的概率去选择平均收益最大的那个臂。<br><strong>Epsilon 的值可以控制对探索和利用的权衡程度。这个值越接近 0，在探索上就越保守。</strong><br>相似的，还有一个更朴素的做法：先试几次，等每个臂都统计到收益之后，就一直选均值最大那个臂。</li></ol><h4 id="4-效果对比"><a href="#4-效果对比" class="headerlink" title="4. 效果对比"></a><strong>4. 效果对比</strong></h4><p>对于上述算法，可以用仿真的方法对比效果，结果如下图：<br><a href="https://postimg.cc/cvsH84Zg" target="_blank" rel="noopener"><img src="https://i.postimg.cc/vZn6kcNz/Bandit.jpg" alt="Bandit效果对比图.jpg"></a></p><blockquote><p>从上到下分别是下面几种。</p><ol><li>完全随机：就是不顾用户反馈的做法。</li><li>朴素选择：就是认准一个效果好的，一直推。</li><li>Epsilon 贪婪算法：每次以小概率尝试新的，大概率选择效果好的。</li><li>UCB：每次都会给予机会较少的候选一些倾向。</li><li>汤普森采样：用贝塔分布管理每一个候选的效果。<br><strong>UCB 算法和汤普森采样都显著优秀很多。</strong></li></ol></blockquote><h3 id="冷启动"><a href="#冷启动" class="headerlink" title="冷启动"></a><strong>冷启动</strong></h3><p>推荐系统冷启动问题可以用 Bandit 算法来解决一部分。<br>大致思路如下：</p><ol><li>用分类或者 Topic 来表示每个用户兴趣，我们可以通过几次试验，来刻画出新用户心目中对每个 Topic 的感兴趣概率。</li><li>这里，如果用户对某个 Topic 感兴趣，就表示我们得到了收益，如果推给了它不感兴趣的 Topic，推荐系统就表示很遗憾 (regret) 了。</li><li>当一个新用户来了，针对这个用户，我们用汤普森采样为每一个 Topic 采样一个随机数，排序后，输出采样值 Top N 的推荐 Item。注意，这里一次选择了 Top N 个候选臂。</li><li>等着获取用户的反馈，没有反馈则更新对应 Topic 的 b 值，点击了则更新对应 Topic 的 a 值。</li></ol><h3 id="三种算法的不足"><a href="#三种算法的不足" class="headerlink" title="三种算法的不足"></a><strong>三种算法的不足</strong></h3><h4 id="1-Epsilon贪婪算法的不足"><a href="#1-Epsilon贪婪算法的不足" class="headerlink" title="1. Epsilon贪婪算法的不足"></a><strong>1. Epsilon贪婪算法的不足</strong></h4><p>(1)    Epsilon贪婪算法中的概率值(Epsilon值)定多少是合理的，能由候选集的条件判断比较合理的范围吗？这个值需要做试验和根据算法结果调整吗？<br>(2)    如果p值是固定的，总有一部分用户是肯定要看到不好的结果的，随着算法搜集到更多的反馈不会改善这个效果。<br>(3)    如果有大量的劣质资源，即使平均收益最大的臂可能都比整个候选集中最好的臂的收益差很多。Exploration的过程中会导致用户对整个系统丧失耐心，好的坏的都不愿意反馈。这样Exploit到好的候选的几率就更低，时间更长，需要更多的用户来做试验。<br>(4)    如何在实际环境中衡量Epsilon贪婪算法对整体的贡献，怎么知道多少次点击或多少用户之后的临界值来判断这个算法是对整体起足够多的正面作用的？ </p><h4 id="2-UCB算法的不足"><a href="#2-UCB算法的不足" class="headerlink" title="2. UCB算法的不足"></a><strong>2. UCB算法的不足</strong></h4><p>候选多时，很多候选都没有显示过，平均收益和其标准差会相同。这时候如何排序？如果纯粹随机，就可能需要较长时间得到候选集中更好的结果。UCB算法本质上是“确定性”（Det erministic）算法，随机探索的能力受到一定限制。 </p><h4 id="3-汤普森采样的不足"><a href="#3-汤普森采样的不足" class="headerlink" title="3. 汤普森采样的不足"></a><strong>3. 汤普森采样的不足</strong></h4><p>汤普森采样相对已经比较好了，我自己想不出更好的解决办法。当有相当数量的候选点击率和点击次数都很接近时，系统Explore到好的候选需要一些资源 (时间，用户等)。回到上面Epsilon贪婪算法的不足中的(3)。如果开始时有大量的劣质资源，没有人工干预发现好的候选比较耗时，整个系统可能还未来得及给用户推荐好的候选已经进入负循环。 </p><p><strong>Epsilon贪婪算法的不足的(3)和(4)适用于所有的Bandit算法。</strong></p><hr><h2 id="18-【MAB问题】结合上下文信息的Bandit算法"><a href="#18-【MAB问题】结合上下文信息的Bandit算法" class="headerlink" title="18.【MAB问题】结合上下文信息的Bandit算法"></a>18.【MAB问题】结合上下文信息的Bandit算法</h2><h3 id="UCB-回顾"><a href="#UCB-回顾" class="headerlink" title="UCB 回顾"></a><strong>UCB 回顾</strong></h3><p>这些 Bandit 算法，都有一个特点：完全没有使用候选臂的特征信息。特征可是机器学习的核心要素，也是机器学习泛化推广的依赖要素。UCB 就是置信上边界的简称，所以 UCB 这个名字就反映了它的全部思想。置信区间可以简单直观地理解为不确定性的程度，区间越宽，越不确定，反之就很确定。</p><blockquote><ol><li>每个候选的回报均值都有个置信区间，随着试验次数增加，置信区间会变窄，相当于逐渐确定了到底回报丰厚还是可怜。</li><li>每次选择前，都根据已经试验的结果重新估计每个候选的均值及置信区间。</li><li>选择置信区间上界最大的那个候选。</li></ol></blockquote><p>选择置信区间上界最大的那个候选”，这句话反映了几个意思：</p><ol><li>如果候选的收益置信区间很宽，相当于被选次数很少，还不确定，那么它会倾向于被多次选择，这个是算法冒风险的部分；</li><li>如果候选的置信区间很窄，相当于被选次数很多，比较确定其好坏了，那么均值大的倾向于被多次选择，这个是算法保守稳妥的部分；</li><li>UCB 是一种乐观冒险的算法，它每次选择前根据置信区间上界排序，反之如果是悲观保守的做法，可以选择置信区间下界排序。</li></ol><h3 id="LinUCB"><a href="#LinUCB" class="headerlink" title="LinUCB"></a><strong>LinUCB</strong></h3><p>“Yahoo!”的科学家们在 2010 年基于 UCB 提出了 LinUCB 算法，它和传统的 UCB 算法相比，最大的改进就是加入了特征信息，每次估算每个候选的置信区间，不再仅仅是根据实验，而是根据特征信息来估算，这一点就非常的“机器学习”了。</p><p>LinUCB 算法做了一个假设：一个物品被选择后推送给一个用户，其收益和特征之间呈线性关系。其简单版本就是让每一个候选臂之间完全互相无关，参数不共享。高级版本就是候选臂之间共享一部分参数。</p><h4 id="简单版本"><a href="#简单版本" class="headerlink" title="简单版本"></a><strong>简单版本</strong></h4><p>假设此时有一个特征—性别，四个产品需要推荐给用户。</p><div class="table-container"><table><thead><tr><th style="text-align:center">用户</th><th style="text-align:center">性别</th><th style="text-align:center">特征</th></tr></thead><tbody><tr><td style="text-align:center">u1</td><td style="text-align:center">男</td><td style="text-align:center">$x_1$=[1,0]</td></tr><tr><td style="text-align:center">u2</td><td style="text-align:center">女</td><td style="text-align:center">$x_2$=[0,1]</td></tr></tbody></table></div><p>两个特征就是Bandit算法要面对的上下文，表示成特征就是下面的样子:</p><div class="table-container"><table><thead><tr><th style="text-align:center">参数</th><th style="text-align:center">候选品（商品）</th></tr></thead><tbody><tr><td style="text-align:center">$\theta_1$=[0.1,0.5]</td><td style="text-align:center">华歌尔内衣</td></tr><tr><td style="text-align:center">$\theta_2$=[0.2,0.6]</td><td style="text-align:center">香奈儿口红</td></tr><tr><td style="text-align:center">$\theta_3$=[0.9,0.1]</td><td style="text-align:center">吉利剃须刀</td></tr><tr><td style="text-align:center">$\theta_4$=[0.5,0.6]</td><td style="text-align:center">苹果笔记本</td></tr></tbody></table></div><p>每一次推荐时，用特征和每一个候选臂的参数去预估它的预期收益和置信区间。</p><p>$x_i \times \theta_j$，这就是给男性用户推荐剃须刀，给女性用户推荐口红，即使是新用户，也可以作出比随机猜测好的推荐，再观察用户是否会点击，用点击信息去更新那个被推荐了的候选臂的参数。<br>这里的例子简化了没有计算置信区间，这是 UCB 的精髓。下面补上。</p><p>假如 D 是候选臂是候选臂在 m 次被选择中积累的特征，相当于就是 m 条样本，特征维度是 d，所以 D 是一个矩阵，维度是 m x d。这 m 次被选择，每次得到用户的点击或者没点击，把这个反馈信息记录为一个 m x 1 的向量，叫做 C。所以这个候选臂对应的参数就是 d x 1 的向量，d 就是特征维度数，记录$\hat \theta$。<br>按照 LinUCB 认为，参数和特征之间线性相乘就应该得到收益：</p><script type="math/tex; mode=display">D_{m\times d} \times \hat \theta_{d \times 1} = C_{m \times 1}</script><p>于是(这里D无法直接求逆的，所以下面会进行变换)： <script type="math/tex">\hat \theta_{d \times 1} = (D_{m \times d}^T)^{-1} C_{m \times 1}</script><br>由于数据稀疏，实际上求参数西塔时是采用岭回归的方法，给原始特征矩阵加上一个单位对角矩阵后再参与计算：</p><script type="math/tex; mode=display">\hat \theta_{d \times 1} = (D_{m \times d}^T D_{m \times d} + I_{d \times d}) ^{-1} D_{m \times d}^T C_{m \times 1}</script><p>每一个候选臂都像这样去更新它的参数，同时，得到参数后，在真正做选择时，用面对上下文的特征和候选臂的参数一起。除了估算期望收益，还要计算置信区间的上边界，如果 x 是上下文特征，则期望收益和置信上边界的计算方法分别是下面的样子。期望收益：</p><script type="math/tex; mode=display">\hat r = x_{d \times 1}^T \hat \theta_{d \times 1}</script><p>置信区间上边界：</p><script type="math/tex; mode=display">\hat b = \alpha \sqrt{x_{d \times 1}^T(D_{m \times d}^T D_{m \times d} + I_{d \times d}) ^{-1} x_{d \times 1}}</script><p>这两个计算结果都是标量数值。置信区间计算公式虽然看起来复杂，实际上反应的思想也很直观，随着被选择次数的增加，也就是 m 增加，这个置信上边界是越来越小的。每一次选择时给每一个候选臂都计算这两个值，相加之后选择最大那个候选臂输出，就是 LinUCB 了。<br><strong>岭回归（ridge regression）主要用于当样本数小于特征数时，对回归参数进行修正。对于加了特征的 Bandit 问题，正好符合这个特点：试验次数（样本）少于特征数。</strong></p><p>LinUCB基本算法描述如下图：<br><a href="https://postimg.cc/8F2gLHb4" target="_blank" rel="noopener"><img src="https://i.postimg.cc/G223wg8W/LinUCB.png" alt="LinUCB.png"></a><br><strong>算法详解：</strong></p><ol><li>设定一个参数$\alpha$，这个参数决定了我们Explore的程度；</li><li>开始试验迭代；</li><li>获取每一个arm的特征向量$x_{a,t}$；</li><li>开始计算每一个arm的预估回报及其置信区间；</li><li>如果arm还从没有被试验过，那么：</li><li>用单位矩阵初始化$A_a$；</li><li>用0向量初始化$b_a$；</li><li>处理完没被试验过的arm；</li><li>计算线性参数$\theta$；</li><li>用$\theta$和特征向量$x_{a,t}$计算预估回报，同时加上置信区间宽度；</li><li>处理完每一个arm；</li><li>选择第10步中最大值对应的arm，观察真实的回报$r_t$；</li><li>更新$A_{at}$；</li><li>更新$b_{at}$；</li><li>算法结束。</li></ol><p>python代码实现LinUCB：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinUCB</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">     self.alpha = <span class="number">0.25</span> </span><br><span class="line">     self.r1 = <span class="number">1</span> <span class="comment"># if worse -&gt; 0.7, 0.8</span></span><br><span class="line">        self.r0 = <span class="number">0</span> <span class="comment"># if worse, -19, -21</span></span><br><span class="line">        <span class="comment"># dimension of user features = d</span></span><br><span class="line">        self.d = <span class="number">6</span></span><br><span class="line">        <span class="comment"># Aa : collection of matrix to compute disjoint part for each article a, d*d</span></span><br><span class="line">        self.Aa = &#123;&#125;</span><br><span class="line">        <span class="comment"># AaI : store the inverse of all Aa matrix</span></span><br><span class="line">        self.AaI = &#123;&#125;</span><br><span class="line">        <span class="comment"># ba : collection of vectors to compute disjoin part, d*1</span></span><br><span class="line">        self.ba = &#123;&#125;</span><br><span class="line"> </span><br><span class="line">        self.a_max = <span class="number">0</span></span><br><span class="line"> </span><br><span class="line">        self.theta = &#123;&#125;</span><br><span class="line"> </span><br><span class="line">        self.x = <span class="literal">None</span></span><br><span class="line">        self.xT = <span class="literal">None</span></span><br><span class="line">        <span class="comment"># linUCB</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_articles</span><span class="params">(self, art)</span>:</span></span><br><span class="line">        <span class="comment"># init collection of matrix/vector Aa, Ba, ba</span></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> art:</span><br><span class="line">            self.Aa[key] = np.identity(self.d)</span><br><span class="line">            self.ba[key] = np.zeros((self.d, <span class="number">1</span>))</span><br><span class="line">            self.AaI[key] = np.identity(self.d)</span><br><span class="line">            self.theta[key] = np.zeros((self.d, <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># 这里更新参数时没有传入更新哪个arm，因为在上一次recommend的时候缓存了被选的那个arm，所以此处不用传入 </span></span><br><span class="line">        <span class="comment"># 另外，update操作不用阻塞recommend，可以异步执行        </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(self, reward)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> reward == <span class="number">-1</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">elif</span> reward == <span class="number">1</span> <span class="keyword">or</span> reward == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> reward == <span class="number">1</span>:</span><br><span class="line">                r = self.r1</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                r = self.r0</span><br><span class="line">            self.Aa[self.a_max] += np.dot(self.x, self.xT)</span><br><span class="line">            self.ba[self.a_max] += r * self.x</span><br><span class="line">            self.AaI[self.a_max] = linalg.solve(self.Aa[self.a_max], np.identity(self.d))</span><br><span class="line">            self.theta[self.a_max] = np.dot(self.AaI[self.a_max], self.ba[self.a_max])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># error</span></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="comment"># 预估每个arm的回报期望及置信区间</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">recommend</span><span class="params">(self, timestamp, user_features, articles)</span>:</span></span><br><span class="line">        xaT = np.array([user_features])</span><br><span class="line">        xa = np.transpose(xaT)</span><br><span class="line">        art_max = <span class="number">-1</span></span><br><span class="line">        old_pa = <span class="number">0</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 获取在update阶段已经更新过的AaI(求逆结果)</span></span><br><span class="line">        AaI_tmp = np.array([self.AaI[article] <span class="keyword">for</span> article <span class="keyword">in</span> articles])</span><br><span class="line">        theta_tmp = np.array([self.theta[article] <span class="keyword">for</span> article <span class="keyword">in</span> articles])</span><br><span class="line">        art_max = articles[np.argmax(np.dot(xaT, theta_tmp) + self.alpha * np.sqrt(np.dot(np.dot(xaT, AaI_tmp), xa)))]</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 缓存选择结果，用于update</span></span><br><span class="line">        self.x = xa</span><br><span class="line">        self.xT = xaT</span><br><span class="line">        <span class="comment"># article index with largest UCB</span></span><br><span class="line">        self.a_max = art_max</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> self.a_max</span><br></pre></td></tr></table></figure></p><blockquote><p>LinUCB 的重点。</p><ol><li>LinUCB 不再是上下文无关地，像盲人摸象一样从候选臂中去选择了，而是要考虑上下文因素，比如是用户特征、物品特征和场景特征一起考虑。</li><li>每一个候选臂针对这些特征各自维护一个参数向量，各自更新，互不干扰。</li><li>每次选择时用各自的参数去计算期望收益和置信区间，然后按照置信区间上边界最大的输出结果。</li><li>观察用户的反馈，简单说就是“是否点击”，将观察的结果返回，结合对应的特征，按照刚才给出的公式，去重新计算这个候选臂的参数。</li></ol></blockquote><p><strong>当 LinUCB 的特征向量始终取 1，每个候选臂的参数是收益均值的时候，LinUCB 就是 UCB。</strong></p><h4 id="高级版的-LinUCB"><a href="#高级版的-LinUCB" class="headerlink" title="高级版的 LinUCB"></a><strong>高级版的 LinUCB</strong></h4><p>与简单版的相比，就是认为有一部分特征对应的参数是在所有候选臂之间共享的，所谓共享，也就是无论是哪个候选臂被选中，都会去更新这部分参数。在“Yahoo！”的应用中，物品是文章。它对特征做了一些工程化的处理，这里以此为例，可供实际应用时参考借鉴。</p><p>首先，原始用户特征有下面几个。</p><ol><li>人口统计学：性别特征（2 类），年龄特征（离散成 10 个区间）。</li><li>地域信息：遍布全球的大都市，美国各个州。</li><li>行为类别：代表用户历史行为的 1000 个类别取值。</li></ol><p>其次，原始文章特征有：</p><ol><li>URL 类别：根据文章来源分成了几十个类别。</li><li>编辑打标签：编辑人工给内容从几十个话题标签中挑选出来的。<br>原始特征向量先经过归一化，变成单位向量。</li></ol><p>再对原始用户特征做第一次降维，降维的方法就是利用用户特征和物品特征以及用户的点击行为去拟合一个矩阵 W。</p><script type="math/tex; mode=display">\phi_u^T W \phi_a^T</script><p>就用逻辑回归拟合用户对文章的点击历史，得到的 W 直觉上理解就是：能够把用户特征映射到物品特征上，相当于对用户特征降维了，映射方法是下面这样。</p><script type="math/tex; mode=display">\psi_u = \phi_u^T W</script><p>这一步可以将原始的 1000 多维用户特征投射到文章的 80 多维的特征空间。<br>然后，用投射后的 80 多维特征对用户聚类，得到 5 个类，文章页同样聚类成 5 个类，再加上常数 1，用户和文章各自被表示成 6 维向量。接下来就应用前面的 LinUCB 算法就是了，特征工程依然还是很有效的。</p><p><strong>我们实际上可以考虑三类特征：U（用户），A（广告或文章），C（所在页面的一些信息）。</strong><br>总结一下LinUCB算法，有以下优点：</p><ul><li>由于加入了特征，所以收敛比UCB更快（论文有证明）；</li><li>特征构建是效果的关键，也是工程上最麻烦和值的发挥的地方；</li><li>由于参与计算的是特征，所以可以处理动态的推荐候选池，编辑可以增删文章；</li><li>特征降维很有必要，关系到计算效率。</li></ul><hr><h2 id="19-【MAB问题】如何将Bandit算法与协同过滤结合使用"><a href="#19-【MAB问题】如何将Bandit算法与协同过滤结合使用" class="headerlink" title="19.【MAB问题】如何将Bandit算法与协同过滤结合使用"></a>19.【MAB问题】如何将Bandit算法与协同过滤结合使用</h2><h3 id="信息茧房"><a href="#信息茧房" class="headerlink" title="信息茧房"></a><strong>信息茧房</strong></h3><p>推荐系统中最经典的算法莫过于协同推荐。在技术上，Bandit 算法就是一个权衡探索和利用的好方法。如果把它结合传统的协同过滤来做推荐，那么在一定程度上就可以延缓信息茧房的到来。如何结合协同过滤的群体智慧，与 Bandit 的走一步看一步一起，让两种思想碰撞，这就是 2016 年有人提出的 COFIBA 算法。</p><h3 id="COFIBA-算法"><a href="#COFIBA-算法" class="headerlink" title="COFIBA 算法"></a><strong>COFIBA 算法</strong></h3><h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a><strong>思想</strong></h4><blockquote><p>很多的推荐场景中都有两个规律。</p><ol><li>相似的用户对同一个物品的反馈可能是一样的。也就是对一个聚类用户群体推荐同一个 item，他们可能都会喜欢，也可能都不喜欢，同样的，同一个用户会对相似的物品反馈也会相同。这实际上就是基于用户的协同过滤基本思想。</li><li>在使用推荐系统过程中，用户的决策是动态进行的，尤其是新用户。这就导致无法提前为用户准备好推荐候选，只能“走一步看一步”，是一个动态的推荐过程。这是 Bandit 的算法基本思想。</li></ol></blockquote><p>每一个推荐候选物品，都可以根据用户对其偏好的不同，将用户分成不同的群体。然后下一次，由用户所在的群体集体帮他预估可能的收益及置信区间，这个集体就有了协同的效果，然后再实时观察真实反馈，回来更新用户的个人参数用于下次调整收益和置信区间，这就有了 Bandit 的思想在里面。<br>如果要推荐的候选物品较多，需要对物品聚类，就不用按照每一个物品对用户聚类，而是按照每一个物品所属的类簇对用户聚类，如此一来，物品的类簇数目相对于物品数就要大大减少。</p><h4 id="细节"><a href="#细节" class="headerlink" title="细节"></a><strong>细节</strong></h4><blockquote><p>COFIBA 算法要点摘要如下：</p><blockquote><ol><li>在时刻 t，有一个用户来访问推荐系统，推荐系统需要从已有的候选池子中挑一个最佳的物品推荐给他，然后观察他的反馈，用观察到的反馈来更新挑选策略。</li><li>这里的每个物品都有一个特征向量，所以这里的 Bandit 算法是 context 相关的，只不过这里虽然是给每个用户维护一套参数，但实际上是由用户所在的聚类类簇一起决定结果的。</li><li>这里依然是用岭回归去拟合用户的权重向量，用于预测用户对每个物品的可能反馈 （payoff），这一点和我们上一次介绍的 LinUCB 算法是一样的。</li></ol></blockquote></blockquote><p>算法流程如下图所示：<br><a href="https://postimg.cc/hJqHjj4Z" target="_blank" rel="noopener"><img src="https://i.postimg.cc/wBtHwyCz/COFIBA.png" alt="COFIBA.png"></a></p><p> 对比LinUCB 算法，COFIBA 的不同有两点：</p><ul><li>基于用户聚类挑选最佳的物品，即相似用户集体动态决策；</li><li>基于用户的反馈情况调整用户和物品的聚类结果。</li></ul><p><strong>整体算法过程如下，在针对某个用户 i，在每一次推荐时做以下事情：</strong></p><ol><li>首先计算用户 i 的 Bandit 参数 W，做法和 LinUCB 算法相同，但是这个参数并不直接参与到选择决策中，注意这和 LinUCB 不同，只是用来更新用户聚类。</li><li>遍历候选物品，每一个物品已经表示成一个向量 x 了。</li><li>每一个物品都对应一个物品聚类类簇，每一个物品类簇对应一个全量用户聚类结果，所以遍历到每一个物品时，就可以判断出当前用户在当前物品面前，自己属于哪个用户聚类类簇，然后把对应类簇中每个用户的 M 矩阵 (对应 LinUCB 里面的 A 矩阵)，b 向量（表示收益向量，对应 LinUCB 里面的 b 向量）加起来，从而针对这个类簇求解一个岭回归参数（类似<br>LinUCB 里面单独针对每个用户所做），同时计算其收益预测值和置信区间上边界。</li><li>每个待推荐的物品都得到一个预测值及置信区间上界，挑出那个上边界最大的物品作为推荐结果。</li><li>观察用户的真实反馈，然后更新用户自己的 M 矩阵和 b 向量，只更新每个用户，对应类簇里其他的不更新。</li></ol><p>以上是 COFIBA 算法的一次决策过程。在收到用户真实反馈之后，还有两个计算过程：</p><ol><li>更新 user 聚类；</li><li>更新 item 聚类。</li></ol><p>更新 user 和 item 的聚类的方法如下图所示：<br><a href="https://postimg.cc/Y4hGmpRQ" target="_blank" rel="noopener"><img src="https://i.postimg.cc/FKxj8zJC/COFIBA.jpg" alt="COFIBA.jpg"></a></p><blockquote><p>步骤详解：<br>(a)    示意图中有 6 个用户，8 个物品，初始化时，用户和物品的类簇个数都是 1。<br>(b)    在某一轮推荐时，推荐系统面对的用户是 4。推荐过程就是遍历 1～8 每个物品，然后在面对每个物品时，用户 4 在哪个类簇中，把对应类簇中的用户聚合起来为这个物品集体预测收益值置信上边界。这里假设最终物品 5 胜出，被推荐出去了。</p><blockquote><p>在时刻 t，物品一共有 3 个聚类类簇，需要更新的用户聚类是物品 5 对应的用户 4 所在类簇。<br>更新方式：看看该类簇里面除了用户 4 之外的用户，对物品 5 的预期收益是不是和用户 4 相近，如果是，则保持原来的连接边，否则删除原来的连接边。删除边之后相当于就重新构建了聚类结果。<br>这里假设新的聚类结果由原来用户 4 所在的类簇分裂成了两个类簇：4 和 5 成一类，6 单独自成一类。</p></blockquote><p>(c) 更新完用户类簇后，被推荐出去的物品 5，它对应的类簇也要更新。</p><blockquote><p>更新方式是：对于每一个和物品 5 还存在连接边的物品，假如叫做物品 j，都有一个对这个物品 j 有相近收益预估值的近邻用户集合，然后看看近邻用户集合是不是和刚刚更新后的用户 4 所在的类簇相同。<br>是的话，保留物品 5 和物品 j 之间的连接边，否则删除。这里示意图中是物品 3 和物品 5 之间的连接边被删除。<br>物品 3 变成了孤家寡人一个，不再和任何物品有链接，独立后就给他初始化了一个全新的用户聚类结果：所有用户是一个类簇。</p></blockquote></blockquote><p>简单来说就是这样：</p><ol><li>用协同过滤来少选可以参与决策的用户代表，用 LinUCB 算法来实际执行选择；</li><li>根据用户的反馈，调整基于用户和基于物品的聚类结果，即对物品和用户的群体代表做换届选举；</li><li>基于物品的聚类如果变化，又进一步改变了用户的聚类结果；</li><li>不断根据用户实时动态的反馈来调整用户决策参数，从而重新划分聚类结果矩阵。</li></ol><h3 id="再谈-EE-问题"><a href="#再谈-EE-问题" class="headerlink" title="再谈 EE 问题"></a><strong>再谈 EE 问题</strong></h3><p>探索和利用这一对矛盾一直客观存在，而 Bandit 算法是公认的一种比较好的解决 EE 问题的方案。<br>除了 Bandit 算法之外，还有一些其他的探索兴趣的办法，比如在推荐时，随机地去掉一些用户历史行为（特征）。<br>解决兴趣探索，势必要冒险，势必要面对用户的未知，而这显然就是可能会伤害当前用户价值的：明知道用户肯定喜欢 A，你还偏偏以某个小概率给推荐非 A。</p><p>实际上，很少有公司会采用这些理性的办法做探索，反而更愿意用一些盲目主观的方式。究其原因，可能是因为：</p><ol><li>互联网产品生命周期短，而探索又是为了提升长期利益的，所以没有动力做；</li><li>用户使用互联网产品时间越来越碎片化，探索的时间长，难以体现出探索的价值；</li><li>同质化互联网产品多，用户选择多，稍有不慎，用户用脚投票，分分钟弃你于不顾；</li><li>已经成规模的平台，红利杠杠的，其实是没有动力做探索的。</li></ol><p>基于这些，我们如果想在自己的推荐系统中引入探索机制，需要注意以下几点：</p><ol><li>用于探索兴趣的物品，要保证其本身质量，纵使用户不感兴趣，也不至于引起其反感，损失平台品牌价值；</li><li>探索兴趣的地方需要产品精心设计，让用户有耐心陪你玩儿；</li><li>深度思考，这样才不会做出脑残的产品，产品不会早早夭折，才有可能让探索机制有用武之地。</li></ol><p><strong>Bandit 算法是一种不太常用在推荐系统的算法，究其原因，是它能同时处理的物品数量不能太多。但是，在冷启动和处理 EE 问题时，Bandit 算法简单好用，值得一试。</strong><br><a href="https://postimg.cc/yDwg9Mb5" target="_blank" rel="noopener"><img src="https://i.postimg.cc/g00V9dqY/MBA.jpg" alt="MBA问题.jpg"></a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/column/intro/74&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考原作：推荐系统三十六式-刑无刀&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;17-【MAB问题】简单却有效的Bandit算法&quot;&gt;&lt;a href=&quot;#17-【MAB问题】简单却有效的Bandit算法&quot; class=&quot;headerlink&quot; title=&quot;17.【MAB问题】简单却有效的Bandit算法&quot;&gt;&lt;/a&gt;17.【MAB问题】简单却有效的Bandit算法&lt;/h2&gt;&lt;h3 id=&quot;推荐就是选择&quot;&gt;&lt;a href=&quot;#推荐就是选择&quot; class=&quot;headerlink&quot; title=&quot;推荐就是选择&quot;&gt;&lt;/a&gt;&lt;strong&gt;推荐就是选择&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;选择的困难在于不知道选择的后果，而且一旦错了就没有机会再来一次。在推荐系统中就对应了少了一次成功展示的机会。选择时不再聚焦到具体每个选项，而是去选择类别，这样压力是不是就小了很多？比如说，把推荐选择具体物品，上升到选择策略。如果后台算法中有三种策略：按照内容相似推荐，按照相似好友推荐，按照热门推荐。每次选择一种策略，确定了策略后，再选择策略中的物品，这样两个步骤。&lt;strong&gt;于是有了 Bandit 算法。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;MAB-问题&quot;&gt;&lt;a href=&quot;#MAB-问题&quot; class=&quot;headerlink&quot; title=&quot;MAB 问题&quot;&gt;&lt;/a&gt;&lt;strong&gt;MAB 问题&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;Bandit 算法来源于人民群众喜闻乐见的赌博学，它要解决的问题是这样的。&lt;/p&gt;
&lt;p&gt;一个赌徒，要去摇老虎机，走进赌场一看，一排老虎机，外表一模一样，但是每个老虎机吐钱的概率可不一样，他不知道每个老虎机吐钱的概率分布是什么，那么想最大化收益该怎么整？&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="推荐系统三十六式" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法" scheme="http://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="推荐" scheme="http://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统三十六式--学习笔记（14-16 模型融合）</title>
    <link href="http://www.xiemingzhao.com/2018/11/05/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F--%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%8814-16%20%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%EF%BC%89/"/>
    <id>http://www.xiemingzhao.com/2018/11/05/推荐系统三十六式--读书笔记（14-16 模型融合）/</id>
    <published>2018-11-04T16:00:00.000Z</published>
    <updated>2019-09-16T15:00:41.104Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://time.geekbang.org/column/intro/74" target="_blank" rel="noopener">参考原作：推荐系统三十六式-刑无刀</a></p><h2 id="14-【模型融合】经典模型融合办法：线性模型和树模型的组合拳"><a href="#14-【模型融合】经典模型融合办法：线性模型和树模型的组合拳" class="headerlink" title="14.【模型融合】经典模型融合办法：线性模型和树模型的组合拳"></a>14.【模型融合】经典模型融合办法：线性模型和树模型的组合拳</h2><p>推荐系统在技术实现上一般划分为三个阶段：挖掘、召回、排序。</p><ul><li>挖掘就是对用户和物品做非常深入的结构化分析，各个角度各个层面的特征都被呈现出来，并且建好索引，供召回阶段使用，大部分挖掘工作都是离线进行的。</li><li>召回，因为物品太多了，每次给一个用户计算推荐结果时，如果对全部物品挨个计算，那将是一场灾难，取而代之的是用一些手段从全量的物品中筛选出一部分比较靠谱的。</li><li>排序，针对筛选出的一部分靠谱的做一个统一的论资排辈，最后这个统一的排序就是下面的主题：融合。</li></ul><a id="more"></a><p><a href="https://postimg.cc/SjrRgMQx" target="_blank" rel="noopener"><img src="https://i.postimg.cc/DyVGyrtL/image.jpg" alt="模型融合.jpg"></a><br><strong>可以注重学习一下图中的SVD,FM以及ALS算法</strong>。</p><p>多种算法推出推荐结果后，需要模型融合的原因：</p><blockquote><ol><li>有的算法可能只给出结果，不给分数，比如用决策树产生一些推荐结果；</li><li>每种算法给出结果时如果有分数，分数的范围不一定一样，所以不能互相比较，大家各自家庭背景不一样；</li><li>即使强行把所有分数都归一化，仍然不能互相比较，因为产生的机制不同，有的可能普遍偏高，有的可能普遍偏低。</li></ol></blockquote><p>融合促使集成学习的诞生，下面的典型的模型融合方案是：逻辑回归和梯度提升决策树组合，又名“辑度组合”。</p><h3 id="“辑度组合”原理"><a href="#“辑度组合”原理" class="headerlink" title="“辑度组合”原理"></a><strong>“辑度组合”原理</strong></h3><p>在推荐系统的模型融合阶段，就要以产品目标为导向。例如，信息流推荐需要以CTR为导向。</p><h4 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a><strong>逻辑回归</strong></h4><p>逻辑回归常常被选来执行这个任务，它的输出值范围就是 0 到 1 之间，刚好满足点击率预估的输出，这是一个基础。因为逻辑回归是广义线性模型，相比于传统线性模型，在线性模型基础上增加了 sigmoid 函数。</p><blockquote><p>在对召回阶段不同算法给出的候选物品计算 CTR 预估时，需要两个东西：</p><ol><li>特征；</li><li>权重。</li></ol></blockquote><ul><li>第一个是特征，就是用量化、向量的方式把一个用户和一个物品的成对组合表示出来。这里说的量化方式包括两种：实数和布尔。假设为x。</li><li>第二个是权重，每个特征都有一个权重，权重就是特征的话事权。假设为w。</li></ul><p>sigmoid函数为：</p><script type="math/tex; mode=display">\sigma (w \times x)=\frac {1}{1+e^{-w \times x}}</script><p>函数的图像如下：<br><a href="https://postimg.cc/mtpDsWHx" target="_blank" rel="noopener"><img src="https://i.postimg.cc/W1TJ02p4/sigmoid.png" alt="sigmoid函数.png"></a><br>逻辑回归特征的取值都要求要在 0 到 1 之间。</p><blockquote><p>CTR预估，发现CTR预估一般都是用LR，而且特征都是离散的。<br>0、 离散特征的增加和减少都很容易，易于模型的快速迭代;<br>1、稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展；<br>2、离散化后的特征对异常数据有很强的鲁棒性;<br>3、逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合；<br>4、 离散化后可以进行特征交叉，加入特征 A 离散化为M个值，特征B离散为N个值，那么交叉之后会有M*N个变量，进一步引入非线性，提升表达能力；<br>5、特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。<br>6、特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。</p></blockquote><p><strong>特征组合的难点在于：组合数目非常庞大，而且并不是所有组合都有效，只有少数组合有效。</strong><br><strong>特征工程 + 线性模型，是模型融合、CTR 预估等居家旅行必备。</strong></p><ul><li>权重的学习主要看两个方面：损失函数的最小化，就是模型的偏差是否足够小；另一个就是模型的正则化，就是看模型的方差是否足够小；</li><li>除了要学习出偏差和方差都较小的模型，还需要能够给工程上留出很多余地，具体来说就是两点，一个是希望越多权重为 0 越好，权重为 0 称之为稀疏，可以减小很多计算复杂度，并且模型更简单，方差那部分会可控。</li><li>另一个是希望能够在线学习这些权重，用户源源不断贡献他们的行为，后台就会源源不断地更新权重，这样才能实现生命的大和谐。</li></ul><p><strong>随机梯度下降常被人诟病的是，它什么也表现不好，很难得到稀疏的模型，效果收敛得也很慢。</strong></p><p><strong>Google 在 2013 年 KDD 上发表了新的学习算法：FTRL，一种结合了 L1 正则和 L2 正则的在线优化算法，现在各家公司都采用了这个算法。</strong></p><p>&nbsp;</p><h4 id="梯度提升决策树-GBDT"><a href="#梯度提升决策树-GBDT" class="headerlink" title="梯度提升决策树 GBDT"></a><strong>梯度提升决策树 GBDT</strong></h4><p>树模型天然就可以肩负起特征组合的任务，从第一个问题开始，也就是树的根节点，到最后得到答案，也就是叶子节点，这一条路径下来就是若干个特征的组合。树模型最原始的是决策树，简称 DT，先驱们常常发现，把“多个表现”略好于“随机乱猜”的模型以某种方式集成在一起往往出奇效，所以就有树模型的集成模型。最常见的就是随机森林，简称 RF，和梯度提升决策树，简称 GBDT。把它分成两部分：一个是 GB，一个是 DT。GB 是得到集成模型的方案，沿着残差梯度下降的方向构建新的子模型，而 DT 就是指构建的子模型要用的决策树。</p><p><strong>GBDT 和其他提升算法的不同之处，比如和 Ada boost 算法不同之处，GBDT 用上一棵树去预测所有样本，得到每一个样本的残差，下一棵树不是去拟合样本的目标值，而是去拟合上一棵树的残差。在得到所有这些树后，真正使用时，是将它们的预测结果相加作为最终输出结果。</strong></p><p>此处有几个问题：</p><ol><li>既然是用来做回归的，如何把它用来做分类呢？可以把损失函数从上面的误差平方和换成适合分类的损失函数，例如对数损失函数。CTR预估的损失函数可以定义为：<script type="math/tex; mode=display">-ylog(p)-(1-y)log(1-p)</script></li><li>通常还需要考虑防止过拟合，也就是损失函数汇总需要增加正则项，正则化的方法一般是：限定总的树个数、树的深度、以及叶子节点的权重大小。</li><li>构建每一棵树时如果遇到实数值的特征，还需要将其分裂成若干区间，分裂指标有很多，可以参考 xgboost 中的计算分裂点收益，也可以参考决策树所用的信息增益。</li></ol><h4 id="二者结合"><a href="#二者结合" class="headerlink" title="二者结合"></a><strong>二者结合</strong></h4><p>将两者(LR+GBDT)结合在一起，用于做模型融合阶段的 CTR 预估。这是 Facebook 在其广告系统中使用的方法，其中 GBDT 的任务就是产生高阶特征组合。</p><p>具体的做法是：GBDT 产生了 N 棵树，一条样本来了后，在每一棵树上都会从根节点走到叶子节点，到了叶子节点后，就是 1 或者 0，或者不变。把每一棵树的输出看成是一个组合特征，取值为 0 或者 1，一共 N 棵树就会产生 N 个新的特征，这 N 个新的特征作为输入进入 LR 模型，输出最终的结果。如下图所示：<br><a href="https://postimg.cc/qgNwHyqj" target="_blank" rel="noopener"><img src="https://i.postimg.cc/pVZ68BHb/gbdt_lr.jpg" alt="gbdt+lr.jpg"></a><br><strong>虽然简单，但在实际应用中非常的有效。</strong></p><hr><h2 id="15-【模型融合】一网打尽协同过滤、矩阵分解和线性模型"><a href="#15-【模型融合】一网打尽协同过滤、矩阵分解和线性模型" class="headerlink" title="15.【模型融合】一网打尽协同过滤、矩阵分解和线性模型"></a>15.【模型融合】一网打尽协同过滤、矩阵分解和线性模型</h2><h3 id="从特征组合说起"><a href="#从特征组合说起" class="headerlink" title="从特征组合说起"></a><strong>从特征组合说起</strong></h3><p>对逻辑回归    朴素的特征组合就是二阶笛卡尔乘积，但是你有没有想过这样暴力组合的问题所在。</p><ol><li>两两组合导致特征维度灾难；</li><li>组合后的特征不见得都有效，事实上大部分可能无效；</li><li>组合后的特征样本非常稀疏，意思就是组合容易，但是并不能在样本中找到对应的组合出现，也就没办法在训练时更新参数。</li></ol><p>如果把包含了特征两两组合的逻辑回归线性部分写出来，就是：</p><script type="math/tex; mode=display">\hat y=w_0 + \sum_{i=1}^nw_ix_i + \sum_{i=1}^n \sum_{j=i+1}^n w_{ij}x_ix_j</script><p>问题就是两两组合后非常有可能没有样本能够学习到 $w_{ij}$，不但没有样本可以用来学习到参数，而且在应用时，如果遇到了这样的组合，也就只能放弃，因为没有学到权重。针对这个问题，就有了一个新的算法模型：<strong>因子分解机模型，也叫做 FM，即 Factorization Machine。</strong>因子分解机也常常用来做模型融合</p><h3 id="FM模型"><a href="#FM模型" class="headerlink" title="FM模型"></a><strong>FM模型</strong></h3><h4 id="1-原理"><a href="#1-原理" class="headerlink" title="1 原理"></a><strong>1 原理</strong></h4><p>作者在2010提出此模型，思想是对上面那个公式中的 $w_{ij}$ 做解耦，让每一个特征学习一个隐因子向量出来。任何两个特征不小心在实际使用时相遇了，需要组合，那么各自掏出自己随身携带的隐因子变量做一个向量点积，就是两者组合特征的权重了。</p><p>针对logistic回归的线性部分：</p><script type="math/tex; mode=display">\hat y = w_0 + \sum_{i=1}^n w_i x_i + \sum_{i=1}^n \sum_{j=i+1}^n <V_i,V_j>x_ix_j</script><p>不同之处就是原来有个$w_{ij}$，变成了这里的两个隐因子向量的点积。它其实认为两个特征之间，即使没有共同出现在一条样本中，也是有间接联系的。例如A和B有关系，B和C有关系，通过点积可以体现出A和C有关系。</p><h4 id="2-模型训练"><a href="#2-模型训练" class="headerlink" title="2    模型训练"></a><strong>2    模型训练</strong></h4><p>因子分解机的参数学习并无特别之处，看目标函数，在这里是把它当作融合模型来看的，用来做 CTR 预估，因此预测目标是一个二分类，因子分解机的输出还需要经过 sigmoid 函数变换：</p><script type="math/tex; mode=display">\sigma(\hat y)=\frac{1}{1+e^{-\hat y}}</script><p>因此，损失目标函数也就是常用的 logistic loss：</p><script type="math/tex; mode=display">loss(\theta) = -\frac{1}{m} \sum_{i=1}^m [y^{(i)}log(\sigma(\hat y)) + (1-y^{(i)})log(1-\sigma(\hat y))]</script><p>公式中 $\sigma(\hat y)$ 是因子分解机的预测输出后，经过 sigmoid 函数变换得到的预估 CTR，$y_(i)$ 是真实样本的类别标记，正样本是 1，负样本是 0，m 是样本总数。<br><strong>注意损失函数实际上还需要加上正则项。</strong></p><h4 id="3-预测阶段"><a href="#3-预测阶段" class="headerlink" title="3    预测阶段"></a><strong>3    预测阶段</strong></h4><p>因子分解机中二阶特征组合那一坨，在实际计算时，复杂度有点高，如果隐因子向量的维度是 k，特征维度是 n，那这个复杂度就是 $O(kn^2)$。<br>其中 n 方是特征要两两组合，k 是每次组合都要对 k 维向量计算点积。可以如下改造：</p><script type="math/tex; mode=display">\begin{align}&\sum_{i=1}^n\sum_{j=i+1}^n<v_i,v_j>x_ix_j\\=&\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n<v_i,v_j>x_ix_j-\frac{1}{2}\sum_{i=1}^n<v_i,v_i>x_ix_i\\=&\frac{1}{2}\sum_{f=1}^k((\sum_{i=1}^n\sum_{j=1}^n\sum_{f=1}^kv_{i,f}v_{j,f}x_ix_j-\sum_{i=1}^n\sum_{f=1}^kv_{i,f}v_{i,f}x_ix_j\\=&\frac{1}{2}\sum_{f=1}^k((\sum_{i=1}^nv_{i,f}x_i)(\sum_{j=1}^nv_{j,f}x_j)-\sum_{i=1}^nv_{i,f}^2x_i^2)\\=&\frac{1}{2}\sum_{f=1}^k((\sum_{i=1}^nv_{i,f}x_i)^2-\sum_{i=1}^nv_{i,f}^2x_i^2)\end{align}</script><blockquote><p>伪代码：<br>loop1 begin:循环k次，k就是隐因子向量的维度，其中，循环到第f次时做一下事情；<br>loop2 begin:循环n个特征，第i次循环时做这样的事情：<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; 1. 从第i个特征的隐因子向量中拿出第f维的值；<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; 2. 计算两个值：A是特征值和f维的值相乘，B是A的平方；<br>loop2 end<br>把n个A累加起来，并平方得到C，把n个B也累加起来，得到D，用C减D得到E；<br>loop1 end<br>把k次循环得到的k个E累加起来，除以2。</p></blockquote><p><strong>二阶组合部分的实际计算方法，现在这样做的复杂度只是 O(kn)</strong></p><h4 id="4-一网打尽其他模型"><a href="#4-一网打尽其他模型" class="headerlink" title="4. 一网打尽其他模型"></a><strong>4. 一网打尽其他模型</strong></h4><p>如下图示例的样本：<br><a href="https://postimg.cc/K3bHJ5hG" target="_blank" rel="noopener"><img src="https://i.postimg.cc/fySQWHH9/image.jpg" alt="FM示例样本.jpg"></a><br>这张图中每一条样本都记录了用户对电影的评分，最右边的 y 是评分，也就是预测目标；左边的特征有五种，用户 ID、当前评分的电影 ID、曾经评过的其他分、评分时间、上一次评分的电影。</p><p>因子分解机可以实现带有特征组合的逻辑回归。假设图中的样本特征只留下用户 ID 和电影 ID，因子分解机模型就变成：</p><script type="math/tex; mode=display">\hat y=w_0+w_u+w_i+<V_u,V_i></script><blockquote><p>因为用户 ID 和电影 ID，在一条样本中，各自都只有一个维度是 1，其他都是 0，所以在一阶部分就没有了求和符合，直接是 wu 和 wi，二阶部分特征乘积也只剩下了一个 1，其他都为 0 了。这不就是带有偏置信息的 SVD 吗？在 SVD 基础上把样本中的特征加上用户历史评过分的电影 ID，再求隐因子向量，就是 SVD++！再加上时间信息，就变成了 time-SVD。</p></blockquote><h4 id="5-FFM"><a href="#5-FFM" class="headerlink" title="5.FFM"></a><strong>5.FFM</strong></h4><p>改进的思路是：不但认为特征和特征之间潜藏着一些不可告人的关系，还认为特征和特征类型有着千丝万缕的关系。这个特征类型，就是某些特征实际上是来自数据的同一个字段，比如用户 ID，占据了很多维度，变成了很多特征，但他们都属于同一个类型，都叫“用户 ID”。这个特征类型就是字段，即 Field。这种改进叫做 Field-aware Factorization Machines，简称 FFM。</p><p>因子分解机是：</p><script type="math/tex; mode=display">\hat y = w_0 + \sum_{i=1}^n w_i x_i + \sum_{i=1}^n \sum_{j=i+1}^n <V_i,V_j>x_ix_j</script><p>FFM 改进的是二阶组合那部分，改进的模型认为每个特征有 f 个隐因子向量，这里的 f 就是特征一共来自多少个字段（Field），二阶组合部分改进后如下：</p><script type="math/tex; mode=display">\sum_{i=1}^n \sum_{j=i+1}^n <V_{i,fj},V_{j,fi}>x_ix_j</script><p>FFM 模型也常用来做 CTR 预估。<strong>在 FM 和 FFM 事件过程中，记得要对样本和特征都做归一化。</strong></p><hr><h2 id="16-【模型融合】深度和宽度兼具的融合模型-Wide-and-Deep"><a href="#16-【模型融合】深度和宽度兼具的融合模型-Wide-and-Deep" class="headerlink" title="16.【模型融合】深度和宽度兼具的融合模型 Wide and Deep"></a>16.【模型融合】深度和宽度兼具的融合模型 Wide and Deep</h2><h3 id="要深还是要宽"><a href="#要深还是要宽" class="headerlink" title="要深还是要宽"></a><strong>要深还是要宽</strong></h3><p>融合排序，最常见的就是 CTR 预估。这里的C可以是点击，收藏，分享以及购买等等。CTR 预估的常见做法就是广义线性模型，如 Logistic Regression，然后再采用特征海洋战术，就是把几乎所有的精力都放在搞特征上：挖掘新特征、挖掘特征组合、寻找新的特征离散方法等等。</p><blockquote><p>这种简单模型加特征工程的做法好处多多：</p><ol><li>线性模型简单，其训练和预测计算复杂度都相对低；</li><li>工程师的精力可以集中在发掘新的有效特征上，俗称特征工程；</li><li>工程师们可以并行化工作，各自挖掘特征；</li><li>线性模型的可解释性相对非线性模型要好。</li></ol></blockquote><p>深度学习在推荐领域的应用，其最大好处就是“洞悉本质般的精深”，优秀的泛化性能，可以给推荐很多惊喜。Google 在 2016 年就发表了他们在 Google Play 应用商店上实践检验过的 CTR 预估方法：Wide &amp; Deep 模型，让两者一起为用户们服务，这样就取得了良好效果。具体的可以参考这篇论文:<a href="https://arxiv.org/pdf/1606.07792.pdf" target="_blank" rel="noopener">Cheng H T, Koc L, Harmsen J, et al. Wide &amp; Deep Learning for Recommender Systems[J]. 2016:7-10.</a></p><h3 id="Wide-amp-Deep-模型"><a href="#Wide-amp-Deep-模型" class="headerlink" title="Wide &amp; Deep 模型"></a><strong>Wide &amp; Deep 模型</strong></h3><p>推荐系统有召回和排序两部构成，不过，推荐系统的检索过程并不一定有显式的检索语句，通常是拿着用户特征和场景特征去检索召回，其中用户特征也就是在前面的专栏中提到的用户画像。<br><a href="https://postimg.cc/bdWLQ8HL" target="_blank" rel="noopener"><img src="https://i.postimg.cc/tCCfG410/image.jpg" alt="推荐系统的召回和排序.jpg"></a><br>深宽模型就是专门用于融合排序的，分成两部分来看。一部分是线性模型，一部分是深度非线性模型。整个示意图如下：<br><a href="https://postimg.cc/0zxYfN6G" target="_blank" rel="noopener"><img src="https://i.postimg.cc/CxncwBS2/image.jpg" alt="深宽模型.jpg"></a><br>首先，线性模型部分，也就是“宽模型”，形式如下：</p><script type="math/tex; mode=display">y=W^TX+b</script><p>这是线性模型的标准形式，逻辑回归只是在这基础上用 sigmoid 函数变换了一下。深度模型其实就是一个前馈神经网络。深度模型对原始的高维稀疏类别型特征，先进行嵌入学习，转换为稠密、低维的实值型向量，转换后的向量维度通常在 10-100 这个范围。这里的嵌入学习，就是先随机初始化嵌入向量，再直接扔到整个前馈网络中，用目标函数来优化学习。</p><p>深度模型中增加隐藏层的含义就是提供了非线性转换。所谓深度学习，就是深度神经网络，就是有不止一层的隐藏层存在。层数越多，非线性越强，模型越复杂。还有两点需要说明：</p><ul><li>隐藏层的激活函数不一定是 sigmoid 函数，甚至往往不用 sigmoid 函数；</li><li>输出层的函数也不一定是 sigmoid 函数，这个根据预测目标而定，回归任务就是 i 直接输出求和部分，二分类是 sigmoid 函数，多分类则是 softmax。</li></ul><p>深模型中，每一个隐藏层激活方式表示如下:</p><script type="math/tex; mode=display">a^{l+1}=f(W^la^l+b^l)</script><p>其中 l 表示第 l 个隐藏层，f 是激活函数，通常选用 ReLU，也叫整流线性单元，为什么选用ReLU 而不是 sigmoid 函数，原因主要是 sigmoid 函数在误差反向传播时梯度容易饱和。<br><a href="https://postimg.cc/QBgxqXT7" target="_blank" rel="noopener"><img src="https://i.postimg.cc/Zq2B4nYw/image.jpg" alt="四种激活函数.jpg"></a></p><blockquote><ol><li>紫色是 sigmoid 函数，就是逻辑回归用的那个，输入值是任意范围，输出是 0 到 1 之间；</li><li>草绿色是反正切函数，和 sigmoid 函数样子很像，输入值是任意范围，输出是 -1 到 1 之间；</li><li>红色就是 ReLU 函数，当输入小于 0 时，输出为 0，当输入大于 0 时，输出等于输入；</li><li>蓝色是 softplus 函数，是一条渐近线，输入趋向于负无穷时，输出趋于 0，输入趋于正无穷时，输出趋向于等于输入。</li></ol></blockquote><p>最后，看看两者的融合，即深宽模型。深模型和宽模型，由逻辑回归作为最终输出单元，深模型最后一个隐藏层作为特征接入逻辑回归，宽模型的原始特征与之一起接入逻辑回归，然后训练参数。参数学习就是通常说的端到端，把深模型和宽模型以及最终融合的权重放在一个训练流程中，直接对目标函数负责，不存在分阶段训练。它与机器学习中的集成学习方法有所区别，集成学习的子模型是独立训练的，只在融合阶段才会学习权重，这里是整体。</p><script type="math/tex; mode=display">P(Y=1|X)=\sigma(W_{wide}^T[X,\Phi(X)]+W_{deep}^Ta^{(lf)}+b)</script><p>上述输出公式中，Y 是我们要预估的行为，二值变量，如购买，或点击，Google 的应用场景为“是否安装APP”。$\sigma$是 sigmoid 函数，$W_{wide}^T$ 宽模型的权重，$\Phi(X)$ 是宽模型的组合特征，$W_{deep}^T$ 应用在深模型输出上的权重，$a^{(lf)}$ 是深模型的最后一层输出，b 是线性模型的偏置。</p><h3 id="几点技巧"><a href="#几点技巧" class="headerlink" title="几点技巧"></a><strong>几点技巧</strong></h3><p>这个深宽模型已经在 TensorFlow 中有开源实现，具体落地时整个数据流如下图所示:<br><a href="https://postimg.cc/yWGBcJb5" target="_blank" rel="noopener"><img src="https://i.postimg.cc/28k6phFz/tensorflow.jpg" alt="深宽模型在tensorflow中的展示.jpg"></a><br><strong>整个流程分为三大块：数据生成，模型训练，模型应用。</strong></p><h4 id="1-数据生成"><a href="#1-数据生成" class="headerlink" title="1 数据生成"></a><strong>1 数据生成</strong></h4><p>几个要点：</p><ul><li>每一条曝光日志就生成一条样本，标签就是 1/0，安装了 App 就是 1，否则就是 0。</li><li>将字符串形式的特征映射为 ID，需要用一个阈值过滤掉那些出现样本较少的特征。</li><li>对连续值做归一化，归一化的方法是：对累积分布函数 P(X&lt;=x) 划分 nq 个分位，落入第 i 个分位的特征都归一化为下列所示：$\frac {i-1}{n_q-1}$</li></ul><h4 id="2-模型训练-1"><a href="#2-模型训练-1" class="headerlink" title="2    模型训练"></a><strong>2    模型训练</strong></h4><p><a href="https://postimg.cc/PLKnxNDS" target="_blank" rel="noopener"><img src="https://i.postimg.cc/KzhG0M8h/image.jpg" alt="深宽模型训练图.jpg"></a></p><blockquote><p>其要点，在深度模型侧：</p><ol><li>每个类别特征 embedding 成一个 32 维向量；</li><li>将所有类别特征的 embedding 变量连成一个 1200 维度左右的大向量；</li><li>1200 维度向量就送进三层以 ReLU 作为激活函数的隐藏层；</li><li>最终从 Logistic Regreesion 输出。</li></ol></blockquote><p>宽模型侧就是传统的做法：特征交叉组合。</p><h4 id="3-模型应用"><a href="#3-模型应用" class="headerlink" title="3 模型应用"></a><strong>3 模型应用</strong></h4><p>模型验证后，就发布到模型服务器。模型服务，每次网络请求输入的是来自召回模块的 App 候选列表以及用户特征，再对输入的每个 App 进行评分。评分就是用我们的“深宽模型”计算，再按照计算的 CTR 从高到低排序。为了让每次请求响应时间在 10ms 量级，每次并不是串行地对每个候选 App 计算，而是多线程并行，将候选 App 分成若干并行批量计算。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/column/intro/74&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考原作：推荐系统三十六式-刑无刀&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;14-【模型融合】经典模型融合办法：线性模型和树模型的组合拳&quot;&gt;&lt;a href=&quot;#14-【模型融合】经典模型融合办法：线性模型和树模型的组合拳&quot; class=&quot;headerlink&quot; title=&quot;14.【模型融合】经典模型融合办法：线性模型和树模型的组合拳&quot;&gt;&lt;/a&gt;14.【模型融合】经典模型融合办法：线性模型和树模型的组合拳&lt;/h2&gt;&lt;p&gt;推荐系统在技术实现上一般划分为三个阶段：挖掘、召回、排序。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;挖掘就是对用户和物品做非常深入的结构化分析，各个角度各个层面的特征都被呈现出来，并且建好索引，供召回阶段使用，大部分挖掘工作都是离线进行的。&lt;/li&gt;
&lt;li&gt;召回，因为物品太多了，每次给一个用户计算推荐结果时，如果对全部物品挨个计算，那将是一场灾难，取而代之的是用一些手段从全量的物品中筛选出一部分比较靠谱的。&lt;/li&gt;
&lt;li&gt;排序，针对筛选出的一部分靠谱的做一个统一的论资排辈，最后这个统一的排序就是下面的主题：融合。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="推荐系统三十六式" scheme="http://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/"/>
    
    
      <category term="机器学习" scheme="http://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法" scheme="http://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="推荐" scheme="http://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
</feed>
