<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小火箭的博客</title>
  
  <subtitle>愿世界和平！！！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.xiemingzhao.com/"/>
  <updated>2019-09-21T06:27:40.039Z</updated>
  <id>https://www.xiemingzhao.com/</id>
  
  <author>
    <name>小火箭</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Deep and Cross Network for Ad Click Predictions (论文解析)</title>
    <link href="https://www.xiemingzhao.com/posts/96501d7f.html"/>
    <id>https://www.xiemingzhao.com/posts/96501d7f.html</id>
    <published>2019-07-28T16:00:00.000Z</published>
    <updated>2019-09-21T06:27:40.039Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1708.05123.pdf" target="_blank" rel="noopener">原始论文：Deep &amp; Cross Network for Ad Click Predictions</a></p><h2 id="深度和交叉网络的广告点击预测"><a href="#深度和交叉网络的广告点击预测" class="headerlink" title="深度和交叉网络的广告点击预测"></a>深度和交叉网络的广告点击预测</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>特征工程已经成为许多预测模型成功的关键。然而，这个过程是不平常的并且经常会要手动特征工程或者穷举搜索。DNNs能够自动地学习特征交叉项；然而，它们都是隐式地生成所有交叉项，并且学习所有类型的交叉特征不一定有效。在本文中，我们提出深度和交叉网络(DCN)，它保持了深度模型的优势，并且又超越了这，它是一种在学习某种边界程度特征交叉项中更为有效的新奇网络。此外，DCN显示地在每一层应用特征交叉，不要求做人工程特征工程，同时也只是给DNN模型增加了一些可以忽略不计的复杂度。我们的实验结果已经证明它在CTR预测数据集和密集的分类数据集上，相对于其他高级模型在模型准确性和记忆方法上都具有优越性。</p><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a><strong>1 介绍</strong></h3><p>点击率（CTR）预测是一个大规模的问题，它对数十亿美元的在线广告业来说至关重要。在广告业中，广告商会想发布商付费以在发布商的网站上展示他们的广告。一个普遍的付费模式是平均点击成本（CPC）模型，即广告商仅在点击发生的时候才会付费。因此，出版商的收入很大程度上依赖于能够准确预测CTR。</p><a id="more"></a><p>识别出常用的预测特征且同时探索出那些看不见的或者稀少的交叉特征是做出好预测的关键。然而，网站级别的推荐系统的数据主要都是离散的和类别型的，这就导致了一个大的和稀疏的特征空间，而这对于特征探索来说是一个挑战。这就限制了大多数的大规模系统都是线性模型例如逻辑回归。</p><p>线性模型是简单的，可解释的并且容易扩展的；然而，它们受限于自己的表达能力。另一方面，交叉特征已经被证明能够有效地提高模型的表达力。不幸的是，它一般要求人工特征工程或者穷举来找到这些特征；再者，泛化出这些看不见的特征交叉项是很困难的。</p><p>在本文中，我们致力于通过引入一个新的神经网络结构来避免特征工程任务——一个<em>交叉网络</em>——它是以自动的方式显示地应用在特征交叉中。交叉网络由多层网络组成，其中特征的最高交叉维度完全由网络层的深度决定。每一层网络都以及已经存在的特征生成一个更高度的交叉项，同时又保留了前一层网络的交叉项。我们将交叉忘了和一个深度神经网络（DNN）进行联合训练。DNN能够捕获特征中的非常复杂的交叉项；然而，相比于我们的交叉忘了它需要同一数量级的参数，也无法形成显示的交叉特征，并且可能无法有效地学习某些特征交叉项。然而，交叉和深度部分的联合训练能够有效地捕获预测性的特征交叉项，并且在Criteo CTR数据集上提供了一个最先进的效果表现。</p><p><strong>1.1 相关工作</strong><br>由于数据集的规模和维度急剧性的增加，于是提出了很多的方法用来避免特定任务中的大规模特征工程，大部分都是基于嵌入技术和神经网络的。</p><p>因式分解机（FMs）将稀疏特征映射到低维的稠密向量上，并且从这些特征的内积中学习特征交叉项。场感知因式分解机（FFMs）让每个特征都可以学习到多个向量，其中每个响亮都是与一个场相关的。遗憾的是，FM和FFM浅显的结构限制了它们的模型表达力。有许多的工作都是为了将FM扩展到一个更高的级别，但是一个缺点就是产生了大量的参数从而大大增加了原本他们不期望产生的计算成本。深度神经网络（DNN）就可以学习到一些重要的高维的特征交叉项，这得益于它们的嵌入向量和非线性的激活函数。最近残差网络的成功使得训练一个非常深的网络有了可能。深度交叉扩展了残差网络，同时通过对所有输入类型的堆叠达到了自动特征学习的效果。</p><p>深度学习的非凡成功引出了它的表达力的理论分析。有研究表明，在给定足够多的的隐含单元或者隐含层的时候，DNN能够再某种平滑线的假设条件下取近似一个有任意准确性的函数。再者，实际上已经发现了DNN在有合适参数的时候就已经能够表现地很好了。一个关键的原因就是实际使用的大多数函数都不是任意选择的。</p><p>一个依然存在的问题就是DNN是否真的在那些实际中使用的表征函数中是最有效的一个。在Kaggle竞赛中，许多胜利者的解决方法中人工精心设计的特征都是低阶的、确切形式且有效地。另一方面，从DNN中学习到的特征都是隐含的且高度非线性的。这就表明了设计一个模型要能够学习到相比于普通的DNN更加有效且确切的有界阶特征交叉项。</p><p>wide-and-deep就是这种想法创建的模型。它将交叉特征作为线性模型的输入，然后将线性模型和DNN模型进行联合训练。然而，wide-and-deep是否成功很大程度上依赖于交叉特征的事前选择，一个指数级的问题就是是否存在还没发现的更有效的方法。</p><p><strong>1.2 主要贡献</strong><br>在本文中，我们提出了Deep &amp; Cross Network（DCN）模型，它能够在同时有稀疏输入和密集输入的时候进行网站规模的自动化特征学习。DCN能够有效地抓取有界阶的有用特征交叉项，学习高度非线性的交叉项，并且不要求人工特征工程或者穷举，同时又只有较低的计算成本。</p><p>本文主要的贡献包括：</p><ul><li>我们提出了一个将特征交叉应用在每一层的新交叉网络，它能够有效地学习到具有预测价值的有限阶交叉特征，并且不要求进行人工特征工程或者穷举。</li><li>交叉忘了是简单且有效的。通过设计，每一层多项式的最高阶都在增加并且由层数的深度决定。整个网络是由从低阶到高阶的交叉项以及所有不同的系数组成的。</li><li>交叉网络是能够有效记忆的，并且能够很简单地实现。</li><li>一个带有交叉网络的DNN，在参数个数少一个量级的情况下，它的对数损失依然比普通的DNN要低。</li></ul><h3 id="2-深度-amp-交叉网络（DCN）"><a href="#2-深度-amp-交叉网络（DCN）" class="headerlink" title="2 深度&amp;交叉网络（DCN）"></a><strong>2 深度&amp;交叉网络（DCN）</strong></h3><p>在这一部分，我们将会介绍深度&amp;交叉网络（DCN）模型的结构。DCN是开始于embedding和stacking层的，紧接着是一个交叉网络和一个深度网络并行。按顺序接着是一个最终的联合层用来合并两个网络的输出。完整的DCN模型如图1中所示。</p><p><img src="https://i.postimg.cc/RCJsj7cj/D-C-1.jpg" alt="D&amp;C-1.jpg"></p><p><strong>2.1 嵌入和堆叠层</strong><br>我们考虑包含稀疏和密集特征的输入数据。在网站级规模的推荐系统如CTR预估中，输入数据大部分都是类别型特征，例如“country=usa”。这样的特征经常会被进行one-hot编码，例如“[0,1,0]”；然而，这就经常导致产生过高维的特征空间来适用大型词典。</p><p>为了降低维度，我们使用了一个embedding过程来将这些二值特征转换成密集的实值向量（通常称为嵌入向量）：</p><script type="math/tex; mode=display">x_{embed,i}=W_{embed,i}x_i</script><p>其中$x_{embed,i}$是嵌入向量，$x_i$是第i个类别的二值输入，$W_{embed,i} \ \in \mathbb R^{n_e \times n_v}$是对应的嵌入矩阵，它可以和网络中其他的参数一起进行优化，$n_e,n_v$分别是嵌入层大小和词典的大小。</p><p>最后，我们将嵌入向量和标准化后的密集特征进行堆叠，形成一个最终的向量：</p><script type="math/tex; mode=display">x_0 = [x_{embed,1}^T,...,x_{embed,k}^T,x_{dense}^T]</script><p>然后再将这个向量喂入到网络中去。</p><p><strong>2.2 交叉网络</strong><br>我们创新交叉网络的关键思想就是以一个有效地方式来显示地应用特征交叉。交叉网络由交叉层组成，每一层都有如下的公式：</p><script type="math/tex; mode=display">x_{l+1} = x_0 x_l^T w_l + b_l x_l = f(x_l , w_l, b_L) + x_l</script><p>其中$x_l,x_{l+1} \ \in \ \mathbb R^d$都是列向量，分别表示第l层和第l+1层交叉网络的输出$w_l, b_l \ \in \ \mathbb R^d$是第l层网络的权重和偏置项参数。每一交叉层在特征交叉f之后都反加上它的输入部分，并且映射函数$f:\mathbb R^d \rightarrow \mathbb R^d$拟合$x_{l+1}-x_l$的残差。一个交叉层的可视化展示如图2所示。</p><p><img src="https://i.postimg.cc/8Cn4Ycsp/D-C-2.jpg" alt="D&amp;C-2.jpg"></p><p><strong>高阶特征交叉项</strong>。交叉网络特殊的结构造就了交叉特征的阶数随着网络层数增加而增加。第l层交叉网络的多项式最高阶数（相对于输入层来说）是l+1。事实上，交叉网络包含了所有的交叉项$x_1^{\alpha_1} x_2^{\alpha_2}…x_d^{\alpha_d}$，其中d取值从1到l+1。详细的分析在章节3。</p><p><strong>复杂度分析</strong>$L_c$表示交叉层的个数，d表示输入层的维度。然后，交叉网络中的参数个数就是：</p><script type="math/tex; mode=display">d \times L_c \times 2</script><p>交叉网络的时间和空间复杂度是关于输入层维度的线性增长。因此，交叉网络相比与其深度部分仅引入了一个微乎其微的复杂度部分，这使得DCN的整体复杂度与传统的DNN基本一致。这个有效性是得益于$x_0x_l^T$的秩为1的属性，这使得我们可以无需计算和存储整个矩阵的时候生成所有的交叉项。</p><p>交叉网络很少的参数限制了模型的能力。为了获得更高阶的非线性交叉项，我们并行引入了深度网络。</p><p><strong>2.3 深度网络</strong><br>深度网络部分是一个全连接的前向神经网络，其每一层的公式可以表示成如下：</p><script type="math/tex; mode=display">h_{l+1} = f(W_lh_l+b_l)</script><p>其中$h_l \in \mathbb R^{n_l},h_{l+1}\in \mathbb R^{n_{l+1}}$分别是第l和第l+1隐含层；$W_l \in \mathbb R^{n_{l+1} \times n_l}, b_l \in \mathbb R^{n_{l+1}}$是第l深度层的参数；$f(\cdot)$是ReLU激活函数。</p><p><strong>复杂度分析</strong>。为了简化，我们假设所有的深度网络层都是等维度的。$L_d$表示深度网络的层数，m表示深度网络层的大小。那么深度网络的参数个数就是：</p><script type="math/tex; mode=display">d \times m + m + (m^2 + m) \times (L_d -1)</script><p><strong>2.4 联合层</strong><br>联合层是合并了了两个网络的输出部分，然后将合并后的向量喂入到标准的逻辑层中。</p><p>下面就是二分类问题的公式：</p><script type="math/tex; mode=display">p = \sigma([x_{l_1}^L,h_{L_2}^T w_{logits})</script><p>其中$x_{L_1} \in \mathbb R^d, h_{L_2} \in \mathbb R^m$分别是交叉网络和深度网络的输出，$w_{logits} \in \mathbb R^{(d+m)}$是合并层的参数向量，并且$\sigma(x) = 1/(1+exp(-x))$。</p><p>损失函数是带有正则项的对数损失函数，</p><script type="math/tex; mode=display">loss = -\frac{1}{N} \sum_{i=1}^N y_i log(p_i) + (1-y_i) log(1-p_i) + \lambda \sum_l ||w_l||^2</script><p>其中$p_i$是根据前一个公式计算的概率值，$y_i$是真实的标签，N是输入层的总数，$\lambda$是L2正则项参数。</p><p>我们将两个网络联合一起进行训练，这使得每一个单独的网络在训练过程中可以感知到其他部分。</p><h3 id="3-交叉网络分析"><a href="#3-交叉网络分析" class="headerlink" title="3 交叉网络分析"></a><strong>3 交叉网络分析</strong></h3><p>在这一部分，我们分析DCN的交叉网络为了更好地理解它的有效性。我们我们提拱了三个角度：多项式近似，泛化成FM，和高效映射。为了简化，我们假设$b_i = 0$。</p><p><em>注意</em>。将$w_j$中的第i个元素表示成$w_j^{(i)}$。对于多索引$\alpha = [\alpha_1,…,\alpha_d] \in \mathbb N^d$和$x = [x_1,…,x_d] \in \mathbb R^d$，我们定义$|\alpha| = \sum_{i=1}^d \alpha_i$。</p><p><em>术语</em>。交叉项（单个的）的等级$x_1^{\alpha_1}x_2^{\alpha_2}…x_d^{\alpha_d}$定义为$|\alpha|$。多项式的阶数由交叉项的最高阶来确定。</p><p><strong>3.1 多项式近似</strong><br>根据魏尔斯特拉斯逼近定理，闭区间上的连续函数可以用多项式函数一致逼近。因此，我们将从多项式逼近的角度来分析交叉网络。特别地，交叉网络近似的同次多项式类，以一种有效地、更具表达力的并且泛化的方式拟合现实数据集。</p><p>我们仔细地研究了关于交叉网络的同次多项式类的近似。我们定义$P_n(x)$表示n次多项式：</p><script type="math/tex; mode=display">P_n(x) = \{\sum_{\alpha} w_{\alpha} x_1^{\alpha_1} x_2^{\alpha_2}...x_d^{\alpha_d}|0 \leq |\alpha| \leq n, \alpha \in \mathbb N^d\}</script><p>这个类中的每个多项式都有$O(d^n)$个系数。我们证明了，仅仅需要$O(d)$个参数，交叉网络就可以包含同次多项式汇总的所有交叉项，并且每一项的系数都互不相同。</p><p><em>定理3.1</em> 考虑一个l层交叉网络，其第i+1层定义为$x_{i+1} = x_0x_i^Tw_i + x_i$。网络的输入设为$x_0 = [x_1,x_2,…,x_d]^T$，输出为$g_l(x_0) = x_l^Tw_l$，其中参数为$w_i,b_i \in \mathbb R^d$。然后，这个多项式$g_l(x_0)$将会衍生出下面的多项式类：</p><script type="math/tex; mode=display">\{\sum_{\alpha} c_{\alpha}(w_0,...,w_L) x_1^{\alpha_1} x_2^{\alpha_2}...x_d^{\alpha_d}|0 \leq |\alpha| \leq l+1, \alpha \in \mathbb N^d \}</script><p>其中$c_{\alpha} = M_{\alpha} \sum_{i \in B_{\alpha}} \sum_{j \in P_{\alpha}} \prod_{k = 1}^{|\alpha|} w_{i_k}^{(j_k)}$，$M_{\alpha}$是常数，且与$w_i$无关，$i = [i_1,…,i_{|\alpha|}] 和 j = [j_1,…,i_{|\alpha|}]$是对应的索引，$B_{\alpha} = \{y \in \{0,1,…,l\}^{|\alpha|}||y_i &lt; y_j \cap y_{|\alpha|} = l\}$，并且$P_{\alpha}$是索引所有排列组成的集合$(1,…,1 \cdots d,…,d)$。</p><p>定理3.1的证明在附录中。我们给定一个示例，考虑$x_1x_2x_3$的系数$c_{\alpha}$，其中$\alpha = (1,1,1,0,…,0)$。对于某些常数，当$l = 2, c_{\alpha} = \sum_{i,j,k \in P_{\alpha}} w_0^{(i)} w_1^{(j)} w_2^{(k)}$；当$l = 3, c_{\alpha} = \sum_{i,j,k \in P_{\alpha}} w_0^{(i)} w_1^{(j)} w_3^{(k)} +  w_0^{(i)} w_2^{(j)} w_3^{(k)} +  w_1^{(i)} w_2^{(j)} w_3^{(k)}$。</p><p><strong>3.2 FM的推广</strong><br>交叉网络这种参数分享的思想类似于FM模型，进一步将其扩展到一个深度结构。</p><p>在FM模型中，特征$x_i$是伴随着一个参数向量$v_i$，并且交叉项$x_ix_j$的权重是由$(v_i,v_i)$计算得到的。在DCN汇总，$x_i$是和标量集$\{w_k^{(i)} \}_k^l$相关的，并且$x_i x_j$的权重是由集合$\{w_k^{(i)} \}_{k=0}^l$ 和 $\{w_k^{(j)} \}_{k=0}^l$中的各参数相乘得到的。模型每个特征学习的一些参数是独立于其他特征的，交叉项的权重是对应参数的某种联合。参数贡献不仅能够是的模型更加有效，而且也能使得模型能够产生看不见的特征交叉项并且使其对于噪声更加稳健。例如，使用带有稀疏特征的数据集的时候。如果两个二值类特征$x_i$和$x_j$很少或者从来不会在训练集中出现，即$x_i \neq 0 \wedge x_j \neq 0$，所以学习到的$x_i,x_j$的权重就不会在预测中输出有异议的信息。</p><p>FM模型是一个比较浅显的结构，其职能表征出2次的交叉项。相反，DCN能够构建所有的交叉项$x_1^{\alpha_1}x_2^{\alpha_2}…x_d^{\alpha_d}$其中$|\alpha|$由一些决定于网络层深度的常数来界定，如定理3.1所声明。因此，交叉网络是将参数共享这种思想从单层扩展到了多层和高次交叉项。注意到，不同于高阶的FM模型，一个交叉网络中的参数的个数仅仅随着输入层维度而线性增的长。</p><p><strong>3.3 高效地投影</strong><br>每一个交叉网络层都会将$x_0和x_l$映射出它们之间所有的成对交叉项，并且以一种有效的方式产生输入层的维度。</p><p>考虑$\tilde x \in \mathbb R^d$作为一个交叉层的输入。交叉层会隐式地构建出$d^2$个成对交叉项$x_i \tilde x_j$，并且会以一个高效记忆的方式将它们映射到d维空间。然而，直接的方式将会带来三倍的成本。</p><p>我们的交叉层提供了有效地解决方案来将成本降低到关于d维的线性函数。对于$x_p = x_0 \tilde x^T w$。这实际上等于：</p><script type="math/tex; mode=display">x_p^T = [x_1\tilde x_1 ... x_1 \tilde x_d \ ... \ x_d \tilde x_1 ... x_d \tilde x_d] \left[\begin{array}{cccc}w&0&...&0 \\ 0&w&...&0 \\ ...&...&...&... \\ 0&0&...&w \end{array} \right]</script><p>其中行向量包含所有的$d^2$个成对的交叉向量$x_i\tilde x_j$，投影矩阵有一个固定的对角结构，其中$w\in \mathbb R^d$是一个列向量。</p><h3 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4 实验结果"></a><strong>4 实验结果</strong></h3><p>在这一部分，我们字啊一些流行的预测数据及上评估DCN模型的表现。</p><p><strong>4.1 Criteo Display Ads 数据</strong><br>Criteo Display广告数据及是为了预测广告点击率的。它包含13个整数型特征和26个类别型特征，其中每个类别都有高基数集。对于这个数据集，<strong>在对数损失上有0.001的提升就可以被认为是实践显著的。</strong>当考虑一个大的用户基础的时候，预测准确率的一个小提升就潜在地带来公司收益的大增长。数据包含11GB的横跨7天的用户日志（大约4100万条记录）。我们使用前6天的数据进行预测，并且将第7天的数据随机地等量地分成测试集和验证集。</p><p><strong>4.2 实现细节</strong><br>DCN是在TensorFlow上实现的，我们简短地讨论一些DCN训练中的一些实现细节。</p><p><em>数据的处理和嵌入*</em>。实值特征是使用对数变化来进行标准化处理的。对于类别特征，我们将特征嵌入成具有维度$6 \times (category cardinality)^{1/4}$的密集向量。将所有的嵌入结果全部连接到一起形成一个1026维的向量。</p><p><em>优化</em>。我们使用Adam这种小批量随机优化的优化器。批量大小社会为512。批量标准化应用在了深度网络中，并且将梯度裁剪常数（gradient clip norm）设为100.</p><p><em>正则化</em>。我们使用early stopping机制，因为我们使用L2正在和dropout都不起作用。</p><p><em>超参数</em>。我们汇报了对隐含层个数，隐含层大小，初始学习率以及交叉层个数进行grid search的结果。隐含层的个数是从2到5，隐含层的大小是从32到1024.对于DCN，交叉层的个数是从1到6,。初始学习率从0.0001到0.001，每次增加0.0001。所有的实验都使用了early stopping，训练步数设为150000，过拟合发生的时候就会提前停止。</p><p><strong>4.3 模型比较</strong><br>我们将DCN和5种模型进行了比较：没有交叉网络的DCN模型（DNN），逻辑回归（LR），因式分解机（FMs），Wide&amp;Deep模型（W&amp;D）和深度交叉模型（DC）。</p><p><em>DNN</em>。嵌入层、输出层以及过程中的超参数都是用与DCN一致的。唯一和DCN不用的就是没有交叉层。</p><p><em>LR</em>。我们使用Siby1——一个大型的机器学习系统来区分逻辑回归。整数型特征会被离散到一个对数尺度。交叉特征将会由一个精致且复杂的特诊供选择工具来进行筛选。所有的单特征是都会被使用。</p><p><em>FM</em>。我们使用了带有特定细节的FM模型。</p><p><em>W&amp;D</em>。不同于DCN，它的宽部分作为输入原始稀疏特征，并且依赖于穷举和知识域来选取有预测价值的交叉特征。我们跳过了这一块的比较因为没有比较好的方法来选择交叉特征。</p><p><em>DC</em>。相比于DCN，DC没有显示地构造交叉特征。它主要依靠堆叠和残差项来隐式地创造交叉特征。我们使用和DCN相同的嵌入层，紧接着是另一个ReLu层来生成输入数据到残差单元系列中。残差单元的个数一半设为1到5之间，输入维度和交叉维度一般是从100到1026。</p><h3 id="4-4-模型表现"><a href="#4-4-模型表现" class="headerlink" title="4.4 模型表现"></a><strong>4.4 模型表现</strong></h3><p>在这一部分，我们首先会列出不同模型在对数损失下的最好的结果，然后我们会将DCN和DNN进行仔细对比，之后，我们再进一步分析引入交叉网络的效果。</p><p><strong>不同模型的表现</strong>。不同模型的对数损失的最好测试结果都列在了表1中。最优的超参数设置是DCN模型有2个深层且大小为1024和6个交叉层，DNN则有大小为1024的5层网络，DC模型有5个输入维度为424交叉维度为537的残差单元，LR模型有42个交叉特征。最终发现最深的交叉结构获得了最好的表现结果，这表明交叉网络中高次的特征交叉项是有用的。如我们所见，DCN要远好于所有其他的模型。特别地，它优于最先进的DNN模型，而且仅仅是相对于DNN用了40%的内存消费。</p><p><em>表1 不同模型的最优对数损失</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">Model</th><th style="text-align:center">DCN</th><th style="text-align:center">DC</th><th style="text-align:center">DNN</th><th style="text-align:center">FM</th><th style="text-align:center">LR</th></tr></thead><tbody><tr><td style="text-align:center">Logloss</td><td style="text-align:center"><strong>0.4419</strong></td><td style="text-align:center">0.4425</td><td style="text-align:center">0.4428</td><td style="text-align:center">0.4464</td><td style="text-align:center">0.4474</td></tr></tbody></table></div><p>对于每个模型的最优超参数设置，我们也汇报了10次不同对数损失测试结果的均值和标准差：<br>$DCN:0.4422 \pm 9 \times 10^{-5}$<br>$DNN:0.4430 \pm 3.7 \times 10^{-4}$<br>$DC:0.4430 \pm 4.3 \times 10^{-4}$。<br>如我们如看到的，DCN一致的大幅优于其他模型。</p><p><strong>DCN和DNN之间的比较</strong>。考虑到交叉网络仅仅额外引入了O(d)个参数，我们就将DCN和它——一个传统的DNN进行比较，并且将实验结果展现出来尽管存在较大的内存预算和损失公差。</p><p>接下来，我们将会汇报一定数量参数的损失数据，它们都是在所有的学习率和模型结构上得到的最好的验证集的损失。嵌入层的参数个数被省略了，因为在我们所有模型的计算中这一部分保持不变。</p><p>表2展示了要获得一个达到预期对数损失阈值的模型所需要的最少的参数个数。从表2中我们可以看出DCN的内存有效性要比单一的DNN模型高出近一个量级，这得益于交叉网络能够有效地学习到有限次的特征交叉项。</p><p><em>表2 要获得一个达到预期对数损失阈值的模型所需要的最少的参数个数</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">Logloss</th><th style="text-align:center">0.4430</th><th style="text-align:center">0.4460</th><th style="text-align:center">0.4470</th><th style="text-align:center">0.4480</th></tr></thead><tbody><tr><td style="text-align:center">DNN</td><td style="text-align:center">3.2E6</td><td style="text-align:center">1.5E5</td><td style="text-align:center">1.5E5</td><td style="text-align:center">7.8E4</td></tr><tr><td style="text-align:center">DCN</td><td style="text-align:center">7.9E5</td><td style="text-align:center">7.3E4</td><td style="text-align:center">3.7E4</td><td style="text-align:center">3.7E4</td></tr></tbody></table></div><p>表2对比了固定内存预算的神经网络的表现。我们可以看到，DCN一致的比DNN要好。在一个小参数体制里，交叉网络参数的个数和深度网络相比相差无几，但是可以看到明显提升这就表明交叉网络在学习有用特征交叉项中更为有效。在大参数体制中，DNN缩小了一些差距了。然而，DCN仍然要比DNN好一大截，这表明它可以有效地学习到一些很有用的甚至一个大DNN都学不到的特征交叉项。</p><p><em>表3 不同的内存预算下获得的最好的对数损失</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">参数</th><th style="text-align:center">5E4</th><th style="text-align:center">1E5</th><th style="text-align:center">4E5</th><th style="text-align:center">1.1E6</th><th style="text-align:center">2.5E6</th></tr></thead><tbody><tr><td style="text-align:center">DNN</td><td style="text-align:center">0.4480</td><td style="text-align:center">0.4471</td><td style="text-align:center">0.4439</td><td style="text-align:center">0.4433</td><td style="text-align:center">0.4431</td></tr><tr><td style="text-align:center">DCN</td><td style="text-align:center"><strong>0.4465</strong></td><td style="text-align:center"><strong>0.4453</strong></td><td style="text-align:center"><strong>0.4432</strong></td><td style="text-align:center"><strong>0.4426</strong></td><td style="text-align:center"><strong>0.4423</strong></td></tr></tbody></table></div><p>我们从更精确的细节来分析对于给定的DNN模型，引入交叉网络的DCN模型的影响。我们首先对比了拥有同样层数和层大小的DNN和DCN模型的最好表现，然后我们展示了验证集的对数损失是如何随着交叉网络层数的增加而变化的。表4展示了DCN和DNN模型在对数损失上面的区别。在同一实验设定下，从最优的对数损失上看DCN模型一致的优于有相同结构的单一DNN模型。这种对于所有超参数的改进是一致的，降低了参数在初始化和随机优化中的随机性影响。</p><p><em>表4 DCN和DNN在验证集上的对数损失之间的区别</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">Layers/Nodes</th><th style="text-align:center">32</th><th style="text-align:center">64</th><th style="text-align:center">128</th><th style="text-align:center">256</th><th style="text-align:center">512</th><th style="text-align:center">1024</th></tr></thead><tbody><tr><td style="text-align:center">2</td><td style="text-align:center">-0.28</td><td style="text-align:center">-0.10</td><td style="text-align:center">-0.16</td><td style="text-align:center">-0.06</td><td style="text-align:center">-0.05</td><td style="text-align:center">-0.08</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">-0.19</td><td style="text-align:center">-0.10</td><td style="text-align:center">-0.13</td><td style="text-align:center">-0.18</td><td style="text-align:center">-0.07</td><td style="text-align:center">-0.05</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">-0.12</td><td style="text-align:center">-0.10</td><td style="text-align:center">-0.06</td><td style="text-align:center">-0.09</td><td style="text-align:center">-0.09</td><td style="text-align:center">-0.21</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">-0.21</td><td style="text-align:center">-0.11</td><td style="text-align:center">-0.13</td><td style="text-align:center">-0.00</td><td style="text-align:center">-0.06</td><td style="text-align:center">-0.02</td></tr></tbody></table></div><p>图3展示了在随机选择的设置中我们增加交叉层数的改进效果。对于图3中的深度网络，当增加了一个交叉层的时候有一个明显的提升。随着更多的交叉层引入的时候，对于某些模型设置会使得对数损失继续下降，这表明引入交叉项对于预测是有效的；鉴于对于其他模型设置对数损失开始波动甚至出现微幅增加，这就表明高阶的特征交叉项的银如意是没有太大作用的</p><p><img src="https://i.postimg.cc/Hxcz1m7Q/D-C-3.jpg" alt="D&amp;C-3.jpg"></p><h3 id="4-5-非CTR数据集"><a href="#4-5-非CTR数据集" class="headerlink" title="4.5 非CTR数据集"></a><strong>4.5 非CTR数据集</strong></h3><p>我们证明了DCN模型在非CTR预测问题中也表现得很好。我们使用来自UCI提供的森林植被类型（forest covertype）（581012样本和54个特征）和 希格斯粒子（Higgs）（11M样本和28个特征）数据集。数据集随机得被分为训练集（90%）和测试集（10%）。对于超参数进行了梯度搜索。深度网络层数从1到10，大小从50到300.交叉网络层数从4到10。残差单元的个数从1到5，他们的出入维度和交叉维度从50到300。对于DCN，输入向量会被直接喂入交叉网络。</p><p>对于森林植被类型数据，DCN在最少的内存消费下获得了最好的测试集准确率0.9740。DNN和DC都是0.9737。DCN最优的超参数设置是8个交叉层且大小为54，6个深度网络层且大小为292，DNN则是有7层大小为292的深度网络层，DC则是有输入维度为271交叉维度为287的4个残差单元。</p><p>对于希格斯粒子数据集，DCN模型获得的最好对数损失测试结果是0.4494，而DNN是0.4506。DCN最优的超参数设定是4层大小为28的交叉网络和4层大小为209深度网络层，DNN则是10层大小为196的深度网络层。DCN在仅用了DNN一半的内存情况下依然表现得比其要好。</p><h3 id="5-结论和未来方向"><a href="#5-结论和未来方向" class="headerlink" title="5 结论和未来方向"></a><strong>5 结论和未来方向</strong></h3><p>区分有效的特征交叉项已经称为了许多预测模型成功的关键。遗憾的是，过程往往需要进行手工特征和穷举。DNN是比较受欢迎的自动特征学习模型；然而，学到的特征是隐式的并且高度非线性的，同时网络并不一定需要很大而且无法学习到某些特征。本文剔除的Deep &amp; Cross Network模型能够处理大的稀疏和密集特征集，并且可以联合传统的深度表示来显示地学习有限次的交叉特征。交叉特征的阶数在每一个交叉层都会增加一。我们的实验结果已经证明了它在系数数据集和密集数据集上都要优于其他最先进的算法，优势体现在模型的准确率和内存使用上。</p><p>我们会进一步地在其他模型中探索使用交叉层，使得深度交叉网络能够有效地训练，研究交叉网络在多项式近似中的有效性，并且在优化过程中可以更好地理解深度网络的交叉项。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1708.05123.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：Deep &amp;amp; Cross Network for Ad Click Predictions&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;深度和交叉网络的广告点击预测&quot;&gt;&lt;a href=&quot;#深度和交叉网络的广告点击预测&quot; class=&quot;headerlink&quot; title=&quot;深度和交叉网络的广告点击预测&quot;&gt;&lt;/a&gt;深度和交叉网络的广告点击预测&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;特征工程已经成为许多预测模型成功的关键。然而，这个过程是不平常的并且经常会要手动特征工程或者穷举搜索。DNNs能够自动地学习特征交叉项；然而，它们都是隐式地生成所有交叉项，并且学习所有类型的交叉特征不一定有效。在本文中，我们提出深度和交叉网络(DCN)，它保持了深度模型的优势，并且又超越了这，它是一种在学习某种边界程度特征交叉项中更为有效的新奇网络。此外，DCN显示地在每一层应用特征交叉，不要求做人工程特征工程，同时也只是给DNN模型增加了一些可以忽略不计的复杂度。我们的实验结果已经证明它在CTR预测数据集和密集的分类数据集上，相对于其他高级模型在模型准确性和记忆方法上都具有优越性。&lt;/p&gt;
&lt;h3 id=&quot;1-介绍&quot;&gt;&lt;a href=&quot;#1-介绍&quot; class=&quot;headerlink&quot; title=&quot;1 介绍&quot;&gt;&lt;/a&gt;&lt;strong&gt;1 介绍&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;点击率（CTR）预测是一个大规模的问题，它对数十亿美元的在线广告业来说至关重要。在广告业中，广告商会想发布商付费以在发布商的网站上展示他们的广告。一个普遍的付费模式是平均点击成本（CPC）模型，即广告商仅在点击发生的时候才会付费。因此，出版商的收入很大程度上依赖于能够准确预测CTR。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="推荐" scheme="https://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="排序" scheme="https://www.xiemingzhao.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="CTR预估" scheme="https://www.xiemingzhao.com/tags/CTR%E9%A2%84%E4%BC%B0/"/>
    
      <category term="神经网络" scheme="https://www.xiemingzhao.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Deep &amp; Cross" scheme="https://www.xiemingzhao.com/tags/Deep-Cross/"/>
    
  </entry>
  
  <entry>
    <title>ABTest显著性计算</title>
    <link href="https://www.xiemingzhao.com/posts/ABTestsignificancecomputing.html"/>
    <id>https://www.xiemingzhao.com/posts/ABTestsignificancecomputing.html</id>
    <published>2019-07-15T16:00:00.000Z</published>
    <updated>2019-10-13T14:16:48.963Z</updated>
    
    <content type="html"><![CDATA[<h2 id="显著性计算—uv-based"><a href="#显著性计算—uv-based" class="headerlink" title="显著性计算—uv based"></a>显著性计算—uv based</h2><p><strong>这里以实验目标为提升CR（Conversion Rate）为例说明</strong></p><h3 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h3><p><strong>显著性：</strong> 显著：新版和老版的CR有明显差异，不显著: 新版和老版没有明显差异。<br><strong>上升幅度：</strong>(新版CR-老版CR)/老版CR<br><strong>功效:</strong> 一般功效（即power值）达到0.8, 我们认为样本量即实验UV充足，可下结论。</p><a id="more"></a><blockquote><p>假设观察实验进行3天后，power=0.5&lt;0.8，并且结果不显著，这时需要累计更多样本。 如果当power已达到0.8时，仍未显著，一般我们认为新版和老版的CR的确无明显差异。</p></blockquote><p><strong>AA校验：</strong>验证主测频道分流是否随机；若两个Control版本之间的指标没有显著差异，则表明分流随机；反之，则需排查Control版本中是否存在异常数据；</p><blockquote><p>AA异常也可能由于两个control版本，其中之一包含一些异常用户（订单数极高），而另外一个版本没有异常用户。</p></blockquote><h4 id="如何结合显著性、power和样本量对实验结果下结论"><a href="#如何结合显著性、power和样本量对实验结果下结论" class="headerlink" title="如何结合显著性、power和样本量对实验结果下结论"></a>如何结合显著性、power和样本量对实验结果下结论</h4><p>power和样本量功能类似，达到样本量基本等同于power达到80%。power与样本量计算相比，power可以更多的利用实验本身的信息，而样本量主要使用频道的数据，计算时与实验设置分流等无关，仅实验剩余天数与实验相关。</p><p>所以这里我们结合power和显著性对实验的结果进行判断。这里以转化率CR为例。</p><blockquote><ol><li>如果power达到80%时，CR仍不显著， 说明此时实验新版与老版无显著差异，停止实验。</li><li>如果power未到达80%，CR不显著，说明此时样本量不充足，需继续实验，累计更多的用户。</li></ol></blockquote><p><strong>以上均基于AA检验正常为前提。</strong></p><p>如果AA异常，需查询原因，如果是AA中某一版本中有少数用户订单数极高，导致AA异常，剔除这种异常用户后重新计算AA  Test的结果， 如果不再显著，AA正常。</p><p>严谨一点，再检查AB 的检验中(一般B&lt;新版&gt; vs C+D<c、d都为老版>)是否存在同样问题，即某一版本出现一些异常用户(订单数极高的用户), 如果存在，剔除后重新计算显著性。</c、d都为老版></p><h3 id="算法说明"><a href="#算法说明" class="headerlink" title="算法说明"></a>算法说明</h3><h4 id="显著性计算"><a href="#显著性计算" class="headerlink" title="显著性计算"></a><strong>显著性计算</strong></h4><p><img src="https://i.postimg.cc/7PNNzHpt/2015-12-23-092348.png" alt="ABtestsample"></p><p>我们将指标提升的百分比定义为lift， <strong>%Lift=（Treatment/Control-1）*100%</strong></p><p>如上图的示例结果图所示，CR 的lift估计值为：-0.79%， 区间（-1.55%,-0%）.  CR lift 的真实值以95%的可能性落在区间（-1.55%,-0%）内。由于区间未包括0，所以CR显著, 并且从数值上看是显著下降。说明新版的CR明显低于老版的CR.</p><p>具体计算方案，以国内酒店频道的CR例,假设:</p><blockquote><ul><li>老版本每个用户的订单数X为：$x_1,x_2,…,x_{n_1}$，其中$n_1$为老版本的用户数，且有：$E[X] = u_1, Var(X) = \sigma_1^2$</li><li>新版本每个用户的订单数Y为：$y_1,y_2,…,y_{n_2}$，其中$n_2$为新版本的用户数，且有：$E[Y] = u_2, Var(Y) = \sigma_2^2$</li><li>尽管 X 和 Y 的分布不满足正态的假设，由大数定律得到，老版人均订单数$(CR_1)$和新版的人均订单数$(CR_2)$分别满足$CR_1 ~ N(u_1，\sigma_1^2 / n_1)$ 和 $CR_2 ~ N(u_2，\sigma_2^2 / n_2)$ 的正态分布。人均订单数即CR。</li></ul></blockquote><p>那么 lift 值的计算方案就如下：<br><strong>Step1： 估计$u_1, u_2, \sigma_1^2, \sigma_2^2$</strong><br>根据上述四个公式即可得到这四个统计量的估计值。</p><p><strong>Step2：抽样产生 lift 的n（一般取10000）个随机数，$lift^i, i = 1, …, n$</strong><br>由于$CR_1 ~ N(u_1，\sigma_1^2 / n_1), CR_2 ~ N(u_2，\sigma_2^2 / n_2)$，那么结合 Step1 中的参数估计，就可以，</p><blockquote><p>产生满足$N(\hat u_1, \hat \sigma_1^2 / n_1)$分布的n个随机数，$CR_1^i, i = 1,2,…,n$<br>产生满足$N(\hat u_2, \hat \sigma_2^2 / n_2)$分布的n个随机数，$CR_2^i, i = 1,2,…,n$</p></blockquote><p>然后我们就可以计算：$lift^i = (CR_2^i - CR_1^i) / CR_1^i, i = 1,2,…,n$</p><p><strong>Step3：计算 lift 的均值和区间（置信度90%）</strong><br>lift 均值： $\sum_{i=1}^n lift^i / n$；<br>区间上界： $lift^i$ 的95%分位数；<br>区间下界： $lift^i$ 的5%分位数。</p><h4 id="功效（power值）计算"><a href="#功效（power值）计算" class="headerlink" title="功效（power值）计算"></a><strong>功效（power值）计算</strong></h4><script type="math/tex; mode=display">Power = \Phi (-Z_{1 - \alpha / 2} + \frac {\Delta}{\sqrt {\sigma_1^2 / n_1 + \sigma_2^2 / n_2} })</script><p>其中：</p><blockquote><p>$\alpha$ 是 Type I Error， 一般为0.05 或者0.1<br>$\sigma_1^2$是老版订单数（或其他指标）的方差，$n_1$是老版的uv数<br>$\sigma_2^2$是新版订单数（或其他指标）的方差，$n_2$是新版的uv数<br>$\Delta = lift * u$中的 lift 是实际实验新版相对老板提升的百分比，一般取值为0.02或者0.04，这里设此目标值是为了固定，使用实际的会出现波动太乱的情况<br>u 是老版的 CR （或者其他检验指标）。</p></blockquote><p>示例：一下以某一次酒店排序实验为例，其 type I error = 0.05, lift = 0.02, 计算 CR 对应的 power。<br>$n_1$ = 老版用户数 = 22917； $n_2$ = 新版用户数 = 34389<br>$\hat u$ = 老版 CR 估计值 = 0.37474<br>$\hat \sigma_1^2$ = 老版订单数方差估计值 = 0.7188733<br>$\hat \sigma_2^2$ = 新版订单数方差估计值 = 0.721059</p><script type="math/tex; mode=display">Power = \Phi (-Z_{1 - \alpha / 2} + \frac {\Delta}{\sqrt {\sigma_1^2 / n_1 + \sigma_2^2 / n_2} }) \\ =  \Phi (-1.959964 + \frac {0.02 \times 0.37474}{\sqrt {0.7188733/22917 + 0.721059/34389} }) \\ = \Phi (-0.923327) = 17.79 \%</script><p>附属代码：<br><strong>AbSampleSize.hql</strong><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.auto.convert.join=<span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join.noconditionaltask.size =<span class="number">2048</span>;</span><br><span class="line"><span class="keyword">set</span> hive.exec.parallel=<span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSampleSize <span class="keyword">PARTITION</span>(d=<span class="string">'$&#123;operate_date&#125;'</span>,clienttype=<span class="string">'$&#123;client_type&#125;'</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  exp.experiment,</span><br><span class="line">        exp.channelid,</span><br><span class="line">        cumstart,</span><br><span class="line">        cumend,</span><br><span class="line">        abversion,</span><br><span class="line"></span><br><span class="line">        channel.SmallestSize*(splitPct/<span class="number">100</span>) <span class="keyword">as</span> SmallestSize,</span><br><span class="line">        exp.uv <span class="keyword">as</span> cumulativeUv,</span><br><span class="line">        <span class="keyword">datediff</span>(<span class="keyword">if</span>(<span class="keyword">datediff</span>(<span class="string">'$&#123;operate_date&#125;'</span>,exp.cumend)&lt;<span class="number">0</span>,<span class="string">'$&#123;operate_date&#125;'</span>,exp.cumend),exp.cumstart)+<span class="number">1</span> <span class="keyword">as</span> <span class="keyword">days</span>,</span><br><span class="line">        <span class="comment">--(channel.SmallestSize/exp.uv*(splitPct/100)-1)*(days)</span></span><br><span class="line">        (channel.SmallestSize/exp.uv*(splitPct/<span class="number">100</span>)<span class="number">-1</span>)*(<span class="keyword">datediff</span>(<span class="keyword">if</span>(<span class="keyword">datediff</span>(<span class="string">'$&#123;operate_date&#125;'</span>,exp.cumend)&lt;<span class="number">0</span>,<span class="string">'$&#123;operate_date&#125;'</span>,exp.cumend),exp.cumstart)+<span class="number">1</span>) <span class="keyword">as</span> remainingDays</span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> report_abtestdb.AbChannelDailyAbsolute channel</span><br><span class="line"><span class="keyword">JOIN</span> <span class="string">`report_abtestdb`</span>.<span class="string">`AbUserCumulativeAbsolute`</span> <span class="keyword">exp</span></span><br><span class="line"><span class="keyword">ON</span> channel.channelid=exp.channelid</span><br><span class="line"><span class="keyword">AND</span> channel.d=<span class="string">'$&#123;operate_date&#125;'</span></span><br><span class="line"><span class="keyword">AND</span> channel.clienttype=<span class="string">'$&#123;client_type&#125;'</span></span><br><span class="line"><span class="keyword">AND</span> exp.d=<span class="string">'$&#123;operate_date&#125;'</span></span><br><span class="line"><span class="keyword">AND</span> exp.clienttype=<span class="string">'$&#123;client_type&#125;'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">JOIN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> experiment,</span><br><span class="line">                    <span class="keyword">version</span>,</span><br><span class="line">                    splitPct</span><br><span class="line">    <span class="keyword">FROM</span> dim_abtestdb.DimAbtestConfig</span><br><span class="line">    <span class="keyword">WHERE</span> d=<span class="string">'$&#123;operate_date&#125;'</span></span><br><span class="line">    <span class="keyword">AND</span> defaultversion=<span class="literal">FALSE</span> </span><br><span class="line">    <span class="keyword">AND</span> <span class="keyword">lower</span>(versionproperty)=<span class="string">'treatment'</span></span><br><span class="line">    <span class="keyword">AND</span> splitPct&gt;<span class="number">0</span></span><br><span class="line">) config</span><br><span class="line"><span class="keyword">ON</span> exp.experiment=config.experiment</span><br><span class="line"><span class="keyword">AND</span> exp.abversion=config.version;</span><br></pre></td></tr></table></figure></p><p><strong>AbSignificance.hql</strong><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.auto.convert.join=<span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join.noconditionaltask.size =<span class="number">2048</span>;</span><br><span class="line"><span class="keyword">set</span> hive.exec.parallel=<span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">add jar abtest_udf-1.0.jar;</span><br><span class="line">add jar commons-math3-3.5.jar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TEMPORARY</span> <span class="keyword">FUNCTION</span> lift_quantile <span class="keyword">AS</span> <span class="string">'com.ctrip.basebiz.abtest3.hive.function.UDFLiftQuantile'</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TEMPORARY</span> <span class="keyword">FUNCTION</span> pnorm <span class="keyword">AS</span> <span class="string">'com.ctrip.basebiz.abtest3.hive.function.statistics.UDFCumulativeProbabilityNormalDistribution'</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TEMPORARY</span> <span class="keyword">FUNCTION</span> makeJson <span class="keyword">AS</span> <span class="string">'com.ctrip.basebiz.abtest3.hive.function.UDFMakeJSONObj'</span>;</span><br><span class="line"></span><br><span class="line">FROM </span><br><span class="line"><span class="comment">-- For Confidence Interval</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">SELECT</span>  treatment.experiment,</span><br><span class="line">            treatment.channelid,</span><br><span class="line">            treatment.abversion,</span><br><span class="line">            treatment.cumstart,</span><br><span class="line">            treatment.cumend,</span><br><span class="line"></span><br><span class="line">            (treatment.mean_pv-control.mean_pv)/control.mean_pv <span class="keyword">as</span> lift_pv,</span><br><span class="line">            lift_quantile(treatment.mean_pv,treatment.std_pv,control.mean_pv,control.std_pv,<span class="number">0.9</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_pv,</span><br><span class="line">            pnorm(<span class="number">-1.644854</span>+<span class="number">0.02</span>*control.mean_pv/<span class="keyword">sqrt</span>(<span class="keyword">power</span>(treatment.stddev_pv,<span class="number">2</span>)/treatment.uv+<span class="keyword">power</span>(control.stddev_pv,<span class="number">2</span>)/control.uv)) <span class="keyword">as</span> power_pv,</span><br><span class="line"></span><br><span class="line">            (treatment.mean_orders-control.mean_orders)/control.mean_orders <span class="keyword">as</span> lift_orders,</span><br><span class="line">            lift_quantile(treatment.mean_orders,treatment.std_orders,control.mean_orders,control.std_orders,<span class="number">0.9</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_orders,</span><br><span class="line">            pnorm(<span class="number">-1.644854</span>+<span class="number">0.02</span>*control.mean_orders/<span class="keyword">sqrt</span>(<span class="keyword">power</span>(treatment.stddev_orders,<span class="number">2</span>)/treatment.uv+<span class="keyword">power</span>(control.stddev_orders,<span class="number">2</span>)/control.uv)) <span class="keyword">as</span> power_orders,</span><br><span class="line"></span><br><span class="line">            (treatment.mean_quantity-control.mean_quantity)/control.mean_quantity <span class="keyword">as</span> lift_quantity,</span><br><span class="line">            lift_quantile(treatment.mean_orders,treatment.std_orders,control.mean_orders,control.std_orders,<span class="number">0.9</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_quantity,</span><br><span class="line">            pnorm(<span class="number">-1.644854</span>+<span class="number">0.02</span>*control.mean_quantity/<span class="keyword">sqrt</span>(<span class="keyword">power</span>(treatment.stddev_quantity,<span class="number">2</span>)/treatment.uv+<span class="keyword">power</span>(control.stddev_quantity,<span class="number">2</span>)/control.uv)) <span class="keyword">as</span> power_quantity,</span><br><span class="line"></span><br><span class="line">            (treatment.dynamicMap[<span class="string">'mean_amount'</span>]-control.dynamicMap[<span class="string">'mean_amount'</span>])/control.dynamicMap[<span class="string">'mean_amount'</span>] <span class="keyword">as</span> lift_amount,</span><br><span class="line">            lift_quantile(treatment.dynamicMap[<span class="string">'mean_amount'</span>],treatment.dynamicMap[<span class="string">'std_amount'</span>],control.dynamicMap[<span class="string">'mean_amount'</span>],control.dynamicMap[<span class="string">'std_amount'</span>],<span class="number">0.9</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_amount,</span><br><span class="line">            pnorm(<span class="number">-1.644854</span>+<span class="number">0.02</span>*control.dynamicMap[<span class="string">'mean_amount'</span>]/<span class="keyword">sqrt</span>(<span class="keyword">power</span>(treatment.dynamicMap[<span class="string">'stddev_amount'</span>],<span class="number">2</span>)/treatment.uv+<span class="keyword">power</span>(control.dynamicMap[<span class="string">'stddev_amount'</span>],<span class="number">2</span>)/control.uv)) <span class="keyword">as</span> power_amount,</span><br><span class="line"></span><br><span class="line">            (treatment.dynamicMap[<span class="string">'mean_cost'</span>]-control.dynamicMap[<span class="string">'mean_cost'</span>])/control.dynamicMap[<span class="string">'mean_cost'</span>] <span class="keyword">as</span> lift_cost,</span><br><span class="line">            lift_quantile(treatment.dynamicMap[<span class="string">'mean_cost'</span>],treatment.dynamicMap[<span class="string">'std_cost'</span>],control.dynamicMap[<span class="string">'mean_cost'</span>],control.dynamicMap[<span class="string">'std_cost'</span>],<span class="number">0.9</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_cost,</span><br><span class="line">            pnorm(<span class="number">-1.644854</span>+<span class="number">0.02</span>*control.dynamicMap[<span class="string">'mean_cost'</span>]/<span class="keyword">sqrt</span>(<span class="keyword">power</span>(treatment.dynamicMap[<span class="string">'stddev_cost'</span>],<span class="number">2</span>)/treatment.uv+<span class="keyword">power</span>(control.dynamicMap[<span class="string">'stddev_cost'</span>],<span class="number">2</span>)/control.uv)) <span class="keyword">as</span> power_cost,</span><br><span class="line"></span><br><span class="line">            (treatment.dynamicMap[<span class="string">'mean_gross_profit'</span>]-control.dynamicMap[<span class="string">'mean_gross_profit'</span>])/control.dynamicMap[<span class="string">'mean_gross_profit'</span>] <span class="keyword">as</span> lift_gross_profit,</span><br><span class="line">            lift_quantile(treatment.dynamicMap[<span class="string">'mean_gross_profit'</span>],treatment.dynamicMap[<span class="string">'std_gross_profit'</span>],control.dynamicMap[<span class="string">'mean_gross_profit'</span>],control.dynamicMap[<span class="string">'std_gross_profit'</span>],<span class="number">0.9</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_gross_profit,</span><br><span class="line">            pnorm(<span class="number">-1.644854</span>+<span class="number">0.02</span>*control.dynamicMap[<span class="string">'mean_gross_profit'</span>]/<span class="keyword">sqrt</span>(<span class="keyword">power</span>(treatment.dynamicMap[<span class="string">'stddev_gross_profit'</span>],<span class="number">2</span>)/treatment.uv+<span class="keyword">power</span>(control.dynamicMap[<span class="string">'stddev_gross_profit'</span>],<span class="number">2</span>)/control.uv)) <span class="keyword">as</span> power_gross_profit</span><br><span class="line"></span><br><span class="line">    <span class="keyword">FROM</span> <span class="string">`report_abtestdb`</span>.<span class="string">`AbUserCumulativeAbsolute`</span> treatment</span><br><span class="line">    <span class="keyword">JOIN</span> <span class="string">`report_abtestdb`</span>.<span class="string">`AbUserCumulativeAbsolute`</span> control</span><br><span class="line">     <span class="keyword">ON</span> treatment.experiment=control.experiment</span><br><span class="line">    <span class="keyword">AND</span> treatment.channelid=control.channelid</span><br><span class="line">    <span class="keyword">AND</span> <span class="keyword">lower</span>(treatment.versionproperty)=<span class="string">'treatment'</span></span><br><span class="line">    <span class="keyword">AND</span> control.abversion=<span class="string">'control'</span></span><br><span class="line">    <span class="keyword">AND</span> treatment.DefaultVersion=<span class="literal">FALSE</span> </span><br><span class="line">    <span class="keyword">AND</span> control.DefaultVersion=<span class="literal">FALSE</span> </span><br><span class="line">    <span class="keyword">AND</span> treatment.clienttype=<span class="string">'$&#123;client_type&#125;'</span></span><br><span class="line">    <span class="keyword">AND</span> control.clienttype=<span class="string">'$&#123;client_type&#125;'</span></span><br><span class="line">    <span class="keyword">WHERE</span> treatment.d=<span class="string">'$&#123;operate_date&#125;'</span></span><br><span class="line">    <span class="keyword">AND</span> control.d=<span class="string">'$&#123;operate_date&#125;'</span></span><br><span class="line">) ciResult</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> </span><br><span class="line"><span class="comment">-- For AA Test</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">SELECT</span>  experiment,</span><br><span class="line">            channelid,</span><br><span class="line">            (mean_pv1-mean_pv2)/mean_pv2 <span class="keyword">as</span> lift_pv,</span><br><span class="line">            lift_quantile(mean_pv1,std_pv1,mean_pv2,std_pv2,<span class="number">0.95</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_pv,</span><br><span class="line"></span><br><span class="line">            (mean_orders1-mean_orders2)/mean_orders2 <span class="keyword">as</span> lift_orders,</span><br><span class="line">            lift_quantile(mean_orders1,std_orders1,mean_orders2,std_orders2,<span class="number">0.95</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_orders,</span><br><span class="line"></span><br><span class="line">            (mean_quantity1-mean_quantity2)/mean_quantity2 <span class="keyword">as</span> lift_quantity,</span><br><span class="line">            lift_quantile(mean_quantity1,std_quantity1,mean_quantity2,std_quantity2,<span class="number">0.95</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_quantity,</span><br><span class="line"></span><br><span class="line">            (mean_amount1-mean_amount2)/mean_amount2 <span class="keyword">as</span> lift_amount,</span><br><span class="line">            lift_quantile(mean_amount1,std_amount1,mean_amount2,std_amount2,<span class="number">0.95</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_amount,</span><br><span class="line"></span><br><span class="line">            (mean_cost1-mean_cost2)/mean_cost2 <span class="keyword">as</span> lift_cost,</span><br><span class="line">            lift_quantile(mean_cost1,std_cost1,mean_cost2,std_cost2,<span class="number">0.95</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_cost,</span><br><span class="line"></span><br><span class="line">            (mean_gross_profit1-mean_gross_profit2)/mean_gross_profit2 <span class="keyword">as</span> lift_gross_profit,</span><br><span class="line">            lift_quantile(mean_gross_profit1,std_gross_profit1,mean_gross_profit2,std_gross_profit2,<span class="number">0.95</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_gross_profit</span><br><span class="line">    <span class="keyword">FROM</span> (</span><br><span class="line">        <span class="keyword">SELECT</span>  experiment,</span><br><span class="line">                channelid,</span><br><span class="line">                abversion <span class="keyword">as</span> i_version,</span><br><span class="line">                <span class="keyword">FIRST_VALUE</span>(abversion)      <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> abversion1,</span><br><span class="line">                <span class="keyword">LAST_VALUE</span>(abversion)       <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> abversion2,</span><br><span class="line"></span><br><span class="line">                <span class="keyword">FIRST_VALUE</span>(mean_pv)        <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_pv1,</span><br><span class="line">                <span class="keyword">LAST_VALUE</span>(mean_pv)         <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_pv2,</span><br><span class="line">                <span class="keyword">FIRST_VALUE</span>(std_pv)         <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_pv1,</span><br><span class="line">                <span class="keyword">LAST_VALUE</span>(std_pv)          <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_pv2, </span><br><span class="line"></span><br><span class="line">                <span class="keyword">FIRST_VALUE</span>(mean_orders)    <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_orders1,</span><br><span class="line">                <span class="keyword">LAST_VALUE</span>(mean_orders)     <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_orders2, </span><br><span class="line">                <span class="keyword">FIRST_VALUE</span>(std_orders)     <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_orders1,</span><br><span class="line">                <span class="keyword">LAST_VALUE</span>(std_orders)      <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_orders2, </span><br><span class="line"></span><br><span class="line">                <span class="keyword">FIRST_VALUE</span>(mean_quantity)  <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_quantity1,</span><br><span class="line">                <span class="keyword">LAST_VALUE</span>(mean_quantity)   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_quantity2, </span><br><span class="line">                <span class="keyword">FIRST_VALUE</span>(std_quantity)   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_quantity1,</span><br><span class="line">                <span class="keyword">LAST_VALUE</span>(std_quantity)    <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_quantity2,</span><br><span class="line"></span><br><span class="line">                <span class="keyword">FIRST_VALUE</span>(dynamicMap[<span class="string">'mean_amount'</span>])  <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_amount1,</span><br><span class="line">                <span class="keyword">LAST_VALUE</span>(dynamicMap[<span class="string">'mean_amount'</span>])   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_amount2, </span><br><span class="line">                <span class="keyword">FIRST_VALUE</span>(dynamicMap[<span class="string">'std_amount'</span>])   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_amount1,</span><br><span class="line">                <span class="keyword">LAST_VALUE</span>(dynamicMap[<span class="string">'std_amount'</span>])    <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_amount2,</span><br><span class="line"></span><br><span class="line">                <span class="keyword">FIRST_VALUE</span>(dynamicMap[<span class="string">'mean_cost'</span>])  <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_cost1,</span><br><span class="line">                <span class="keyword">LAST_VALUE</span>(dynamicMap[<span class="string">'mean_cost'</span>])   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_cost2, </span><br><span class="line">                <span class="keyword">FIRST_VALUE</span>(dynamicMap[<span class="string">'std_cost'</span>])   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_cost1,</span><br><span class="line">                <span class="keyword">LAST_VALUE</span>(dynamicMap[<span class="string">'std_cost'</span>])    <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_cost2,</span><br><span class="line"></span><br><span class="line">                <span class="keyword">FIRST_VALUE</span>(dynamicMap[<span class="string">'mean_gross_profit'</span>])  <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_gross_profit1,</span><br><span class="line">                <span class="keyword">LAST_VALUE</span>(dynamicMap[<span class="string">'mean_gross_profit'</span>])   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_gross_profit2, </span><br><span class="line">                <span class="keyword">FIRST_VALUE</span>(dynamicMap[<span class="string">'std_gross_profit'</span>])   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_gross_profit1,</span><br><span class="line">                <span class="keyword">LAST_VALUE</span>(dynamicMap[<span class="string">'std_gross_profit'</span>])    <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_gross_profit2</span><br><span class="line">        <span class="keyword">FROM</span> <span class="string">`report_abtestdb`</span>.<span class="string">`AbUserCumulativeAbsolute`</span></span><br><span class="line">        <span class="keyword">WHERE</span> d=<span class="string">'$&#123;operate_date&#125;'</span></span><br><span class="line">        <span class="keyword">AND</span> clienttype=<span class="string">'$&#123;client_type&#125;'</span></span><br><span class="line">        <span class="keyword">AND</span> <span class="keyword">lower</span>(versionproperty)=<span class="string">'control'</span></span><br><span class="line">        <span class="keyword">AND</span> abversion&lt;&gt;<span class="string">'control'</span></span><br><span class="line">        <span class="keyword">AND</span> DefaultVersion=<span class="literal">FALSE</span></span><br><span class="line">    ) control</span><br><span class="line">    <span class="keyword">WHERE</span> i_version=abversion1</span><br><span class="line">    <span class="keyword">AND</span> abversion1&lt;&gt;abversion2</span><br><span class="line">) aaResult</span><br><span class="line"><span class="keyword">ON</span>  ciResult.experiment=aaResult.experiment</span><br><span class="line"><span class="keyword">AND</span> ciResult.channelid=aaResult.channelid</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSignificance <span class="keyword">PARTITION</span>(d=<span class="string">'$&#123;operate_date&#125;'</span>,clienttype=<span class="string">'$&#123;client_type&#125;'</span>,<span class="keyword">index</span>=<span class="string">'cr_pv'</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  ciResult.experiment,</span><br><span class="line">        ciResult.channelid,</span><br><span class="line">        ciResult.cumstart,</span><br><span class="line">        ciResult.cumend,</span><br><span class="line">        ciResult.abversion,</span><br><span class="line">        (ciResult.lift_quantile_pv.lci&gt;<span class="number">0</span> <span class="keyword">or</span> ciResult.lift_quantile_pv.uci&lt;<span class="number">0</span>) <span class="keyword">as</span> isSignificant,</span><br><span class="line">        ciResult.lift_pv <span class="keyword">as</span> lift,</span><br><span class="line">        makeJson(<span class="keyword">map</span>(</span><br><span class="line">            <span class="string">'uci'</span>,<span class="keyword">CAST</span>(ciResult.lift_quantile_pv.uci <span class="keyword">AS</span> <span class="keyword">STRING</span>),</span><br><span class="line">            <span class="string">'lci'</span>,<span class="keyword">CAST</span>(ciResult.lift_quantile_pv.lci <span class="keyword">AS</span> <span class="keyword">STRING</span>))</span><br><span class="line">        ) <span class="keyword">as</span> ciExt,</span><br><span class="line">        (aaResult.lift_quantile_pv.lci&lt;=<span class="number">0</span> <span class="keyword">AND</span> aaResult.lift_quantile_pv.uci&gt;=<span class="number">0</span>) <span class="keyword">as</span> isAANormal,</span><br><span class="line">        makeJson(<span class="keyword">map</span>(</span><br><span class="line">            <span class="string">'uci'</span>,<span class="keyword">CAST</span>(aaResult.lift_quantile_pv.uci <span class="keyword">AS</span> <span class="keyword">STRING</span>),</span><br><span class="line">            <span class="string">'lci'</span>,<span class="keyword">CAST</span>(aaResult.lift_quantile_pv.lci <span class="keyword">AS</span> <span class="keyword">STRING</span>))) <span class="keyword">as</span> aaExt,</span><br><span class="line">        ciResult.power_pv <span class="keyword">as</span> <span class="string">`power`</span>,</span><br><span class="line">        makeJson(<span class="keyword">map</span>()) <span class="keyword">as</span> powerExt</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSignificance <span class="keyword">PARTITION</span>(d=<span class="string">'$&#123;operate_date&#125;'</span>,clienttype=<span class="string">'$&#123;client_type&#125;'</span>,<span class="keyword">index</span>=<span class="string">'cr_orders'</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  ciResult.experiment,</span><br><span class="line">        ciResult.channelid,</span><br><span class="line">        ciResult.cumstart,</span><br><span class="line">        ciResult.cumend,</span><br><span class="line">        ciResult.abversion,</span><br><span class="line">        (ciResult.lift_quantile_orders.lci&gt;<span class="number">0</span> <span class="keyword">or</span> ciResult.lift_quantile_orders.uci&lt;<span class="number">0</span>) <span class="keyword">as</span> isSignificant,</span><br><span class="line">        ciResult.lift_orders <span class="keyword">as</span> lift,</span><br><span class="line">        makeJson(<span class="keyword">map</span>(</span><br><span class="line">            <span class="string">'uci'</span>,<span class="keyword">CAST</span>(ciResult.lift_quantile_orders.uci <span class="keyword">AS</span> <span class="keyword">STRING</span>),</span><br><span class="line">            <span class="string">'lci'</span>,<span class="keyword">CAST</span>(ciResult.lift_quantile_orders.lci <span class="keyword">AS</span> <span class="keyword">STRING</span>))</span><br><span class="line">        ) <span class="keyword">as</span> ciExt,</span><br><span class="line">        (aaResult.lift_quantile_orders.lci&lt;=<span class="number">0</span> <span class="keyword">AND</span> aaResult.lift_quantile_orders.uci&gt;=<span class="number">0</span>) <span class="keyword">as</span> isAANormal,</span><br><span class="line">        makeJson(<span class="keyword">map</span>(</span><br><span class="line">            <span class="string">'uci'</span>,<span class="keyword">CAST</span>(aaResult.lift_quantile_orders.uci <span class="keyword">AS</span> <span class="keyword">STRING</span>),</span><br><span class="line">            <span class="string">'lci'</span>,<span class="keyword">CAST</span>(aaResult.lift_quantile_orders.lci <span class="keyword">AS</span> <span class="keyword">STRING</span>))) <span class="keyword">as</span> aaExt,</span><br><span class="line">        ciResult.power_orders <span class="keyword">as</span> <span class="string">`power`</span>,</span><br><span class="line">        makeJson(<span class="keyword">map</span>()) <span class="keyword">as</span> powerExt</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSignificance <span class="keyword">PARTITION</span>(d=<span class="string">'$&#123;operate_date&#125;'</span>,clienttype=<span class="string">'$&#123;client_type&#125;'</span>,<span class="keyword">index</span>=<span class="string">'cr_quantity'</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  ciResult.experiment,</span><br><span class="line">        ciResult.channelid,</span><br><span class="line">        ciResult.cumstart,</span><br><span class="line">        ciResult.cumend,</span><br><span class="line">        ciResult.abversion,</span><br><span class="line">        (ciResult.lift_quantile_quantity.lci&gt;<span class="number">0</span> <span class="keyword">or</span> ciResult.lift_quantile_quantity.uci&lt;<span class="number">0</span>) <span class="keyword">as</span> isSignificant,</span><br><span class="line">        ciResult.lift_quantity <span class="keyword">as</span> lift,</span><br><span class="line">        makeJson(<span class="keyword">map</span>(</span><br><span class="line">            <span class="string">'uci'</span>,<span class="keyword">CAST</span>(ciResult.lift_quantile_quantity.uci <span class="keyword">AS</span> <span class="keyword">STRING</span>),</span><br><span class="line">            <span class="string">'lci'</span>,<span class="keyword">CAST</span>(ciResult.lift_quantile_quantity.lci <span class="keyword">AS</span> <span class="keyword">STRING</span>))</span><br><span class="line">        ) <span class="keyword">as</span> ciExt,</span><br><span class="line">        (aaResult.lift_quantile_quantity.lci&lt;=<span class="number">0</span> <span class="keyword">AND</span> aaResult.lift_quantile_quantity.uci&gt;=<span class="number">0</span>) <span class="keyword">as</span> isAANormal,</span><br><span class="line">        makeJson(<span class="keyword">map</span>(</span><br><span class="line">            <span class="string">'uci'</span>,<span class="keyword">CAST</span>(aaResult.lift_quantile_quantity.uci <span class="keyword">AS</span> <span class="keyword">STRING</span>),</span><br><span class="line">            <span class="string">'lci'</span>,<span class="keyword">CAST</span>(aaResult.lift_quantile_quantity.lci <span class="keyword">AS</span> <span class="keyword">STRING</span>))) <span class="keyword">as</span> aaExt,</span><br><span class="line">        ciResult.power_quantity <span class="keyword">as</span> <span class="string">`power`</span>,</span><br><span class="line">        makeJson(<span class="keyword">map</span>()) <span class="keyword">as</span> powerExt</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSignificance <span class="keyword">PARTITION</span>(d=<span class="string">'$&#123;operate_date&#125;'</span>,clienttype=<span class="string">'$&#123;client_type&#125;'</span>,<span class="keyword">index</span>=<span class="string">'cr_amount'</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  ciResult.experiment,</span><br><span class="line">        ciResult.channelid,</span><br><span class="line">        ciResult.cumstart,</span><br><span class="line">        ciResult.cumend,</span><br><span class="line">        ciResult.abversion,</span><br><span class="line">        (ciResult.lift_quantile_amount.lci&gt;<span class="number">0</span> <span class="keyword">or</span> ciResult.lift_quantile_amount.uci&lt;<span class="number">0</span>) <span class="keyword">as</span> isSignificant,</span><br><span class="line">        ciResult.lift_amount <span class="keyword">as</span> lift,</span><br><span class="line">        makeJson(<span class="keyword">map</span>(</span><br><span class="line">            <span class="string">'uci'</span>,<span class="keyword">CAST</span>(ciResult.lift_quantile_amount.uci <span class="keyword">AS</span> <span class="keyword">STRING</span>),</span><br><span class="line">            <span class="string">'lci'</span>,<span class="keyword">CAST</span>(ciResult.lift_quantile_amount.lci <span class="keyword">AS</span> <span class="keyword">STRING</span>))</span><br><span class="line">        ) <span class="keyword">as</span> ciExt,</span><br><span class="line">        (aaResult.lift_quantile_amount.lci&lt;=<span class="number">0</span> <span class="keyword">AND</span> aaResult.lift_quantile_amount.uci&gt;=<span class="number">0</span>) <span class="keyword">as</span> isAANormal,</span><br><span class="line">        makeJson(<span class="keyword">map</span>(</span><br><span class="line">            <span class="string">'uci'</span>,<span class="keyword">CAST</span>(aaResult.lift_quantile_amount.uci <span class="keyword">AS</span> <span class="keyword">STRING</span>),</span><br><span class="line">            <span class="string">'lci'</span>,<span class="keyword">CAST</span>(aaResult.lift_quantile_amount.lci <span class="keyword">AS</span> <span class="keyword">STRING</span>))) <span class="keyword">as</span> aaExt,</span><br><span class="line">        ciResult.power_amount <span class="keyword">as</span> <span class="string">`power`</span>,</span><br><span class="line">        makeJson(<span class="keyword">map</span>()) <span class="keyword">as</span> powerExt</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSignificance <span class="keyword">PARTITION</span>(d=<span class="string">'$&#123;operate_date&#125;'</span>,clienttype=<span class="string">'$&#123;client_type&#125;'</span>,<span class="keyword">index</span>=<span class="string">'cr_cost'</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  ciResult.experiment,</span><br><span class="line">        ciResult.channelid,</span><br><span class="line">        ciResult.cumstart,</span><br><span class="line">        ciResult.cumend,</span><br><span class="line">        ciResult.abversion,</span><br><span class="line">        (ciResult.lift_quantile_cost.lci&gt;<span class="number">0</span> <span class="keyword">or</span> ciResult.lift_quantile_cost.uci&lt;<span class="number">0</span>) <span class="keyword">as</span> isSignificant,</span><br><span class="line">        ciResult.lift_cost <span class="keyword">as</span> lift,</span><br><span class="line">        makeJson(<span class="keyword">map</span>(</span><br><span class="line">            <span class="string">'uci'</span>,<span class="keyword">CAST</span>(ciResult.lift_quantile_cost.uci <span class="keyword">AS</span> <span class="keyword">STRING</span>),</span><br><span class="line">            <span class="string">'lci'</span>,<span class="keyword">CAST</span>(ciResult.lift_quantile_cost.lci <span class="keyword">AS</span> <span class="keyword">STRING</span>))</span><br><span class="line">        ) <span class="keyword">as</span> ciExt,</span><br><span class="line">        (aaResult.lift_quantile_cost.lci&lt;=<span class="number">0</span> <span class="keyword">AND</span> aaResult.lift_quantile_cost.uci&gt;=<span class="number">0</span>) <span class="keyword">as</span> isAANormal,</span><br><span class="line">        makeJson(<span class="keyword">map</span>(</span><br><span class="line">            <span class="string">'uci'</span>,<span class="keyword">CAST</span>(aaResult.lift_quantile_cost.uci <span class="keyword">AS</span> <span class="keyword">STRING</span>),</span><br><span class="line">            <span class="string">'lci'</span>,<span class="keyword">CAST</span>(aaResult.lift_quantile_cost.lci <span class="keyword">AS</span> <span class="keyword">STRING</span>))) <span class="keyword">as</span> aaExt,</span><br><span class="line">        ciResult.power_cost <span class="keyword">as</span> <span class="string">`power`</span>,</span><br><span class="line">        makeJson(<span class="keyword">map</span>()) <span class="keyword">as</span> powerExt</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSignificance <span class="keyword">PARTITION</span>(d=<span class="string">'$&#123;operate_date&#125;'</span>,clienttype=<span class="string">'$&#123;client_type&#125;'</span>,<span class="keyword">index</span>=<span class="string">'cr_gross_profit'</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  ciResult.experiment,</span><br><span class="line">        ciResult.channelid,</span><br><span class="line">        ciResult.cumstart,</span><br><span class="line">        ciResult.cumend,</span><br><span class="line">        ciResult.abversion,</span><br><span class="line">        (ciResult.lift_quantile_gross_profit.lci&gt;<span class="number">0</span> <span class="keyword">or</span> ciResult.lift_quantile_gross_profit.uci&lt;<span class="number">0</span>) <span class="keyword">as</span> isSignificant,</span><br><span class="line">        ciResult.lift_gross_profit <span class="keyword">as</span> lift,</span><br><span class="line">        makeJson(<span class="keyword">map</span>(</span><br><span class="line">            <span class="string">'uci'</span>,<span class="keyword">CAST</span>(ciResult.lift_quantile_gross_profit.uci <span class="keyword">AS</span> <span class="keyword">STRING</span>),</span><br><span class="line">            <span class="string">'lci'</span>,<span class="keyword">CAST</span>(ciResult.lift_quantile_gross_profit.lci <span class="keyword">AS</span> <span class="keyword">STRING</span>))</span><br><span class="line">        ) <span class="keyword">as</span> ciExt,</span><br><span class="line">        (aaResult.lift_quantile_gross_profit.lci&lt;=<span class="number">0</span> <span class="keyword">AND</span> aaResult.lift_quantile_gross_profit.uci&gt;=<span class="number">0</span>) <span class="keyword">as</span> isAANormal,</span><br><span class="line">        makeJson(<span class="keyword">map</span>(</span><br><span class="line">            <span class="string">'uci'</span>,<span class="keyword">CAST</span>(aaResult.lift_quantile_gross_profit.uci <span class="keyword">AS</span> <span class="keyword">STRING</span>),</span><br><span class="line">            <span class="string">'lci'</span>,<span class="keyword">CAST</span>(aaResult.lift_quantile_gross_profit.lci <span class="keyword">AS</span> <span class="keyword">STRING</span>))) <span class="keyword">as</span> aaExt,</span><br><span class="line">        ciResult.power_gross_profit <span class="keyword">as</span> <span class="string">`power`</span>,</span><br><span class="line">        makeJson(<span class="keyword">map</span>()) <span class="keyword">as</span> powerExt</span><br><span class="line">;</span><br></pre></td></tr></table></figure></p><p><strong>UDFCumulativeProbabilityNormalDistribution.java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ctrip.basebiz.abtest3.hive.function.statistics;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.math3.distribution.NormalDistribution;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.Description;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDF;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Description</span>(name = <span class="string">"pnorm"</span>,</span><br><span class="line">        value = <span class="string">"_FUNC_(quantile,mean,sd) - Density, distribution function, quantile "</span> +</span><br><span class="line">                <span class="string">"function and random generation for the normal distribution with mean"</span> +</span><br><span class="line">                <span class="string">" equal to mean and standard deviation equal to sd"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UDFCumulativeProbabilityNormalDistribution</span> <span class="keyword">extends</span> <span class="title">UDF</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">evaluate</span><span class="params">(Double quantile)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> evaluate(quantile, <span class="number">0.0</span>D, <span class="number">1.0</span>D);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">evaluate</span><span class="params">(Double quantile, Double mean, Double sd)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (quantile == <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.0</span>;</span><br><span class="line">        NormalDistribution normalDistribution = <span class="keyword">new</span> NormalDistribution(mean, sd);</span><br><span class="line">        <span class="keyword">return</span> normalDistribution.cumulativeProbability(quantile);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span>  <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        UDFCumulativeProbabilityNormalDistribution d=<span class="keyword">new</span> UDFCumulativeProbabilityNormalDistribution();</span><br><span class="line">        System.out.println(d.evaluate(<span class="number">0.9</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>UDFLiftQuantile.java</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">package com.ctrip.basebiz.abtest3.hive.function;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.hive.ql.exec.Description;</span><br><span class="line">import org.apache.hadoop.hive.ql.exec.UDF;</span><br><span class="line">import org.apache.hadoop.hive.serde2.io.DoubleWritable;</span><br><span class="line"></span><br><span class="line">import java.math.BigDecimal;</span><br><span class="line">import java.math.RoundingMode;</span><br><span class="line">import java.util.Collections;</span><br><span class="line">import java.util.PriorityQueue;</span><br><span class="line">import java.util.Random;</span><br><span class="line"></span><br><span class="line">@Description(name = &quot;lift_quantile&quot;,</span><br><span class="line">        value = &quot;_FUNC_(meanTreatment,stdTreatment,meanControl,stdControl,confidenceLevel,samplingNum).&quot;,</span><br><span class="line">        extended = &quot;Construct sets of random number obey Gaussian distribution whose mean and standard deviation &quot; +</span><br><span class="line">                &quot;is the same as treatment version and control version. &quot; +</span><br><span class="line">                &quot;Return lift&apos;s upper and lower quantile whose Confidence Level is confidenceLevel.\n&quot; +</span><br><span class="line">                &quot; Lift = (Treatment - Control) / Control &quot;)</span><br><span class="line">public class UDFLiftQuantile extends UDF &#123;</span><br><span class="line">    public static class UDFLiftQuantileResult &#123;</span><br><span class="line">        public DoubleWritable mean;</span><br><span class="line">        public DoubleWritable lci;</span><br><span class="line">        public DoubleWritable uci;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public UDFLiftQuantileResult evaluate(Double mTreatment, Double stdTreatment,</span><br><span class="line">                                          Double mControl, Double stdControl,</span><br><span class="line">                                          Double confidenceLevel, Integer samplingNum) &#123;</span><br><span class="line">        boolean isArgInvalid = (mTreatment == .0 &amp;&amp; stdTreatment == .0) || (mControl == .0 &amp;&amp; stdControl == .0);</span><br><span class="line">        if (isArgInvalid) &#123;</span><br><span class="line">            UDFLiftQuantileResult result = new UDFLiftQuantileResult();</span><br><span class="line">            result.mean = new DoubleWritable(0);</span><br><span class="line">            result.lci = new DoubleWritable(0);</span><br><span class="line">            result.uci = new DoubleWritable(0);</span><br><span class="line">            return result;</span><br><span class="line">        &#125;</span><br><span class="line">        Random randomTreatment = new Random();</span><br><span class="line">        Random randomControl = new Random();</span><br><span class="line">        int queueMaxSize = (int) (Math.floor((1.0 - confidenceLevel) / 2 * samplingNum) + 1);</span><br><span class="line">        PriorityQueue&lt;Double&gt; lciQueue = new PriorityQueue&lt;Double&gt;(queueMaxSize, Collections.reverseOrder());</span><br><span class="line">        PriorityQueue&lt;Double&gt; uciQueue = new PriorityQueue&lt;Double&gt;(queueMaxSize);</span><br><span class="line">        BigDecimal sum = BigDecimal.ZERO;</span><br><span class="line">        for (int i = 0; i &lt; samplingNum; i++) &#123;</span><br><span class="line">            double vTreatment = mTreatment + randomTreatment.nextGaussian() * stdTreatment;</span><br><span class="line">            double vControl = mControl + randomControl.nextGaussian() * stdControl;</span><br><span class="line">            if (vControl == 0.0) &#123;</span><br><span class="line">                i--;</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line">            double lift = (vTreatment - vControl) / vControl;</span><br><span class="line">            sum = sum.add(BigDecimal.valueOf(lift));</span><br><span class="line">            if (lciQueue.size() &lt; queueMaxSize || lciQueue.peek() &gt;= lift) &#123;</span><br><span class="line">                lciQueue.add(lift);</span><br><span class="line">                if (lciQueue.size() &gt; queueMaxSize) &#123;</span><br><span class="line">                    lciQueue.poll();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            if (uciQueue.size() &lt; queueMaxSize || uciQueue.peek() &lt;= lift) &#123;</span><br><span class="line">                uciQueue.add(lift);</span><br><span class="line">                if (uciQueue.size() &gt; queueMaxSize) &#123;</span><br><span class="line">                    uciQueue.poll();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        UDFLiftQuantileResult result = new UDFLiftQuantileResult();</span><br><span class="line">        result.lci = new DoubleWritable(lciQueue.poll());</span><br><span class="line">        result.uci = new DoubleWritable(uciQueue.poll());</span><br><span class="line">        result.mean = new DoubleWritable(sum.divide(BigDecimal.valueOf(samplingNum), RoundingMode.HALF_EVEN).doubleValue());</span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        for (int i = 0; i &lt; 10; i++) &#123;</span><br><span class="line">            System.out.println(&quot;Nyan~&quot;);</span><br><span class="line">            run();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private static void run() &#123;</span><br><span class="line">        UDFLiftQuantile o = new UDFLiftQuantile();</span><br><span class="line">        UDFLiftQuantileResult result = o.evaluate(0.666141754, 0.257336891, 0.373081111, 0.079436106, 0.8, 100000);</span><br><span class="line">        //UDFLiftQuantileResult result = o.evaluate(.0, .0, .0, .0, 0.8, 1000);</span><br><span class="line">        //UDFLiftQuantileResult result = o.evaluate(.0, .0, 1.0, 2.0, 0.8, 1000);</span><br><span class="line">        //UDFLiftQuantileResult result = o.evaluate(2.0, 54.0, .0, .0, 0.8, 1000);</span><br><span class="line">        System.out.println(result.mean);</span><br><span class="line">        System.out.println(result.lci);</span><br><span class="line">        System.out.println(result.uci);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="显著性计算—date-based"><a href="#显著性计算—date-based" class="headerlink" title="显著性计算—date based"></a>显著性计算—date based</h2><h3 id="方法简述"><a href="#方法简述" class="headerlink" title="方法简述"></a>方法简述</h3><p>当总体呈现正态分布且总体标准差未知，而且容量小于30，那么这时一切可能的样本平均数与总体平均数的离差统计量呈T分布。</p><p>该方法采用统计中的two sample t test， 检验两组数据的均值是否相等。例如100个男生身高数据和100个女生身高数据，通过该方法可以检验男生的平均身高是否显著不等于女生的平均身高。</p><p>在报表中我们输入的两组数据，一组是一个版本每日的指标数据，另外一组是选择的另外一个版本对应的每日的指标数据。指标可以是任意数值型指标，比如UV数，点击率，订单数等等。</p><p>该方法我们只做两两间的比较。</p><h3 id="实验举例"><a href="#实验举例" class="headerlink" title="实验举例"></a>实验举例</h3><p>我们以一个首页改版为例，如下图所示：</p><p><img src="https://i.postimg.cc/g0RV2mVD/2015-12-23-092010.png" alt="AB home page"></p><p>首页改版，通过上面图片发现海外酒店位置发生变化，所以我们想知道位置的改变是否会影响海外酒店的点击数量，分流比：新版：老版=50%：50%</p><p>我们拿到了每天新老版本的点击UV数，通过统计检验，判断是否新版的点击UV数明显低于老版。<br>数据如下：</p><p><img src="https://i.postimg.cc/jSD6BzCB/abtestoutcome.png" alt="home AB outcome"></p><h3 id="检验方法"><a href="#检验方法" class="headerlink" title="检验方法"></a>检验方法</h3><p>假设x：新版每日UV数，y：老板每日UV数。计算如下统计量：</p><script type="math/tex; mode=display">t = \frac {\bar x - \bar y}{s \sqrt{1 / n_1 + 1 / n_2} }</script><p>这里，</p><blockquote><p>$\bar x$ 是新版均值，$\bar x = \sum_{i=1}^{n_1} x_i / n_1, n_1 是天数$<br>$\bar y$ 是老板均值，$\bar y = \sum_{i=1}^{n_1} y_i / n_2, n_2 是天数$<br>$s = \sqrt{[(n_1 - 1) s_1^2 + (n_2 - 1) s_2^2] / (n_1 + n_2 -2)}$，其中<br>$s_1^2 = \sum_{i=1}^{n_1} (x_i - \bar x)^2 / (n_1 - 1), s_2^2 = \sum_{i=1}^{n_2} (y_i - \bar y) / (n_2 - 1)$</p></blockquote><p>若 $| t | &gt; t_{n_1 + n_2 - 2, 1 - \alpha / 2}$，则显著，否则不显著。$t_{n_1 + n_2 - 2, 1 - \alpha / 2}$数值可通过查表或者计算器获取。</p><h3 id="示例剖析"><a href="#示例剖析" class="headerlink" title="示例剖析"></a>示例剖析</h3><p>基于上述方案，我们对前面的例子进行计算有：<br>$\bar x = 7555.111, \bar y = 14935$<br>共有9天数据，所以$n_1 = n_2 = 9$</p><p>$s_1^2 = 1556811, s_2^2 = 335096.8, s = 972.6015$<br>t = (7555.111-14935) / 3890.406/$\sqrt{2/9}$ = -16.09612</p><p>查表或者计算机可得：$t_{n_1 + n_2 - 2, 1 - \alpha / 2} = t_{16,1 - \alpha / 2} = 1.745884（自由度=9+9-2=16）$<br>由于$| t | &gt; t_{16,1 - \alpha / 2}$，所以新版还外加酒店宫格点击用户数相对老版是显著下降的。</p><p>最小样本量：<br>在方法简述中提到：当总体呈现正态分布且总体标准差未知，而且容量小于30，那么这时一切可能的样本平均数与总体平均数的离差统计量呈T分布。</p><p>在ABtest中实验天数小于30天即可用T检验来进行判定。那么是不是实验天数越小越好呢？答案显然是否定的，实验天数越多得到的结论可靠性越好，</p><p>但是业务人员希望实验天数越少越好，两者之间形成了悖论。在此，一般建议实验最少进行两周（14天）：一周数据（7天）太少，且旅游数据大部分都是以一周为一个周期上下浮动，选择两周可以有效地平滑掉周期对结果的影响。</p><h3 id="实验最小-uv-量"><a href="#实验最小-uv-量" class="headerlink" title="实验最小 uv 量"></a>实验最小 uv 量</h3><p>假设实验组分流比例 (B) = 对照组分流比例 (C+D), 指标(CR等)满足正态分布(Central Limit Theorem)且方差相等。</p><p>选择参与实验的主指标数量为m (选项有CR, Quantity, GP-C)。对于每个选中的主指标, 计算该指标需要的最小样本量$S_i$:</p><script type="math/tex; mode=display">n = \frac {((k+1) + (k+1)/k) \sigma^2 (z_{a - \alpha / 2m} + z_{1 - \beta})^2}{\Delta^2}= treatment_uv + control_uv</script><blockquote><ul><li>$\Delta = lift * u_x$，大流量 lift 可取值0.02，小流量可取0.03<br>  （$u_x$可取该指标在试验频道前2周的均值；$lift = (u_y - u_x)/u_x$，其中$(u_y - u_x)$是实验组和对照组的均值差）</li><li>Type I Error 一般取$\alpha = 10 \%$；Type II Error 一般取$\beta = 0.2(Power = 10 \%)$</li><li>$z_x$是正态分布累计概率为 x 时对应的分位数</li><li>$\sigma^2$是该指标子啊试验频道前2周的方差。k = 实验组UV/对照组UV</li></ul></blockquote><p><strong>最后选取实验的所需最小样本量的最大值$max{S_i: i = 1, …, m}$</strong></p><h4 id="知识小科普："><a href="#知识小科普：" class="headerlink" title="知识小科普："></a>知识小科普：</h4><p>T检验和成对T检验的区别：<br>通常T检验或成对T检验是用来判断两组数据的平均值是否在统计上有差别,换一个理解,对两组数据而言,每组数据本身内部有一个波动范围(组内变异),而两组数据之间平均值的波动相称为组间变异,如果组间变异相对于组内变异小的话,就可以认为两组数据之间的平均值是没有差异的,这是T检验的做法. 而对于成对T检验,在一组中的数据与另一组的数据有对应关系,也就是两组数据是以成队的形式出现的,这个时候,运用这两个成队数据之间的差值,可以得到一个数据列,如果这个数据列的平均值在统计上是非零的,即可认为两组数据均值是有差异的,在这个地方,没有单独的去考虑两组数据之内的差异,而是通过将两组数据中对应的数据相减,得到一组数据,通过类似偏倚的算法,来看它在统计是是否非零.换一句话说,是当组内差异比较大(或者说是噪音较大),但是可以通过其它一个因子作区隔时,可以用成对T检验。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;显著性计算—uv-based&quot;&gt;&lt;a href=&quot;#显著性计算—uv-based&quot; class=&quot;headerlink&quot; title=&quot;显著性计算—uv based&quot;&gt;&lt;/a&gt;显著性计算—uv based&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;这里以实验目标为提升CR（Conversion Rate）为例说明&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;名词解释&quot;&gt;&lt;a href=&quot;#名词解释&quot; class=&quot;headerlink&quot; title=&quot;名词解释&quot;&gt;&lt;/a&gt;名词解释&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;显著性：&lt;/strong&gt; 显著：新版和老版的CR有明显差异，不显著: 新版和老版没有明显差异。&lt;br&gt;&lt;strong&gt;上升幅度：&lt;/strong&gt;(新版CR-老版CR)/老版CR&lt;br&gt;&lt;strong&gt;功效:&lt;/strong&gt; 一般功效（即power值）达到0.8, 我们认为样本量即实验UV充足，可下结论。&lt;/p&gt;
    
    </summary>
    
    
      <category term="ABTest" scheme="https://www.xiemingzhao.com/categories/ABTest/"/>
    
    
      <category term="ABTest" scheme="https://www.xiemingzhao.com/tags/ABTest/"/>
    
  </entry>
  
  <entry>
    <title>如何构建一个ABTest</title>
    <link href="https://www.xiemingzhao.com/posts/ABTestbuilding.html"/>
    <id>https://www.xiemingzhao.com/posts/ABTestbuilding.html</id>
    <published>2019-07-11T16:00:00.000Z</published>
    <updated>2019-10-13T14:14:58.857Z</updated>
    
    <content type="html"><![CDATA[<h2 id="如何构建一个ABTest"><a href="#如何构建一个ABTest" class="headerlink" title="如何构建一个ABTest"></a>如何构建一个ABTest</h2><h3 id="谁会参与"><a href="#谁会参与" class="headerlink" title="谁会参与"></a>谁会参与</h3><ol><li>业务部门。 定义一个Ab Testing.</li><li>Ab Testing管理后台。 录入一个Ab Tesing.</li><li>业务开发者。 负责具体的方案开发实现。</li><li>用户。我们所关心的用户。</li><li>数据收集系统。收集我们关心的数据。</li><li>数据分析系统。根据收集到的数据，分析出我们所关心的指标。</li></ol><a id="more"></a><h3 id="构建一个Ab-Testing的流程"><a href="#构建一个Ab-Testing的流程" class="headerlink" title="构建一个Ab Testing的流程"></a>构建一个Ab Testing的流程</h3><blockquote><p><strong>简要步骤</strong><br><img src="https://i.postimg.cc/qMbXmmB8/ab-testing-lifecycle-summary.jpg" alt="ab-testing-lifecycle-summary"></p></blockquote><ol><li>业务部门负责定义一个ab testing</li><li>管理后台负责录入管理ab testing</li><li>业务开发负责具体的业务实现</li><li>日志系统负责收集数据</li><li>数据分析系统负责生成指定报表</li></ol><p>Ab Testing Framework 在其中的作用：</p><ol><li>无数据管理，提供restful api接口</li><li>提供client library 供业务开发使用，实现分流。</li></ol><h3 id="流程细化"><a href="#流程细化" class="headerlink" title="流程细化"></a>流程细化</h3><p><img src="https://i.postimg.cc/0yhGvbwj/ab-testing-lifecycle.png" alt="ab-testing-lifecycle"></p><h3 id="Ab-Testing-Framework"><a href="#Ab-Testing-Framework" class="headerlink" title="Ab Testing Framework"></a>Ab Testing Framework</h3><p><img src="https://i.postimg.cc/kXXvvrCJ/where-is-ab-testing-framework.png" alt="where-is-ab-testing-framework"></p><h3 id="AB-Test-基础方面"><a href="#AB-Test-基础方面" class="headerlink" title="AB Test 基础方面"></a>AB Test 基础方面</h3><p><strong>1. ab配置系统环境</strong><br>由于生产环境的防火墙限制，实验不能往生产环境同步。建议实验先配置生产环境，然后往fws环境和uat环境进行同步。</p><p><strong>2. 实验状态</strong></p><blockquote><p>a.目前一个实验有配置中、待审核、审核通过（进行中）、实验结束等状态。<br>b.审核通过之后到了实验开始时间即为进行中。其中，实验开始时间以计算开始时间为准。<br>c.同步过去的实验状态为配置中。同步实验不能同步实验的分流规则，没有分流规则的实验一定是配置中状态。<br>d.实验的版本数有改动会清空规则，实验重新进入配置中状态。</p></blockquote><p><strong>3. 实验类型</strong><br>借助于浏览器的是web实验，web实验里面分为online实验和h5实验，区分在于是否采用h5技术；借助于app的是app实验，app实验里面分为app native、app hybrid和app服务端实验。采用手机原生态接口的，或者建立在原生态接口之上的是app native实验；其中，再混入h5或其他技术，是hybrid实验。</p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:left">online实验</th><th style="text-align:left">h5实验</th><th style="text-align:left">app native实验</th><th style="text-align:left">app hybrid实验</th><th style="text-align:left">app 服务端实验</th></tr></thead><tbody><tr><td style="text-align:center">实验位置</td><td style="text-align:left">客户端</td><td style="text-align:left">客户端</td><td style="text-align:left">客户端</td><td style="text-align:left">客户端</td><td style="text-align:left">服务端</td></tr><tr><td style="text-align:center">采用技术</td><td style="text-align:left">html、css、js等web技术</td><td style="text-align:left">主要为h5技术，web app</td><td style="text-align:left">native app</td><td style="text-align:left">hybrid app</td><td style="text-align:left">服务端技术</td></tr></tbody></table></div><p>最容易混淆的是h5实验和app hybrid实验，需要注意，这两个的区别在于h5实验直接借助浏览器呈现实验页面，而app hybrid实验借助于携程app，直接或间接的采用系统的原生态接口。也可参考H5 &amp; Native &amp; Hybrid。</p><p><strong>4. ab实验版本</strong></p><ul><li>版本号。abtest测试至少需要4个版本号，3个版本号放置老版，1个版本号放置新版。如果有多个新版，可在这基础上新增版本号代表新版。老版为control，新版为treatment。、</li><li>版本开多少流量。在4个版本ABCD中，B为新版，ACD为老版。其中，建议A老版，默认版，盛放流量余量；B新版，新版流量；CD老版，AA实验流量。流量关系需要满足1.sum(A+B+C+D)=100%；2.C=D；3.C+D=B。</li><li>不建议实验上线之后还修改版本。如果修改了版本，请重新分配流量。</li></ul><p><strong>5. 分流</strong></p><ol><li>分流比是否正常<br>可通过dashboard监控来看分流比，其中metricname为abtest.client.reqeust.count,expcode选择实验号，并按expversion分组。在请求数达到一定量的前提，如果存在分流比和配置的分流比出入较大，即分流异常。</li><li>分流比异常原因<br>A. 分流总体较少；B. 实验相互干扰；C.实验存在嵌套（目前不支持）；D.配置或ab代码有误</li><li>app实验分流请求总数很大<br>该请求数表示直接调用abtest.client.dll的接口数，不反映app实验的用户分流请求数。基于app渠道的特殊性，只要用户启动app，将在app加载所有app实验的的ab分流结果。</li></ol><h3 id="异常数据剔除"><a href="#异常数据剔除" class="headerlink" title="异常数据剔除"></a>异常数据剔除</h3><p>异常用户判断逻辑：<br>1.取出所有μ+3Sigma以外的，放入集合A;<br>2.对集合A中的用户做LOF（Local Outlier Factor），取出离群点放入集合B；<br>3.取集合B中用户，其数值大于μ+4Sigma的，视为异常用户。</p><p><strong>这里可根据多个维度进行判断，例如pv量，order量以及amount量</strong></p><p>异常数据剔除逻辑：<br>1.取出异常用户，将该用户在实验有效期内参与的数据均做剔除；</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;如何构建一个ABTest&quot;&gt;&lt;a href=&quot;#如何构建一个ABTest&quot; class=&quot;headerlink&quot; title=&quot;如何构建一个ABTest&quot;&gt;&lt;/a&gt;如何构建一个ABTest&lt;/h2&gt;&lt;h3 id=&quot;谁会参与&quot;&gt;&lt;a href=&quot;#谁会参与&quot; class=&quot;headerlink&quot; title=&quot;谁会参与&quot;&gt;&lt;/a&gt;谁会参与&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;业务部门。 定义一个Ab Testing.&lt;/li&gt;
&lt;li&gt;Ab Testing管理后台。 录入一个Ab Tesing.&lt;/li&gt;
&lt;li&gt;业务开发者。 负责具体的方案开发实现。&lt;/li&gt;
&lt;li&gt;用户。我们所关心的用户。&lt;/li&gt;
&lt;li&gt;数据收集系统。收集我们关心的数据。&lt;/li&gt;
&lt;li&gt;数据分析系统。根据收集到的数据，分析出我们所关心的指标。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="ABTest" scheme="https://www.xiemingzhao.com/categories/ABTest/"/>
    
    
      <category term="ABTest" scheme="https://www.xiemingzhao.com/tags/ABTest/"/>
    
  </entry>
  
  <entry>
    <title>DeepFM A Factorization-Machine based Neural Network for CTR Prediction (论文解析)</title>
    <link href="https://www.xiemingzhao.com/posts/4bbfbe93.html"/>
    <id>https://www.xiemingzhao.com/posts/4bbfbe93.html</id>
    <published>2019-06-28T16:00:00.000Z</published>
    <updated>2019-09-21T06:27:40.045Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1703.04247.pdf" target="_blank" rel="noopener">原始论文：DeepFM:A Factorization-Machine based Neural Network for CTR Prediction</a></p><h2 id="DeepFM-基于神经网络的因式分解机做点击率预估"><a href="#DeepFM-基于神经网络的因式分解机做点击率预估" class="headerlink" title="DeepFM:基于神经网络的因式分解机做点击率预估"></a>DeepFM:基于神经网络的因式分解机做点击率预估</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>对于推荐系统中的最大化CTR来说，学习那些用户行为背后的复杂而精确的特征交叉项是至关重要的。尽管有很大的提升，但是方法似乎在低阶或者高阶的交差项上带有很强的偏置项，又或者会要求专业性的特征工程。在这篇文章，我们会展示可以构造出一个端到端的学习模型，特别是对于低阶和高阶的交叉项的学习。DeepFM，提出的这个模型联合了因式分解机的推荐能力和一个新的神经网络结构在特征方面的深度学习能力。相比于Google提出的最新的Wide &amp; Deep模型，DeepFM的“wide”和“deep”部分有一个共享输入层，并且除了最原始的特征不需要额外的特征工程。综合性的实验结果证明了DeepFM相比于其他的CTR模型在基础数据及和商业数据集上都有着更好的效果和效率。</p><a id="more"></a><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a><strong>1 介绍</strong></h3><p>点击率(CTR)预测对于推荐系统是至关重要的，它是估计用户对某个商业项目进行点击的概率。大部分的推荐系统的目标是最大化点击次数，所以返回给用户的项目可以按照估计出的CTR进行排序；然而对于其他的高级应用例如在线广告，提升CTR可以增加企业的收入，所以总体上来说，排序的策略可以调整为CTR*bid，这里的bid是指用户每次点击给系统产生的收益。但是不管怎样，不断提升CTR可以创造更多的收益。不论什么情况，可以明确地是准确地预测CTR是最关键的。</p><p>通过用户的点击行为序列学习到背后潜在的特征交叉项对于CTR预测是特别重要的。根据我们在主流的app商店的研究，发现用户常常在用餐时间下载外卖类app，这就是一种二阶的交互信息：app应用类别和时间，这类的二阶交互信息可以用以CTR预估。再比如，男性青少年偏爱射击类和角色扮演游戏，这表明了这个三阶的交叉项：包含了性别，年龄和app的应用类别，也是有助于CTR。总的来说，这些用户行为背后的特征交互是非常复杂的，这里的低阶和高阶的特征交叉项都有着特别重要的作用。2016年谷歌的Wide &amp; Deep model系统基于低阶和高阶特征的交互信息在整体上都带来了额外的性能提升。</p><p>建模的核心挑战在于特征之间的交互信息。一些容易理解的特征交叉项可以有专业的人设计出来（例如上述举例的）。然而，大多数的特征交互项是隐藏于数据背后且难以利用先验知识发现的（例如啤酒与尿布的案例，是通过通过数据的而不是专家发现的），这种是仅可以通过机器学习字段捕获的。基于对于一些易理解的交互项来说，它们看上去也不像转接能够构造出来的，特别是在特征数量特别庞大的时候。</p><p>尽管普通的线性模型特别的简单，例如FTRL，但是在实际应用中却展示了相当好的效果。然而，线性模型缺少学习特征交叉项的能力，所以一般是在后期手动方式添加特征之间的交互项。这样的方法不仅难以泛化到高阶特征，也难以应付训练集中较少或者尚未出现的特征。2010年提出的因子分解机(FM)可以解决这个问题，FM是通过隐向量的内积表现特征之间的交叉项。尽管原则上FM可以构建高阶的特征交叉项，但是在实际中考虑到构建特征之间更高阶的关系会更加复杂，所以一般只采用2阶。</p><p>深度学习在特征表示上是一个很强大的算法，所以在学习复杂的特征交叉项上也具有很大潜力。所以就扩展出了一些想法，例如用CNN和RNN来做CTR预估。但是基于CNN的模型只能处理相邻特征，而基于RNN的模型由于天然的序列依赖特性更适于CTR领域。2016年有学者提出了Factorization-machine supported Neural Network (FNN)，该模型用FM进行预训练，再输入到DNN，因此这也使得模型受限于FM。Qu等人于2016年提出Product-based Neural Network (PNN)在嵌入层和全连接层之间引入一个product 层来表示特征之间的相互作用。其实FNN和PNN都仅仅能够表达低阶的特征间相互作用，且程度有限。为了能够同时表达低阶和高阶的特征信息，cheng等人于2016年提出一个混合网络结构：Wide &amp; Deep模型，该模型融合了一个线性模型（wide）和深度学习模型。在这个模型中，两个部分wide part和deep part分别需要两个不同的输入，其中wide part需要依赖专家的特征工程。</p><p>可以看出现有模型偏向于低或高阶特征交互，或依赖于特征工程。在本文，我们证明了可以构建一个学习模型，它是可以通过端到端的方式学习到所有阶数的特征交叉项，而除了原始的特征不需要任何额外的特征工程我们的主要贡献总结如下：</p><ul><li>我们提出了一个新的神经网络模型DeepFM，它是结合了FM和深度神经网络（DNN）的结构。它既可以像FM一样构建低阶的特征交叉项也可以像DNN一样拟合高阶的特特征交叉项。而不像Wide &amp; Deep模型，DeepFM可以在无需任何特征工程的条件下进行端到端的训练。</li><li>我们对DeepFM在基础数据集和商业数据集上都进行了评估，结果表明了它相对于目前已存在的CTR预估模型有一致性的提升效果。</li></ul><h3 id="2-我们的方法"><a href="#2-我们的方法" class="headerlink" title="2 我们的方法"></a><strong>2 我们的方法</strong></h3><p>假设数据的训练集包含n个样本$(\mathcal{X},y)$，其中$\mathcal{X}$是一个包含m个特征域的数据集，一版记录了相关的用户和物品对，并且$y \in (0,1)$对应的标签标示用户的点击行为（1表示用户点击了物品，否则为0）。$\mathcal{X}$可能会包含类别型特征（例如性别，位置）和连续型特征（例如年龄）。每个类别型特征都会被表示成一个one-hot编码的向量，每个连续型特征都会用它自己的值表示，或者在进行离散后也表示成一个one-hot编码的向量。然后，每个样本都会被转换成$(x,y)$，其中$x = [x_{field_1},x_{field_2},\cdots, x_{field_j},\cdots,x_{field_m}]$是一个d维的向量，$x_{field_1}$是$\mathcal{X}$中第j个特征的向量表示。一般的，x是一个高维且极度稀疏的向量。CTR预估的任务就是构建一个预测模型$\hat y = CTR_model(x)$来预估在给定上下文的条件下一个用户点击某个app的概率。</p><h4 id="2-1-DeepFM"><a href="#2-1-DeepFM" class="headerlink" title="2.1 DeepFM"></a><strong>2.1 DeepFM</strong></h4><p>我们的目标是学习高阶和低阶的特征交叉项。为了做到这个，我们提出了基于神经网络的因式分解机（DeepFM）。如图1所示，DeepFM由两部分组成，<em>FM部分和deep部分</em>，二者共享同一输入层。对于特征i，一个标量$w_i$作为权重来表示其一阶的重要性，一个潜在的向量$V_i$用来衡量它与其他特征的交叉项的重要性。$V_i$被喂入FM部分取构建2阶的特征交叉项，同时也被喂入深度部分取构建高阶的特征交叉项。所有的参数，包括$w_i，V_i$和网络参数$(W^{(l)},b^{(l)})$都在合并的模型中进行联合训练的：</p><script type="math/tex; mode=display">\hat y = sigmoid(y_{FM}+y_{DNN})</script><p>其中，$\hat y \in (0,1)$是预测的CTR，$y_{FM}$是FM部分的输出结果，$y_{DNN}$是深度部分的输出结果。</p><p><img src="https://i.postimg.cc/657HJBcP/DeepFM-1.jpg" alt="DeepFM-1.jpg"></p><p><strong>FM部分</strong><br>FM部分是一个因式分解机，它是在[Rendle,2010]中提出来用在推荐中学习特征交叉项的。除了线性的（一阶）特征交叉项，FM还利用特征间的隐向量的内积构建了成对的（二阶）特征交叉项。相比于以前的方法，特别是在数据集很稀疏的时候它可以更有效地捕获到二阶特征交叉项。在以前的算法中，特征i和j组成的交叉项的参数只能在某一数据记录同时出现特征i和j的时候才能得到训练。而在FM模型中，它们会通过它们的隐含向量$V_i和V_j$的内积计算得到。得益于这种灵活的设计，无论i（或j）何时出现在数据记录中FM模型都能够训练隐含向量$V_i(V_j)$。因此，那些从不或者很少出现在训练数据中的特征交叉项可以有FM模型很好的学习到。</p><p><img src="https://i.postimg.cc/ZRKcfm0V/DeepFM-2.jpg" alt="DeepFM-2.jpg"></p><p>如图2所示，FM的输出是由一个累加单元加上一系列内几单元组成的：</p><script type="math/tex; mode=display">y_{FM} = <w,x> + \sum_{j_1 = 1}^d \sum_{j_2 = j_1 + 1}^d <V_i,V_j> x_{j_1} \cdot x_{j_2}</script><p>其中$w \in R^d 和 V_i \in R^k$（k是给定的）。累加单元$(<w,x>)$反映了一阶特征的重要性，内积单元代表了二阶特征交叉项的影响。</w,x></p><p><strong>Deep部分</strong><br><img src="https://i.postimg.cc/wxrVkSzQ/DeepFM-3.jpg" alt="DeepFM-3.jpg"></p><p>深度部分是一个前馈神经网络，通常是来学习高阶特征交叉项的。如图3所示，一条数据记录（一个向量）被喂入神经网络。相比于输入数据是图片或者音频的神经网络，即输入数据是连续且密集的，CTR预估模型的输入数据则大不相同，它要求一个新设计的网络结构。特别地，CTR预估的原始特征输入向量一般都是高度稀疏的、超高维度的、类别型和连续型混合的并且聚合到特征域的（例如性别，位置，年龄）。这表明嵌入层是在将数据输入到第一层隐含层之前将输入向量压缩到了一个低维且密集的实值向量，否则网路将无法进行训练。</p><p><img src="https://i.postimg.cc/yNKnZcKq/DeepFM-4.jpg" alt="DeepFM-4.jpg"></p><p>图4提取了输入层到嵌入层的子网络结构。我们能够之处这个网络结构中的两个有趣的特点：1）尽管不同输入特征域向量的长度不同，但是它们 的嵌入向量确实相同大小(k)的；2）FM中的隐含特征向量（V）是作为网络的权重，它们是学习到的用来将输入特征向量压缩成嵌入向量的。在论文[Zhang tw al., 2016]，V是由FM提前训练好的值来作为初始化的。在这里，不是使用FM的隐含特征向量来初始化网络，而是除了DNN模型外，我们是将FM模型作为我们整体学习框架中的一部分。如此，我们就不需要通过FM来提前训练了，相反我们是将整体的网络结构以端到端的方式来进行联合训练。将嵌入层的输出表示成：</p><script type="math/tex; mode=display">a^{(0)} = [e_1,e_2,...,e_m]</script><p>其中$e_i$是第i个特征的嵌入，m是特征的个数。然后，$a^{(0)}$是喂入到深度神经网络的，并且前向的过程是：</p><script type="math/tex; mode=display">a^{(l+1)} = \sigma(W^{(l)}a^{(l)} + b^{(l)})</script><p>其中l是网络的层数，$\sigma$是激活函数。$W^{(l)},a^{(l)}, b^{(l)}$分别是输出，模型权重和第l层的偏置项。之后，一个密集的实值特征向量就产生了，这最终会输入到CTR预估模型的sigmiod激活函数中去：$y_{DNN} = \sigma(W^{|H|+1} \cdot a^H + b^{|H|+1})$，其中$|H|$是隐含层的数量。</p><p>值得指出的是FM部分和deep部分共享同一特征嵌入层，这就带来了两个好处：1）可以从原始特征中同时学习了低阶和高阶的特征交叉项；2）不需要像Wide &amp; Deep一样在输入层上做专门的特征工程。</p><h4 id="2-2-与其他神经网络之间的关系"><a href="#2-2-与其他神经网络之间的关系" class="headerlink" title="2.2 与其他神经网络之间的关系"></a><strong>2.2 与其他神经网络之间的关系</strong></h4><p>受到深度学习在多种应用中取得巨大成功的影响，最近很多用来做CTR预估的深度模型被开发出来。这一部分将我们提出的DeepFM与其他现存的CTR预估深度模型进行比较。</p><p><img src="https://i.postimg.cc/28Bx928R/DeepFM-5.jpg" alt="DeepFM-5.jpg"></p><p><strong>FNN</strong>：如图5左侧所示，FNN是一个FM初始化的前馈神经网络模型[Zhang et al., 2016]。FM预训练的方法导致了两个限制：1）嵌入层的参数会由FM完全决定；2）引入的预训练步骤会使得模型的有效性降低。此外，FNN仅能捕获高阶的特征交叉项。相反，DeepFM不需预训练并且能够学习到高阶和低阶的特征交叉项。</p><p><strong>PNN</strong>：为了抓取高阶的特征交叉项，PNN在嵌入层和第一层隐含层之间强加了一个乘积层[Qu et al., 2016]。根据乘积运算的不同类型，又有三种不同的模型：IPNN,OPNN和PNN<em>，其中IPNN是基于向量内积的，OPNN是基于外积的，PNN</em>是基于内积和外积一起的。</p><p>为了使得计算更加有效，作者提出了一个内积和外积的近似计算：1）内积可以通过消除某些神经元来近似计算；2）外积可以通过将m个k维的特征向量压缩成一个k维的向量来近似计算。然而，我们发现外积相对于内积不太可靠，这是因为外积的这种近似计算会丢失很多信息使得结果不稳定。尽管内积相对比较可靠，它仍然需要很高的计算复杂度，因为乘积层的输出是与第一层隐含层所有的神经单元相连的。不同于PNN，DeepFM中的乘积层的输出仅与最终的输出层（一个神经元）相连。例如FNN，所有的PNN都忽略低阶特征交叉项。</p><p><strong>Wide &amp; Deep</strong>：Wide &amp; Deep（图5右侧所示）是由谷歌提出的来同时构建低阶和高阶特征交叉项的。如论文[Cheng te al., 2016]所示，它在“宽”部分部分的输入时需要专业的特征工程（例如，在app推荐中的用户安装的app和展示的app间的交叉特征）。相反，DeepFM不需要太多大额专业知识来处理输入层就可以直接地从原始特征中学习。</p><p>一个简单地扩展就是用FM替换这个模型中的LR部分（本文的第三部分我们也评估了这一扩展）。这个扩展类似于DeepFM，但是DeepFM在FM和deep部分之间共享了嵌入层。这种特征嵌入层共享的方法通过低阶和高阶特征交叉项影响了（以回传的方式）特征的表达，这就使得其可以更精确的构建特征表达。</p><p><img src="https://i.postimg.cc/tJ9N1jGh/Deep-FM-t1.jpg" alt="Deep-FM-t1.jpg"></p><p><strong>总结</strong>：综上所述，DeepFM和其他深度模型之间关系主要是表1中提到的4个方面。如我们所见，DeepFM是一个不需要预训练和特征工程的模型，并且能够抓取低阶和高阶的特征交叉项。</p><h3 id="3-实验"><a href="#3-实验" class="headerlink" title="3 实验"></a><strong>3 实验</strong></h3><p><strong>数据集</strong><br>我们基于以下两个数据集来评估我们提出的DeepFM模型的效果和效率：</p><p><strong>1) Criteo Dataset</strong>：Criteo Dataset包含4500万的用户点击记录，有13个连续型特征和26个类别型特征。我们将数据集随机得分为两部分：90%用来作为训练集，剩下的10%作为测试集。</p><p><strong>2)Company Dataset</strong>：为了验证DeepFM模型在真实的工业CTR预估中的表现，我们在Company Dataset数据集上进行了实验。我们从Company App Store的游戏中心收集了连续7天的的用户点击记录数据作为训练集，下一天的数据作为测试集。全部收集的数据集大概有10亿条记录。在这个数据集中，有应用的特征（例如名称和类型等等），用户特征（例如用户下载的应用等等），上下文特征（例如操作时间等等）。</p><p><strong>评估指标</strong><br>在我们的实验中主要使用两个评价指标：<strong>AUC</strong>和<strong>Logloss</strong>。</p><p><strong>模型比较</strong><br>我们在实验中比较了9个模型：<strong>LR, FM, FNN, PNN (三种变体), Wide &amp; Deep, 和 DeepFM.</strong>在Wide &amp; Deep模型中，为了消除特征工程的工作量，我们将原始的 Wide &amp; Deep 模型中宽部分的LR用FM来代替。为了区别 Wide &amp; Deep 的这两种变体模型，我们分别把它们命名为 LR &amp; DNN 和 FM &amp; DNN。</p><p><strong>参数设定</strong><br>为了在Criteo dataset数据集上评估模型，我们追随[Qu et al., 2016]中的FNN和PNN的参数设定：(1)dropout:0.5;(2)网络结构：400-400-400；（3）优化器：Adam；（4）激活函数：IPNN用tanh，其他的深度模型用relu。为了公平，我们的DeepFM模型使用同样的设定。LR和FM的优化器分别是FTRL和Adam，并且FM隐含的维度是10.</p><p>为了在公司的数据集上获得每个模型最好的效果，我们仔细地进行参数学习，会在3.3部分详细讨论。</p><h4 id="3-2-效果评估"><a href="#3-2-效果评估" class="headerlink" title="3.2 效果评估"></a><strong>3.2 效果评估</strong></h4><p>在这一部分，我们会评估3.1部分列出的模型，并且在两个数据集上对比它们的效果和效率。</p><p><strong>效率对比</strong><br><img src="https://i.postimg.cc/vmvhLT84/DeepFM-6.jpg" alt="DeepFM-6.jpg"></p><p>深度学习模型的销量在现实世界中是非常重要的。我们通过以下公式对比了各个模型在Criteo数据集上的效率表现：$\frac{|training time of deep CTR model|}{|training time of LR|}$。结果如图6所示，包含了在CPU（左侧）和GPU（右侧）上的测试结果，我们观察到了以下结果：1）FNN的预训练使其变得不是很有效率；2）尽管IPNN 和 PNN*在GPU上的表现要好于其他模型，但由于内积计算的操作使得他们仍然具有很高的计算成本；3）DeepFM几乎在所有的测试中表现地最有效率。</p><p><strong>效果对比</strong><br><img src="https://i.postimg.cc/prkYz6P3/Deep-FM-t2.jpg" alt="Deep-FM-t2.jpg"></p><p>不同CTR预估模型在Criteo和Company*的数据集上的表现如表2所示，我们可以得到如下观察结果：</p><ul><li>学习特征交叉项能够提升CTR预估模型的效果。这一发现实际上是来自于LR（它是唯一一个没有考虑特征交叉的模型）的表现要差于其他模型。对于Company* 和 Criteo数据集来说，DeepFM作为最好的模型其表现在AUC上要比LR分别高出0.86%和4.18%。</li><li>同时学习高阶和低阶的特征交叉项能够提高CTR预估模型的表现。DeepFM 模型的表现要好于那些仅仅学习低阶特征交叉项（例如FM）或者高阶特征交叉项（例如FNN, IPNN, OPNN, PNN*）的模型。相比于第二好的模型，DeepFM 在两个数据集上的AUC分别提升了0.37%和0.25%（Logloss 分别提升了0.42% 和0.29%）。</li><li>同时学习高阶和低阶的特征交叉项的时候，还共享特征的嵌入能够提高CTR预估模型的表现。DeepFM 的表现要好于那些在学习高阶和低阶特征交叉项的时候使用不同的特征嵌入的模型（例如LR &amp; DNN 和 FM &amp; DNN）。相比于这两个模型，在 Company* 和 Criteo 数据集上，DeepFM在AUC上要分别提升0.48%和0.33%（在Logloss上分别提升0.61%和0.66%）。</li></ul><p>总的来说，我们提出的 DeepFM 模型打败了其他的竞争者，在Company* 数据集上的AUC 和 Logloss分别提升了0.37%和0.42%。实际上，离线AUC评估指标的小改进很肯带来在线CTR的显著提升。如[Cheng et al., 2016]中所述，相比于LR，Wide &amp; Deep 将AUC提高了0.275%（离线），在线的CTR提高了3.9%。公司应用商店的每日流量价值百万美元，因此即使是几个百分点的CTR提升也能够带来每年百万美元的额外收入</p><h4 id="3-3-超参数研究"><a href="#3-3-超参数研究" class="headerlink" title="3.3 超参数研究"></a><strong>3.3 超参数研究</strong></h4><p>我们研究了在公司数据集上不同模型的不同超参数的影响力。顺序是：1）激活函数；2）dropout率；3）每层神经元个数；4）隐含层的层数；5）网络形状。</p><p><strong>激活函数</strong><br>根据[Qu et al., 2016]所述，在深度模型中<em>relu</em>和<em>tanh</em>是比<em>sigmoid</em>更适合的。再本文中，我们对比了深度模型在使用relu和tanh的效果。如图7所示，除了IPNN外，在所有的深度模型中relu都比tanh更加合适。可能的原因是relu降低了稀疏性。</p><p><img src="https://i.postimg.cc/Xqrgbgf5/DeepFM-7.jpg" alt="DeepFM-7.jpg"></p><p><strong>Dropout</strong><br>Dropout[Srivastava et al., 2014]是网络中一个神经元保留下来的概率。Dropout 是一种用来折中神经网络的准确度和复杂度的正则技术。我们分别尝试了dropout在1.0,0.9,0.8,0.7,0.6,0.5下的效果。如图8所示，所有的模型当它们的dropout提前设定好的时候（0.6到0.9）都取得了它们最好的表现。结果表明往模型中加入一些合理的随机性能够增强模型的稳健性。</p><p><img src="https://i.postimg.cc/sX6JqLhy/DeepFM-8.jpg" alt="DeepFM-8.jpg"></p><p><strong>每层的神经网络个数</strong><br>当其他因素保持一致的时候，增加每一层的神经元个数会引入更高的复杂度。正如我们从图9可以观察到的，增加每一层的神经元个数并不总是能够带来收益。例如，当每一层神经元的个数从400增加到800的时候，DeepFM 的表现趋于稳定；更糟的是，当我们把神经元车上从400增加到800的时候OPNN表现反尔变差了。这是因为过度复杂的模型容易造成过拟合。在我们的数据集中，每一层设定200-400神经元是一个不错的选择。</p><p><img src="https://i.postimg.cc/7hjnYT9W/DeepFM-9.jpg" alt="DeepFM-9.jpg"></p><p><strong>隐含层的个数</strong><br>如图10所呈现的，增加隐含层的个数在一开始能够提高模型的表现，然而，如果层数一直增加他们的表现则会逐渐变差。这种现象一版也是由于过拟合造成的。</p><p><img src="https://i.postimg.cc/HxxwwtPN/Deep-FM-10.jpg" alt="Deep-FM-10.jpg"></p><p><strong>网络形状</strong><br>我们测试了4种网络形状：不变、增长、减小和菱形。当我们改变网络的结构，我们会固定隐含层的个数以及总神经元的个数。例如，当隐含层数量是3且总神经元个数是600的时候，四中网络形状是：不变（200-200-200），增长（100-200-300），减小（300-200-100）和菱形（150-300-150）。正如从图11中可以看到，“不变”的网络形状一般要好于其他三种形状，这也与之前的研究保持了一致性[Larochelle et al., 2009]。</p><p><img src="https://i.postimg.cc/g04yL74R/Deep-FM-11.jpg" alt="Deep-FM-11.jpg"></p><h3 id="4-相关工作"><a href="#4-相关工作" class="headerlink" title="4 相关工作"></a><strong>4 相关工作</strong></h3><p>在这篇文章，我们提出了一个新的深度学习网络结构用来做CTR预估。最相关的领域就是推荐系统中的CTR预估和深度学习。在这一部分，我们讨论一下这两个领域的相关工作。</p><p>CTR预估在推荐系统是特别地重要。除了一般的线性模型和FM，还有一些其他的模型会被用来做CTR预估，例如基于树，基于张量的模型，支持向量机，以及贝叶斯模型。</p><p>其他相关的领域就是推荐系统中的深度学习了。在第1部分和第2.2部分，我们已经提到了几个用来做CTR预估的深度学习模型，因此在这里我们不再讨论它们。一些深度模型一般会被用于推荐任务而不是CTR预估。[Salakhutdinov et al., 2007; Sedhain et al., 2015; Wang et al., 2015]提出通过深度学习来改进协同过滤。[Wang andWang, 2014; van den Oord et al., 2013]的作者通过深度学习来提取一些满意的特征用于改进音乐推荐。[Chen et al., 2016]设计了一个深度学习网路用来构建广告展示中的图片特征和基础特征。[Covington et al., 2016]开发了一个两部神经网络框架用来做YouTube的视频推荐。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a><strong>结论</strong></h3><p>在本文中，我们提出了DeepFM模型，是一个基于神经网络的因式分解机用来做CTR预估，克服了当前最先进模型的缺点并获得了一个更好的表现。DeepFM 是联合训练了一个深度部分和FM部分。它是通过以下几个优势获得了更好地表现：1）它不需要任何预训练；2）它能够同时学习高阶和低阶的特征交叉项；3）它引入了一个特征嵌入层共享的策略来避免特征工程。我们在两个实际数据集上进行了大量的实验来比较DeepFM和最先进模型之间的效果和效率。我们的实验结果表名了：1）DeepFM在两个数据集上的AUC和Logloss的表现都要好于最先进的模型；2）DeepFM相比于当下最先进有效的深度模型而言要更有效率。</p><p>在未来的研究中有两个有趣的方向。一个是探索一些策略（例如引入pooling层）来增强学习更有用的高阶特征交叉项。另一个就是在GPU集群上训练DeepFM来解决大规模数据的问题。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.04247.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：DeepFM:A Factorization-Machine based Neural Network for CTR Prediction&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;DeepFM-基于神经网络的因式分解机做点击率预估&quot;&gt;&lt;a href=&quot;#DeepFM-基于神经网络的因式分解机做点击率预估&quot; class=&quot;headerlink&quot; title=&quot;DeepFM:基于神经网络的因式分解机做点击率预估&quot;&gt;&lt;/a&gt;DeepFM:基于神经网络的因式分解机做点击率预估&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;对于推荐系统中的最大化CTR来说，学习那些用户行为背后的复杂而精确的特征交叉项是至关重要的。尽管有很大的提升，但是方法似乎在低阶或者高阶的交差项上带有很强的偏置项，又或者会要求专业性的特征工程。在这篇文章，我们会展示可以构造出一个端到端的学习模型，特别是对于低阶和高阶的交叉项的学习。DeepFM，提出的这个模型联合了因式分解机的推荐能力和一个新的神经网络结构在特征方面的深度学习能力。相比于Google提出的最新的Wide &amp;amp; Deep模型，DeepFM的“wide”和“deep”部分有一个共享输入层，并且除了最原始的特征不需要额外的特征工程。综合性的实验结果证明了DeepFM相比于其他的CTR模型在基础数据及和商业数据集上都有着更好的效果和效率。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="推荐" scheme="https://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="排序" scheme="https://www.xiemingzhao.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="CTR预估" scheme="https://www.xiemingzhao.com/tags/CTR%E9%A2%84%E4%BC%B0/"/>
    
      <category term="神经网络" scheme="https://www.xiemingzhao.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="DeepFM" scheme="https://www.xiemingzhao.com/tags/DeepFM/"/>
    
  </entry>
  
  <entry>
    <title>LTR信息检索评价指标</title>
    <link href="https://www.xiemingzhao.com/posts/5fb7303d.html"/>
    <id>https://www.xiemingzhao.com/posts/5fb7303d.html</id>
    <published>2019-06-26T16:00:00.000Z</published>
    <updated>2019-09-21T06:27:40.072Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-RP"><a href="#1-RP" class="headerlink" title="1 RP"></a>1 RP</h2><p>R（recall）表示召回率、查全率，指查询返回结果中相关文档占所有相关文档的比例；P（precision）表示准确率、精度，指查询返回结果中相关文档占所有查询结果文档的比例。假设有如下的混淆矩阵：</p><div class="table-container"><table><thead><tr><th style="text-align:center">—-</th><th style="text-align:center">Predict P</th><th style="text-align:center">Predict N</th></tr></thead><tbody><tr><td style="text-align:center">Target P</td><td style="text-align:center">TP</td><td style="text-align:center">FN</td></tr><tr><td style="text-align:center">Target N</td><td style="text-align:center">FP</td><td style="text-align:center">TN</td></tr></tbody></table></div><a id="more"></a><p>正确率、召回率（查全率）、精准度、$F_{\beta}$ score、假阳率以及真阳率：</p><script type="math/tex; mode=display">Accuracy = \frac{TP+FN}{TP+TN+FP+FN}</script><script type="math/tex; mode=display">Recall=\frac{TP}{TP+FN}</script><script type="math/tex; mode=display">Precision=\frac{TP}{TP+FP}</script><script type="math/tex; mode=display">F_{\beta}=(1+\beta^2) \cdot \frac{Precision \cdot Recall}{\beta^2 \cdot Precision + Recall}</script><p>其中，F-Score/F-measure 作为综合指标，平衡 recall 和 precision 的影响，较为全面的评价一个模型。F1-Score 表示准确率和召回率一样重要；F2-Score 表示召回率比准确率重要一倍；F0.5-Score 表示准确率比召回率重要一倍。</p><script type="math/tex; mode=display">FPR=\frac{FP}{FP+TN}</script><script type="math/tex; mode=display">TPR=\frac{TP}{TP+FN}</script><p><img src="https://i.postimg.cc/XX64QYxH/AUC.png" alt="AUC.png"></p><p>其中：<br>假阳率FPR=ROC曲线的X轴指标<br>真阳率TPR=ROC曲线的Y轴指标=召回率<br>AUC值就是曲线右下部分面积。</p><h2 id="2-MAP"><a href="#2-MAP" class="headerlink" title="2 MAP"></a>2 MAP</h2><p><img src="https://i.postimg.cc/28dVMsvb/PR.jpg" alt="PR.jpg"><br>如上图的PR曲线，对其进行积分求曲线下方的面积，就是AP(Average Precision)，即</p><script type="math/tex; mode=display">AP=\int_0^1 p(r) dr</script><p>其中，p 表示 precision，r 表示 recall，p 是一个以 r 为参数的函数，AP 的计算是对排序位置敏感的，相关文档排序的位置越靠前，检索出相关的文档越多，AP 值越大。</p><p>近似计算约等于 AAP（Aproximate Average Precision）：</p><script type="math/tex; mode=display">AAP=\sum_{k=1}^Np(k)\Delta r(k)=\frac{\sum_{k=1}^Np(k) \cdot rel(k)}{number Of Relevant Documents}</script><p>其中，N 代表所有相关文档的总数，p(k) 表示能检索出 k 个相关文档时的 precision 值，而 △r(k) 则表示检索相关文档个数从 k-1 变化到 k 时（通过调整阈值）recall 值的变化情况。<br>rel(k) 表示第 k 个文档是否相关，若相关则为1，否则为0，则可以简化公式为：</p><script type="math/tex; mode=display">AP=\frac{1}{N} \cdot \sum_{i=1}^N\frac{i}{position(i)}</script><p>其中，N 表示相关文档总数，position(i) 表示第 i 个相关文档在检索结果列表中的位置。</p><p>MAP（Mean Average Precision）即多个查询的平均正确率（AP）的均值，从整体上反映模型的检索性能。</p><p>下面举一个例子来说明上述公式的计算：<br>查询 query1 对应总共有4个相关文档，查询 query2 对应总共有5个相关文档。当通过模型执行查询1、2时，分别检索出4个相关文档（Rank=1、2、4、7）和3个相关文档（Rank=1、3、5）。<br>则 query1AP=(1/1+2/2+3/4+4/7)/4=0.83，query2AP=(1/1+2/3+3/5+0+0)/5=0.45，最后 MAP=(0.83+0.45)/2=0.64。</p><h2 id="3-NDCG"><a href="#3-NDCG" class="headerlink" title="3 NDCG"></a>3 NDCG</h2><h3 id="3-1-CG-Cumulative-Gain-累计效益"><a href="#3-1-CG-Cumulative-Gain-累计效益" class="headerlink" title="3.1 CG(Cumulative Gain)累计效益"></a>3.1 CG(Cumulative Gain)累计效益</h3><script type="math/tex; mode=display">CG@k=\sum_{i=1}^k rel_i</script><p>其中 k 表示 k 个文档组成的集合，rel 表示第 i 个文档的相关度，例如相关度分为以下几个等级：</p><div class="table-container"><table><thead><tr><th style="text-align:center">Relevance Rating</th><th style="text-align:center">Value</th></tr></thead><tbody><tr><td style="text-align:center">Perfect</td><td style="text-align:center">5</td></tr><tr><td style="text-align:center">Excellent</td><td style="text-align:center">4</td></tr><tr><td style="text-align:center">Good</td><td style="text-align:center">3</td></tr><tr><td style="text-align:center">Fair</td><td style="text-align:center">2</td></tr><tr><td style="text-align:center">Simple</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">Bad</td><td style="text-align:center">0</td></tr></tbody></table></div><h3 id="3-2-DCG-Discounted-Cumulative-Gain"><a href="#3-2-DCG-Discounted-Cumulative-Gain" class="headerlink" title="3.2 DCG(Discounted Cumulative Gain)"></a>3.2 DCG(Discounted Cumulative Gain)</h3><p>在 CG 的计算中没有考虑到位置信息，例如检索到三个文档的相关度依次为（3，-1，1）和（-1，1，3），根据 CG 的计算公式得出的排名是相同的，但是显然前者的排序好一些。</p><p>所以需要在 CG 计算的基础上加入位置信息的计算，现假设根据位置的递增，对应的价值递减，为 1/log2(i+1)，其中 log2(i+1) 为折扣因子；</p><script type="math/tex; mode=display">DCG@k=\sum_{i=1}^k \frac{rel_i}{log_2 (i+1)}</script><p>另一种增加相关度影响比重的 DCG 计算公式：</p><script type="math/tex; mode=display">DCG@k=\sum_{i=1}^k \frac{2^{rel_i}-1}{log_2 (i+1)}</script><h3 id="3-3-IDCG-idea-DCG"><a href="#3-3-IDCG-idea-DCG" class="headerlink" title="3.3 IDCG(idea DCG)"></a>3.3 IDCG(idea DCG)</h3><p>理想情况下，按照相关度从大到小排序，然后计算 DCG 可以取得最大值情况。</p><script type="math/tex; mode=display">IDCG@k=\sum_{i=1}^{|REL|} \frac{2^{rel_i}-1}{log_2 (i+1)}</script><p>其中 |REL| 表示文档按照相关度从大到小排序，取前 k 个文档组成的集合。就是按理想排序情景的前k个。</p><h3 id="3-4-NDCG-Normalized-DCG"><a href="#3-4-NDCG-Normalized-DCG" class="headerlink" title="3.4 NDCG(Normalized DCG)"></a>3.4 NDCG(Normalized DCG)</h3><p>由于每个查询所能检索到的结果文档集合长度不一致，k 值的不同会影响 DCG 的计算结果。所以不能简单的对不同查询的 DCG 结果进行平均，需要先归一化处理。</p><p>NDCG 就是利用 IDCG 进行归一化处理，表示当前的 DCG 与理想情况下的 IDCG 相差多大：</p><script type="math/tex; mode=display">NDCG@k=\frac{DCG@k}{IDCG@K}</script><p>这样每个查询的 NDCG 均在 0-1 范围内，不同查询之间就可以进行比较，求取多个查询的平均 NDCG。</p><h2 id="4-ERR"><a href="#4-ERR" class="headerlink" title="4 ERR"></a>4 ERR</h2><h3 id="4-1-PR-reciprocal-rank"><a href="#4-1-PR-reciprocal-rank" class="headerlink" title="4.1 PR(reciprocal rank)"></a>4.1 PR(reciprocal rank)</h3><p>倒数排名，指检索结果中第一个相关文档的排名的倒数。</p><script type="math/tex; mode=display">RR=\frac{1}{rank_i}</script><h3 id="4-2-MRR-mean-reciprocal-rank"><a href="#4-2-MRR-mean-reciprocal-rank" class="headerlink" title="4.2 MRR(mean reciprocal rank)"></a>4.2 MRR(mean reciprocal rank)</h3><p>多个查询的倒数排名的均值，公式如下：</p><script type="math/tex; mode=display">MRR=\frac{1}{|N|} \sum_{i=1}^{|N|} \frac{1}{rank_i}</script><p>ranki 表示第 i 个查询的第一个相关文档的排名。</p><h3 id="4-3-Cascade-Model-瀑布模型"><a href="#4-3-Cascade-Model-瀑布模型" class="headerlink" title="4.3 Cascade Model(瀑布模型)"></a>4.3 Cascade Model(瀑布模型)</h3><p>点击模型中的瀑布模型，考虑到在同一个检索结果列表中各文档之间的位置依赖关系，假设用户从上至下查看，如果遇到某一检索结果项满意并进行点击，则操作结束；否则跳过该项继续往后查看。第 i 个位置的文档项被点击的概率为：</p><script type="math/tex; mode=display">P(C_i)=r_i \prod_{j=1}^{i-1} (1-r_j)</script><p>其中 ri 表示第 i 个文档被点击的概率，前 i-1 个文档则没有被点击，概率均为 1-rj；</p><h3 id="4-4-ERR-Expected-reciprocal-rank"><a href="#4-4-ERR-Expected-reciprocal-rank" class="headerlink" title="4.4 ERR(Expected reciprocal rank)"></a>4.4 ERR(Expected reciprocal rank)</h3><p>预期的倒数排名，表示用户的需求被满足时停止的位置的倒数的期望，与 RR 计算第一个相关文档的位置倒数不同。<br>首先用户在位置 r 处停止的概率 PPr 计算公式如下：</p><script type="math/tex; mode=display">PP_r=\prod_{i=1}^{r-1}(1-R_i) R_r</script><p>其中 Ri 是关于文档相关度等级的函数，现假设该函数为：</p><script type="math/tex; mode=display">R_i=R(g_i)=\frac{2^g-1}{2^{g_max}}</script><p>当文档是不相关的（g=0），则用户检索到相关文档的概率为0；而当文档极其相关（g=4，如果相关度划分5个等级）时，用户检索到相关文档的概率接近于1。上面公式中的 g 表示文档的相关度，参考 NDCG 中的 rel。</p><p>更通用一点来讲，ERR 不一定是计算用户需求满足时停止的位置的倒数的期望，它可以是基于位置的函数</p><script type="math/tex; mode=display">ERR=\sum_{r=1}^n \varphi(r)P Pr=\sum_{r=1}^n \frac{1}{r} P Pr=\sum_{r=1}^n \frac{1}{r} \prod_{i=1}^{r-1}(1-R_i)R_r</script><p>可以看出，当 φ(r)=1/r 时就是 ERR，当 φ(r)=1/log2(r+1) 就是DCG。</p><p><a href="https://www.cnblogs.com/memento/p/8673309.html" target="_blank" rel="noopener">参考文章:https://www.cnblogs.com/memento/p/8673309.html</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-RP&quot;&gt;&lt;a href=&quot;#1-RP&quot; class=&quot;headerlink&quot; title=&quot;1 RP&quot;&gt;&lt;/a&gt;1 RP&lt;/h2&gt;&lt;p&gt;R（recall）表示召回率、查全率，指查询返回结果中相关文档占所有相关文档的比例；P（precision）表示准确率、精度，指查询返回结果中相关文档占所有查询结果文档的比例。假设有如下的混淆矩阵：&lt;/p&gt;
&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;—-&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Predict P&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Predict N&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Target P&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;TP&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;FN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Target N&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;FP&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;TN&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="排序" scheme="https://www.xiemingzhao.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="LTR" scheme="https://www.xiemingzhao.com/tags/LTR/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客提交链接到搜索引擎来收录</title>
    <link href="https://www.xiemingzhao.com/posts/HexoblogSE.html"/>
    <id>https://www.xiemingzhao.com/posts/HexoblogSE.html</id>
    <published>2019-06-14T16:00:00.000Z</published>
    <updated>2019-11-10T09:35:13.647Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>博客的搭建和个性化可以参考我的其他文章<a href="https://www.xiemingzhao.com/tags/Hexo/">Hexo搭建博客汇总</a>。当你博客搭建完毕后，如果不能被人搜索得到，心里难免会有些失落。所以，接下来我们介绍 Google 和百度收录博客网站的方法。整体来说，Google 实在是太效率了，收录操作不仅简单且迅速，基本一个小时内就可以检索了。相比之下，百度搜索则鸡肋的很，不仅操作繁杂，而且及时操作成功了收录成功与否还去取决于网站质量以及其其他原因。</p><p><strong>首先如何检测自己的博客能否被检索呢？</strong><br>在百度或者Google的搜索框内输入以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">site:www.xiemingzhao.com</span><br></pre></td></tr></table></figure><p>将<code>site:</code>后面的网址改为你自己的博客地址就行了，如果在搜索结果中能够展示自己博客的页面，那么就说已经被收录且可被搜索到。反之，则没有被收录。</p><h2 id="Google-收录"><a href="#Google-收录" class="headerlink" title="Google 收录"></a>Google 收录</h2><p>搜索网站的收录，其实就是将网站里各个网页对应的连接收录。所以，有一个东西就叫做站点地图，顾名思义，就是将自己网站下所有的页面集中到一起。</p><h3 id="安装站点地图"><a href="#安装站点地图" class="headerlink" title="安装站点地图"></a>安装站点地图</h3><p>我们需要安装以下插件来生成站点地图：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-sitemap --save</span><br><span class="line">npm install hexo-generator-baidu-sitemap --save</span><br></pre></td></tr></table></figure><p>可以看得出来，上面包含两个工具包，因为后面也是进行百度收录，而百度的站点地图格式与Google是有差异的，所以一次性将这两个全都安装了。</p><p>然后我们打开站点配置文件，找到或者添加如下的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#hexo sitemap</span><br><span class="line">sitemap:</span><br><span class="line">  path: sitemap.xml</span><br><span class="line">baidusitemap:</span><br><span class="line">  path: baidusitemap.xml</span><br></pre></td></tr></table></figure><p><em>实际上，在操作中发现只要保留上面的<code>sitemap</code>配置，省略下面的也能生成两个</em></p><p>到此，后面再部署博客的时候，你会发现<code>public</code>目录下面多了 <code>sitemap.xml</code> 和 <code>baidusitemap.xml</code> 两个文件，同样的在线上也可添加这个页面，例如我的就是<a href="https://www.xiemingzhao.com/sitemap.xml">我的站点地图</a>。</p><blockquote><p>注意：</p><ol><li>插件生成的 sitemap 的文章链接，都是以站点配置文件中的 url 为基础的，如果将博客绑定了域名，那最好将 url 字段填写为绑定的域名。</li><li>不想生成 sitemap 的页面，可在页面最上方以 —- 分割的区域内，即 Front-matter 中，添加代码 sitemap: false。</li></ol></blockquote><h3 id="添加-robots-txt"><a href="#添加-robots-txt" class="headerlink" title="添加 robots.txt"></a>添加 robots.txt</h3><blockquote><p>robots.txt（统一小写）是一种存放于网站根目录下的 ASCII 编码的文本文件，它通常告诉网络搜索引擎的漫游器（又称网络蜘蛛），此网站中的哪些内容是不应被搜索引擎的漫游器获取的，哪些是可以被漫游器获取的。</p></blockquote><p>在 <code>source</code> 目录下增加 <code>robots.txt</code> 文件， 我的文件具体内容如下可供参考，注意将域名改为自己的网站：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">User-agent: *</span><br><span class="line">Allow: /</span><br><span class="line">Allow: /archives/</span><br><span class="line">Allow: /tags/</span><br><span class="line">Allow: /categories/</span><br><span class="line">Allow: /about/</span><br><span class="line">Allow: /guestbook/</span><br><span class="line">Allow: /others/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disallow: /js/</span><br><span class="line">Disallow: /css/</span><br><span class="line">Disallow: /lib/</span><br><span class="line"></span><br><span class="line">Sitemap: https://www.xiemingzhao.com/sitemap.xml</span><br><span class="line">Sitemap: https://www.xiemingzhao.com/baidusitemap.xml</span><br></pre></td></tr></table></figure><p>这样在下次部署博客时，<code>robots.txt</code> 就会被上传至网站了。稍后我们在提交 <code>sitemap</code> 时，可以顺便测试它是否被搜索引擎正确解析了。</p><h3 id="提交站点到-Google"><a href="#提交站点到-Google" class="headerlink" title="提交站点到 Google"></a>提交站点到 Google</h3><p>我们打开<a href="https://www.google.com/webmasters/tools/home?hl=zh-CN" target="_blank" rel="noopener">Google 的站点平台</a>。你会看到如下页面，紧接着就是注册和登录，你有账号的话直接登录都可以。</p><p><img src="https://i.postimg.cc/xjJ40fbg/se1.jpg" alt="se1"></p><p>紧接着，点击左上角的<code>添加资源</code>，开始验证自己的博客网站，你会看到如下页面，这里建议选择第二个，直接诸如博客站点的主链接就行了，例如我的就是<code>https://www.xiemingzhao.com</code>。点击继续后，需要你做一个很简单的验证方式，那就是将验证<code>html</code>文件下周下来之后放到自己博客站点的根目录上，然后可以部署一下。</p><p><img src="https://i.postimg.cc/26J94Jg4/se2.jpg" alt="se2"></p><p>之后回到验证的页面，点击验证即可，验证程刚后，就可以对你的博客站点进行站点地图的提交了。我们点击左侧的<code>站点地图</code>选项，你会看到如下的页面，在这里输入前面构建好的<code>sitemap</code>的地址再提交就可以了。</p><p><img src="https://i.postimg.cc/jjMFjCX3/se3.jpg" alt="se3"></p><p>到这里就完成了 Google 的检索收录，是不是超级简单。稍等一段时间，就可以去Google上面进行测试自己的博客站点，我的在一个小时内就已经能够检索到了。</p><h2 id="百度的收录"><a href="#百度的收录" class="headerlink" title="百度的收录"></a>百度的收录</h2><p>百度的收录相比对Google要复杂的多，首先需要注册<a href="https://ziyuan.baidu.com" target="_blank" rel="noopener">百度站长平台</a>。目前，账号需要绑定熊掌号才可以，因为熊掌号是百度的资源实名认证和管理的方法，不过对于我们来说确实麻烦了好多。这一些都很简单，就是费一些时间，当你实名认证并且绑定好账号之后，让我们开始下面的提交收录。</p><p>这里附上<a href="https://ziyuan.baidu.com/college/courseinfo?id=267&amp;page=2" target="_blank" rel="noopener">百度站长工具平台使用帮助手册</a>，如果你有兴趣深入研究，可以仔细研究一下这个手册，里面基本上包含了各种坑的解决方法，缺点就是繁琐。</p><h3 id="验证网站"><a href="#验证网站" class="headerlink" title="验证网站"></a>验证网站</h3><p>首先需要的就是验证网站，我们进入<a href="https://ziyuan.baidu.com/site/siteadd" target="_blank" rel="noopener">站点管理</a>，添加自己的博客站点地址，然后一步一步往下点，会有一些让你选择与你博客有关系的问题，客观的选择就可以了。</p><p>直到最后一步，网站的验证，如下所示，百度的验证有很多种方案，但我们跟上述Google一样，选择文件验证，方便又高效，下载对应的<code>html</code>文件，放入博客的根目录，部署后，访问一下试试，可以的话，回到验证页面，点击验证即可完成，基本上没什么难度。</p><blockquote><p>百度站长平台提供三种验证方式（百度统计的导入方式已下线）：文件验证、html标签验证、CNAME验证。<br>1.文件验证：您需要下载验证文件，将文件上传至您的服务器，放置于域名根目录下。<br>2.html标签验证：将html标签添加至网站首页html代码的<head><meta name="generator" content="Hexo 3.9.0">标签与</head>标签之间。<br>3.CNAME验证：您需要登录域名提供商或托管服务提供商的网站，添加新的DNS记录。</p></blockquote><h3 id="链接提交"><a href="#链接提交" class="headerlink" title="链接提交"></a>链接提交</h3><p>接下来最终要就是这一步，但也是最复杂方法最多的，不着急我们慢慢来。首先，进入站长平台，然后进入<code>网页抓取</code>目录下的<code>链接提交</code>页面，我们可以看到如下图，数据提交方式下面紧邻的是提交连接数量，目前你可得是没有的。再往下，你会发现有两个模块，分别是<code>自动提交</code>和<code>手动提交</code>。</p><p>其中收到提交点击去可以发现是需要你将你需要被检索的网站一个一个的列出来才行，这种笨方法当然不是我们要选择的。让我们回来看自动提交下面，分为三种方法，其中主动推送(实时)又分为四中示例，整个结构如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">链接提交：</span><br><span class="line">    手动提交</span><br><span class="line">    自动提交：</span><br><span class="line">        主动推送（实时）：</span><br><span class="line">            curl推送</span><br><span class="line">            post推送</span><br><span class="line">            php推送</span><br><span class="line">            ruby推送</span><br><span class="line">        自动推送</span><br><span class="line">        sitemap</span><br></pre></td></tr></table></figure><p><img src="https://i.postimg.cc/J0k6KxWS/se4.jpg" alt="se4"></p><h3 id="sitemap-提交"><a href="#sitemap-提交" class="headerlink" title="sitemap 提交"></a>sitemap 提交</h3><p>在上面，我们已经构建了<code>baidusitemap</code>了，在这里当然要使用了。我们选择自动提交中的<code>sitemap</code>，输入自己的<code>baidusitemap.xml</code>链接即可，一般都是自己的域名加上这个，例如我的就是<a href="https://www.xiemingzhao.com/baidusitemap.xml">https://www.xiemingzhao.com/baidusitemap.xml</a>。提交完成后可查看是否成功。</p><blockquote><p>注意：和谷歌不同，百度翻译速度很慢，而且百度提交了链接也不一定收录，要不断提升文章质量和数量才行。</p></blockquote><h3 id="百度相关的搜索配置"><a href="#百度相关的搜索配置" class="headerlink" title="百度相关的搜索配置"></a>百度相关的搜索配置</h3><p>由于 GitHub 屏蔽了百度的爬虫，即使提交成功，百度知道这里有可供抓取的链接，也不一定能抓取成功。首先我们先检测一下百度爬虫是否可以抓取网页。在百度站长平台<code>网页抓取</code>-&gt;<code>抓取诊断</code> 中，选择<code>PC UA</code>点击抓取，查看抓取状态，如果显示<code>抓取失败</code>，则需要进一步的配置。</p><p>可以测试一下<code>移动 UA</code>，因为一般这个一定是会成功的。</p><h3 id="主动推送和自动推送"><a href="#主动推送和自动推送" class="headerlink" title="主动推送和自动推送"></a>主动推送和自动推送</h3><p>我们讲过，百度<code>sitemap</code>的提交不一定能够成功，而且即使成功效率也低。百度本身也不提倡，所以还有另两种方案。</p><p>在前面提到的百度站长手册中，有讲解这一切，包括如何选择链接提交方式</p><blockquote><p>1、主动推送：最为快速的提交方式，推荐您将站点当天新产出链接立即通过此方式推送给百度，以保证新链接可以及时被百度收录。<br>2、自动推送：最为便捷的提交方式，请将自动推送的 JS 代码部署在站点的每一个页面源代码中，部署代码的页面在每次被浏览时，链接会被自动推送给百度。可以与主动推送配合使用。<br>3、sitemap：您可以定期将网站链接放到 sitemap 中，然后将 sitemap 提交给百度。百度会周期性的抓取检查您提交的 sitemap，对其中的链接进行处理，但收录速度慢于主动推送。<br>4、手动提交：一次性提交链接给百度，可以使用此种方式</p></blockquote><h4 id="自动推送"><a href="#自动推送" class="headerlink" title="自动推送"></a>自动推送</h4><p>next 主题已经部署了自动推送的代码，我们只需在主题配置文件 中找到 <code>baidu_push</code> 字段 , 设置其为 true 即可。</p><h4 id="主动推送（实时）"><a href="#主动推送（实时）" class="headerlink" title="主动推送（实时）"></a>主动推送（实时）</h4><p>这个方案好处在于成功率大，且具有实时性。可以参考这篇文章<a href="https://hui-wang.info/2016/10/23/Hexo%E6%8F%92%E4%BB%B6%E4%B9%8B%E7%99%BE%E5%BA%A6%E4%B8%BB%E5%8A%A8%E6%8F%90%E4%BA%A4%E9%93%BE%E6%8E%A5/" target="_blank" rel="noopener"> Hexo 插件之百度主动提交链接</a>。</p><p><img src="https://i.postimg.cc/1t4YVP7m/se5.jpg" alt="se5"></p><p>首先我们在如上图中找到自己的秘钥，保存留用。紧接着，我们需要安装以下插件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-baidu-url-submit --save</span><br></pre></td></tr></table></figure></p><p>然后，同样在根目录下，把以下内容配置到_config.yml文件中:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">baidu_url_submit:</span><br><span class="line">  count: 1 ## 提交最新的一个链接</span><br><span class="line">  host: www.hui-wang.info ## 在百度站长平台中注册的域名</span><br><span class="line">  token: your_token ## 请注意这是您的秘钥， 所以请不要把博客源代码发布在公众仓库里!</span><br><span class="line">  path: baidu_urls.txt ## 文本文档的地址， 新链接会保存在此文本文档里</span><br></pre></td></tr></table></figure><p>其次，记得查看_config.ym文件中url的值，必须包含是百度站长平台注册的域名（一般有www）， 比如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># URL</span><br><span class="line">url: http://www.hui-wang.info</span><br><span class="line">root: /</span><br><span class="line">permalink: :year/:month/:day/:title/</span><br></pre></td></tr></table></figure><p>最后，加入新的deployer:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">- type: s3 ## 这是我原来的deployer</span><br><span class="line">  bucket: hui-wang.info</span><br><span class="line">- type: baidu_url_submitter ## 这是新加的</span><br></pre></td></tr></table></figure><p>执行hexo deploy的时候，新的连接就会被推送了。</p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>推送功能的实现，分为两部分：</p><ul><li>新链接的产生， hexo generate 会产生一个文本文件，里面包含最新的链接</li><li>新链接的提交， hexo deploy 会从上述文件中读取链接，提交至百度搜索引擎</li></ul><blockquote><p>注意：</p><ol><li>百度每天主动提交的链接数量是有限制的。<br>（主动推送可提交的链接数量上限是根据您提交的新产生有价值链接数量而决定的，百度会根据您提交数量的情况不定期对上限额进行调整，提交的新产生有价值链接数量越多，可提交链接的上限越高。）</li><li>主动推送是否成功会在执行 hexo deploy 时显示, success后的数字为主动推送成功的链接数。</li></ol></blockquote><p><strong>附录</strong><br>其实，这些提交方法可以混合使用，最痛苦的是，及时提交成功了，要等好久也不知道自己的博客能否被收录。所以百度收录真的很鸡肋，比较注重网站的质量。</p><p>于是催生了另一种方案，那就是在 <code>Coding.net</code> 上进行镜像部署。这是利用 Coding.net 提供的 Coding Pages 功能另外部署一个镜像，让百度爬虫访问此镜像，普通用户还是访问位于 Github Pages 的页面。具体的这里就不在介绍，可以参考夏明额参考文章或者其他博主的文章。</p><p><strong>参考文章</strong><br><a href="http://www.yuan-ji.me/Hexo-%E4%BC%98%E5%8C%96%EF%BC%9A%E6%8F%90%E4%BA%A4sitemap%E5%8F%8A%E8%A7%A3%E5%86%B3%E7%99%BE%E5%BA%A6%E7%88%AC%E8%99%AB%E6%8A%93%E5%8F%96-GitHub-Pages-%E9%97%AE%E9%A2%98/" target="_blank" rel="noopener">Hexo 优化：提交 sitemap 及解决百度爬虫无法抓取 GitHub Pages 链接问题</a><br><a href="https://www.jianshu.com/p/1ff2fcbdd155" target="_blank" rel="noopener">Hexo博客第三方主题next进阶教程</a><br><a href="https://hui-wang.info/2016/10/23/Hexo%E6%8F%92%E4%BB%B6%E4%B9%8B%E7%99%BE%E5%BA%A6%E4%B8%BB%E5%8A%A8%E6%8F%90%E4%BA%A4%E9%93%BE%E6%8E%A5/" target="_blank" rel="noopener">Hexo插件之百度主动提交链接</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;博客的搭建和个性化可以参考我的其他文章&lt;a href=&quot;https://www.xiemingzhao.com/tags/H
      
    
    </summary>
    
    
      <category term="博客搭建" scheme="https://www.xiemingzhao.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="Hexo" scheme="https://www.xiemingzhao.com/tags/Hexo/"/>
    
      <category term="网站收录" scheme="https://www.xiemingzhao.com/tags/%E7%BD%91%E7%AB%99%E6%94%B6%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>Wide and Deep Learning for Recommender Systems (论文解析)</title>
    <link href="https://www.xiemingzhao.com/posts/e59f436c.html"/>
    <id>https://www.xiemingzhao.com/posts/e59f436c.html</id>
    <published>2019-06-11T16:00:00.000Z</published>
    <updated>2019-09-21T06:27:40.100Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://scholar.google.com.hk/scholar_url?url=https://dl.acm.org/ft_gateway.cfm%3Fid%3D2988454%26type%3Dpdf&amp;hl=zh-CN&amp;sa=X&amp;scisig=AAGBfm0TVpSA7DpxrGGn23_Zbb27fZpvyQ&amp;nossl=1&amp;oi=scholarr" target="_blank" rel="noopener">原始论文：Wide &amp; Deep Learning for Recommender Systems</a></p><h2 id="推荐系统之Wide-amp-Deep机器学习算法"><a href="#推荐系统之Wide-amp-Deep机器学习算法" class="headerlink" title="推荐系统之Wide &amp; Deep机器学习算法"></a>推荐系统之Wide &amp; Deep机器学习算法</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>不包含非线性特征变换的一般线性模型被广泛地应用在具有稀疏输入的大规模回归和分类问题中。通过一个<em>宽的</em>交叉积特征变换来实现对特征交叉的记忆是很有效和可解释的，而泛化能力需要更多的特征工程工作。考虑少用特征工程，深度神经网络可以更好地起到品泛化的作用，它会从稀疏的特征中学习到那些低维度看不见的密集嵌入。然而，具有嵌入的深度神经网络很容易过度泛化，并在用户-物品交互稀疏和稠密的时候会推荐一些不太相关的项物品。在本文中，我们提出广泛和深度学习——联合训练宽线性模型和深层神经网络——如此来结合记忆模型和泛化模型的好处从而构成更好的推荐系统。我们在Google Play上制作并评估了该系统，它是一个活跃的商业移动应用商店，上面超过10亿活跃用户和超过一百万个应用程序。在线实验结果表明相对于仅用wide模型和deep模型而言，Wide＆Deep显着增加了app的获取。我们也在TensorFlow中开源了我们的实现。</p><p><strong>关键词</strong>  Wide &amp; Deep学习，推荐系统</p><a id="more"></a><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a><strong>1. 介绍</strong></h3><p>一个推荐系统可以被看作是一个搜索排序系统，其中输入的请求是一个用户和上下文信息的集合，输出则是一个物品列表的排序。给定一个请求，推荐系统的任务就是在数据集中找到相关的物品，并且根据一定的目标，例如点击和购买，将所有的项目进行排序。</p><p>推荐系统的一个挑战是类似于一版的搜索排序问题，就是同时实现记忆和泛化的能力。记忆可以被宽泛地定义为学习物品或特征的频繁共现，并且开发历史数据中可用的相关性。另一方面，泛化是基于相关性的传递性和探索从来没有或很少发生在过去的新特征组合。推荐是基于记忆的，通常更具局部性并且与那些用户已经对其产生过行为的物品直接相关。与记忆相比，泛化倾向于改善推荐物品的多样性。在本文中，我们关注Google Play商店中应用程序推荐的问题，但方法应该适用于通用推荐系统。</p><p>对于工业环境中的大规模在线推荐和排序系统，一般的线性模型例如逻辑回归都是被广泛使用的，因为它们是简单，可扩展和可解释的。模型经常是使用one-hot编码的二值化稀疏特征进行训练的。例如，二进制特征“user_installed_app = netflix”，如果用户安装了Netflix那么该特征具有值1。使用通过对稀疏特征进行交叉积变化可以有效地实现记忆功能，例如AND（user_installed_app = netflix，impres-sion_app = pandora），如果用户安装了Netflix后有显示了Pandora，则其值为1。这解释了特征对的共现与目标标签有多么的相关。泛化功能是可以通过使用那些颗粒度较小的特征来添加的，例如AND（user_installed_category = video，impression_category =music），但手动特征工程常常还是需要的。交叉积变化的一个限制是他们没有办法泛化出那些没有出现在训练数据中的请求-物品特征对。</p><p>基于嵌入的模型，例如因式分解机或深度神经网络，可以通过对每个请求和物品特征学习出一个低维的嵌入向量来泛化出那些看不到的请求-物品特征对，如此可以减少特征工程的负担。然而，当底层的请求-物品矩阵是稀疏和高秩的时候，想要学习出一个有效的请求和物品的低维表示是非常困难的，例如具有特定偏好的用户或具有狭隘吸引力的商机物品。在这种情况下它与大多数的查询项对之间都是没有交互的，但密集的嵌入将会导致对所有的查询-物品对都有一个非零预测，因此可以过度泛化从而产生不相关的推荐。另一方面，有交叉积特征变换的线性模型在不用特别多参数的情况下可以记住这种“特殊规则”。</p><p>在本文中，我们提出Wide &amp; Deep学习框架来在同一个模型中同时完成记忆和泛化的任务，如图1所示，它是通过联合训练出一个线性模型和一个神经网络模型。</p><p>这篇文章的主要贡献包括：</p><ul><li>Wide &amp; Deep学习框架是通过联合训练一个有嵌入层的前向神经网络和一个有特征变换的线性模型，如此可以得到一个基于稀疏输入的一般推荐系统模型。</li><li>Wide &amp; Deep推荐系统的实现和评估是在Google Play上完成的，它是一个移动应用程序商店，其上拥有超过十亿的活跃用户和超过一百万的应用程序。</li><li>我们提供了一个开源的实现，它是通过TensorFlow中的一个高级API实现的。</li></ul><p>尽管思想很简单，我们还是证明了Wide &amp; Deep框架极大地提升了移动应用商店的app下载率，并且同时满足训练和高速服务的需求。</p><p><img src="https://i.postimg.cc/Ssdx68zn/relate-papers21-1.jpg" alt="wide&amp;deep-1"></p><p><img src="https://i.postimg.cc/nrLc0zv0/relate-papers21-2.jpg" alt="wide&amp;deep-2"></p><h3 id="2-推荐系统概述"><a href="#2-推荐系统概述" class="headerlink" title="2. 推荐系统概述"></a><strong>2. 推荐系统概述</strong></h3><p>图2显示了app推荐系统的概述。一个查询，可以包括各种用户和用户访问应用商店时会生成的上下文特征。推荐系统返回应用列表（也被称为展示），在这上面用户可以执行一些特定的行为例如点击或购买。这些用户操作，随着查询和展示，都记录在日志中，作为模型的训练数据。</p><p>由于数据库中有超过一百万的应用，在查询服务的潜在要求（经常是O(10)毫秒）的条件下，为每个查询都对所有的应用进行打分是难以实现的。因此，在收到一个查询后的第一步是<em>检索</em>。检索系统返回一个较短的物品列表，这个列表是使用各种特征对请求的最好匹配，通常是机器学习模型和人为定义规则的一个联合。在降低了候选池之后，排序系统会通过它们打出的分数对所有物品进行排序。这个得分经常是$P(y|x)$，它是表示给定特征x后的定于行为标签y的概率，其中x包括用户的特征（例如国家、语言、人口统计学指标），上下文特征（例如设备、一天中的第几个小时、周几），还有展示特征（例如应用年龄、应用的历史统计）。在本文中，我们聚焦于使用Wide &amp; Deep学习框架的排序模型。</p><h3 id="3-Wide-amp-Deep学习"><a href="#3-Wide-amp-Deep学习" class="headerlink" title="3. Wide &amp; Deep学习"></a><strong>3. Wide &amp; Deep学习</strong></h3><p><strong>3.1 Wide部分</strong><br>宽模型部分是一个广义线性模型，形式一般为$y = w^T x+b$，如图1左侧所示。y是预测，$x=[x_1,x_2,…,x_d]$是一个d维特征的向量，$w=[w_1,w_2,…w_d]$是模型参数且b是偏置项。特征集合包含原始输入的特征以及经过转换的特征。一个最终演的变换就是<em>交叉积变换</em>，如下定义：</p><script type="math/tex; mode=display">\phi_k(x)=\prod_{i=1}^d x_i^{c_{ki}} \ , \ c_{ki} \ \in \ \{0,1\}</script><p>其中$c_{ki}$是一个布尔变量，也就是如果第i个特征是第k个变换$\phi_k$的一部分则其取值为1，否则是0。对于二值特征，当且仅当交叉项的组成特征（例如“gender=female” and “language=en”）全部是1的时候交叉积变换（例如“AND(gender=female, language=en)”）才是1，否则就是0。这就获得了二值特征的交叉项，并且往广义线性模型中增加了非线性。</p><p><strong>3.2 Deep部分</strong><br>深模型部分是一个前向神经网络，如图1中右侧所示。对于类别特征，原始输入是特征字符串（例如“language=en”）。每个这种稀疏、高维类别特征都会首先被转换成一个低维并且稠密的实值向量，通常被称为嵌入向量。嵌入层的维度一般在O(10)到O(100)。嵌入向量会被随机的初始化，然后其值会在训练过程中通过最小化最终损失函数来训练。这些低维的稠密嵌入向量会被喂入神经网络前向通过的隐含层中。特别地，每个隐含层的计算是：</p><script type="math/tex; mode=display">a^{l+1} = f(W^{(l)}a^{(l)} + b^{(l)})</script><p>其中l是层数，f是激活函数，经常被设成整数线性单元(ReLUs)。$a^{(l)}, b^{(l)}和W^{(l)}$分别是激活项、偏置项和模型第l层的权重项。</p><p><strong>3.3 Wide &amp; Deep模型的联合训练</strong><br>宽模型部分和深模型部分会被用加权求和联合到一起，然后输出部分会进行对数概率变换后作为预测结果，在这之后一般会喂入一个普通的逻辑损失函数中进行联合训练。注意到<em>联合训练</em>和<em>合并</em>之间是有区别的。合并，一般是每个模型独自分开训练互不干扰，他们的预测结果只在推断的时候才会联合，训练过程中并不会。相反，联合训练会同时优化所有的参数，是通过在训练的过程中汇总获取宽模型和深模型的所有参数进行计算。模型大小的含义：对于模型合并，由于训练是分开的，每个单独的模型大小通常需要比较的大（例如有特别多的特征和变换）从而来得到<br>一个合理准确的起作用的模型合并。相比之下，对于联合训练中的宽模型部分只需要去实现深度模型的弱势部分就可以了，所以它有一个很小量级的交叉积特征变换，而不是一个全量的宽模型。</p><p>Wide &amp; Deep模型的联合训练是通过使用小批量随机优化从输出层同时进行宽模型和深模型的反向梯度传播来完成的。在实验中，我们使用Follow-the-regularized-leader (FTRL)算法和L1正则项作为宽模型部分的优化器，同时AdaGrad作为深度部分的优化器。</p><p>图1中间部分展示了联合模型。属于逻辑回归的问题，模型的预测结果为：</p><script type="math/tex; mode=display">P(Y=1|x)=\sigma(w_{wide}^T [x,\phi (x)] + w_{deep}^T a^{(l_f)} +b)</script><p>其中Y是二值类别标签，$\sigma(\cdot)$是sigmoid函数，$\phi(x)$是原始特征x的交叉积变换，b是偏置项。$w_{wide}$是宽模型权重参数向量，$w_{deep}$是应用在最终激活项$a^{(l_f)}$的的权重参数<br>。</p><h3 id="4-系统实现"><a href="#4-系统实现" class="headerlink" title="4. 系统实现"></a><strong>4. 系统实现</strong></h3><p>应用推荐管道的实现包含三个步骤：数据生成，模型训练，以及模型服务，如图3中所示。</p><p><img src="https://i.postimg.cc/L5047pDR/relate-papers21-3.jpg" alt="wide&amp;deep-3"></p><p><strong>4.1 数据生成</strong><br>在这个步骤，在一个时期的用户和应用展示数据被用来生成训练数据。每个样本对应于一次展示。标签就是应用获取：1代表展示的应用被安装了，否则为0。</p><p>词汇表，是用来将类别特征中的字符串匹配成整数型IDs的，也是在这一步骤中生成的。系统为所有的字符型特征计算IDs的空间，其中特征只计算那些出现次数超过最小次数的。连续型的实值特征会被标准化到[0,1]，方法是将特征值x匹配到该特征的累积分布函数$P(X\leq x)$，分成了$n_q$分位数。第i个分位数标准化后的值是$\frac{i-1}{n_q-1}$。分位数的边界是在数据生成过程中计算的。</p><p><img src="https://i.postimg.cc/BZ2dVshC/relate-papers21-4.jpg" alt="wide&amp;deep-4"></p><p><strong>4.2 模型训练</strong><br>我们在实验中使用的模型结构如图4所示。在训练中，我们的输入层接手输入数据和词汇表，然后用一个标签一起生成稀疏的和密集的特征。宽模型部分由用户安装应用和展示应用做交叉积变换得到。对于模型的深度部分，一个32维的嵌入向量是从每个类别型特征中学到的。我们将所有的嵌入向量串联在一起形成一个密集的特征，这就构成了一个接近1200维的密集向量。串联的向量接着会被喂入3个ReLU网络层，最优通过逻辑层输出单元。</p><p>Wide &amp; Deep模型是在5000亿个样本上训练得到的。每一次一个新的训练数据集到达时，模型需要被再次训练。然而，每次再训练花费的时间都是特别昂贵的计算成本同时新数据更新模型将会产生一定的延迟。为了战胜这个挑战，我们实现一个热启动的系统，它是用前一个模型的嵌入层和线性模型权重参数来初始化本次新模型。</p><p><strong>4.3 模型服务</strong><br>每一次模型被训练完成和确定之后，我们将其加载到模型服务中。对于每次请求，服务会从应用检索系统中接受到一个应用候选集和用户特征来对背个应用进行打分。然后，应用将会根据得分从高到低进行排序，我们将会按照此顺序将应用展示给用户。分数将会通过运行一个Wide &amp; Deep模型的前向推断得到。</p><p>为了在10ms的需求下服务每一次请求，我们使用多线程并行来优化表现，它是通过并行运行小批量实现的而不是在一个但线程中对所有的候选应用进行打分的。</p><h3 id="5-实验结果"><a href="#5-实验结果" class="headerlink" title="5. 实验结果"></a><strong>5. 实验结果</strong></h3><p>为了评估Wide &amp; Deep学习在实际推荐系统中的有效性，我们运行了一个实验并在多方面对系统进行了评估：应用获取和服务表现。</p><p><em>表1：不同模型的离线和在线的效果矩阵。在线的获取Gain值是相对于对照组的。</em></p><div class="table-container"><table><thead><tr><th style="text-align:left">Model</th><th style="text-align:center">Offline AUC</th><th style="text-align:center">Online Acqusition Gain</th></tr></thead><tbody><tr><td style="text-align:left">Wide (control)</td><td style="text-align:center">0.726</td><td style="text-align:center">0%</td></tr><tr><td style="text-align:left">Deep</td><td style="text-align:center">0.722</td><td style="text-align:center">+2.9%</td></tr><tr><td style="text-align:left">Wide &amp; Deep</td><td style="text-align:center">0.728</td><td style="text-align:center">+3.9%</td></tr></tbody></table></div><p><strong>5.1 应用获取</strong><br>我们在一个A/B测试框架中进行了3周的在线实验。对于对照组，随机选择1%的用户并使用之前的排序模型来生成推荐排序，先前的模型是一个高度优化后的仅有宽度逻辑回归的模型，它有很丰富的交叉积特征变换。对于实验组，我们随机选取另1%的用户并用Wide &amp; Deep模型来生成推荐排序，训练数据使用同样的特征集合。如表1中所示，相对于对照组，Wide &amp; Deep提高了主页面上的应用获取率大约+3.9%（统计显著）。结果也和另一1%用户组进行对比，这一组仅仅使用了深度模型结构和相同的特征，同样的Wide &amp; Deep模型有1+%的一个收益（统计显著的）。</p><p>除了线上实验，我们也展示了离线对抗集的AUC。然而Wide &amp; Deep有一个略高的离线AUC，对在线流量的影响更为显着。一个可能的原因是离线数据集的展示和标签是固定的额，而在线系统可以通过混合记忆和泛化来生成新的探索性的推荐，并且可以从新的用户反馈中学习到更多。</p><p><strong>5.2 服务表现</strong><br>在面临我们商业性移动应用商店的时候，高级别流量高吞吐量和低延迟的服务要求是一个挑战。在流量巅峰，我们的推荐服务在每秒内对超过1000万个应用进行打分。在单线程的时候，在一个单批量中对所有候选app进行打分将花费31毫秒。我们使用多线程实现，并将每一批量分成更小的批量，这显著地降低用户端延迟到14毫秒（包括服务高峰期），结果如表2所示。</p><p><em>表2：批量大小和线程个数的服务延迟对比</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">Batch size</th><th style="text-align:center">Number of Threads</th><th style="text-align:center">Serving Latency (ms)</th></tr></thead><tbody><tr><td style="text-align:center">200</td><td style="text-align:center">1</td><td style="text-align:center">31</td></tr><tr><td style="text-align:center">100</td><td style="text-align:center">2</td><td style="text-align:center">17</td></tr><tr><td style="text-align:center">50</td><td style="text-align:center">4</td><td style="text-align:center">4</td></tr></tbody></table></div><h3 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6. 相关工作"></a><strong>6. 相关工作</strong></h3><p>将带有交叉积特征变换的宽线性模型和带有密集嵌入的深度神经网络模型联合到一起的想法是受到前人工作启发的，例如因式分解机这种加入了泛化能力的线性模型，它通过将两个变量之间的交叉项分解成两个变量之间的点积。在本文中，我们通过在嵌入层通过神经网络之间的时候而不是点积来学习更高地非线性交叉项从而达到扩展模型的能力。</p><p>在语言模型中，循环神经网络（RNNs）和带有n-gram特征最大熵模型的联合训练已经被提出来了，通过学习输入层和输出层之间的直接权重能够显著地降低RNN的复杂度（例如隐含层的大小）。在计算机视觉中，深度残差学习已经被用于降低训练深度模型的困难度，并且通过跨越一层或多层的捷径连接达到了提高准确率的效果。带有图模型神经网络的联合训练已经被应用在了从图片中评估人类姿势。在我们提出的这个前向神经网络和线性模型的联合训练的工作中，在稀疏特征和输出单元之间带有直接连接，这是为了通用化带有稀疏输入数据的推荐和排序问题。</p><p>在推荐系统文献中，协同深度学习已经通过结合内容信息的深度学习和评分矩阵的协同过滤被探索了。同样也有很多关于移动应用推荐系统的先前工作，例如将CF用在用户的应用使用记录上的AppJoy。不同于基于CF的或者基于内容方法的这些先前工作，我们的推荐系统是在用户和展示数据上联合训练Wide &amp; Deep模型。</p><h3 id="7-结论"><a href="#7-结论" class="headerlink" title="7. 结论"></a><strong>7. 结论</strong></h3><p>记忆和泛化对于推荐系统来说都很重要。宽线性模型通过使用交叉积特征变换能够有效的基于稀疏特征之间的交叉项，而深度神经网络可以通过低维嵌入层来泛化出那些重要确又看不见的特征交叉项。我们呈现的Wide &amp; Deep学习框架是为了联合这两种模型的各自长处。我们在Google Play这个大规模的商业应用商店上对我们这个框架进行了产品化和评估。在线实验的结果证明了相对于仅用宽和深度模型来说，Wide &amp; Deep模型在应用获取上带来了显著地提升。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://scholar.google.com.hk/scholar_url?url=https://dl.acm.org/ft_gateway.cfm%3Fid%3D2988454%26type%3Dpdf&amp;amp;hl=zh-CN&amp;amp;sa=X&amp;amp;scisig=AAGBfm0TVpSA7DpxrGGn23_Zbb27fZpvyQ&amp;amp;nossl=1&amp;amp;oi=scholarr&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：Wide &amp;amp; Deep Learning for Recommender Systems&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;推荐系统之Wide-amp-Deep机器学习算法&quot;&gt;&lt;a href=&quot;#推荐系统之Wide-amp-Deep机器学习算法&quot; class=&quot;headerlink&quot; title=&quot;推荐系统之Wide &amp;amp; Deep机器学习算法&quot;&gt;&lt;/a&gt;推荐系统之Wide &amp;amp; Deep机器学习算法&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;不包含非线性特征变换的一般线性模型被广泛地应用在具有稀疏输入的大规模回归和分类问题中。通过一个&lt;em&gt;宽的&lt;/em&gt;交叉积特征变换来实现对特征交叉的记忆是很有效和可解释的，而泛化能力需要更多的特征工程工作。考虑少用特征工程，深度神经网络可以更好地起到品泛化的作用，它会从稀疏的特征中学习到那些低维度看不见的密集嵌入。然而，具有嵌入的深度神经网络很容易过度泛化，并在用户-物品交互稀疏和稠密的时候会推荐一些不太相关的项物品。在本文中，我们提出广泛和深度学习——联合训练宽线性模型和深层神经网络——如此来结合记忆模型和泛化模型的好处从而构成更好的推荐系统。我们在Google Play上制作并评估了该系统，它是一个活跃的商业移动应用商店，上面超过10亿活跃用户和超过一百万个应用程序。在线实验结果表明相对于仅用wide模型和deep模型而言，Wide＆Deep显着增加了app的获取。我们也在TensorFlow中开源了我们的实现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键词&lt;/strong&gt;  Wide &amp;amp; Deep学习，推荐系统&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="推荐系统" scheme="https://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Wide &amp; Deep" scheme="https://www.xiemingzhao.com/tags/Wide-Deep/"/>
    
  </entry>
  
  <entry>
    <title>An overview of gradient descent optimization algorithms (论文解析)</title>
    <link href="https://www.xiemingzhao.com/posts/eafa0d01.html"/>
    <id>https://www.xiemingzhao.com/posts/eafa0d01.html</id>
    <published>2019-06-10T16:00:00.000Z</published>
    <updated>2019-09-21T06:27:40.027Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://ruder.io/optimizing-gradient-descent/" target="_blank" rel="noopener">原始论文：An overview of gradient descent optimization algorithms</a></p><h2 id="梯度下降优化算法综述"><a href="#梯度下降优化算法综述" class="headerlink" title="梯度下降优化算法综述"></a>梯度下降优化算法综述</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>虽然梯度下降优化算法越来越受欢迎，但通常作为黑盒优化器使用，因此很难对其优点和缺点的进行实际的解释。本文旨在让读者对不同的算法有直观的认识，以帮助读者使用这些算法。在本综述中，我们介绍梯度下降的不同变形形式，总结这些算法面临的挑战，介绍最常用的优化算法，回顾并行和分布式架构，以及调研用于优化梯度下降的其他的策略。</p><h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a><strong>1 引言</strong></h3><p>梯度下降法是最著名的优化算法之一，也是迄今优化神经网络时最常用的方法。同时，在每一个最新的深度学习库中都包含了各种优化的梯度下降法的实现（例如：参见lasagne，caffe和keras的文档）。然而，这些算法通常是作为黑盒优化器使用，因此，很难对其优点和缺点的进行实际的解释。</p><a id="more"></a><p>本文旨在让读者对不同的优化梯度下降的算法有直观的认识，以帮助读者使用这些算法。在第2部分，我们首先介绍梯度下降的不同变形形式。在第3部分，我们将简要总结在训练的过程中所面临的挑战。随后，在第4部分，我们将介绍最常用的优化算法，包括这些算法在解决以上挑战时的动机以及如何得到更新规则的推导形式。在第5部分，我们将简单讨论在并行和分布式环境中优化梯度下降的算法和框架。最后，在第6部分，我们将思考对优化梯度下降有用的一些其他策略。</p><p>梯度下降法是最小化目标函数$J(\theta)$的一种方法，其中，$θ \in \mathbb R^d$为模型参数，梯度下降法利用目标函数关于参数的梯度$\triangledown_{\theta}J(\theta)$的反方向更新参数。学习率$\eta$决定达到最小值或者局部最小值过程中所采用的步长的大小。即，我们沿着目标函数的斜面下降的方向，直到到达谷底。如果你对梯度下降法不熟悉，你可以从<a href="http://cs231n.github.io/optimization-1/" target="_blank" rel="noopener">此处资料</a>找到介绍神经网络优化的材料。</p><h3 id="2-梯度下降法的变形形式"><a href="#2-梯度下降法的变形形式" class="headerlink" title="2 梯度下降法的变形形式"></a><strong>2 梯度下降法的变形形式</strong></h3><p>梯度下降法有3中变形形式，它们之间的区别为我们在计算目标函数的梯度时使用到多少数据。根据数据量的不同，我们在参数更新的精度和更新过程中所需要的时间两个方面做出权衡。</p><h4 id="2-1-批梯度下降法"><a href="#2-1-批梯度下降法" class="headerlink" title="2.1 批梯度下降法"></a><strong>2.1 批梯度下降法</strong></h4><p>Vanilla梯度下降法，又称为批梯度下降法（batch gradient descent），在整个训练数据集上计算损失函数关于参数$\theta$的梯度：</p><script type="math/tex; mode=display">\theta = \theta - \eta \cdot \triangledown_{\theta}J(\theta)</script><p>因为在执行每次更新时，我们需要在整个数据集上计算所有的梯度，所以批梯度下降法的速度会很慢，同时，批梯度下降法无法处理超出内存容量限制的数据集。批梯度下降法同样也不能在线更新模型，即在运行的过程中，不能增加新的样本。</p><p>批梯度下降法的代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(nb_epochs):</span><br><span class="line">    params_grad = evaluate_gradient(loss_function, data, params)</span><br><span class="line">    params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure></p><p>对于给定的迭代次数，首先，我们利用全部数据集计算损失函数关于参数向量params的梯度向量params_grad。注意，最新的深度学习库中提供了自动求导的功能，可以有效地计算关于参数梯度。如果你自己求梯度，那么，梯度检查是一个不错的主意（关于如何正确检查梯度的一些技巧可以参见<a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">此处资料</a>）。</p><p>然后，我们利用梯度的方向和学习率更新参数，学习率决定我们将以多大的步长更新参数。对于凸误差函数，批梯度下降法能够保证收敛到全局最小值，对于非凸函数，则收敛到一个局部最小值。</p><h4 id="2-2-随机梯度下降法"><a href="#2-2-随机梯度下降法" class="headerlink" title="2.2 随机梯度下降法"></a><strong>2.2 随机梯度下降法</strong></h4><p>相反，随机梯度下降法（stochastic gradient descent, SGD）根据每一条训练样本$x^{(i)}$和标签$y^{(i)}$更新参数：</p><script type="math/tex; mode=display">\theta = \theta - \eta \cdot \triangledown_{\theta}J(\theta;x^{(i)};y^{(i)})</script><p>对于大数据集，因为批梯度下降法在每一个参数更新之前，会对相似的样本计算梯度，所以在计算过程中会有冗余。而SGD在每一次更新中只执行一次，从而消除了冗余。因而，通常SGD的运行速度更快，同时，可以用于在线学习。SGD以高方差频繁地更新，导致目标函数出现如图1所示的剧烈波动。</p><p><img src="https://i.postimg.cc/0y9Fzn1Z/optimizer-01.jpg" alt="optimizer-01.jpg"></p><p>与批梯度下降法的收敛会使得损失函数陷入局部最小相比，由于SGD的波动性，一方面，波动性使得SGD可以跳到新的和潜在更好的局部最优。另一方面，这使得最终收敛到特定最小值的过程变得复杂，因为SGD会一直持续波动。然而，已经证明当我们缓慢减小学习率，SGD与批梯度下降法具有相同的收敛行为，对于非凸优化和凸优化，可以分别收敛到局部最小值和全局最小值。与批梯度下降的代码相比，SGD的代码片段仅仅是在对训练样本的遍历和利用每一条样本计算梯度的过程中增加一层循环。注意，如6.1节中的解释，在每一次循环中，我们打乱训练样本。</p><pre><code class="lang-python">for i in range(nb_epochs):    np.random.shuffle(data)    for example in data:        params_grad = evaluate_gradient(loss_function, example, params)        params = params - learning_rate * params_grad</code></pre><h4 id="2-3-小批量梯度下降法"><a href="#2-3-小批量梯度下降法" class="headerlink" title="2.3 小批量梯度下降法"></a><strong>2.3 小批量梯度下降法</strong></h4><p>小批量梯度下降法最终结合了上述两种方法的优点，在每次更新时使用n个小批量训练样本：</p><script type="math/tex; mode=display">\theta = \theta - \eta \cdot \triangledown_{\theta}J(\theta;x^{(i:i+n)};y^{(i:i+n)})</script><p>这种方法，a)减少参数更新的方差，这样可以得到更加稳定的收敛结果；b)可以利用最新的深度学习库中高度优化的矩阵优化方法，高效地求解每个小批量数据的梯度。通常，小批量数据的大小在50到256之间，也可以根据不同的应用有所变化。当训练神经网络模型时，小批量梯度下降法是典型的选择算法，当使用小批量梯度下降法时，也将其称为SGD。注意：在下文的改进的SGD中，为了简单，我们省略了参数$x^{(i:i+n)};y^{(i:i+n)}$。</p><p>在代码中，不是在所有样本上做迭代，我们现在只是在大小为50的小批量数据上做迭代：</p><pre><code class="lang-python">for i in range(nb_epochs):    np.random.shuffle(data)    for batch in get_batches(data, batch_size=50):        params_grad = evaluate_gradient(loss_function, batch, params)        params = params - learning_rate * params_grad</code></pre><h3 id="3-挑战"><a href="#3-挑战" class="headerlink" title="3 挑战"></a><strong>3 挑战</strong></h3><p>虽然Vanilla小批量梯度下降法并不能保证较好的收敛性，但是需要强调的是，这也给我们留下了如下的一些挑战：</p><p>选择一个合适的学习率可能是困难的。学习率太小会导致收敛的速度很慢，学习率太大会妨碍收敛，导致损失函数在最小值附近波动甚至偏离最小值。<br>学习率调整[17]试图在训练的过程中通过例如退火的方法调整学习率，即根据预定义的策略或者当相邻两代之间的下降值小于某个阈值时减小学习率。然而，策略和阈值需要预先设定好，因此无法适应数据集的特点[4]。<br>此外，对所有的参数更新使用同样的学习率。如果数据是稀疏的，同时，特征的频率差异很大时，我们也许不想以同样的学习率更新所有的参数，对于出现次数较少的特征，我们对其执行更大的学习率。<br>高度非凸误差函数普遍出现在神经网络中，在优化这类函数时，另一个关键的挑战是使函数避免陷入无数次优的局部最小值。Dauphin等人[5]指出出现这种困难实际上并不是来自局部最小值，而是来自鞍点，即那些在一个维度上是递增的，而在另一个维度上是递减的。这些鞍点通常被具有相同误差的点包围，因为在任意维度上的梯度都近似为0，所以SGD很难从这些鞍点中逃开。</p><h3 id="4-梯度下降优化算法"><a href="#4-梯度下降优化算法" class="headerlink" title="4 梯度下降优化算法"></a><strong>4 梯度下降优化算法</strong></h3><p>下面，我们将列举一些算法，这些算法被深度学习社区广泛用来处理前面提到的挑战。我们不会讨论在实际中不适合在高维数据集中计算的算法，例如诸如牛顿法的二阶方法。</p><h4 id="4-1-动量法"><a href="#4-1-动量法" class="headerlink" title="4.1 动量法"></a><strong>4.1 动量法</strong></h4><p>SGD很难通过陡谷，即在一个维度上的表面弯曲程度远大于其他维度的区域[19]，这种情况通常出现在局部最优点附近。在这种情况下，SGD摇摆地通过陡谷的斜坡，同时，沿着底部到局部最优点的路径上只是缓慢地前进，这个过程如图2a所示。</p><p><img src="https://i.postimg.cc/FKBBnQdn/optimizer-02.jpg" alt="optimizer-02.jpg"></p><p>如图2b所示，动量法[16]是一种帮助SGD在相关方向上加速并抑制摇摆的一种方法。动量法将历史步长的更新向量的一个分量$\gamma$增加到当前的更新向量中（部分实现中交换了公式中的符号）</p><script type="math/tex; mode=display">v_t = \gamma v_{t-1} + \eta \triangledown_{\theta}J(\theta) \\\theta = \theta - v_t</script><p>动量项$\gamma$通常设置为0.9或者类似的值。</p><p>从本质上说，动量法，就像我们从山上推下一个球，球在滚下来的过程中累积动量，变得越来越快（直到达到终极速度，如果有空气阻力的存在，则$\gamma&lt;1$）。同样的事情也发生在参数的更新过程中：对于在梯度点处具有相同的方向的维度，其动量项增大，对于在梯度点处改变方向的维度，其动量项减小。因此，我们可以得到更快的收敛速度，同时可以减少摇摆。</p><h4 id="4-2-Nesterov加速梯度下降法"><a href="#4-2-Nesterov加速梯度下降法" class="headerlink" title="4.2 Nesterov加速梯度下降法"></a><strong>4.2 Nesterov加速梯度下降法</strong></h4><p>然而，球从山上滚下的时候，盲目地沿着斜率方向，往往并不能令人满意。我们希望有一个智能的球，这个球能够知道它将要去哪，以至于在重新遇到斜率上升时能够知道减速。</p><p>Nesterov加速梯度下降法（Nesterov accelerated gradient，NAG）[13]是一种能够给动量项这样的预知能力的方法。我们知道，我们利用动量项$\gamma v_{t-1}$来更新参数θ。通过计算$\theta - \gamma v_{t-1}$能够告诉我们参数未来位置的一个近似值（梯度并不是完全更新），这也就是告诉我们参数大致将变为多少。通过计算关于参数未来的近似位置的梯度，而不是关于当前的参数$\theta$的梯度，我们可以高效的求解 ：</p><script type="math/tex; mode=display">v_t = \gamma v_{t-1} + \eta \triangledown_{\theta}J(\theta - \gamma v_{t-1}) \\\theta = \theta - v_t</script><p>同时，我们设置动量项$\gamma$大约为0.9。动量法首先计算当前的梯度值（图3中的小的蓝色向量），然后在更新的累积梯度（大的蓝色向量）方向上前进一大步，Nesterov加速梯度下降法NAG首先在先前累积梯度（棕色的向量）方向上前进一大步，计算梯度值，然后做一个修正（绿色的向量）。这个具有预见性的更新防止我们前进得太快，同时增强了算法的响应能力，这一点在很多的任务中对于RNN的性能提升有着重要的意义[2]。</p><p><img src="https://i.postimg.cc/8C5YHC56/optimizer-03.jpg" alt="optimizer-03.jpg"></p><p>对于NAG的直观理解的另一种解释可以参见<a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">此处资料</a>，同时Ilya Sutskever在其博士论文[18]中给出更详细的综述。</p><p>既然我们能够使得我们的更新适应误差函数的斜率以相应地加速SGD，我们同样也想要使得我们的更新能够适应每一个单独参数，以根据每个参数的重要性决定大的或者小的更新。</p><h4 id="4-3-Adagrad"><a href="#4-3-Adagrad" class="headerlink" title="4.3 Adagrad"></a><strong>4.3 Adagrad</strong></h4><p>Adagrad[7]是这样的一种基于梯度的优化算法：让学习率适应参数，对于出现次数较少的特征，我们对其采用更大的学习率，对于出现次数较多的特征，我们对其采用较小的学习率。因此，Adagrad非常适合处理稀疏数据。Dean等人[6]发现Adagrad能够极大提高了SGD的鲁棒性并将其应用于Google的大规模神经网络的训练，其中包含了YouTube视频中的猫的识别。此外，Pennington等人[15]利用Adagrad训练Glove词向量，因为低频词比高频词需要更大的步长。</p><p>前面，我们每次更新所有的参数$\theta$时，每一个参数$\theta_i$都使用的是相同的学习率$\eta$。由于Adagrad在t时刻对每一个参数$\theta_i$使用了不同的学习率，我们首先介绍Adagrad对每一个参数的更新，然后我们对其向量化。为了简洁，令$g_{t,i}$为在t时刻目标函数关于参数$\theta_i$的梯度：</p><script type="math/tex; mode=display">g_{t,i} = \triangledown_{\theta}J(\theta_i)</script><p>在t时刻，对每个参数$\theta_i$的更新过程变为：</p><script type="math/tex; mode=display">\theta_{t+1,i} = \theta_{t,i} - \eta \cdot g_{t,i}</script><p>对于上述的更新规则，在t时刻，基于对$\theta_i$计算过的历史梯度，Adagrad修正了对每一个参数$\theta_i$的学习率：</p><script type="math/tex; mode=display">\theta_{t+1,i} = \theta_{t,i} - \frac{\eta}{\sqrt{G_{t,ii} + \epsilon}} \cdot g_{t,i}</script><p>其中，$G_t \in \mathbb R^{d \times d}$是一个对角矩阵，对角线上的元素i,i是直到t时刻为止，所有关于$\theta_i$的梯度的平方和（Duchi等人[7]将该矩阵作为包含所有先前梯度的外积的完整矩阵的替代，因为即使是对于中等数量的参数d，矩阵的均方根的计算都是不切实际的。），$\是平滑项，用于防止除数为0（通常大约设置为1e−8）。<strong>比较有意思的是，如果没有平方根的操作，算法的效果会变得很差。</strong></p><p>由于$G_t$的对角线上包含了关于所有参数θ的历史梯度的平方和，现在，我们可以通过$G_t$和$g_t$之间的元素向量乘法$\odot$向量化上述的操作：</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \odot g_t</script><p>Adagrad算法的一个主要优点是无需手动调整学习率。在大多数的应用场景中，通常采用常数0.01。</p><p>Adagrad的一个主要缺点是它在分母中累加梯度的平方：由于没增加一个正项，在整个训练过程中，累加的和会持续增长。这会导致学习率变小以至于最终变得无限小，在学习率无限小时，Adagrad算法将无法取得额外的信息。接下来的算法旨在解决这个不足。</p><h4 id="4-4-Adadelta"><a href="#4-4-Adadelta" class="headerlink" title="4.4 Adadelta"></a><strong>4.4 Adadelta</strong></h4><p>Adadelta[21]是Adagrad的一种扩展算法，以处理Adagrad学习速率单调递减的问题。不是计算所有的梯度平方，Adadelta将计算计算历史梯度的窗口大小限制为一个固定值w。</p><p>在Adadelta中，无需存储先前的w个平方梯度，而是将梯度的平方递归地表示成所有历史梯度平方的均值。在t时刻的均值$E[g^2]_t$只取决于先前的均值和当前的梯度（分量$\gamma$类似于动量项）：</p><script type="math/tex; mode=display">E[g^2]_t = \gamma E[g^2]_{t-1} + (1-\gamma)g_t^2</script><p>我们将$\gamma$设置成与动量项相似的值，即0.9左右。为了简单起见，我们利用参数更新向量$\Delta \theta_t$重新表示SGD的更新过程：</p><script type="math/tex; mode=display">\Delta \theta_t = - \eta \cdot g_{t,i} \\\theta_{t+1} = \theta_t + \Delta \theta_t</script><p>我们先前得到的Adagrad参数更新向量变为：</p><script type="math/tex; mode=display">\Delta \theta_t = -\frac{\eta}{\sqrt{G_t +\epsilon}} \odot g_t</script><p>现在，我们简单将对角矩阵$G_t$替换成历史梯度的均值$E[g^2]_t$：</p><script type="math/tex; mode=display">\Delta \theta_t = - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}}g_t</script><p>由于分母仅仅是梯度的均方根（root mean squared，RMS）误差，我们可以简写为：</p><script type="math/tex; mode=display">\Delta \theta_t = - \frac{\eta}{RMS|g|_t}g_t</script><p>作者指出上述更新公式中的每个部分（与SGD，动量法或者Adagrad）并不一致，即更新规则中必须与参数具有相同的假设单位。为了实现这个要求，作者首次定义了另一个指数衰减均值，这次不是梯度平方，而是参数的平方的更新：</p><script type="math/tex; mode=display">E[\Delta \theta^2]_t = \gamma E[\Delta \theta^2]_{t-1} +(1-\gamma) \Delta \theta^2_t</script><p>因此，参数更新的均方根误差为：</p><script type="math/tex; mode=display">RMS[\Delta \theta]_t = \sqrt{E[\Delta \theta^2]_t + \epsilon}</script><p>由于$RMS[\Delta \theta]_t$是未知的，我们利用参数的均方根误差来近似更新。利用$RMS[\Delta \theta]_{t−1}$替换先前的更新规则中的学习率$\eta$，最终得到Adadelta的更新规则：</p><script type="math/tex; mode=display">\Delta \theta_t = - \frac{RMS[\theta]_{t−1}}{RMS|g|_t} g_t \\\theta_{t+1} = \theta_t +\Delta \theta_t</script><p>使用Adadelta算法，我们甚至都无需设置默认的学习率，因为更新规则中已经移除了学习率。</p><h4 id="4-5-RMSprop"><a href="#4-5-RMSprop" class="headerlink" title="4.5 RMSprop"></a><strong>4.5 RMSprop</strong></h4><p>RMSprop是一个未被发表的自适应学习率的算法，该算法由Geoff Hinton在其<a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" target="_blank" rel="noopener">Coursera课堂的课程6e</a>中提出。</p><p>RMSprop和Adadelta在相同的时间里被独立的提出，都起源于对Adagrad的极速递减的学习率问题的求解。实际上，RMSprop是先前我们得到的Adadelta的第一个更新向量的特例：</p><script type="math/tex; mode=display">E[g^2]_t = 0.9 E[g^2]_{t-1} + 0.1 g^2_t \\\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t</script><p>同样，RMSprop将学习率分解成一个平方梯度的指数衰减的平均。Hinton建议将$\gamma$设置为0.9，对于学习率$\eta$，一个好的固定值为0.001。</p><h4 id="4-6-Adam"><a href="#4-6-Adam" class="headerlink" title="4.6 Adam"></a><strong>4.6 Adam</strong></h4><p>自适应矩估计（Adaptive Moment Estimation，Adam）[9]是另一种自适应学习率的算法，Adam对每一个参数都计算自适应的学习率。除了像Adadelta和RMSprop一样存储一个指数衰减的历史平方梯度的平均$v_t$，Adam同时还保存一个历史梯度的指数衰减均值$m_t$，类似于动量：</p><script type="math/tex; mode=display">m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t \\v_t = \beta_2 v_{t-1} + (1-\beta_2) g^2_t</script><p>$m_t$和$v_t$分别是对梯度的一阶矩（均值）和二阶矩（非确定的方差）的估计，正如该算法的名称。当$m_t$和$v_t$初始化为0向量时，Adam的作者发现它们都偏向于0，尤其是在初始化的步骤和当衰减率很小的时候（例如$\beta_1$和$\beta_2$趋向于1）。</p><p>通过计算偏差校正的一阶矩和二阶矩估计来抵消偏差：</p><script type="math/tex; mode=display">\hat m_t = \frac{m_t}{1-\beta_1^t} \\\hat v_t = \frac{v_t}{1-\beta_2^t}</script><p>正如我们在Adadelta和RMSprop中看到的那样，他们利用上述的公式更新参数，由此生成了Adam的更新规则：</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat v_t} + \epsilon} \hat m_t</script><p>作者建议$\beta_1$取默认值为0.9，$\beta_2$为0.999，$\epsilon$为10−8。他们从经验上表明Adam在实际中表现很好，同时，与其他的自适应学习算法相比，其更有优势。</p><h4 id="4-7-算法可视化"><a href="#4-7-算法可视化" class="headerlink" title="4.7 算法可视化"></a><strong>4.7 算法可视化</strong></h4><p>下面两张图给出了上述优化算法的优化行为的直观理解。（还可以看看这里关于Karpathy对相同的图片的描述以及另一个简明关于算法讨论的概述）。</p><p>在图4a中，我们看到不同算法在损失曲面的等高线上走的不同路线。所有的算法都是从同一个点出发并选择不同路径到达最优点。注意：Adagrad，Adadelta和RMSprop能够立即转移到正确的移动方向上并以类似的速度收敛，而动量法和NAG会导致偏离，想像一下球从山上滚下的画面。然而，NAG能够在偏离之后快速修正其路线，因为NAG通过对最优点的预见增强其响应能力。</p><p>图4b中展示了不同算法在鞍点出的行为，鞍点即为一个点在一个维度上的斜率为正，而在其他维度上的斜率为负，正如我们前面提及的，鞍点对SGD的训练造成很大困难。这里注意，SGD，动量法和NAG在鞍点处很难打破对称性，尽管后面两个算法最终设法逃离了鞍点。而Adagrad，RMSprop和Adadelta能够快速想着梯度为负的方向移动，其中Adadelta走在最前面。</p><p><img src="https://i.postimg.cc/dtYSf63v/optimizers-04.gif" alt="optimizers-04.gif"><img src="https://i.postimg.cc/rsSZm0hv/optimizers-05.gif" alt="optimizers-05.gif"></p><p>正如我们所看到的，自适应学习速率的方法，即 Adagrad、 Adadelta、 RMSprop 和Adam，最适合这些场景下最合适，并在这些场景下得到最好的收敛性。</p><h4 id="4-8-选择使用哪种优化算法？"><a href="#4-8-选择使用哪种优化算法？" class="headerlink" title="4.8 选择使用哪种优化算法？"></a><strong>4.8 选择使用哪种优化算法？</strong></h4><p>那么，我们应该选择使用哪种优化算法呢？如果输入数据是稀疏的，选择任一自适应学习率算法可能会得到最好的结果。选用这类算法的另一个好处是无需调整学习率，选用默认值就可能达到最好的结果。</p><p>总的来说，RMSprop是Adagrad的扩展形式，用于处理在Adagrad中急速递减的学习率。RMSprop与Adadelta相同，所不同的是Adadelta在更新规则中使用参数的均方根进行更新。最后，Adam是将偏差校正和动量加入到RMSprop中。在这样的情况下，RMSprop、Adadelta和Adam是很相似的算法并且在相似的环境中性能都不错。Kingma等人[9]指出在优化后期由于梯度变得越来越稀疏，偏差校正能够帮助Adam微弱地胜过RMSprop。综合看来，Adam可能是最佳的选择。</p><p>有趣的是，最近许多论文中采用不带动量的SGD和一种简单的学习率的退火策略。已表明，通常SGD能够找到最小值点，但是比其他优化的SGD花费更多的时间，与其他算法相比，SGD更加依赖鲁棒的初始化和退火策略，同时，SGD可能会陷入鞍点，而不是局部极小值点。因此，如果你关心的是快速收敛和训练一个深层的或者复杂的神经网络，你应该选择一个自适应学习率的方法。</p><h3 id="5-并行和分布式SGD"><a href="#5-并行和分布式SGD" class="headerlink" title="5 并行和分布式SGD"></a><strong>5 并行和分布式SGD</strong></h3><p>当存在大量的大规模数据和廉价的集群时，利用分布式SGD来加速是一个显然的选择。SGD本身有固有的顺序：一步一步，我们进一步进展到最小。SGD提供了良好的收敛性，但SGD的运行缓慢，特别是对于大型数据集。相反，SGD异步运行速度更快，但客户端之间非最理想的通信会导致差的收敛。此外，我们也可以在一台机器上并行SGD，这样就无需大的计算集群。以下是已经提出的优化的并行和分布式的SGD的算法和框架。</p><h4 id="5-1-Hogwild"><a href="#5-1-Hogwild" class="headerlink" title="5.1 Hogwild!"></a><strong>5.1 Hogwild!</strong></h4><p>Niu等人[14]提出称为Hogwild!的更新机制，Hogwild!允许在多个CPU上并行执行SGD更新。在无需对参数加锁的情况下，处理器可以访问共享的内存。这种方法只适用于稀疏的输入数据，因为每一次更新只会修改一部分参数。在这种情况下，该更新策略几乎可以达到一个最优的收敛速率，因为CPU之间不可能重写有用的信息。</p><h4 id="5-2-Downpour-SGD"><a href="#5-2-Downpour-SGD" class="headerlink" title="5.2 Downpour SGD"></a><strong>5.2 Downpour SGD</strong></h4><p>Downpour SGD是SGD的一种异步的变形形式，在Google，Dean等人[6]在他们的DistBelief框架（TensorFlow的前身）中使用了该方法。Downpour SGD在训练集的子集上并行运行多个模型的副本。这些模型将各自的更新发送给一个参数服务器，参数服务器跨越了多台机器。每一台机器负责存储和更新模型的一部分参数。然而，因为副本之间是彼此不互相通信的，即通过共享权重或者更新，因此可能会导致参数发散而不利于收敛。</p><h4 id="5-3-延迟容忍SGD"><a href="#5-3-延迟容忍SGD" class="headerlink" title="5.3 延迟容忍SGD"></a><strong>5.3 延迟容忍SGD</strong></h4><p>通过容忍延迟算法的开发，McMahan和Streeter[11]将AdaGraad扩展成并行的模式，该方法不仅适应于历史梯度，同时适应于更新延迟。该方法已经在实践中被证实是有效的。</p><h4 id="5-4-TensorFlow"><a href="#5-4-TensorFlow" class="headerlink" title="5.4 TensorFlow"></a><strong>5.4 TensorFlow</strong></h4><p>TensorFlow[1]是Google近期开源的框架，该框架用于实现和部署大规模机器学习模型。TensorFlow是基于DistBelief开发，同时TensorFlow已经在内部用来在大量移动设备和大规模分布式系统的执行计算。在2016年4月发布的分布式版本依赖于图计算，图计算即是对每一个设备将图划分成多个子图，同时，通过发送、接收节点对完成节点之间的通信。</p><h4 id="5-5-弹性平均SGD"><a href="#5-5-弹性平均SGD" class="headerlink" title="5.5 弹性平均SGD"></a><strong>5.5 弹性平均SGD</strong></h4><p>Zhang等人[22]提出的弹性平均SGD（Elastic Averaging SGD，EASGD）连接了异步SGD的参数客户端和一个弹性力，即参数服务器存储的一个中心变量。EASGD使得局部变量能够从中心变量震荡得更远，这在理论上使得在参数空间中能够得到更多的探索。经验表明这种增强的探索能力通过发现新的局部最优点，能够提高整体的性能。</p><h3 id="6-优化SGD的其他策略"><a href="#6-优化SGD的其他策略" class="headerlink" title="6 优化SGD的其他策略"></a><strong>6 优化SGD的其他策略</strong></h3><p>最后，我们介绍可以与前面提及到的任一算法配合使用的其他的一些策略，以进一步提高SGD的性能。对于其他的一些常用技巧的概述可以参见[10]。</p><h4 id="6-1-数据集的洗牌和课程学习"><a href="#6-1-数据集的洗牌和课程学习" class="headerlink" title="6.1 数据集的洗牌和课程学习"></a><strong>6.1 数据集的洗牌和课程学习</strong></h4><p>总的来说，我们希望避免向我们的模型中以一定意义的顺序提供训练数据，因为这样会使得优化算法产生偏差。因此，在每一轮迭代后对训练数据洗牌是一个不错的主意。</p><p>另一方面，在很多情况下，我们是逐步解决问题的，而将训练集按照某个有意义的顺序排列会提高模型的性能和SGD的收敛性，如何将训练集建立一个有意义的排列被称为课程学习[3]。</p><p>Zaremba and Sutskever[20]只能使用课程学习训练LSTM来评估简单程序，并表明组合或混合策略比单一的策略更好，通过增加难度来排列示例。</p><h4 id="6-2-批量归一化"><a href="#6-2-批量归一化" class="headerlink" title="6.2 批量归一化"></a><strong>6.2 批量归一化</strong></h4><p>为了便于学习，我们通常用0均值和单位方差初始化我们的参数的初始值来归一化。 随着不断训练，参数得到不同的程度的更新，我们失去了这种归一化，随着网络变得越来越深，这种现象会降低训练速度，且放大参数变化。</p><p>批量归一化[8]在每次小批量数据反向传播之后重新对参数进行0均值单位方差标准化。通过将模型架构的一部分归一化，我们能够使用更高的学习率，更少关注初始化参数。批量归一化还充当正则化的作用，减少（有时甚至消除）Dropout的必要性。</p><h4 id="6-3-Early-stopping"><a href="#6-3-Early-stopping" class="headerlink" title="6.3 Early stopping"></a><strong>6.3 Early stopping</strong></h4><p>如Geoff Hinton所说：“Early Stopping是美丽好免费午餐”（NIPS 2015 Tutorial slides）。你因此必须在训练的过程中时常在验证集上监测误差，在验证集上如果损失函数不再显著地降低，那么应该提前结束训练。</p><h4 id="6-4-梯度噪音"><a href="#6-4-梯度噪音" class="headerlink" title="6.4 梯度噪音"></a><strong>6.4 梯度噪音</strong></h4><p>Neelakantan等人[12]在每个梯度更新中增加满足高斯分布$N(0,\sigma^2_t)$的噪音：</p><script type="math/tex; mode=display">g_{t,i} = g_{t,i} + N(0,\sigma^2_t)</script><p>高斯分布的方差需要根据如下的策略退火：</p><script type="math/tex; mode=display">\sigma_t^2 = \frac{\eta}{(1+t)^\gamma}</script><p>他们指出增加了噪音，使得网络对不好的初始化更加鲁棒，同时对深层的和复杂的网络的训练特别有益。他们猜测增加的噪音使得模型更优机会逃离当前的局部最优点，以发现新的局部最优点，这在更深层的模型中更加常见。</p><h3 id="7-总结"><a href="#7-总结" class="headerlink" title="7 总结"></a><strong>7 总结</strong></h3><p>在这篇博客文章中，我们初步研究了梯度下降的三个变形形式，其中，小批量梯度下降是最受欢迎的。 然后我们研究了最常用于优化SGD的算法：动量法，Nesterov加速梯度，Adagrad，Adadelta，RMSprop，Adam以及不同的优化异步SGD的算法。 最后，我们已经考虑其他一些改善SGD的策略，如洗牌和课程学习，批量归一化和early stopping。</p><p><a href="https://blog.csdn.net/google19890102/article/details/69942970" target="_blank" rel="noopener">参考博文：梯度下降优化算法综述-zhiyong_will</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://ruder.io/optimizing-gradient-descent/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：An overview of gradient descent optimization algorithms&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;梯度下降优化算法综述&quot;&gt;&lt;a href=&quot;#梯度下降优化算法综述&quot; class=&quot;headerlink&quot; title=&quot;梯度下降优化算法综述&quot;&gt;&lt;/a&gt;梯度下降优化算法综述&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;虽然梯度下降优化算法越来越受欢迎，但通常作为黑盒优化器使用，因此很难对其优点和缺点的进行实际的解释。本文旨在让读者对不同的算法有直观的认识，以帮助读者使用这些算法。在本综述中，我们介绍梯度下降的不同变形形式，总结这些算法面临的挑战，介绍最常用的优化算法，回顾并行和分布式架构，以及调研用于优化梯度下降的其他的策略。&lt;/p&gt;
&lt;h3 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;&lt;strong&gt;1 引言&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;梯度下降法是最著名的优化算法之一，也是迄今优化神经网络时最常用的方法。同时，在每一个最新的深度学习库中都包含了各种优化的梯度下降法的实现（例如：参见lasagne，caffe和keras的文档）。然而，这些算法通常是作为黑盒优化器使用，因此，很难对其优点和缺点的进行实际的解释。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="Gradient Descent" scheme="https://www.xiemingzhao.com/tags/Gradient-Descent/"/>
    
      <category term="Optimization" scheme="https://www.xiemingzhao.com/tags/Optimization/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客文章链接优化</title>
    <link href="https://www.xiemingzhao.com/posts/Hexoblogurloptimize.html"/>
    <id>https://www.xiemingzhao.com/posts/Hexoblogurloptimize.html</id>
    <published>2019-06-10T16:00:00.000Z</published>
    <updated>2019-11-10T09:35:10.155Z</updated>
    
    <content type="html"><![CDATA[<h2 id="文章的URL"><a href="#文章的URL" class="headerlink" title="文章的URL"></a>文章的URL</h2><p>文章默认的URL配置是包含年月日以及文章标题的，而且每次文章文章有修改就会引起一些链接的变化，繁琐且不易于检索传播。而URL地址对于SEO来说（Search Engine Optimization：搜索引擎优化）是相当重要的，如何缩短并固定每篇文章的连接，同时又可以在链接后面加上<code>html</code>使其显得更为正式。这就是本篇文章需要讲解的。</p><p>效果可参考<a href="www.xiemingzhao.com">我的博客</a>，部署环境是<code>Hexo+Next</code>。</p><h2 id="插件安装与配置"><a href="#插件安装与配置" class="headerlink" title="插件安装与配置"></a>插件安装与配置</h2><p>基于<code>Hexo</code>搭建的博客，可以通过插件<code>hexo-abbrlink</code>来实现自定义文章的连接。首先我们使用如下代码进行优化：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-abbrlink --save</span><br></pre></td></tr></table></figure><p>接着打开站点配置文件<code>_config.yml</code>，按照如下部分进行相关配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># URL</span><br><span class="line">## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;</span><br><span class="line">url: https://www.xiemingzhao.com</span><br><span class="line">root: /</span><br><span class="line">#permalink: :year/:month/:day/:title/</span><br><span class="line">#permalink_defaults:</span><br><span class="line">permalink: posts/:abbrlink.html</span><br><span class="line">abbrlink:</span><br><span class="line">  alg: crc32  # 算法：crc16(default) and crc32</span><br><span class="line">  rep: hex    # 进制：dec(default) and hex</span><br></pre></td></tr></table></figure></p><p>如上所示，是我本人的配置，其中<code>url</code>配置的是我博客所关联的域名，具体域名的捆绑可参考我的另一篇博客，<a href="https://www.xiemingzhao.com/posts/Hexoblogdomain.html">Hexo博客绑定域名</a>。另，<code>permalink</code>的配置，我多加了一个固定链接<code>posts</code>，纯属个人喜好，你也可以去掉直接配置成<code>:abbrlink.html</code>。</p><h2 id="文章配置与效果"><a href="#文章配置与效果" class="headerlink" title="文章配置与效果"></a>文章配置与效果</h2><p>我们完成了如上的配置后，如果不对博客文章做任何处理的话，在部署的时候，将会根据算法随机生成每篇博客的数字链接。当然，如果你觉得使用随机的数字连接不具有识别性，想要自定义每篇博客的链接的话也是可以的，只需要在你的博客<code>.md</code>文章的头部配置如下字段即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">abbrlink: your_blog_url</span><br></pre></td></tr></table></figure><p>例如，我的这篇博客就是配置成<code>abbrlink: Hexoblogurloptimize</code>，最终我的博客的连接就是<a href="https://www.xiemingzhao.com/posts/Hexoblogurloptimize.html">https://www.xiemingzhao.com/posts/Hexoblogurloptimize.html</a>。</p><p>通过这一顿操作，你就可以随心所欲控制你的博客的链接了。每次修改博客文章的时候，只要不修改<code>abbrlink</code>配置项，那么这篇博客的链接就永远不会发生变化。这样不仅有利于博客链接的记忆与传播，更有利于整个博客的SEO优化，提升检索度和排名。</p><h2 id="一些官方配置信息"><a href="#一些官方配置信息" class="headerlink" title="一些官方配置信息"></a>一些官方配置信息</h2><p>官方文章中你还可以使用如下变量的配置，当然除了这些还可以使用<code>Front-matter</code>中的所有属性。</p><div class="table-container"><table><thead><tr><th style="text-align:left">变量</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><code>:year</code></td><td style="text-align:left">文章的发表年份（4 位数）</td></tr><tr><td style="text-align:left"><code>:month</code></td><td style="text-align:left">文章的发表月份（2 位数）</td></tr><tr><td style="text-align:left"><code>:i_month</code></td><td style="text-align:left">文章的发表月份（去掉开头的零）</td></tr><tr><td style="text-align:left"><code>:day</code></td><td style="text-align:left">文章的发表日期 (2 位数)</td></tr><tr><td style="text-align:left"><code>:i_day</code></td><td style="text-align:left">文章的发表日期（去掉开头的零）</td></tr><tr><td style="text-align:left"><code>:title</code></td><td style="text-align:left">文件名称</td></tr><tr><td style="text-align:left"><code>:id</code></td><td style="text-align:left">文章 ID</td></tr><tr><td style="text-align:left"><code>:category</code></td><td style="text-align:left">分类。如果文章没有分类，则是 <code>default_category</code> 配置信息。</td></tr></tbody></table></div><p>假设你在永久链接中使用一些变量，利于<code>lang</code>，你可以在<code>permalink_defaults</code>中进行个变量的默认值配置，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">permalink_defaults:</span><br><span class="line">  lang: en</span><br></pre></td></tr></table></figure><p>如此，你不指定该变量的时候，就会使用默认值，增加了灵活性。</p><p><strong>参考文章</strong><br><a href="https://zuiyu1818.cn/posts/NexT_seourl.html" target="_blank" rel="noopener">Hexo | 博客文章链接优化</a><br><a href="https://hexo.io/zh-cn/docs/permalinks.html" target="_blank" rel="noopener">永久链接（Permalinks）</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;文章的URL&quot;&gt;&lt;a href=&quot;#文章的URL&quot; class=&quot;headerlink&quot; title=&quot;文章的URL&quot;&gt;&lt;/a&gt;文章的URL&lt;/h2&gt;&lt;p&gt;文章默认的URL配置是包含年月日以及文章标题的，而且每次文章文章有修改就会引起一些链接的变化，繁琐且不易于检
      
    
    </summary>
    
    
      <category term="博客搭建" scheme="https://www.xiemingzhao.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="Hexo" scheme="https://www.xiemingzhao.com/tags/Hexo/"/>
    
      <category term="链接优化" scheme="https://www.xiemingzhao.com/tags/%E9%93%BE%E6%8E%A5%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>XGBoost A Scalable Tree Boosting System (论文解析)</title>
    <link href="https://www.xiemingzhao.com/posts/15b10533.html"/>
    <id>https://www.xiemingzhao.com/posts/15b10533.html</id>
    <published>2019-06-09T16:00:00.000Z</published>
    <updated>2019-11-10T09:33:52.415Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://delivery.acm.org/10.1145/2940000/2939785/p785-chen.pdf?" target="_blank" rel="noopener">原始论文：XGBoost: A Scalable Tree Boosting System</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Tree boosting 是一个高效的并且广泛应用的机器学习方法。在本文中，我们会介绍一个可扩展的端到端的 tree boosting 系统，它叫 XGBoost，它被数据科学家广泛地应用，并且在许多机器学习挑战取得了最好的结果。对于稀疏数据我们提出了稀疏性感知算法，以及加权分位数梗概用来近似树模型学习。更重要的是，我们提供了对缓存访问模式，数据压缩和分片的见解来建立一个可扩展的提升树系统。通过综合这些看法， XGBoost 只需要使用比现有系统少得多的资源就可以扩展出超过数十亿的实例。</p><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>大规模机器学习</p><a id="more"></a><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h2><p>机器学习和数据驱动的方法在许多领域变得非常重要。智能垃圾邮件分类器通过从大量垃圾邮件数据和用户反馈中学习来如何保护我们免受垃圾邮件的侵害；广告系统学会将正确的广告放到正确的语境中；欺诈检测系统保护银行免受恶意攻击者的攻击；异常现象检测系统帮助实验物理学家发现引发新物理现象的因素。驱动这些技术成功应用的因素有两个：使用能够发现复杂数据依赖性的有效的（统计）模型，以及能从大型数据集里学习获得偏好模型的可扩展的学习系统。</p><p>在机器学习算法的实践应用中，梯度提升树算法非常卓越。提升树在很多标准分类基准上表现非常出色。LambdaMART是提升树算法的变种，在排序任务中也表现出了不错的效果。XGBoost除了被用作单独的预测器，还被用于实际的广告点击率的问题中。它是集成算法的一种，也经常用于Netfix等竞赛。</p><p>在本文中，我们描述了XGBoost，一种针对提升树的可扩展的机器学习系统。该系统有开源的软件包可用。该系统的影响已经在许多机器学习和数据挖掘任务重得到认可。以机器学习竞赛网站kaggle为例。2015年，kaggle的博客上发布了29个挑战获胜的解决方案，其中17个解决方案用了XGBoost。在这些解决方案中，8个只用了XGBoost来训练模型，而大多数其他解决方案将XGBoost与神经网络进行了结合。第二种常用的方法是深度神经网络，出现在了11个解决方案中。KDDCup2015也证明了该系统的成功，其中前10名的队伍都用了XGBoost。此外，获胜团队表示，集成算法的效果仅仅比XGBoost略优一点。</p><p>这些结果表明，我们的系统在各种问题中表现都非常优异。这些获胜的解决方案涉及到的问题有：商店销量预测；高能物理事件分类；网络文本分类；顾客行为预测；运动检测；广告点击率预测；恶意软件识别；产品分类；风险预测；在线课程辍学率预测；虽然数据分析和特征工程在其中发挥了重要作用，但大家都选择XGBoost算法也是一个事实，这表明了我们的系统和提升树的影响和重要性。</p><p>XGBoost成功的重要因素是它可以扩展到所有场景中。该系统在单台机器上的运行速度比现有流行的解决方案快10倍以上，并可在分布式或内存有限的环境中扩展到数十亿个示例。XGBoost的可扩展性归功于几个重要的系统和算法优化。这些创新包括：一种用于稀疏数据的树学习算法；加权分位数草图能够在近似树学习中处理样本的权重，这在理论上是合理的。并行和分布式计算使得学习速度更快，从而加快了模型的探索。更重要的是，XGBoost利用外核计算，使数据科学家能够在桌面上处理数十亿个示例。最后，更令人兴奋的是，将这些技术结合起来，利用端对端系统以最少的集群资源将其扩展到更大的数据规模。本文主要贡献如下：</p><ul><li>我们设计并构建了一个高度扩展的端对端的提升树系统</li><li>我们提出了一个用于高效运算的理论上正确的加权分位数草图</li><li>我们为并行树模型学习提出了一种新颖的稀疏感知算法</li><li>我们提出了一种有效的缓存感知块结构用于树模型的核外学习</li></ul><p>虽然现在存在一些并行提升树模型的研究工作，但核外计算、缓存感知和稀疏感知学习等方向还尚未有人涉略。更重要的是，结合这些方面的技术构建出的端对端的系统为实际应用提供了一种新的解决方案。这使得数据科学家和研究人员能够构建提升树算法的强大变种。除了这些主要的贡献之外，我们还提出了一个正则化学习的方法。</p><p>本文其余的部分安排如下。第二部分我们回顾了提升树，并介绍了正则化的目标。然后，我们在第三部分介绍分割节点寻找的方法，第四部分是系统设计，包括相关的实验结果，为我们提到的每个优化方法提供量化支持。相关工作放在在第五节讨论。第六部分详细的介绍了端对端的评估。最后，我们在第七部分总结这篇论文。</p><h2 id="2-提升树简介"><a href="#2-提升树简介" class="headerlink" title="2.提升树简介"></a>2.提升树简介</h2><p>我们在这一节中介绍梯度提升树算法。公式推导遵循文献中的梯度提升思想。特别地，其中的二阶方法源自Friedman等人。我们对正则项进行了微小的改进，这在实践中有所帮助。</p><p><img src="https://i.postimg.cc/2ywczj7k/xgb-1.jpg" alt="xgb-1.jpg"></p><h3 id="2-1-正则化学习目标"><a href="#2-1-正则化学习目标" class="headerlink" title="2.1 正则化学习目标"></a>2.1 正则化学习目标</h3><p>对于一个给定的数据集有n个样本和m个特征$\mathcal D={(x_i,y_i)}(|\mathcal D|=n,x_i \in \mathbb R^m,y_i \in \mathbb R)$，树集成算法使用个数为K的加法模型（如图1）来预测输出。</p><script type="math/tex; mode=display">\hat y_i = \phi(x_i) = \sum_{k=1}^k F_k (x_i), f_k \in \mathcal F</script><p>其中$\mathcal F = {f(x) = w_{q(x)}}(q: \mathbb R^m \rightarrow T, w \in \mathbb R^T)$是回归树（也叫做CART）的空间。$q$表示将样本映射到叶节点的树的结构。$T$是每棵树叶子的数量。每个$F_k$对应了独立的树结构$q$和叶权值$w$。与决策树不同，每棵回归树的每个叶子上包含连续的连续值打分，我们用$w_i$表示第$i$个叶子的打分。对于一个给定的例子，我们将使用树中的决策规则（由$q$给出）将其分类到叶子节点中，并通过对相应叶子中的分数求和来计算最终预测（由$w$给出）。为了学习模型中使用的函数集合，我们最小化下面的正则化的项。</p><script type="math/tex; mode=display">\mathcal L(\phi) = \sum_i l(\hat y_i, y_i) + \sum_k \Omega(f_k)</script><script type="math/tex; mode=display">where \Omega(f) = \gamma T + \frac{1}{2} \lambda ||w||^2</script><p>这里$L$是一个可微的凸损失函数，它表示预测$y_i$和目标$y$之间的差值。第二项$\Omega$是惩罚项，惩罚模型的复杂度（即回归树模型）。附加正则化项会有助于使最终学习到的权值更加平滑，避免过拟合。直观地说，带有正则化的目标函数倾向于选择简单的预测模型。类似的正则化技术已被用于正则化贪心森林算法（RGF）模型中。我们的目标函数和相应的学习算法比RGF更简单，更容易实现并行化。当正则化参数被设置为零时，目标函数退化为传统的梯度提升树。</p><h3 id="2-2-梯度提升树"><a href="#2-2-梯度提升树" class="headerlink" title="2.2 梯度提升树"></a>2.2 梯度提升树</h3><p>公式（2）中的树集成模型中包含函数作为参数的情况，不能使用欧氏空间中的传统优化方法来优化。替代的方法是模型以累加的方式训练。形式上,$\hat y_i^{(t)}$是第$t$次迭代中第$i$个实例的预测，我们把$f_t$加到下面的最小化目标中。</p><script type="math/tex; mode=display">\mathcal L^{(t)} = \sum_{t=1}^n l(y_i,\hat y_i^{(t-1)} + f_t(x_i)) + \Omega(f_t)</script><p>这意味着我们根据公式（2）贪婪地将$f_t$加到了目标函数中，这对我们模型提升最大（因为是沿梯度下降的）。一般情况下，二阶近似（泰勒二阶展开近似）可以用于快速优化目标函数。（因为有二阶信息，所以优化起来比一阶速度快。例如，牛顿法就比传统的梯度下降快）。</p><script type="math/tex; mode=display">\mathcal L^{(t)} \simeq \sum_{t=1}^n [l(y_i,\hat y^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t)</script><p>其中，$g_i = \partial_{\hat y^{(t-1)}} l(y_i,\hat y^{(t-1)})$和$h_i = \partial_{\hat y^{(t-1)}}^2 l(y_i,\hat y^{(t-1)})$，分别为损失函数一阶和二阶的梯度值。在第$t$步迭代中，我们可以去掉常数项以简化目标函数。（t步的时候t-1步的损失已经是定值）</p><script type="math/tex; mode=display">\tilde{\mathcal L}^{(t)} \simeq \sum_{t=1}^n [g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t)</script><p>定义$I_j = {i|q(x_i)=j}$为叶子结点j里面的样本，我们可以通过扩展$\Omega$来重写公式（3）：</p><script type="math/tex; mode=display">\tilde{\mathcal L}^{(t)} = \sum_{t=1}^n [g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T w_j^2 \\=\sum_{j=1}^T[(\sum_{i \in I_j} g_i) w_j + \frac{1}{2}(\sum_{i \in I_j} h_i + \lambda) w_j^2] + \gamma T</script><p>对于一个固定的结构$q(x)$，我们可以计算叶子结点$j$的最优权重$w_j^*$：</p><script type="math/tex; mode=display">w_j^* = -\frac{\sum_{i \in I_j} g_i} {\sum_{i \in I_j} h_i + \lambda}</script><p>并通过下式计算相应的最优值：</p><script type="math/tex; mode=display">\tilde{\mathcal{L}}^{(t)}(q)=-\frac{1}{2} \sum_{j=1}^{T} \frac{\left(\sum_{i \in I_{j}} g_{i}\right)^{2}}{\sum_{i \in I_{j}} h_{i}+\lambda}+\gamma T</script><p>公式（6）可以作为一个评估方程去评价一棵树的结构$q$。这个打分就像评估决策树的杂质分数，不同的是它是为了更广泛的目标函数导出的。图2示出了如何计算这个分数。</p><p><img src="https://i.postimg.cc/bNmCWJvL/xgb-2.jpg" alt="xgb-2.jpg"></p><p>通常来说不可能枚举出所有的树结构$q$，而是用贪心算法，从一个叶子开始分裂，反复给树添加分支。假设$I_L$和$I_R$ 是分裂后左右节点中包含的样本集合。使$I＝I_L \cup I_R$，通过下式分裂后会使损失函数降低。</p><script type="math/tex; mode=display">\mathcal{L}_{\text {split}}=\frac{1}{2}\left[\frac{\left(\sum_{i \in I_{L}} g_{i}\right)^{2}}{\sum_{i \in I_{L}} h_{i}+\lambda}+\frac{\left(\sum_{i \in I_{R}} g_{i}\right)^{2}}{\sum_{i \in I_{R}} h_{i}+\lambda}-\frac{\left(\sum_{i \in I} g_{i}\right)^{2}}{\sum_{i \in I} h_{i}+\lambda}\right]-\gamma</script><p>这个公式用于评价候选分裂节点的好坏。</p><h3 id="2-3-收缩和列子采样"><a href="#2-3-收缩和列子采样" class="headerlink" title="2.3 收缩和列子采样"></a>2.3 收缩和列子采样</h3><p>除了在2.1节中使用的正则化项，我们还使用了两种技术来进一步防止过拟合。第一种技术是Friedman引入的收缩。在每一次提升树训练迭代后，在前面乘一个因子$η$来收缩其权重（也就是我们说的学习率，或者叫步长）。与随机优化中的学习率类似，收缩减少了每棵树的影响，并为将来的树模型留出了改进模型的空间。第二种技术上列（特征）子采样。这个技术用于随机森林中，在商业软件TreeNet4中实现，用于梯度增强，但未在现有的开源包中实现。根据用户反馈，使用列子采样可以比传统的行子采样（也支持）更能防止过度采样。列子采样还能加速稍后描述的并行算法。</p><h2 id="3-分裂查找算法"><a href="#3-分裂查找算法" class="headerlink" title="3. 分裂查找算法"></a>3. 分裂查找算法</h2><h3 id="3-1-基准贪婪算法"><a href="#3-1-基准贪婪算法" class="headerlink" title="3.1 基准贪婪算法"></a>3.1 基准贪婪算法</h3><p>树模型学习过程中的一个关键问题是找到最佳分裂节点，如公式（7）所示。为了做到这一点，一个分裂查找算法枚举出了所有特征上的所有可能的分裂节点，我们称之为贪婪算法。大多数现有的单机版本的提升树已经实现了，如scikit-learn、R中的GBM以及XGBoost的单机版本。在Alg.1中给出贪婪算法的详细描述。算法要求列举出所有特征的所有可能的分割点。为了提高效率，算法必须先将特征取值排序，并按顺序访问数据，然后根据公式（7）计算出当前分割点的梯度统计量。</p><p><img src="https://i.postimg.cc/mZN63Vfv/xgb-a1.jpg" alt="xgb-a1.jpg"></p><h3 id="3-2-近似算法"><a href="#3-2-近似算法" class="headerlink" title="3.2 近似算法"></a>3.2 近似算法</h3><p>贪婪算法是非常有效的，因为它贪婪地枚举除了所有可能的分裂点。然而，当数据不能完全读入内存时，这样做就不会很有效率。同样的问题也出现在分布式环境中。为了有效支持这两种环境中的提升树，我们需要一种近似算法。</p><p><img src="https://i.postimg.cc/L5RQKgfQ/xgb-a2.jpg" alt="xgb-a2.jpg"></p><p>我们总结了一个近似框架，类似于在过去的文献中提到的想法「参考文献17、2、22」，如Alg.2描述。总结来说，该算法首先根据特征分布的百分位数提出可能的候选分裂点（具体的准则在3.3中给出）。然后算法将连续特征值映射到候选分割点分割出的箱子中。计算出每个箱子中数据的统计量（这里的统计量指的是公式（7）中的$g$和$h$），然后根据统计量找到最佳的分割点。</p><p>该算法有两种变体，区别为分裂点的准则何时给出。全局选择在树构造的初始阶段要求给出所有候选分裂点，并且在树的所有层中使用相同的分裂节点用于分裂。局部选择在分裂后重新给出分裂候选节点。全局方法比局部方法需要更少的步骤。然而，通常在全局选择中需要更多的候选点，因为在每次分裂后候选节点没有被更新。局部选择在分裂后更新候选节点，并且可能更适合于深度更深的树。图3给出了基于希格斯玻色子数据集的不同算法的比较。我们发现，本地变种确实需要更少的候选人。当给出足够的候选节点，全局变种可以达到与本地变种一样的准确率。（局部选择步骤多的意思就是每分裂一次都需要更新3.3中对应的min(x)和max(x)，相比全局选择来说候选点间隔更细）</p><p>大多数现有的分布式树模型学习的近似算法也遵循这一框架。值得注意的是，直接构造梯度统计量的近似直方图也是可行的。也可以使用分箱策略来代替分位数划分。分位数策略的优点是可分配和可重计算，我们将在下一节中详细说明。从图3中，我们还发现，当设置合理的近似水平，分位数策略可以得到与贪心算法相同的精度。</p><p>我们的系统有效地支持单机版的贪心算法，同时也支持近似算法的本地变种和全球变种的所有设置。用户可以根据需求自由选择。</p><p><img src="https://i.postimg.cc/8PpXZWTj/xgb-3.jpg" alt="xgb-3.jpg"></p><h3 id="3-3-加权分位数梗概"><a href="#3-3-加权分位数梗概" class="headerlink" title="3.3 加权分位数梗概"></a>3.3 加权分位数梗概</h3><p>近似算法中很重要的一步是列出候选的分割点。通常特征的百分位数作为候选分割点的分布会比较均匀。具体来说，设$\mathcal{D}_{k}=\left\{\left(x_{1 k}, h_{1}\right),\left(x_{2 k}, h_{2}\right) \cdots\left(x_{n k}, h_{n}\right)\right\}$表示样本的第$k$个特征的取值和其二阶梯度统计量。我们可以定义一个排序方程$r_{k} : \mathbb{R} \rightarrow[0,+\infty)$：</p><script type="math/tex; mode=display">r_{k}(z)=\frac{1}{\sum_{(x, h) \in \mathcal{D}_{k}} h} \sum_{(x, h) \in \mathcal{D}_{k}, x<z} h</script><p>上式表示样本中第$k$个特征的取值小于$z$的比例（公式表达的是取值小于$z$的二阶梯度统计量的比例）。我们的目标是找到候选的分割节点$\left\{s_{k 1}, s_{k 2}, \cdots s_{k l}\right\}$。</p><script type="math/tex; mode=display">\left|r_{k}\left(s_{k, j}\right)-r_{k}\left(s_{k, j+1}\right)\right|<\epsilon, \quad s_{k 1}=\min_{i} \mathbf{x}_{i k}, s_{k l}=\max_{i} \mathbf{x}_{i k}</script><p>这里$\epsilon$是一个近似因子（就是衡量两者的差距）。直观的说，大概有$\frac{1}{\epsilon}$个分割点（例，如果从0-1之间分割，分割点之间差距小于0.2，那么就是大概有5个分割点）。这里每一个数据点用$h_i$来代表权重。我们来看看为什么$h_i$能代表权重，我们可以把公式（3）重写为：</p><script type="math/tex; mode=display">\sum_{i=1}^{n} \frac{1}{2} h_{i}\left(f_{t}\left(\mathbf{x}_{i}\right)-g_{i} / h_{i}\right)^{2}+\Omega\left(f_{t}\right)+\text {constant}</script><p>这实际上是权值为$h_i$，标签为$g_i/h_i$的加权平方损失。对于大数据集来说，找到满足标准的候选分割点是非常不容易的。当每个实例具有相等的权重时，一个现存的叫分位数草图的算法解决了这个问题。然而，对于加权的数据集没有现存的分位数草图算法。因此，大部分现存的近似算法要么对可能失败的数据的随机子集进行排序，要么使用没有理论保证的启发式算法。</p><p>为了解决这个问题，我们引入了一种新的分布式加权分位数草图算法，该算法可以处理加权数据，并且可以从理论上证明。通常的做法是提出一种支持合并和修建操作的数据结构，每个操作都是可以被证明保持一定准确度的。附录中给出了算法的详细描述以及证明。</p><h3 id="3-4-稀疏性感知分裂查找"><a href="#3-4-稀疏性感知分裂查找" class="headerlink" title="3.4 稀疏性感知分裂查找"></a>3.4 稀疏性感知分裂查找</h3><p>在许多实际问题中，输入$X$稀疏是常见的。稀疏有多个可能的原因导致：<br>1）数据中存在缺失值；<br>2）有些统计数值常常为0；<br>3）特征工程的结果，如one-hot编码。<br>算法对数据中稀疏模式的感知能力是非常重要的。为了做到这一点，我们建议在每个树节点中添加一个默认的方向，如图4所示。当稀疏矩阵$x$中的值丢失时，实例被分类为默认的方向。</p><p><img src="https://i.postimg.cc/VkNTkth3/xgb-4.jpg" alt="xgb-4.jpg"></p><p>在每个分支中有两种默认方向。最优的默认方向是从数据中学习出来的。具体算法在Alg.3显示。关键步骤是只访问非缺失的数据$I_k$。算法将不存在的值视为缺失值并学习默认方向去处理它（这里的不存在的值应该说的是不符合特征意义或者不合理的值）。当非存在的值对应于用户特定说明的值时，可以将枚举结果限制为一致的方案来应用这个算法。</p><p><img src="https://i.postimg.cc/mrv6j5rs/xgb-a3.jpg" alt="xgb-a3.jpg"></p><p>据我们所知，大多数现有的树学习算法要么只对密集数据进行优化，要么需要特定的步骤来处理特殊情况，例如类别编码。XGBoost以统一的方式处理所有稀疏模式。更重要的是，我们的方法利用稀疏性，使得计算的复杂度与输入中的非缺失数据的数量成线性关系。图5显示了稀疏感知算法和一个常规算法在数据集Allstate-10K（此数据集在第6部分描述）上的比较。我们发现稀疏感知算法的运行速度比常规版本快50倍。这证实了稀疏感知算法的重要性。</p><p><img src="https://i.postimg.cc/MprLMT2X/xgb-5.jpg" alt="xgb-5.jpg"></p><h2 id="4-系统设计"><a href="#4-系统设计" class="headerlink" title="4. 系统设计"></a>4. 系统设计</h2><h3 id="4-1-并行学习的列存储"><a href="#4-1-并行学习的列存储" class="headerlink" title="4.1 并行学习的列存储"></a>4.1 并行学习的列存储</h3><p>树学习中最耗时的部分是数据排序。为了减少排序的成本，我们提出将数据存储在内存单元中，称之为block。每个block中的数据每列根据特征取值排序，并以压缩列（CSC）格式储存。这种输入数据布局只需要在训练前计算一次，可以在后续迭代中重复使用。</p><p>在贪婪算法中，我们将整个数据集存储在单个block中，并通过对预排序的数据进行线性扫描来实现分割点搜索。我们集体对所有叶子进行分割查找，这样只需扫描一次block就可以得到所有叶子节点处所有候选分裂节点的统计信息。图6显示了如何将数据集转换成相应格式并使用block结构找到最优分割。</p><p><img src="https://i.postimg.cc/LsYbzp2D/xgb-6.jpg" alt="xgb-6.jpg"></p><p>当使用近似算法时，block结构也非常有用。在这种情况下，可以使用多个block，每个block对应于数据集中的不同的行子集。不同的block可以分布在机器上，或者在非核心设置中存储在磁盘上。使用排序结构，分位数查找步骤在完成排序的列上就变成了线性扫描。这对于在每个分支中频繁更新候选分割点的本地优先算法非常有价值。直方图聚合中的二分搜索也变成了线性时间合并样式算法。</p><p>收集每列统计信息这一步骤可以实现并行化，这也给我们提供了一种寻找分割点的并行算法。还有一点重要的是，列的block结构同样支持列子采样，因为从block结构中选择列子集是非常容易的。</p><p><strong>时间复杂度分析</strong><br>设$d$为树的最大深度，$K$为树的总数。对于贪婪算法，原始稀疏感知算法的时间复杂度为$O(Kd∥x∥_0\log n)$。这里我们使用$||x||_0$来表示训练数据中的非缺失条目的数量。另一方面，在block结构上仅消耗$O(Kd∥x∥_0+∥x∥_0\log n)$。这里$O(x∥_0\log n)$是可以摊销的有一次性预处理成本。该分析表名block结构可以节省额外的logn的复杂度，这在$n$很大时很重要。对于近似算法，基于二分搜索的原始算法的时间复杂度为$O(Kd∥x∥_0\log q)$。这里$q$是数据集中候选分割节点的数量。虽然$q$通常介于32和100之间，但对数因子仍会引入开销。使用block结构，我们可以将之间减少到$O(Kd∥x∥_0+∥x∥_0\log n)$，其中$B$是每个块中的最大行数。我们再次可以在计算中保存额外的$log q$因子。</p><h3 id="4-2-缓存感知访问"><a href="#4-2-缓存感知访问" class="headerlink" title="4.2 缓存感知访问"></a>4.2 缓存感知访问</h3><p>虽然block结构有助于优化分割点查找的时间复杂度，但是算法需要通过行索引间接提取梯度统计量，因为这些值是按特征的顺序访问的，这是一种非连续的内存访问（意思就是按值排序以后指针就乱了）。分割点枚举的简单实现在累积和非连续内存提取之间引入了即时读/写依赖性（参见图8）。当梯度统计信息不适合CPU缓存进而发生缓存未命中时，这会减慢分割点查找的速度。</p><p><img src="https://i.postimg.cc/hPs6ns2L/xgb-8.jpg" alt="xgb-8.jpg"></p><p>对于贪心算法，我们可以通过缓存感知预取算法来缓解这个问题。 具体来说，我们在每个线程中分配一个内部缓冲区，获取梯度统计信息并存入，然后以小批量方式执行累积。预取的操作将直接读/写依赖关系更改为更长的依赖关系，有助于数据行数较大时减少运行开销。图7给出了Higgs和Allstate数据集上缓存感知与非缓存感知算法的比较。我们发现，当数据集很大时，实现缓存感知的贪婪算法的运行速度是朴素版本的两倍。</p><p><img src="https://i.postimg.cc/4dp2SQKh/xgb-7.jpg" alt="xgb-7.jpg"></p><p>对于近似算法，我们通过选择正确的block尺寸来解决问题。 我们将block尺寸定义为block中包含的最大样本数，因为这反映了梯度统计量的高速缓存存储成本。选择过小的block会导致每个线程的工作量很小，并行计算的效率很低。另一方面，过大的block会导致高速缓存未命中现象，因为梯度统计信息不适合CPU高速缓存。良好的block尺寸平衡了这两个因素。 我们在两个数据集上比较了block大小的各种选择，结果如图9所示。该结果验证了我们的讨论，并表明每个块选择$2^{16}$个样本可以平衡缓存资源利用和并行化效率。</p><p><img src="https://i.postimg.cc/15s2b2rR/xgb-9.jpg" alt="xgb-9.jpg"></p><h3 id="4-3-核外计算的块"><a href="#4-3-核外计算的块" class="headerlink" title="4.3 核外计算的块"></a>4.3 核外计算的块</h3><p>我们系统的一个目标是充分利用机器的资源来实现可扩展的学习。 除处理器和内存外，利用磁盘空间处理不适合主内存的数据也很重要。为了实现核外计算，我们将数据分成多个块并将每个块存储在磁盘上。在计算过程中，使用独立的线程将块预取到主存储器缓冲区是非常重要的，因为计算可以因此在磁盘读取的情况下进行。但是，这并不能完全解决问题，因为磁盘读取会占用了大量计算时间。减少开销并增加磁盘IO的吞吐量非常重要。 我们主要使用两种技术来改进核外计算。</p><p><strong>块压缩</strong> 我们使用的第一种技术是块压缩。该块从列方向压缩，并在加载到主存储器时通过独立的线程进行解压。这可以利用解压过程中的一些计算与磁盘读取成本进行交换。我们使用通用的压缩算法来压缩特征值。对于行索引，我们通过块的起始索引开始减去行索引，并使用16位整型来存储每个偏移量。这要求每个块有$2^{16}$个样本，这也被证实是一个好的设置（好的设置指的是$2^{16}$这个数字的设置）。在我们测试的大多数数据集中，我们实现了大约26％到29％的压缩率。</p><p><strong>块分片</strong><br>第二种技术是以另一种方式将数据分成多个磁盘。为每个磁盘分配一个实现预取的线程，并将数据提取到内存缓冲区中。然后，训练线程交替地从每个缓冲区读取数据。当有多个磁盘可用时，这有助于提高磁盘读取的吞吐量。</p><h2 id="5-相关工作"><a href="#5-相关工作" class="headerlink" title="5 . 相关工作"></a>5 . 相关工作</h2><p>我们的系统通过函数的加法模型实现了梯度提升。梯度提升树已成功用于分类，排序，结构化预测以及其他领域。XGBoost采用正则化模型来防止过度拟合，类似于正则化贪心森林，但简化了并行化的目标和算法。列采样是一种从随机森林借鉴来技术，简单且有效。虽然稀疏感知学习在其他类型的模型（如线性模型）中是必不可少的，但很少有关这方面在树模型学习中的研究。本文提出的算法是第一个可以处理各种稀疏模式的统一方法。</p><p>现存有很多树模型并行学习的研究。大多数算法都属于本文所述的近似框架。值得注意的是，还可以按列对数据进行分区并应用贪婪算法。我们的框架也支持这一点，并且可以使用诸如缓存感知预防之类的技术来使这类算法受益。虽然大多数现有的工作都集中在并行化的算法方面，但我们的工作在两个未经探索的方面得到了成果：核外计算和缓存感知学习。这让我们对联合优化系统和算法的有了深刻的理解，并构建了一个端到端系统，可以在非常有限的计算资源下处理大规模问题。在表1中，我们还总结了我们的系统与现存开源系统的对比。</p><p><img src="https://i.postimg.cc/HnCRYhG2/xgb-t1.jpg" alt="xgb-t1.jpg"></p><p>分位数摘要（无权重）是数据库社区中的经典问题。然而，近似提升树算法揭示了一个更普遍的问题——在加权数据上找分位数。据我们所知，本文提出的加权分位数草图是第一个解决该问题的方法。 加权分位数摘要也不是专门针对树模型学习的，可以在将来服务于数据科学和机器学习中的其他应用。</p><h2 id="6-端到端的预估"><a href="#6-端到端的预估" class="headerlink" title="6. 端到端的预估"></a>6. 端到端的预估</h2><h3 id="6-1-系统实现"><a href="#6-1-系统实现" class="headerlink" title="6.1 系统实现"></a>6.1 系统实现</h3><p>我们以开源软件包的形式实现了XGBoost。该软件包是可移植和可重复使用的。它支持各种加权分类和各种阶的目标函数，以及用户定义的目标函数。它对流行的语言都提供支持，例如python，R，Julia，并且与语言特定的数据科学库（如scikit-learn）自然集成。分布式版本构建在rabit库上，用于allreduce。XGBoost的可移植性使其可用于许多生态系统，而不仅仅是绑定在特定平台。分布式XGBoost可以轻松运行在Hadoop，MPI Sun Grid引擎上。最近，我们还在jvm 大数据栈（如Flink和Spark）上实现了分布式XGBoost。分布式版本也已集成到阿里巴巴的天池云平台中。我们相信未来会有更多的整合。</p><h3 id="6-2-数据集和设置"><a href="#6-2-数据集和设置" class="headerlink" title="6.2 数据集和设置"></a>6.2 数据集和设置</h3><p>我们在实验中使用了四个数据集。表2给出了这些数据集的摘要信息。在一些实验中，由于基线较慢，我们使用随机选择的数据子集，或者演示算法在不同大小的数据集下的性能。在这些情况下，我们使用后缀来表示大小。例如，Allstate-10K表示具有10K实例的Allstate数据集的子集。</p><p><img src="https://i.postimg.cc/B6FRGGzb/xgb-t2.jpg" alt="xgb-t2.jpg"></p><p>我们使用的第一个数据集是Allstate保险索赔数据集。任务是根据不同的风险因素预测保险索赔的可能性和成本。在实验中，我们将任务简化为仅预测保险索赔的概率。此数据集用于评估在3.4节中提到的稀疏感知算法。此数据中的大多数稀疏特征都是独热编码。我们随机选择10M样本作为训练集，并将其余部分用作验证集。</p><p>第二个数据集是高能物理学的希格斯玻色子数据集。该数据是使用蒙特卡洛仿真模拟物理现象生成的。它包含21个运动学特征，由加速器中的粒子探测器测量得到。还包含七个额外的粒子派生物理量。任务是分类是否物理现象与希格斯玻色子相对应。我们随机选择10M实例作为训练集，并将其余部分用作验证集。</p><p>第三个数据集是Yahoo! learning to rank比赛数据集，这是learning to rank算法最常用的基准之一。 数据集包含20K网页搜索查询结果，每个查询对应于一个有大约22个文档的列表。任务是根据查询的相关性对文档进行排名。我们在实验中使用官方的训练测试集分割标准。</p><p>最后一个数据集是criteo百万级别的点击日志数据集。我们使用此数据集来评估系统在核外和分布式环境中的扩展性。该数据包含13个数值特征和26个ID特征，其中有用户ID，项目ID和广告商信息ID等。由于树模型更擅长处理连续特征，前十天我们通过计算平均的CTR和ID特征的统计信息对数据预处理，接下来的十天用相应的统计信息替换ID特征，处理完成后就可以作为训练集。预处理后的训练集包含1.7billion个样本，每个样本具有67个特征（13个数值特征，26个平均CTR特征和26个统计特征）。整个数据集的LibSVM格式超过1TB。</p><p>我们将前三个数据集用于单机并行环境中，将最后一个数据集用于分布式和核外计算的环境。所有单机实验均在戴尔PowerEdge R420上进行，配备两个八核Intel Xeon（E5-2470）（2.3GHz）和64GB内存。如果未指定，则所有实验使用机器中的所有可用核心运行。分布式和核外实验的机器配置将在相应的部分中描述。在所有实验中，我们统一设置提升树的最大深度等于8，学习率等于0.1，除非明确指定否则不进行列子采样。当我们将最大深度设置为其他时，我们可以得到相似的结果。</p><h3 id="6-3-分类"><a href="#6-3-分类" class="headerlink" title="6.3 分类"></a>6.3 分类</h3><p>在本节中，我们在Higgs-1M数据集上通过对比其他两种常用的基于贪心算法的提升树，评估基于贪心算法的XGBoost的性能。由于scikit-learn只能处理非稀疏输入，我们选择密集Higgs数据集进行比较。我们在1M的数据子集上运行scikit-learn版本的XGBoost，这样可以在合理的时间内跑完。在比较中，R的GBM使用贪心算法，只扩展树的一个分支，这使它更快但可能导致准确性不足，而scikit-learn和XGBoost都生成完整的树。结果在表3中显示，XGBoost和scikit-learn都比R的GBM表现出更好的性能，而XGBoost的运行速度比scikit-learn快10倍。在实验中，我们还发现列子采样后的结果略差于使用所有特征训练的结果。这可能是因为此数据集中的重要特征很少，贪心算法的精确结果会更好。</p><p><img src="https://i.postimg.cc/wBZnPB0n/xgb-t3.jpg" alt="xgb-t3.jpg"></p><h3 id="6-4-排序学习"><a href="#6-4-排序学习" class="headerlink" title="6.4 排序学习"></a>6.4 排序学习</h3><p>我们接下来评估XGBoost在learning to rank问题上的表现。我们与pGBRT进行比较，pGBRT是以前此类任务中表现最好的系统。XGBoost使用贪心算法，而pGBRT仅支持近似算法。结果显示在表4和图10中。我们发现XGBoost运行速度更快。有趣的是，列采样不仅可以缩短运行时间，还能提高准确性。原因可能是由于子采样有助于防止过拟合，这是许多用户观察出来的。</p><p><img src="https://i.postimg.cc/Z5Kkv2Ws/xgb-10.jpg" alt="xgb-10.jpg"><br><img src="https://i.postimg.cc/Z5fG8H3b/xgb-t4.jpg" alt="xgb-t4.jpg"></p><h3 id="6-5-核外实验"><a href="#6-5-核外实验" class="headerlink" title="6.5 核外实验"></a>6.5 核外实验</h3><p>我们还在核外环境中使用criteo数据评估了我们的系统。我们在一台AWS c3.8xlarge机器上进行了实验（32个vcores，两个320 GB SSD，60 GB RAM）。 结果显示在图11中。我们可以发现压缩将计算速度提高了三倍，并且分成两个磁盘进一步加速了2倍。对于此类实验，非常重要的一点是使大数据集来排空系统文件缓存以实现真正的核外环境。这也是我们所做的。当系统用完文件缓存时，我们可以观察到转折点。要注意的是，最终方法中的转折点不是那么明显。这得益于更大的磁盘吞吐量和更好的计算资源利用率。我们的最终方法能够在一台机器上处理17亿个样本。</p><p><img src="https://i.postimg.cc/c1QP90Y5/xgb-11.jpg" alt="xgb-11.jpg"></p><h3 id="6-6-分布实验"><a href="#6-6-分布实验" class="headerlink" title="6.6 分布实验"></a>6.6 分布实验</h3><p>最后，我们在分布式环境中评估系统。我们在EC2上使用m3.2xlarge机器建立了一个YARN集群，这是集群的非常常见。每台机器包含8个虚拟内核，30GB内存和两个80GB SSD本地磁盘。数据集存储在AWS S3而不是HDFS上，以避免购买持久存储。</p><p><img src="https://i.postimg.cc/8cB3jmNV/xgb-12.jpg" alt="xgb-12.jpg"></p><p>我们首先将我们的系统与两个生产力级别的分布式系统进行比较：Spark MLLib和H2O。我们使用32 m3.2xlarge机器并测试不同输入尺寸的系统的性能。两个基线系统都是内存分析框架，需要将数据存储在RAM中，而XGBoost可以在内存不足时切换到核外设置。结果如图12所示。我们可以发现XGBoost的运行速度比基线系统快。更重要的是，它能够利用核外计算的优势，在给定有限的计算资源的情况下平稳扩展到所有17亿个样本。基线系统仅能够使用给定资源处理数据的子集。该实验显示了将所有系统的改进结合在一起优势。我们还通过改变机器数量来评估XGBoost的缩放属性。结果显示在图13中。随着我们添加更多机器，我们可以发现XGBoost的性能呈线性变化。重要的是，XGBoost只需要四台机器即可处理17亿个数据。这表明系统有可能处理更大的数据。</p><p><img src="https://i.postimg.cc/XvpTQ5cw/xgb-13.jpg" alt="xgb-13.jpg"></p><h2 id="7-结论"><a href="#7-结论" class="headerlink" title="7. 结论"></a>7. 结论</h2><p>在本文中，我们叙述了在构建XGBoost过程中学到的经验（XGBoost是一个可扩展的提升树系统，被数据科学家广泛使用，并在很多问题上有很好的表现）。 我们提出了一种用于处理稀疏数据的新型稀疏感知算法和用于近似学习的理论上合理的加权分位数草图算法。我们的经验表明，缓存访问模式，数据压缩和分片是构建可扩展的端到端系统以实现提升树的基本要素。这些经验也可以应用于其他机器学习系统。通过结合这些经验，XGBoost能够使用最少量的资源解决大规模的实际问题。</p><p><a href="https://blog.csdn.net/zhaojc1995/article/details/89238051" target="_blank" rel="noopener">参考译文：XGBoost原论文阅读翻译-了不起的赵队</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://delivery.acm.org/10.1145/2940000/2939785/p785-chen.pdf?&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：XGBoost: A Scalable Tree Boosting System&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;p&gt;Tree boosting 是一个高效的并且广泛应用的机器学习方法。在本文中，我们会介绍一个可扩展的端到端的 tree boosting 系统，它叫 XGBoost，它被数据科学家广泛地应用，并且在许多机器学习挑战取得了最好的结果。对于稀疏数据我们提出了稀疏性感知算法，以及加权分位数梗概用来近似树模型学习。更重要的是，我们提供了对缓存访问模式，数据压缩和分片的见解来建立一个可扩展的提升树系统。通过综合这些看法， XGBoost 只需要使用比现有系统少得多的资源就可以扩展出超过数十亿的实例。&lt;/p&gt;
&lt;h2 id=&quot;关键词&quot;&gt;&lt;a href=&quot;#关键词&quot; class=&quot;headerlink&quot; title=&quot;关键词&quot;&gt;&lt;/a&gt;关键词&lt;/h2&gt;&lt;p&gt;大规模机器学习&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="XGB" scheme="https://www.xiemingzhao.com/tags/XGB/"/>
    
  </entry>
  
  <entry>
    <title>Hexo+Next博客主题个性化设置全集</title>
    <link href="https://www.xiemingzhao.com/posts/HexoNextindividual.html"/>
    <id>https://www.xiemingzhao.com/posts/HexoNextindividual.html</id>
    <published>2019-06-09T16:00:00.000Z</published>
    <updated>2019-10-14T16:42:40.653Z</updated>
    
    <content type="html"><![CDATA[<p>想要小白详细版本的Github+Hexo+Next搭建博客教程，可访问我的另一篇博客<a href="https://www.xiemingzhao.com/posts/GithubHexoNextblog">使用Github+Hexo+Next免费搭建自己的博客（最细攻略）</a>。</p><p><strong>注意：以下非特殊说明路径都是基于你本地博客的根目录，效果主要基于hexo+next实现效果，大部分效果均可在<a href="www.xiemingzhao.com">我的博客</a>中保留，可先睹为快，再决定是否需要</strong></p><h2 id="1-实现展示fork-me-on-github效果"><a href="#1-实现展示fork-me-on-github效果" class="headerlink" title="1.实现展示fork me on github效果"></a>1.实现展示<em>fork me on github</em>效果</h2><p>先上效果图：</p><p><img src="https://i.postimg.cc/hvQg06CC/next-individual1.jpg" alt="fork me on github"></p><a id="more"></a><p>这类效果图主要有两类样式，分别是显示<code>fork me on github</code>还有一个显示github图标的，可分别在<a href="https://github.blog/2008-12-19-github-ribbons/" target="_blank" rel="noopener">第一种地址</a>和<a href="http://tholman.com/github-corners/" target="_blank" rel="noopener">第二种地址</a>里面选择自己喜欢的款式，然后复制对应框中的代码。接着打开<code>themes/next/layout/_layout.swig</code>文件，将刚才复制的代码粘贴在<code>&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;</code>代码下面，保持缩进与其对其，同时把<code>herf</code>后面对应的github地址换成你自己的。这里需要注意的是，目前复制的代码中新增了width和height参数，却没有了位置的参数。如下图所示，如果你想跟我一样只设置位置，大小默认，那么就可以删除width和height参数，并新增top,right,和border参数。想要测试在线效果的话，可用<code>hexo s</code>本地测试，或者<code>hexo d -g</code>线上测试。</p><p><img src="https://i.postimg.cc/ryDtbp3H/next-individual2.jpg" alt="fork code"></p><h2 id="2-添加动态背景"><a href="#2-添加动态背景" class="headerlink" title="2.添加动态背景"></a>2.添加动态背景</h2><p>先看效果图：</p><p><img src="https://i.postimg.cc/wTJRqG6c/next-individual3.gif" alt="background"></p><p><strong>注意：</strong>如果你是使用<code>next</code>主题并且版本在5.1.1以上，例如我自己就是，那么设置起来就极其简单，直接在主题配置文件中找到<code>canvas_nest</code>配置字段改成true即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">canvas_nest: true</span><br></pre></td></tr></table></figure></p><p>那如果你符合next以及5.1.1版本的要求怎么办呢？不着急，我们通过一些配置文件的修改也能够达到目的。上述符合的话只需要打开开关的原因是以下这些配置都已经集合进去了。</p><h3 id="修改-layout-swig"><a href="#修改-layout-swig" class="headerlink" title="修改_layout.swig"></a>修改<code>_layout.swig</code></h3><p>首先我们打开配置文件：<code>/themes/next/layout/_layout.swig</code>，然后在 <code>&lt; /body&gt;</code>之前添加代码(注意不要放在<code>&lt; /head&gt;</code>的后面)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123; % if theme.canvas_nest % &#125;</span><br><span class="line">&lt;script type=&quot;text/javascript&quot;</span><br><span class="line">color=&quot;0,0,0&quot; opacity=&apos;0.5&apos; zIndex=&quot;-1&quot; count=&quot;150&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">&#123; % endif % &#125;</span><br></pre></td></tr></table></figure><p>其中有几个配置参数解释一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">color： 线条的颜色，默认是 0,0,0 ，对应的是(R,G,B)参数；</span><br><span class="line">opacity： 线条的透明度（0~1），默认是0.5；</span><br><span class="line">count： 线条的总数量，默认是150；</span><br><span class="line">zIndex： 北京的z-index属性，css属性用户控制所在层的位置，默认是-1。</span><br></pre></td></tr></table></figure><h3 id="修改主题配置文件"><a href="#修改主题配置文件" class="headerlink" title="修改主题配置文件"></a>修改主题配置文件</h3><p>我们打开主题配置文件：<code>/themes/next/_config.yml</code>，在里面添加以下代码，一版放在最后面即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># --------------------------------------------------------------</span><br><span class="line"># background settings</span><br><span class="line"># --------------------------------------------------------------</span><br><span class="line"># add canvas-nest effect</span><br><span class="line"># see detail from https://github.com/hustcc/canvas-nest.js</span><br><span class="line">canvas_nest: true</span><br></pre></td></tr></table></figure><p>然后就可以使用经典的三个不输命令来测试了，在gitbash中运行<code>hexo clean</code>和<code>hexo g</code>，以及<code>hexo s</code>可在本地测试，或者<code>hexo d</code>即可在线上进行展示效果。</p><h2 id="3-点击出现桃心效果"><a href="#3-点击出现桃心效果" class="headerlink" title="3. 点击出现桃心效果"></a>3. 点击出现桃心效果</h2><p>先看效果图：</p><p><img src="https://i.postimg.cc/7PjTykyZ/next-individual4.gif" alt="click"></p><p>首先打开目录：<code>/themes/next/source/js/src/</code>，之后在里面新建一个<code>love.js</code>的文件，文件里面复制进去以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!function(e,t,a)&#123;function n()&#123;c(&quot;.heart&#123;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);&#125;.heart:after,.heart:before&#123;content: &apos;&apos;;width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 500%;-moz-border-radius: 50%;position: fixed;&#125;.heart:after&#123;top: -5px;&#125;.heart:before&#123;left: -5px;&#125;&quot;),o(),r()&#125;function r()&#123;for(var e=0;e&lt;d.length;e++)d[e].alpha&lt;=0?(t.body.removeChild(d[e].el),d.splice(e,1)):(d[e].y--,d[e].scale+=.004,d[e].alpha-=.013,d[e].el.style.cssText=&quot;left:&quot;+d[e].x+&quot;px;top:&quot;+d[e].y+&quot;px;opacity:&quot;+d[e].alpha+&quot;;transform:scale(&quot;+d[e].scale+&quot;,&quot;+d[e].scale+&quot;) rotate(45deg);background:&quot;+d[e].color+&quot;;z-index:99999&quot;);requestAnimationFrame(r)&#125;function o()&#123;var t=&quot;function&quot;==typeof e.onclick&amp;&amp;e.onclick;e.onclick=function(e)&#123;t&amp;&amp;t(),i(e)&#125; &#125;function i(e)&#123;var a=t.createElement(&quot;div&quot;);a.className=&quot;heart&quot;,d.push(&#123;el:a,x:e.clientX-5,y:e.clientY-5,scale:1,alpha:1,color:s()&#125;),t.body.appendChild(a)&#125;function c(e)&#123;var a=t.createElement(&quot;style&quot;);a.type=&quot;text/css&quot;;try&#123;a.appendChild(t.createTextNode(e))&#125;catch(t)&#123;a.styleSheet.cssText=e&#125;t.getElementsByTagName(&quot;head&quot;)[0].appendChild(a)&#125;function s()&#123;return&quot;rgb(&quot;+~~(255*Math.random())+&quot;,&quot;+~~(255*Math.random())+&quot;,&quot;+~~(255*Math.random())+&quot;)&quot;&#125;var d=[];e.requestAnimationFrame=function()&#123;return e.requestAnimationFrame||e.webkitRequestAnimationFrame||e.mozRequestAnimationFrame||e.oRequestAnimationFrame||e.msRequestAnimationFrame||function(e)&#123;setTimeout(e,1e3/60)&#125; &#125;(),n()&#125;(window,document);</span><br></pre></td></tr></table></figure><p>接着打开配置文件<code>/themes/next/layout/_layout.swig</code>，在最后加上以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 页面点击小红心 --&gt;</span><br><span class="line">&lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/love.js&quot;&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure><p>到此就完成了，可以部署测试一下效果。</p><h2 id="4-修改文章链接样式"><a href="#4-修改文章链接样式" class="headerlink" title="4. 修改文章链接样式"></a>4. 修改文章链接样式</h2><p>先看效果图：</p><p><img src="https://i.postimg.cc/Sj041d3m/next-individual5.gif" alt="blog link style"></p><p>打开配置文件：<code>themes/next/source/css/_common/components/post/post.styl</code>，在最后面添加如下的代码来设置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// 文章内链接文本样式</span><br><span class="line">.post-body p a&#123;</span><br><span class="line">  color: #0593d3;</span><br><span class="line">  border-bottom: none;</span><br><span class="line">  border-bottom: 1px solid #0593d3;</span><br><span class="line">  &amp;:hover &#123;</span><br><span class="line">    color: #fc6423;</span><br><span class="line">    border-bottom: none;</span><br><span class="line">    border-bottom: 1px solid #fc6423;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中<code>.post-body</code>是为了值效果不影响标题，而后面的<code>p</code>是为了起到不影响首页<code>阅读原文</code>的效果，<code>color: #fc6423;</code>是颜色的配置项，可以自定义。</p><h2 id="5-修改文章底部标签符号"><a href="#5-修改文章底部标签符号" class="headerlink" title="5. 修改文章底部标签符号#"></a>5. 修改文章底部标签符号<strong>#</strong></h2><p>默认的文章底部显示的标签是以<code>#</code>来展示的，看上去蛮怪的，我们改成另一种样式，</p><p>我们打开模板配置文件：<code>/themes/next/layout/_macro/post.swig</code>，然后搜索<code>rel=&quot;tag&quot;&gt;#</code>，将其中的<code>#</code>换成<code>&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;</code>，保存后部署即可。</p><h2 id="6-文章末尾添加“结束”标记"><a href="#6-文章末尾添加“结束”标记" class="headerlink" title="6. 文章末尾添加“结束”标记"></a>6. 文章末尾添加“结束”标记</h2><p>先看效果图：</p><p><img src="https://i.postimg.cc/G25dGdj8/next-individual6.jpg" alt="blog ending"></p><p>首先打开文件夹：<code>/themes/next/layout/_macro</code>，然后在其中新建<code>passage-end-tag.swig</code>文件，并添加以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">    &#123; % if not is_index % &#125;</span><br><span class="line">        &lt;div style=&quot;text-align:center;color: #ccc;font-size:14px;&quot;&gt;-------------本文结束&lt;i class=&quot;fa fa-paw&quot;&gt;&lt;/i&gt;感谢您的阅读-------------&lt;/div&gt;</span><br><span class="line">    &#123; % endif % &#125;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure><p>其中<code>-------------本文结束</code>和<code>感谢您的阅读-------------</code>两处可根据自己的喜好进行修改。</p><p>接着，打开配置文件：<code>/themes/next/layout/_macro/post.swig</code>，在<code>END POST BODY</code>和<code>&lt;footer class=&quot;post-footer&quot;&gt;</code>之间添加以下代码，一般就放在紧邻<code>END POST BODY</code>后面即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">  &#123; % if not is_index % &#125;</span><br><span class="line">    &#123; % include &apos;passage-end-tag.swig&apos; % &#125;</span><br><span class="line">  &#123; % endif % &#125;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure><p>最后打开主题配置文件，在最后面添加以下代码即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 文章末尾添加“本文结束”标记</span><br><span class="line">passage_end_tag:</span><br><span class="line">  enabled: true</span><br></pre></td></tr></table></figure></p><p>到这里就完成了，可以部署后看看线上的效果，每一篇文章都添加了。</p><h2 id="7-头像触碰旋转"><a href="#7-头像触碰旋转" class="headerlink" title="7. 头像触碰旋转"></a>7. 头像触碰旋转</h2><p>先上效果图：</p><p><img src="https://i.postimg.cc/mgsztykx/next-individual7.gif" alt="headpicture"></p><p>头像的配置这里不赘述了，可参考本文开头提到的另一篇博客。接下来为了实现触碰旋转，我们需要先打开配置文件：<code>/themes/next/source/css/_common/components/sidebar/sidebar-author.styl</code>，然后再最后添加如下一段代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">.site-author-image &#123;</span><br><span class="line">  display: block;</span><br><span class="line">  margin: 0 auto;</span><br><span class="line">  padding: $site-author-image-padding;</span><br><span class="line">  max-width: $site-author-image-width;</span><br><span class="line">  height: $site-author-image-height;</span><br><span class="line">  border: $site-author-image-border-width solid $site-author-image-border-color;</span><br><span class="line"></span><br><span class="line">  /* 头像圆形 */</span><br><span class="line">  border-radius: 80px;</span><br><span class="line">  -webkit-border-radius: 80px;</span><br><span class="line">  -moz-border-radius: 80px;</span><br><span class="line">  box-shadow: inset 0 -1px 0 #333sf;</span><br><span class="line"></span><br><span class="line">  /* 设置循环动画 [animation: (play)动画名称 (2s)动画播放时长单位秒或微秒 (ase-out)动画播放的速度曲线为以低速结束 </span><br><span class="line">    (1s)等待1秒然后开始动画 (1)动画播放次数(infinite为循环播放) ]*/</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  /* 鼠标经过头像旋转360度 */</span><br><span class="line">  -webkit-transition: -webkit-transform 1.0s ease-out;</span><br><span class="line">  -moz-transition: -moz-transform 1.0s ease-out;</span><br><span class="line">  transition: transform 1.0s ease-out;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">img:hover &#123;</span><br><span class="line">  /* 鼠标经过停止头像旋转 </span><br><span class="line">  -webkit-animation-play-state:paused;</span><br><span class="line">  animation-play-state:paused;*/</span><br><span class="line"></span><br><span class="line">  /* 鼠标经过头像旋转360度 */</span><br><span class="line">  -webkit-transform: rotateZ(360deg);</span><br><span class="line">  -moz-transform: rotateZ(360deg);</span><br><span class="line">  transform: rotateZ(360deg);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/* Z 轴旋转动画 */</span><br><span class="line">@-webkit-keyframes play &#123;</span><br><span class="line">  0% &#123;</span><br><span class="line">    -webkit-transform: rotateZ(0deg);</span><br><span class="line">  &#125;</span><br><span class="line">  100% &#123;</span><br><span class="line">    -webkit-transform: rotateZ(-360deg);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">@-moz-keyframes play &#123;</span><br><span class="line">  0% &#123;</span><br><span class="line">    -moz-transform: rotateZ(0deg);</span><br><span class="line">  &#125;</span><br><span class="line">  100% &#123;</span><br><span class="line">    -moz-transform: rotateZ(-360deg);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">@keyframes play &#123;</span><br><span class="line">  0% &#123;</span><br><span class="line">    transform: rotateZ(0deg);</span><br><span class="line">  &#125;</span><br><span class="line">  100% &#123;</span><br><span class="line">    transform: rotateZ(-360deg);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="8-修改-代码块样式"><a href="#8-修改-代码块样式" class="headerlink" title="8. 修改``代码块样式"></a>8. 修改``代码块样式</h2><p>先看效果图：</p><p><img src="https://i.postimg.cc/rmmqDK52/next-individual8.jpg" alt="code style"></p><p>首先打开配置文件：<code>/themes/next/source/css/_custom/custom.styl</code>，如果对应路径下没有的话就新建一个，然后在里面添加以下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">// Custom styles.</span><br><span class="line">code &#123;</span><br><span class="line">    color: #ff7600;</span><br><span class="line">    background: #fbf7f8;</span><br><span class="line">    margin: 2px;</span><br><span class="line">&#125;</span><br><span class="line">// 大代码块的自定义样式</span><br><span class="line">.highlight, pre &#123;</span><br><span class="line">    margin: 5px 0;</span><br><span class="line">    padding: 5px;</span><br><span class="line">    border-radius: 3px;</span><br><span class="line">&#125;</span><br><span class="line">.highlight, code, pre &#123;</span><br><span class="line">    border: 1px solid #d6d6d6;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="9-主页文章添加阴影效果"><a href="#9-主页文章添加阴影效果" class="headerlink" title="9. 主页文章添加阴影效果"></a>9. 主页文章添加阴影效果</h2><p>先看效果图：</p><p><img src="https://i.postimg.cc/g0GzPMJJ/next-individual9.jpg" alt="home paper back"></p><p>紧接着上面的步骤，继续在配置文件<code>/themes/next/source/css/_custom/custom.styl</code>中最后面添加下面的代码即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 主页文章添加阴影效果</span><br><span class="line"> .post &#123;</span><br><span class="line">   margin-top: 60px;</span><br><span class="line">   margin-bottom: 60px;</span><br><span class="line">   padding: 25px;</span><br><span class="line">   -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);</span><br><span class="line">   -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h2 id="10-侧栏社交连接"><a href="#10-侧栏社交连接" class="headerlink" title="10. 侧栏社交连接"></a>10. 侧栏社交连接</h2><p>效果如下：</p><p><img src="https://i.postimg.cc/jq1SJQ8g/next-individual10.jpg" alt="social link"></p><p>首先打开主题配置文件<code>_config.yml</code>，然后搜索<code>social</code>关键词，找到<code>social</code>和<code>social_icons</code>参数配置区域，可以看到如下的代码配置块：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">social:</span><br><span class="line">  GitHub: https://github.com/xiemingzhao</span><br><span class="line">  Google: https://plus.google.com/xiemingzhao</span><br><span class="line">  Twitter: https://twitter.com/xiemingzhao</span><br><span class="line">  #FB Page: https://www.facebook.com/yourname || facebook</span><br><span class="line">  #VK Group: https://vk.com/yourname || vk</span><br><span class="line">  #StackOverflow: https://stackoverflow.com/yourname || stack-overflow</span><br><span class="line">  #YouTube: https://youtube.com/yourname || youtube</span><br><span class="line">  #Instagram: https://instagram.com/yourname || instagram</span><br><span class="line">  #Skype: skype:yourname?call|chat || skype</span><br><span class="line"></span><br><span class="line">social_icons:</span><br><span class="line">  enable: true</span><br><span class="line">  icons_only: false</span><br><span class="line">  transition: false</span><br><span class="line">  GitHub: github</span><br><span class="line">  Google: google</span><br><span class="line">  Twitter: twitter</span><br></pre></td></tr></table></figure><p>如上所示，<code>social</code>模块是配置各个社交连接项的，不需要的可以注释掉，也可以新增其他的社交项，名称也都没有限制，社交项对应的图标是使用<code>fontawesome</code>的icon图标的，可以在<a href="https://fontawesome.com/icons?from=io" target="_blank" rel="noopener">fontawesome图标官网</a>找到你喜欢的。图标的配置可以在<code>social</code>模块中的对应链接后面使用<code>||</code>隔开配置，也可在下面的<code>social_icons</code>模块配置，不管怎样，最后记得要把<code>social_icons</code>模块中的<code>enable</code>设为<code>true</code>哦。</p><h2 id="11-站点底部和文章顶部显示访问量"><a href="#11-站点底部和文章顶部显示访问量" class="headerlink" title="11. 站点底部和文章顶部显示访问量"></a>11. 站点底部和文章顶部显示访问量</h2><p>先看看如下两个效果图：</p><p><img src="https://i.postimg.cc/CxTMcMpb/next-individual11.jpg" alt="uv and pv"></p><p><img src="https://i.postimg.cc/sDZDPQqV/next-individual12.jpg" alt="site uv and pv"></p><p>使用next主题的好处在这里就体现出来了，配置这个很简单，只需要打开主题配置文件<code>/theme/next/_config.yml</code>后，搜索<code>busuanzi</code>找到如下配置代码块后进行相关配置即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># Show PV/UV of the website/page with busuanzi.</span><br><span class="line"># Get more information on http://ibruce.info/2015/04/04/busuanzi/</span><br><span class="line">busuanzi_count:</span><br><span class="line">  # count values only if the other configs are false</span><br><span class="line">  enable: true</span><br><span class="line">  # custom uv span for the whole site</span><br><span class="line">  site_uv: true</span><br><span class="line">  site_uv_header: &lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt; 访客数</span><br><span class="line">  site_uv_footer: 人</span><br><span class="line">  # custom pv span for the whole site</span><br><span class="line">  site_pv: true</span><br><span class="line">  site_pv_header: &lt;i class=&quot;fa fa-eye&quot;&gt;&lt;/i&gt; 总访问量</span><br><span class="line">  site_pv_footer: 次</span><br><span class="line">  # custom pv span for one page only</span><br><span class="line">  page_pv: true</span><br><span class="line">  page_pv_header: &lt;i class=&quot;fa fa-file-o&quot;&gt;&lt;/i&gt; 阅读数</span><br><span class="line">  page_pv_footer: 次</span><br></pre></td></tr></table></figure><p>如上代码所示的是我本人的配置，主要分为三大块：</p><blockquote><p>site_uv表示是否显示整个网站的UV数<br>site_pv表示是否显示整个网站的PV数<br>page_pv表示是否显示每个页面的PV数</p></blockquote><p>需要的则把对应的开关配成<code>true</code>，另<code>site_uv_header</code>配置项中的文字是显示的名称，而<code>site_pv_footer</code>则是对应的统计单位。当然如果你是其他主题，也可配置，网上教程很多。到此就配置结束，可以使以部署测试效果，但是这里如果使用<code>hexo s</code>来测试，你会发现数字特别大，这是正常现象，因为不蒜子用户使用一个存储空间，所以你只要<code>hexo d -g</code>部署到线上进行测试就完毕了。</p><h2 id="12-网站底部字数统计"><a href="#12-网站底部字数统计" class="headerlink" title="12. 网站底部字数统计"></a>12. 网站底部字数统计</h2><p>如上述第11部分效果图所示。</p><p>首先需要安装一个统计包，我们将控制台路径切到根目录或者在根目录调出<code>git bash</code>，然后运行如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-wordcount --save</span><br></pre></td></tr></table></figure><p>接着打开配置文件<code>/themes/next/layout/_partials/footer.swig</code>，之后在最下面新增以下代码即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;div class=&quot;theme-info&quot;&gt;</span><br><span class="line">  &lt;div class=&quot;powered-by&quot;&gt;&lt;/div&gt;</span><br><span class="line">  &lt;span class=&quot;post-count&quot;&gt;博客全站共&#123; &#123; totalcount(site) &#125; &#125;字&lt;/span&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure><h2 id="13-文章页面的统计功能"><a href="#13-文章页面的统计功能" class="headerlink" title="13. 文章页面的统计功能"></a>13. 文章页面的统计功能</h2><p>如上述第11部分效果图所示。</p><p>这一块的统计主要是对于每篇文章在头部显示字数和推荐阅读时长，配置方法与上述类似，现在根目录运行以下代码安装统计包：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-wordcount --save</span><br></pre></td></tr></table></figure><p>紧接着在主题配置文件中搜索<code>post_wordcount</code>配置模块，并按照如下代码进行配置，如果没有的话直接新增也可以：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Post wordcount display settings</span><br><span class="line"># Dependencies: https://github.com/willin/hexo-wordcount</span><br><span class="line">post_wordcount:</span><br><span class="line">  item_text: true</span><br><span class="line">  wordcount: true</span><br><span class="line">  min2read: true</span><br></pre></td></tr></table></figure><h2 id="14-顶部加载进度条"><a href="#14-顶部加载进度条" class="headerlink" title="14. 顶部加载进度条"></a>14. 顶部加载进度条</h2><p>先看效果图：</p><p><img src="https://i.postimg.cc/YS8p21Gx/next-individual13.gif" alt="loading"></p><p>这个功能在next主题中配置起来又是如此的简单，只需要打开主题配置文件，之后搜搜<code>pace</code>找到如下的代码配置模块：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># Progress bar in the top during page loading.</span><br><span class="line">pace: true</span><br><span class="line"># Themes list:</span><br><span class="line">#pace-theme-big-counter</span><br><span class="line">#pace-theme-bounce</span><br><span class="line">#pace-theme-barber-shop</span><br><span class="line">#pace-theme-center-atom</span><br><span class="line">#pace-theme-center-circle</span><br><span class="line">#pace-theme-center-radar</span><br><span class="line">#pace-theme-center-simple</span><br><span class="line">#pace-theme-corner-indicator</span><br><span class="line">#pace-theme-fill-left</span><br><span class="line">#pace-theme-flash</span><br><span class="line">#pace-theme-loading-bar</span><br><span class="line">#pace-theme-mac-osx</span><br><span class="line">#pace-theme-minimal</span><br><span class="line"># For example</span><br><span class="line"># pace_theme: pace-theme-center-simple</span><br><span class="line">pace_theme: pace-theme-minimal</span><br></pre></td></tr></table></figure><p>将其中的<code>pace</code>项设为<code>true</code>即可打开进度条效果，其中<code>pace_theme</code>配置项是选择进度条效果，可选的配置项都列在了各个注释中，可以参考<a href="https://www.jianshu.com/p/d08513d38786" target="_blank" rel="noopener">这篇文章</a>看看不同进度条的展示效果，选择一个自己最喜欢的即可。</p><h2 id="15-添加README-md文件"><a href="#15-添加README-md文件" class="headerlink" title="15. 添加README.md文件"></a>15. 添加<code>README.md</code>文件</h2><p>我们在 Hexo 目录下的 source 根目录下添加一个 README.md 文件，修改站点配置文件 _config.yml，将 skip_render 参数的值设置为：<code>skip_render: README.md</code>即可。</p><p>这样再每次部署的时候就不会重新渲染<code>README.md</code>文件，否则每次都要修改对应的文件。</p><h2 id="16-修改网站图标"><a href="#16-修改网站图标" class="headerlink" title="16. 修改网站图标"></a>16. 修改网站图标</h2><p>图标展示如下所示：</p><p><img src="https://i.postimg.cc/kG2MpB5v/next-individual14.jpg" alt="site picture"></p><p>Hexo博客默认图标是一个六边形的黑色背景白色前景N的图案。如果你想要修改对应的图案或者从其他渠道也可以，可以去<a href="http://www.easyicon.net/" target="_blank" rel="noopener">EasyIcon</a>找到喜欢的图案下载，下载的时候有好几种大小，该如何选择呢。</p><p>我们可以进入<code>/themes/next/source/images</code>目录，并且同时打开主题配置文件，搜索<code>favicon</code>找到其如下的配置代码模块：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># For example, you put your favicons into `hexo-site/source/images` directory.</span><br><span class="line"># Then need to rename &amp; redefine they on any other names, otherwise icons from Next will rewrite your custom icons in Hexo.</span><br><span class="line">favicon:</span><br><span class="line">  small: /images/favicon-16x16-next.png</span><br><span class="line">  medium: /images/favicon-32x32-next.png</span><br><span class="line">  apple_touch_icon: /images/apple-touch-icon-next.png</span><br><span class="line">  safari_pinned_tab: /images/logo.svg</span><br><span class="line">  android_manifest: /images/manifest.json</span><br><span class="line">  ms_browserconfig: /images/browserconfig.xml</span><br></pre></td></tr></table></figure><p>对比images文件夹里的文件，相比你就知道各种大小的 favicon 图案对应什么场景需求了，然后将你选择好的不同大小的图案替换现有的图案，保持名称和后缀一样就可以了。</p><h2 id="16-增加版权信息"><a href="#16-增加版权信息" class="headerlink" title="16. 增加版权信息"></a>16. 增加版权信息</h2><p>先看效果图：</p><p><img src="https://i.postimg.cc/P5WX9Gd9/next-individual15.jpg" alt="copyright"></p><p>对文章添加版本信息也是对自己发布的内容的一种保护方式，也是为了减少别人引用时候的费力度，于人于己都是好事。我门首先打开目录：<code>themes/next/layout/_macro/</code>，然后新建一个文件<code>my-copyright.swig</code>，内容添加如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#123; % if page.copyright % &#125;</span><br><span class="line">&lt;div class=&quot;my_post_copyright&quot;&gt;</span><br><span class="line">  &lt;script src=&quot;//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- JS库 sweetalert 可修改路径 --&gt;</span><br><span class="line">  &lt;script src=&quot;https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">  &lt;script src=&quot;https://unpkg.com/sweetalert/dist/sweetalert.min.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;本文标题:&lt;/span&gt;&lt;a href=&quot;&#123; &#123; url_for(page.path) &#125; &#125;&quot;&gt;&#123; &#123; page.title &#125; &#125;&lt;/a&gt;&lt;/p&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;文章作者:&lt;/span&gt;&lt;a href=&quot;/&quot; title=&quot;访问 &#123; &#123; theme.author &#125; &#125; 的个人博客&quot;&gt;&#123; &#123; theme.author &#125; &#125;&lt;/a&gt;&lt;/p&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;发布时间:&lt;/span&gt;&#123; &#123; page.date.format(&quot;YYYY年MM月DD日 - HH:MM&quot;) &#125; &#125;&lt;/p&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;最后更新:&lt;/span&gt;&#123; &#123; page.updated.format(&quot;YYYY年MM月DD日 - HH:MM&quot;) &#125; &#125;&lt;/p&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;原始链接:&lt;/span&gt;&lt;a href=&quot;&#123; &#123; url_for(page.path) &#125; &#125;&quot; title=&quot;&#123; &#123; page.title &#125; &#125;&quot;&gt;&#123; &#123; page.permalink &#125; &#125;&lt;/a&gt;</span><br><span class="line">    &lt;span class=&quot;copy-path&quot;  title=&quot;点击复制文章链接&quot;&gt;&lt;i class=&quot;fa fa-clipboard&quot; data-clipboard-text=&quot;&#123; &#123; page.permalink &#125; &#125;&quot;  aria-label=&quot;复制成功！&quot;&gt;&lt;/i&gt;&lt;/span&gt;</span><br><span class="line">  &lt;/p&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;许可协议:&lt;/span&gt;&lt;i class=&quot;fa fa-creative-commons&quot;&gt;&lt;/i&gt; &lt;a rel=&quot;license&quot; href=&quot;https://creativecommons.org/licenses/by-nc-nd/4.0/&quot; target=&quot;_blank&quot; title=&quot;Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)&quot;&gt;署名-非商业性使用-禁止演绎 4.0 国际&lt;/a&gt; 转载请保留原文链接及作者。&lt;/p&gt;  </span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;script&gt; </span><br><span class="line">    var clipboard = new Clipboard(&apos;.fa-clipboard&apos;);</span><br><span class="line">      $(&quot;.fa-clipboard&quot;).click(function()&#123;</span><br><span class="line">      clipboard.on(&apos;success&apos;, function()&#123;</span><br><span class="line">        swal(&#123;   </span><br><span class="line">          title: &quot;&quot;,   </span><br><span class="line">          text: &apos;复制成功&apos;,</span><br><span class="line">          icon: &quot;success&quot;, </span><br><span class="line">          showConfirmButton: true</span><br><span class="line">          &#125;);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;);  </span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&#123; % endif % &#125;</span><br></pre></td></tr></table></figure><p>可以看到代码中配置了主要会披露的几项内容：</p><blockquote><p>1.本文标题<br>2.文章作者<br>3.发布时间<br>4.最后更新<br>5.原始链接<br>6.许可协议</p></blockquote><p>根据你的需求选择去留就好，在我们设置里面剔除了发布时间和最后更新的披露。</p><p>接下来我们再打开目录：<code>next/source/css/_common/components/post/</code>，并在其中新建文件：<code>my-post-copyright.styl</code>，之后里面添加如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">.my_post_copyright &#123;</span><br><span class="line">  width: 85%;</span><br><span class="line">  max-width: 45em;</span><br><span class="line">  margin: 2.8em auto 0;</span><br><span class="line">  padding: 0.5em 1.0em;</span><br><span class="line">  border: 1px solid #d3d3d3;</span><br><span class="line">  font-size: 0.93rem;</span><br><span class="line">  line-height: 1.6em;</span><br><span class="line">  word-break: break-all;</span><br><span class="line">  background: rgba(255,255,255,0.4);</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright p&#123;margin:0;&#125;</span><br><span class="line">.my_post_copyright span &#123;</span><br><span class="line">  display: inline-block;</span><br><span class="line">  width: 5.2em;</span><br><span class="line">  color: #b5b5b5;</span><br><span class="line">  font-weight: bold;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright .raw &#123;</span><br><span class="line">  margin-left: 1em;</span><br><span class="line">  width: 5em;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright a &#123;</span><br><span class="line">  color: #808080;</span><br><span class="line">  border-bottom:0;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright a:hover &#123;</span><br><span class="line">  color: #a3d2a3;</span><br><span class="line">  text-decoration: underline;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright:hover .fa-clipboard &#123;</span><br><span class="line">  color: #000;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright .post-url:hover &#123;</span><br><span class="line">  font-weight: normal;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright .copy-path &#123;</span><br><span class="line">  margin-left: 1em;</span><br><span class="line">  width: 1em;</span><br><span class="line">  +mobile()&#123;display:none;&#125;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright .copy-path:hover &#123;</span><br><span class="line">  color: #808080;</span><br><span class="line">  cursor: pointer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还没结束呢，我们还需要打开配置文件：<code>/themes/next/layout/_macro/post.swig</code>，搜索找到<code>next/layout/_macro/post.swig</code>所在的代码块，在其前面新增一段代码，最终结果如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">  &#123; % if not is_index % &#125;</span><br><span class="line">  &#123; % include &apos;passage-end-tag.swig&apos; % &#125;</span><br><span class="line">  &#123; % endif % &#125;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line"></span><br><span class="line">&lt;div&gt;</span><br><span class="line">  &#123; % if not is_index % &#125;</span><br><span class="line">    &#123; % include &apos;my-copyright.swig&apos; % &#125;</span><br><span class="line">  &#123; % endif % &#125;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure><p>要保持对其哦，然后就差最后一步了，打开配置文件：<code>/themes/next/source/css/_common/components/post/post.styl</code>，再最后新增一行如下的代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@import &quot;my-post-copyright&quot;</span><br></pre></td></tr></table></figure><p>保存后部署即可。可能这时候你发现文章还是没有出现版权，那是因为还有一个很关键的因素，那就是你需要在你想添加版权的文章的头部增加<code>copyright: true</code>的配置项。例如本篇博文的配置汇总就有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: Hexo+Next博客主题个性化设置全集</span><br><span class="line">date: 2019-06-10</span><br><span class="line">abbrlink: Hexo+Next_individual</span><br><span class="line">categories:</span><br><span class="line">- 博客搭建</span><br><span class="line">tags:</span><br><span class="line">- Hexo</span><br><span class="line">- Next</span><br><span class="line">copyright: true</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p>如果不想每次手动添加，想要实现<code>hexo new</code>的时候就自动添加的话，也是可以的。还记得之前提过新建博客的配置模板文件吗？打开<code>/scaffolds/post.md</code>在其中添加<code>copyright: true</code>即可。</p><h2 id="17-隐藏或修改底部驱动-主题信息"><a href="#17-隐藏或修改底部驱动-主题信息" class="headerlink" title="17. 隐藏或修改底部驱动/主题信息"></a>17. 隐藏或修改底部<code>驱动/主题</code>信息</h2><p>默认的话底部一般会显示<code>由 Hexo 强力驱动 | Next 主题</code>之类的信息。如果你想要去掉或者删除，则可以打开配置文件<code>/themes/next/layout/_partials/footer.swig/</code>，之后找到如下两块代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123; % if theme.footer.powered % &#125;</span><br><span class="line">  &lt;div class=&quot;powered-by&quot;&gt;&#123;#</span><br><span class="line">  #&#125;&#123; &#123; __(&apos;footer.powered&apos;, &apos;&lt;a class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://hexo.io&quot;&gt;Hexo&lt;/a&gt;&apos;) &#125; &#125;&#123;#</span><br><span class="line">#&#125;&lt;/div&gt;</span><br><span class="line">&#123; % endif % &#125;</span><br><span class="line"></span><br><span class="line">&#123; % if theme.footer.theme.enable % &#125;</span><br><span class="line">  &lt;div class=&quot;theme-info&quot;&gt;&#123;#</span><br><span class="line">  #&#125;&#123; &#123; __(&apos;footer.theme&apos;) &#125; &#125; &amp;mdash; &#123;#</span><br><span class="line">  #&#125;&lt;a class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://github.com/iissnan/hexo-theme-next&quot;&gt;&#123;#</span><br><span class="line">    #&#125;NexT.&#123; &#123; theme.scheme &#125; &#125;&#123;#</span><br><span class="line">  #&#125;&lt;/a&gt;&#123; % if theme.footer.theme.version % &#125; v&#123; &#123; theme.version &#125; &#125;&#123; % endif % &#125;&#123;#</span><br><span class="line">#&#125;&lt;/div&gt;</span><br><span class="line">&#123; % endif % &#125;</span><br></pre></td></tr></table></figure><p>简单看一下，第一部分包含<code>powered-by</code>关键词就知道是设置<code>由 Hexo 强力驱动</code>代码块，另一部分有关键词<code>theme-info</code>则是设置主题信息的。根据自己需要进行修改和删除即可。</p><h2 id="18-修改底部桃心标志"><a href="#18-修改底部桃心标志" class="headerlink" title="18. 修改底部桃心标志"></a>18. 修改底部桃心标志</h2><p>这个比较简单，打开文件：<code>/themes/next/layout/_partials/footer.swig</code>，找到以下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;span class=&quot;with-love&quot;&gt;</span><br><span class="line">  &lt;i class=&quot;fa fa-&#123; &#123; theme.footer.icon &#125; &#125;&quot;&gt;&lt;/i&gt;</span><br><span class="line">&lt;/span&gt;</span><br></pre></td></tr></table></figure><p>其中<code>&lt;i class=&quot;fa fa-{ { theme.footer.icon } }&quot;&gt;&lt;/i&gt;</code>就是这个图标的配置，同样的可以去<a href="http://fontawesome.io/icons/" target="_blank" rel="noopener">icons图库</a>找到自己喜欢的图标替换这里的配置即可。然鹅，我自己没有修改，是因为没找到比这个心更合适的，当然教程还是要写给大家的。</p><h2 id="19-文章加密访问"><a href="#19-文章加密访问" class="headerlink" title="19. 文章加密访问"></a>19. 文章加密访问</h2><p>虽然博客主要是对外交流使用，但是有时候也可以用来记录自己的一些私密事情，这时候难免像有个只有自己能进去的一片天地。毕竟以前的qq空间还有加密功能呢。Hexo自然也少不了，下面我们就开始。</p><p>首先打开配置文件：<code>/themes/next/layout/_partials/head.swig</code>，在<code>&lt;meta name</code>代码坐在模块和<code>{ % if theme.pace % }</code>所在代码块之间新增如下代码即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;meta charset=&quot;UTF-8&quot;/&gt;</span><br><span class="line">&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;</span><br><span class="line">&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, maximum-scale=1&quot;/&gt;</span><br><span class="line">&lt;meta name=&quot;theme-color&quot; content=&quot;&#123; &#123; theme.android_chrome_color &#125; &#125;&quot;&gt;</span><br><span class="line"></span><br><span class="line">&lt;script&gt;</span><br><span class="line">    (function()&#123;</span><br><span class="line">        if(&apos;&#123; &#123; page.password &#125; &#125;&apos;)&#123;</span><br><span class="line">            if (prompt(&apos;请输入文章密码&apos;) !== &apos;&#123; &#123; page.password &#125; &#125;&apos;)&#123;</span><br><span class="line">                alert(&apos;密码错误！&apos;);</span><br><span class="line">                history.back();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)();</span><br><span class="line">&lt;/script&gt;</span><br><span class="line"></span><br><span class="line">&#123; % if theme.pace % &#125;</span><br><span class="line">  &#123; % set pace_css_uri = url_for(theme.vendors._internal + &apos;/pace/&apos;+ theme.pace_theme +&apos;.min.css?v=1.0.2&apos;) % &#125;</span><br></pre></td></tr></table></figure><p>同样的还需要主动触发的一步，也就是需要在你想要加密的文章头部添加<code>password:xxxxxx</code>配置项即可，后面的<code>xxxxxx</code>即是这篇文章的查看密码。</p><h2 id="20-添加分享功能"><a href="#20-添加分享功能" class="headerlink" title="20. 添加分享功能"></a>20. 添加分享功能</h2><p>先看效果图：</p><p><img src="https://i.postimg.cc/C59MTSBT/next-individual16.jpg" alt="share"></p><p>Hexo可以给博客增加分享功能，这样就可以实现分享页面/图片以及文章了。有的人使用<code>jiathis</code>分享功能，直接在主题配置文件中找到这个模块，将其改为<code>true</code>即可，但是亲测好像不是特别好用。</p><p>这里介绍的是百度分享功能，简洁实用。首先打开站点配置文件，搜索<code>baidushare</code>关键词，如下配置打开分享功能：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Baidu Share</span><br><span class="line"># Available value:</span><br><span class="line">#    button | slide</span><br><span class="line"># Warning: Baidu Share does not support https.</span><br><span class="line">baidushare:</span><br><span class="line">  type: button</span><br><span class="line">  baidushare: true</span><br></pre></td></tr></table></figure><p>但是在部署使用的时候可能会引发<code>Warning: Baidu Share does not support https</code>从而不可使用。不怕，博主<a href="https://github.com/hrwhisper/baiduSh" target="_blank" rel="noopener">hrwhisper</a>发布了一个修复方案，我这里简介一下。</p><p>首先下载上面博文发布的<a href="https://github.com/hrwhisper/baiduShare" target="_blank" rel="noopener">static</a>文件夹。下载后解压，将<code>static</code>文件夹保存在<code>/themes/next/source</code>文件夹下面。</p><p>最后打开文件：<code>/themes/next/layout/_partials/share/baidushare.swig</code>，将文件末尾的一行代码按如下提示进行修改：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.src=&apos;http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion=&apos;+~(-new Date()/36e5)];</span><br><span class="line">#改为</span><br><span class="line">.src=&apos;/static/api/js/share.js?v=89860593.js?cdnversion=&apos;+~(-new Date()/36e5)];</span><br></pre></td></tr></table></figure><p>修改完成后，重新部署就可以正常使用分享功能了。</p><h2 id="21-博文置顶"><a href="#21-博文置顶" class="headerlink" title="21. 博文置顶"></a>21. 博文置顶</h2><p>有时候我们想将某一篇文章置顶在首页。我们可以这么实现。修改 <code>hero-generator-index</code> 插件，把文件<code>node_modules/hexo-generator-index/lib/generator.js</code> 内的代码替换为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&apos;use strict&apos;;</span><br><span class="line">var pagination = require(&apos;hexo-pagination&apos;);</span><br><span class="line">module.exports = function(locals)&#123;</span><br><span class="line">  var config = this.config;</span><br><span class="line">  var posts = locals.posts;</span><br><span class="line">    posts.data = posts.data.sort(function(a, b) &#123;</span><br><span class="line">        if(a.top &amp;&amp; b.top) &#123; // 两篇文章top都有定义</span><br><span class="line">            if(a.top == b.top) return b.date - a.date; // 若top值一样则按照文章日期降序排</span><br><span class="line">            else return b.top - a.top; // 否则按照top值降序排</span><br><span class="line">        &#125;</span><br><span class="line">        else if(a.top &amp;&amp; !b.top) &#123; // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233）</span><br><span class="line">            return -1;</span><br><span class="line">        &#125;</span><br><span class="line">        else if(!a.top &amp;&amp; b.top) &#123;</span><br><span class="line">            return 1;</span><br><span class="line">        &#125;</span><br><span class="line">        else return b.date - a.date; // 都没定义按照文章日期降序排</span><br><span class="line">    &#125;);</span><br><span class="line">  var paginationDir = config.pagination_dir || &apos;page&apos;;</span><br><span class="line">  return pagination(&apos;&apos;, posts, &#123;</span><br><span class="line">    perPage: config.index_generator.per_page,</span><br><span class="line">    layout: [&apos;index&apos;, &apos;archive&apos;],</span><br><span class="line">    format: paginationDir + &apos;/%d/&apos;,</span><br><span class="line">    data: &#123;</span><br><span class="line">      __index: true</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>之后，想要指定某篇文章置顶的时候，就可以在文章的头部配置<code>top: 100</code>，top值越大越靠前。其实就是文章优先按照top值进行降序排列，没有top值的或者top值相同的就按照文章时间进行降序排列。</p><h2 id="22-修改字体大小和鼠标样式"><a href="#22-修改字体大小和鼠标样式" class="headerlink" title="22. 修改字体大小和鼠标样式"></a>22. 修改字体大小和鼠标样式</h2><p>字体大小的修改，可以打开文件： <code>/themes/next/source/css/ _variables/base.styl</code>，将<code>$font-size-base</code>配置项改成你想要的大小即可，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$font-size-base =16px</span><br></pre></td></tr></table></figure><p>鼠标样式的修改则需要打开文件： <code>/themes/next/source/css/_custom/custom.styl</code>，然后在里面添加如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 鼠标样式</span><br><span class="line">  * &#123;</span><br><span class="line">      cursor: url(&quot;http://om8u46rmb.bkt.clouddn.com/sword2.ico&quot;),auto!important</span><br><span class="line">  &#125;</span><br><span class="line">  :active &#123;</span><br><span class="line">      cursor: url(&quot;http://om8u46rmb.bkt.clouddn.com/sword1.ico&quot;),auto!important</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>其中<code>url</code> 里面必须是 ico 图片，ico 图片可以上传到图床，生成对应外链添加到这里就好了。</p><h2 id="23-点击爆炸效果"><a href="#23-点击爆炸效果" class="headerlink" title="23. 点击爆炸效果"></a>23. 点击爆炸效果</h2><p>在前我们介绍了如何实现点击出现<code>心</code>的效果，这里介绍一个更浮夸的效果，点击时候爆炸。配置方式差不多的，首先在目录： <code>/themes/next/source/js/src</code> 里面建一个叫 <code>fireworks.js</code> 的文件，添加如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;use strict&quot;;function updateCoords(e)&#123;pointerX=(e.clientX||e.touches[0].clientX)-canvasEl.getBoundingClientRect().left,pointerY=e.clientY||e.touches[0].clientY-canvasEl.getBoundingClientRect().top&#125;function setParticuleDirection(e)&#123;var t=anime.random(0,360)*Math.PI/180,a=anime.random(50,180),n=[-1,1][anime.random(0,1)]*a;return&#123;x:e.x+n*Math.cos(t),y:e.y+n*Math.sin(t)&#125; &#125;function createParticule(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=colors[anime.random(0,colors.length-1)],a.radius=anime.random(16,32),a.endPos=setParticuleDirection(a),a.draw=function()&#123;ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.fillStyle=a.color,ctx.fill()&#125;,a&#125;function createCircle(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=&quot;#F00&quot;,a.radius=0.1,a.alpha=0.5,a.lineWidth=6,a.draw=function()&#123;ctx.globalAlpha=a.alpha,ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.lineWidth=a.lineWidth,ctx.strokeStyle=a.color,ctx.stroke(),ctx.globalAlpha=1&#125;,a&#125;function renderParticule(e)&#123;for(var t=0;t&lt;e.animatables.length;t++)&#123;e.animatables[t].target.draw()&#125; &#125;function animateParticules(e,t)&#123;for(var a=createCircle(e,t),n=[],i=0;i&lt;numberOfParticules;i++)&#123;n.push(createParticule(e,t))&#125;anime.timeline().add(&#123;targets:n,x:function(e)&#123;return e.endPos.x&#125;,y:function(e)&#123;return e.endPos.y&#125;,radius:0.1,duration:anime.random(1200,1800),easing:&quot;easeOutExpo&quot;,update:renderParticule&#125;).add(&#123;targets:a,radius:anime.random(80,160),lineWidth:0,alpha:&#123;value:0,easing:&quot;linear&quot;,duration:anime.random(600,800)&#125;,duration:anime.random(1200,1800),easing:&quot;easeOutExpo&quot;,update:renderParticule,offset:0&#125;)&#125;function debounce(e,t)&#123;var a;return function()&#123;var n=this,i=arguments;clearTimeout(a),a=setTimeout(function()&#123;e.apply(n,i)&#125;,t)&#125; &#125;var canvasEl=document.querySelector(&quot;.fireworks&quot;);if(canvasEl)&#123;var ctx=canvasEl.getContext(&quot;2d&quot;),numberOfParticules=30,pointerX=0,pointerY=0,tap=&quot;mousedown&quot;,colors=[&quot;#FF1461&quot;,&quot;#18FF92&quot;,&quot;#5A87FF&quot;,&quot;#FBF38C&quot;],setCanvasSize=debounce(function()&#123;canvasEl.width=2*window.innerWidth,canvasEl.height=2*window.innerHeight,canvasEl.style.width=window.innerWidth+&quot;px&quot;,canvasEl.style.height=window.innerHeight+&quot;px&quot;,canvasEl.getContext(&quot;2d&quot;).scale(2,2)&#125;,500),render=anime(&#123;duration:1/0,update:function()&#123;ctx.clearRect(0,0,canvasEl.width,canvasEl.height)&#125; &#125;);document.addEventListener(tap,function(e)&#123;&quot;sidebar&quot;!==e.target.id&amp;&amp;&quot;toggle-sidebar&quot;!==e.target.id&amp;&amp;&quot;A&quot;!==e.target.nodeName&amp;&amp;&quot;IMG&quot;!==e.target.nodeName&amp;&amp;(render.play(),updateCoords(e),animateParticules(pointerX,pointerY))&#125;,!1),setCanvasSize(),window.addEventListener(&quot;resize&quot;,setCanvasSize,!1)&#125;&quot;use strict&quot;;function updateCoords(e)&#123;pointerX=(e.clientX||e.touches[0].clientX)-canvasEl.getBoundingClientRect().left,pointerY=e.clientY||e.touches[0].clientY-canvasEl.getBoundingClientRect().top&#125;function setParticuleDirection(e)&#123;var t=anime.random(0,360)*Math.PI/180,a=anime.random(50,180),n=[-1,1][anime.random(0,1)]*a;return&#123;x:e.x+n*Math.cos(t),y:e.y+n*Math.sin(t)&#125; &#125;function createParticule(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=colors[anime.random(0,colors.length-1)],a.radius=anime.random(16,32),a.endPos=setParticuleDirection(a),a.draw=function()&#123;ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.fillStyle=a.color,ctx.fill()&#125;,a&#125;function createCircle(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=&quot;#F00&quot;,a.radius=0.1,a.alpha=0.5,a.lineWidth=6,a.draw=function()&#123;ctx.globalAlpha=a.alpha,ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.lineWidth=a.lineWidth,ctx.strokeStyle=a.color,ctx.stroke(),ctx.globalAlpha=1&#125;,a&#125;function renderParticule(e)&#123;for(var t=0;t&lt;e.animatables.length;t++)&#123;e.animatables[t].target.draw()&#125; &#125;function animateParticules(e,t)&#123;for(var a=createCircle(e,t),n=[],i=0;i&lt;numberOfParticules;i++)&#123;n.push(createParticule(e,t))&#125;anime.timeline().add(&#123;targets:n,x:function(e)&#123;return e.endPos.x&#125;,y:function(e)&#123;return e.endPos.y&#125;,radius:0.1,duration:anime.random(1200,1800),easing:&quot;easeOutExpo&quot;,update:renderParticule&#125;).add(&#123;targets:a,radius:anime.random(80,160),lineWidth:0,alpha:&#123;value:0,easing:&quot;linear&quot;,duration:anime.random(600,800)&#125;,duration:anime.random(1200,1800),easing:&quot;easeOutExpo&quot;,update:renderParticule,offset:0&#125;)&#125;function debounce(e,t)&#123;var a;return function()&#123;var n=this,i=arguments;clearTimeout(a),a=setTimeout(function()&#123;e.apply(n,i)&#125;,t)&#125; &#125;var canvasEl=document.querySelector(&quot;.fireworks&quot;);if(canvasEl)&#123;var ctx=canvasEl.getContext(&quot;2d&quot;),numberOfParticules=30,pointerX=0,pointerY=0,tap=&quot;mousedown&quot;,colors=[&quot;#FF1461&quot;,&quot;#18FF92&quot;,&quot;#5A87FF&quot;,&quot;#FBF38C&quot;],setCanvasSize=debounce(function()&#123;canvasEl.width=2*window.innerWidth,canvasEl.height=2*window.innerHeight,canvasEl.style.width=window.innerWidth+&quot;px&quot;,canvasEl.style.height=window.innerHeight+&quot;px&quot;,canvasEl.getContext(&quot;2d&quot;).scale(2,2)&#125;,500),render=anime(&#123;duration:1/0,update:function()&#123;ctx.clearRect(0,0,canvasEl.width,canvasEl.height)&#125; &#125;);document.addEventListener(tap,function(e)&#123;&quot;sidebar&quot;!==e.target.id&amp;&amp;&quot;toggle-sidebar&quot;!==e.target.id&amp;&amp;&quot;A&quot;!==e.target.nodeName&amp;&amp;&quot;IMG&quot;!==e.target.nodeName&amp;&amp;(render.play(),updateCoords(e),animateParticules(pointerX,pointerY))&#125;,!1),setCanvasSize(),window.addEventListener(&quot;resize&quot;,setCanvasSize,!1)&#125;;</span><br></pre></td></tr></table></figure><p>紧接着，打开文件： <code>/themes/next/layout/_layout.swig</code>，在 <code>&lt;/body&gt;</code>上面添加如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123; % if theme.fireworks % &#125;</span><br><span class="line">   &lt;canvas class=&quot;fireworks&quot; style=&quot;position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;&quot; &gt;&lt;/canvas&gt; </span><br><span class="line">   &lt;script type=&quot;text/javascript&quot; src=&quot;//cdn.bootcss.com/animejs/2.2.0/anime.min.js&quot;&gt;&lt;/script&gt; </span><br><span class="line">   &lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/fireworks.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">&#123; % endif % &#125;</span><br></pre></td></tr></table></figure><p>最后进入主题配置文件，在里面最后按如下配置开启效果即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Fireworks</span><br><span class="line">fireworks: true</span><br></pre></td></tr></table></figure><p>然鹅，这里我再次没有选择，因为这个效果感觉很容易影响阅读，华而不实。</p><p><strong>参考博文</strong><br><a href="https://www.cnblogs.com/php-linux/p/8416122.html" target="_blank" rel="noopener">hexo的next主题个性化教程:打造炫酷网站</a><br><a href="https://asdfv1929.github.io/2018/05/25/baidu-share/" target="_blank" rel="noopener">Hexo NexT主题中添加百度分享功能</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;想要小白详细版本的Github+Hexo+Next搭建博客教程，可访问我的另一篇博客&lt;a href=&quot;https://www.xiemingzhao.com/posts/GithubHexoNextblog&quot;&gt;使用Github+Hexo+Next免费搭建自己的博客（最细攻略）&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：以下非特殊说明路径都是基于你本地博客的根目录，效果主要基于hexo+next实现效果，大部分效果均可在&lt;a href=&quot;www.xiemingzhao.com&quot;&gt;我的博客&lt;/a&gt;中保留，可先睹为快，再决定是否需要&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-实现展示fork-me-on-github效果&quot;&gt;&lt;a href=&quot;#1-实现展示fork-me-on-github效果&quot; class=&quot;headerlink&quot; title=&quot;1.实现展示fork me on github效果&quot;&gt;&lt;/a&gt;1.实现展示&lt;em&gt;fork me on github&lt;/em&gt;效果&lt;/h2&gt;&lt;p&gt;先上效果图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/hvQg06CC/next-individual1.jpg&quot; alt=&quot;fork me on github&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="博客搭建" scheme="https://www.xiemingzhao.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="Hexo" scheme="https://www.xiemingzhao.com/tags/Hexo/"/>
    
      <category term="Next" scheme="https://www.xiemingzhao.com/tags/Next/"/>
    
  </entry>
  
  <entry>
    <title>Understanding LSTM Networks (论文解析)</title>
    <link href="https://www.xiemingzhao.com/posts/eff2088e.html"/>
    <id>https://www.xiemingzhao.com/posts/eff2088e.html</id>
    <published>2019-05-28T16:00:00.000Z</published>
    <updated>2019-09-21T06:27:40.089Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">原始论文：Understanding LSTM Networks</a></p><h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><p>人类并不是每时每刻都从一片空白的大脑开始他们的思考。在你阅读这篇文章时候，你都是基于自己已经拥有的对先前所见词的理解来推断当前词的真实含义。我们不会将所有的东西都全部丢弃，然后用空白的大脑进行思考。我们的思想拥有持久性。</p><p>传统的神经网络并不能做到这点，看起来也像是一种巨大的弊端。例如，假设你希望对电影中的每个时间点的时间类型进行分类。传统的神经网络应该很难来处理这个问题——使用电影中先前的事件推断后续的事件。</p><p>RNN 解决了这个问题。RNN 是包含循环的网络，允许信息的持久化。</p><a id="more"></a><p><img src="https://i.postimg.cc/Gm0s294H/LSTM-1.png" alt="Recurrent Neural Networks have loops.jpg"></p><p>在上面的示例图中，神经网络的模块，正在读取某个输入 ，并输出一个值。循环可以使得信息可以从当前步传递到下一步。</p><p>这些循环使得 RNN 看起来非常神秘。然而，如果你仔细想想，这样也不比一个正常的神经网络难于理解。RNN 可以被看做是同一神经网络的多次复制，每个神经网络模块会把消息传递给下一个。所以，如果我们将这个循环展开：</p><p><img src="https://i.postimg.cc/G2p4Ny5S/LSTM-2.png" alt="An unrolled recurrent neural network.jpg"></p><p>链式的特征揭示了 RNN 本质上是与序列和列表相关的。他们是对于这类数据的最自然的神经网络架构。</p><p>并且 RNN 也已经被人们应用了！在过去几年中，应用 RNN 在语音识别，语言建模，翻译，图片描述等问题上已经取得一定成功，并且这个列表还在增长。我建议大家参考 Andrej Karpathy 的博客文章——<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">The Unreasonable Effectiveness of Recurrent Neural Networks</a> 来看看更丰富有趣的 RNN 的成功应用。</p><p>而这些成功应用的关键之处就是 LSTM 的使用，这是一种特别的 RNN，比标准的 RNN 在很多的任务上都表现得更好。几乎所有的令人振奋的关于RNN的结果都是通过 LSTM 达到的。这篇博文也会就 LSTM 进行展开。</p><h2 id="长期依赖（Long-Term-Dependencies）问题"><a href="#长期依赖（Long-Term-Dependencies）问题" class="headerlink" title="长期依赖（Long-Term Dependencies）问题"></a>长期依赖（Long-Term Dependencies）问题</h2><p>RNN 的关键点之一就是他们可以用来连接先前的信息到当前的任务上，例如使用过去的视频段来推测对当前段的理解。如果 RNN 可以做到这个，他们就变得非常有用。但是真的可以么？答案是，还有很多依赖因素。</p><p>有时候，我们仅仅需要知道先前的信息来执行当前的任务。例如，我们有一个语言模型用来基于先前的词来预测下一个词。如果我们试着预测 “the clouds are in the sky” 最后的词，我们并不需要任何其他的上下文 —— 因此下一个词很显然就应该是 sky。在这样的场景中，相关的信息和预测的词位置之间的间隔是非常小的，RNN 可以学会使用先前的信息。</p><p><img src="https://i.postimg.cc/Njw5tVnX/LSTM-3.png" alt="不太长的相关信息和位置间隔"></p><p>但是同样会有一些更加复杂的场景。假设我们试着去预测“I grew up in France… I speak fluent French”最后的词。当前的信息建议下一个词可能是一种语言的名字，但是如果我们需要弄清楚是什么语言，我们是需要先前提到的离当前位置很远的 France 的上下文的。这说明相关信息和当前预测位置之间的间隔就肯定变得相当的大。</p><p>不幸的是，在这个间隔不断增大时，RNN 会丧失学习到连接如此远的信息的能力。</p><p><img src="https://i.postimg.cc/bvyrDnpN/LSTM-4.png" alt="相当长的相关信息和位置间隔"></p><p>在理论上，RNN 绝对可以处理这样的 长期依赖 问题。人们可以仔细挑选参数来解决这类问题中的最初级形式，但在实践中，RNN 肯定不能够成功学习到这些知识。<a href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf" target="_blank" rel="noopener">Bengio, et al. (1994)</a>等人对该问题进行了深入的研究，他们发现一些使训练 RNN 变得非常困难的相当根本的原因。<br>然而，幸运的是，LSTM 并没有这个问题！</p><h2 id="LSTM-网络"><a href="#LSTM-网络" class="headerlink" title="LSTM 网络"></a>LSTM 网络</h2><p>Long Short Term 网络—— 一般就叫做 LSTM ——是一种 RNN 特殊的类型，可以学习长期依赖信息。LSTM 由Hochreiter &amp; Schmidhuber (1997)提出，并在近期被Alex Graves进行了改良和推广。在很多问题，LSTM 都取得相当巨大的成功，并得到了广泛的使用。<br>LSTM 通过刻意的设计来避免长期依赖问题。记住长期的信息在实践中是 LSTM 的默认行为，而非需要付出很大代价才能获得的能力！<br>所有 RNN 都具有一种重复神经网络模块的链式的形式。在标准的 RNN 中，这个重复的模块只有一个非常简单的结构，例如一个 tanh 层。</p><p><img src="https://i.postimg.cc/wTN7SHwH/LSTM-5.png" alt="The repeating module in a standard RNN contains a single layer"></p><p>LSTM 同样是这样的结构，但是重复的模块拥有一个不同的结构。不同于 单一神经网络层，这里是有四个，以一种非常特殊的方式进行交互。</p><p><img src="https://i.postimg.cc/gJr04PxC/LSTM-6.png" alt="The repeating module in an LSTM contains four interacting layers."></p><p>不必担心这里的细节。我们会一步一步地剖析 LSTM 解析图。现在，我们先来熟悉一下图中使用的各种元素的图标。</p><p><img src="https://i.postimg.cc/YC1LmkF8/LSTM-7.png" alt="LSTM 中的图标"></p><p>在上面的图例中，每一条黑线传输着一整个向量，从一个节点的输出到其他节点的输入。粉色的圈代表按位 pointwise 的操作，诸如向量的和，而黄色的矩阵就是学习到的神经网络层。合在一起的线表示向量的连接，分开的线表示内容被复制，然后分发到不同的位置。</p><h2 id="LSTM-的核心思想"><a href="#LSTM-的核心思想" class="headerlink" title="LSTM 的核心思想"></a>LSTM 的核心思想</h2><p>LSTM 的关键就是细胞状态，水平线在图上方贯穿运行。</p><p>细胞状态类似于传送带。直接在整个链上运行，只有一些少量的线性交互。信息在上面流传保持不变会很容易。</p><p><img src="https://i.postimg.cc/ZqH9VcVd/LSTM-8.png" alt="LSTM单元"></p><p>LSTM 有通过精心设计的称作为“门”的结构来去除或者增加信息到细胞状态的能力。门是一种让信息选择式通过的方法。他们包含一个 sigmoid 神经网络层和一个按位的乘法操作。</p><p><img src="https://i.postimg.cc/nLpj45Yx/LSTM-9.png" alt="LSTM操作节点"></p><p>Sigmoid 层输出 0 到 1 之间的数值，描述每个部分有多少量可以通过。0 代表“不许任何量通过”，1 就指“允许任意量通过”！</p><p>LSTM 拥有三个门，来保护和控制细胞状态。</p><h2 id="逐步理解-LSTM"><a href="#逐步理解-LSTM" class="headerlink" title="逐步理解 LSTM"></a>逐步理解 LSTM</h2><p>在我们 LSTM 中的第一步是决定我们会从细胞状态中丢弃什么信息。这个决定通过一个称为忘记门层完成。该门会读取 $h_{t-1}$ 和 $x_t$，输出一个在 0 到 1 之间的数值给每个在细胞状态 $C_{t-1}$ 中的数字。1 表示“完全保留”，0 表示“完全舍弃”。<br>让我们回到语言模型的例子中来基于已经看到的预测下一个词。在这个问题中，细胞状态可能包含当前<strong>主语</strong>的性别，因此正确的<strong>代词</strong>可以被选择出来。当我们看到新的<strong>主语</strong>，我们希望忘记旧的<strong>主语</strong>。</p><p><img src="https://i.postimg.cc/d1ShK0MQ/LSTM-10.png" alt="决定丢弃信息"></p><p>下一步是确定什么样的新信息被存放在细胞状态中。这里包含两个部分。第一，sigmoid 层称 “输入门层” 决定什么值我们将要更新。然后，一个 tanh 层创建一个新的候选值向量，$\tilde{C_t}$，会被加入到状态中。下一步，我们会讲这两个信息来产生对状态的更新。</p><p>在我们语言模型的例子中，我们希望增加新的主语的性别到细胞状态中，来替代旧的需要忘记的主语。</p><p><img src="https://i.postimg.cc/2ybVjfmQ/LSTM-11.png" alt="确定更新的信息"></p><p>现在是更新旧细胞状态的时间了，$C_{t-1}$ 更新为 $C_t$。前面的步骤已经决定了将会做什么，我们现在就是实际去完成。</p><p>我们把旧状态与 $f_t$ 相乘，丢弃掉我们确定需要丢弃的信息。接着加上 $i_t * \tilde{C_t}$。这就是新的候选值，根据我们决定更新每个状态的程度进行变化。</p><p>在语言模型的例子中，这就是我们实际根据前面确定的目标，丢弃旧代词的性别信息并添加新的信息的地方。</p><p><img src="https://i.postimg.cc/NF3L5PfW/LSTM-12.png" alt="更新细胞状态"></p><p>最终，我们需要确定输出什么值。这个输出将会基于我们的细胞状态，但是也是一个过滤后的版本。首先，我们运行一个 sigmoid 层来确定细胞状态的哪个部分将输出出去。接着，我们把细胞状态通过 tanh 进行处理（得到一个在 -1 到 1 之间的值）并将它和 sigmoid 门的输出相乘，最终我们仅仅会输出我们确定输出的那部分。</p><p>在语言模型的例子中，因为他就看到了一个 <strong>代词</strong>，可能需要输出与一个<strong>动词</strong> 相关的信息。例如，可能输出是否代词是单数还是负数，这样如果是动词的话，我们也知道动词需要进行的词形变化。</p><p><img src="https://i.postimg.cc/tRwsS7t2/LSTM-13.png" alt="输出信息"></p><h2 id="LSTM-的变体"><a href="#LSTM-的变体" class="headerlink" title="LSTM 的变体"></a>LSTM 的变体</h2><p>我们到目前为止都还在介绍正常的 LSTM。但是不是所有的 LSTM 都长成一个样子的。实际上，几乎所有包含 LSTM 的论文都采用了微小的变体。差异非常小，但是也值得拿出来讲一下。</p><p>其中一个流形的 LSTM 变体，就是由 <a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf" target="_blank" rel="noopener">Gers &amp; Schmidhuber (2000)</a> 提出的，增加了 “peephole connection”。是说，我们让 门层 也会接受细胞状态的输入。</p><p><img src="https://i.postimg.cc/250645Sd/LSTM-14.png" alt="peephole 连接"></p><p>上面的图例中，我们增加了 peephole 到每个门上，但是许多论文会加入部分的 peephole 而非所有都加。</p><p>另一个变体是通过使用 coupled 忘记和输入门。不同于之前是分开确定什么忘记和需要添加什么新的信息，这里是一同做出决定。我们仅仅会当我们将要输入在当前位置时忘记。我们仅仅输入新的值到那些我们已经忘记旧的信息的那些状态 。</p><p><img src="https://i.postimg.cc/MpbXp5kF/LSTM-15.png" alt="coupled 忘记门和输入门"></p><p>另一个改动较大的变体是 Gated Recurrent Unit (GRU)，这是由 <a href="http://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="noopener">Cho, et al. (2014)</a> 提出。它将忘记门和输入门合成了一个单一的 更新门。同样还混合了细胞状态和隐藏状态，和其他一些改动。最终的模型比标准的 LSTM 模型要简单，也是非常流行的变体。</p><p><img src="https://i.postimg.cc/cHjLb5Yr/LSTM-16.png" alt="GRU"></p><p>这里只是部分流行的 LSTM 变体。当然还有很多其他的，如<a href="http://arxiv.org/pdf/1508.03790v2.pdf" target="_blank" rel="noopener">Yao, et al. (2015)</a> 提出的 Depth Gated RNN。还有用一些完全不同的观点来解决长期依赖的问题，如<a href="http://arxiv.org/pdf/1402.3511v1.pdf" target="_blank" rel="noopener">Koutnik, et al. (2014)</a> 提出的 Clockwork RNN。<br>要问哪个变体是最好的？其中的差异性真的重要吗？<a href="http://arxiv.org/pdf/1503.04069.pdf" target="_blank" rel="noopener">Greff, et al. (2015)</a> 给出了流行变体的比较，<strong>结论是他们基本上是一样的</strong>。<a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" target="_blank" rel="noopener">Jozefowicz, et al. (2015)</a> 则在超过 1 万种 RNN 架构上进行了测试，发现一些架构在某些任务上也取得了比 LSTM 更好的结果。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>刚开始，我提到通过 RNN 得到重要的结果。本质上所有这些都可以使用 LSTM 完成。对于大多数任务确实展示了更好的性能！</p><p>由于 LSTM 一般是通过一系列的方程表示的，使得 LSTM 有一点令人费解。然而本文中一步一步地解释让这种困惑消除了不少。</p><p>LSTM 是我们在 RNN 中获得的重要成功。很自然地，我们也会考虑：哪里会有更加重大的突破呢？在研究人员间普遍的观点是：“Yes! 下一步已经有了——那就是注意力！” 这个想法是让 RNN 的每一步都从更加大的信息集中挑选信息。例如，如果你使用 RNN 来产生一个图片的描述，可能会选择图片的一个部分，根据这部分信息来产生输出的词。实际上，Xu, et al.(2015)已经这么做了——如果你希望深入探索注意力可能这就是一个有趣的起点！还有一些使用注意力的相当振奋人心的研究成果，看起来有更多的东西亟待探索……</p><p>注意力也不是 RNN 研究领域中唯一的发展方向。例如，Kalchbrenner, et al. (2015) 提出的 Grid LSTM 看起来也是很有前途。使用生成模型的 RNN，诸如Gregor, et al. (2015) Chung, et al. (2015) 和 Bayer &amp; Osendorfer (2015) 提出的模型同样很有趣。在过去几年中，RNN 的研究已经相当的燃，而研究成果当然也会更加丰富！</p><p><a href="https://www.jianshu.com/p/9dc9f41f0b29#" target="_blank" rel="noopener">参考博文：[译]理解 LSTM 网络-朱小虎</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：Understanding LSTM Networks&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;循环神经网络&quot;&gt;&lt;a href=&quot;#循环神经网络&quot; class=&quot;headerlink&quot; title=&quot;循环神经网络&quot;&gt;&lt;/a&gt;循环神经网络&lt;/h2&gt;&lt;p&gt;人类并不是每时每刻都从一片空白的大脑开始他们的思考。在你阅读这篇文章时候，你都是基于自己已经拥有的对先前所见词的理解来推断当前词的真实含义。我们不会将所有的东西都全部丢弃，然后用空白的大脑进行思考。我们的思想拥有持久性。&lt;/p&gt;
&lt;p&gt;传统的神经网络并不能做到这点，看起来也像是一种巨大的弊端。例如，假设你希望对电影中的每个时间点的时间类型进行分类。传统的神经网络应该很难来处理这个问题——使用电影中先前的事件推断后续的事件。&lt;/p&gt;
&lt;p&gt;RNN 解决了这个问题。RNN 是包含循环的网络，允许信息的持久化。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://www.xiemingzhao.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="LSTM" scheme="https://www.xiemingzhao.com/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客多设备管理</title>
    <link href="https://www.xiemingzhao.com/posts/Hexoblogbranch.html"/>
    <id>https://www.xiemingzhao.com/posts/Hexoblogbranch.html</id>
    <published>2019-05-26T16:00:00.000Z</published>
    <updated>2019-10-13T14:13:29.128Z</updated>
    
    <content type="html"><![CDATA[<p>想要小白详细版本的Github+Hexo+Next搭建博客教程，可访问我的另一篇博客<a href="https://www.xiemingzhao.com/posts/GithubHexoNextblog">使用Github+Hexo+Next免费搭建自己的博客（最细攻略）</a>。</p><h2 id="多设备管理博客"><a href="#多设备管理博客" class="headerlink" title="多设备管理博客"></a>多设备管理博客</h2><p>博客建立好之后，面临的就是维护和更新博客，但是总不能每次都带着自己的电脑吧，如果想在自己的办公电脑上也操作自己的博客呢？于是广大的IT人才们想出了构建github分支来管理自己的博客。</p><h3 id="1-github-创建分支"><a href="#1-github-创建分支" class="headerlink" title="1. github 创建分支"></a>1. github 创建分支</h3><p>不管你有无看过我的另一篇博客<a href="https://www.xiemingzhao.com/posts/GithubHexoNextblog">使用Github+Hexo+Next免费搭建自己的博客（最细攻略）</a>，相信你自己博客的时候都是在yourname.github.io仓库下的master分支上创建的。既然我们是在本地上管理离线文档的，那我们就领创建一个分值，只用来存储每次更新的离线文件，相当于一个本地了。</p><a id="more"></a><p>如下图，在分支的输入框中新建一个分支确认就好了，我这里已经新建好了，一般取名hexo打扰其他的也都OK：</p><p><img src="https://i.postimg.cc/yxKQvdvC/branch1.jpg" alt="branch1"></p><p>然后我们需要进入<code>settings</code>模块，如下图，再点击<code>Branches</code>，接着选择默认分支为你刚才新创建的，我这里就是<code>hexo</code>，毕竟以后体检离线文件是要提交到这里的，所以将它设为默认分支，保存就好了。</p><p><img src="https://i.postimg.cc/3JKfGkkg/branch2.jpg" alt="branch2"></p><h3 id="2-本地clone分支"><a href="#2-本地clone分支" class="headerlink" title="2. 本地clone分支"></a>2. 本地clone分支</h3><p>注意哦，到目前还未使用新电脑，既然要使用新电脑进行备份更新，那我们先在本地也完成备份更新的步骤，后面新电脑操作跟本地差不多。我们在你博客管理目录中新建一个分支管理目录，例如，我的目录下面就有一个创建的目录<code>myname.github.io</code>以及一个分支目录<code>hexo</code>，之后基本上就只使用<code>hexo</code>分支，换电脑时候也类似只会有一个<code>hexo</code>分支来更新管理。</p><p>创建好新的目录后，使用控制台进入博客根目录（也就是能够看到主分支和hexo分支的目录）执行下面的命令，将分之内容clone到本地分支：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone -b hexo https://github.com/yourname/yourname.github.io</span><br></pre></td></tr></table></figure></p><p>然后本地的hexo分支文件夹中会多了很多文件，进入hexo文件夹中右键掉出<code>git bash</code>执行<code>git branch</code>，会返回你当前所处的是<code>hexo</code>分支。</p><p>这里去站点配置文件<code>_config.yml</code>中检查一下branch的配置是否为主分支：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">    type: git</span><br><span class="line">    repo: https://github.com/yourname/yourname.github.io</span><br><span class="line">    branch: master</span><br></pre></td></tr></table></figure></p><h3 id="3-备份到分支"><a href="#3-备份到分支" class="headerlink" title="3. 备份到分支"></a>3. 备份到分支</h3><p>进阶上述完成clone分支后，我们需要删除一些文件，因为我们需要的是备份部署资源，其他在发布生成过程中产生的静态文件并不需要保留。首先我们删除除了<strong>.git</strong>文件夹的其它所有文件和文件夹，主要是为了得到版本管理的.git。当然，最新版好像这一部分也不需要保留了，那就先保留着吧，到时候部署的时候不行的话再删也不迟。</p><p>接着把本地主管理目录（也就是<code>yourname.github.io</code>的文件夹）一下7个文件/文件夹复制到本地分支目录<code>hexo</code>中去：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scaffolds/ #文件夹（文章的模板）；</span><br><span class="line">source/ #资源文件夹；</span><br><span class="line">themes/ #文件夹里面的主题；</span><br><span class="line">.git/ #版本管理</span><br><span class="line">.gitignore #限定在提交的时候哪些文件可以忽略</span><br><span class="line">_config.yml #站点配置</span><br><span class="line">package.json #说明使用哪些包；</span><br></pre></td></tr></table></figure></p><p>如下图所示，分支文件夹中应该包含上述的文件，我这里有一些其他的是因为已经使用了很久，添加了其他功能，部署的时候产生的：</p><p><img src="https://i.postimg.cc/NfpJkQXZ/branch3.jpg" alt="branch3"></p><p>不需要更新的文件可利用.gitignore文件来配置需要忽略备份的文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/.deploy_git/  </span><br><span class="line">/blogSource/  </span><br><span class="line">/node_modules/  </span><br><span class="line">/public/  </span><br><span class="line">*.db  </span><br><span class="line">*.json</span><br></pre></td></tr></table></figure></p><p><em>不过最新版一版不用配置，文件中应该已经有了</em></p><p>这里可执行一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install</span><br></pre></td></tr></table></figure></p><p>防止后续的部署会失败，而所依赖的包都在上一步中的package.json备份文件里，所以直接这一个命令就可以了。</p><p><strong>注：</strong>如果使用的主题是从GitHub克隆的，那么主题文件夹下有Git管理文件，需要将它们移除，我使用的是hexo-next，需要移除的文件是<code>themes/next/.git*</code>。</p><p><strong>不要hexo init去整体初始化，因为需要的文件我们已经拷贝过来了。</strong></p><h3 id="4-提交分支和更新"><a href="#4-提交分支和更新" class="headerlink" title="4. 提交分支和更新"></a>4. 提交分支和更新</h3><p>我们使用控制台进入hexo分支目录或者在hexo分支目录里面调出<code>git bash</code>一次运行以下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .  #后面的点要加哦</span><br><span class="line">git commit -m ‘新电脑部署’  #引号内的内容是对每次提交的备注</span><br><span class="line">git push  #推送文件,保证xxx分支版本为最新版本</span><br></pre></td></tr></table></figure></p><p>以后每次更新，本地可使用<code>hexo</code>分支来操作，每次操作完将修改的部署文件提交到备份分支就可以了，具体可以使用如下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">git pull  # 保持本地操作为最新版本</span><br><span class="line">hexo n xxx #编辑、撰写文章或其他博客更新改动</span><br><span class="line">hexo clean # 可选，如果配置文件没有更改，忽略该命令</span><br><span class="line">hexo g</span><br><span class="line">hexo s #本地测试</span><br><span class="line">hexo d</span><br><span class="line">git add .</span><br><span class="line">git commit -m ‘在新电脑上提交新文章’</span><br><span class="line">git push #保证xxx分支版本为最新版本</span><br></pre></td></tr></table></figure></p><p><strong>如果上述中间出错，可删除<code>.git/ #版本管理</code>文件后重试。</strong></p><h3 id="5-新电脑迁移"><a href="#5-新电脑迁移" class="headerlink" title="5. 新电脑迁移"></a>5. 新电脑迁移</h3><p>前面讲了一大堆已经实现了分制管理，且每次本地主机也是拉取线上最新的，更改部署后，也将最新的版本提交到线上。这样使得真个流程先关起来，每次都是对最新版本进行更新，线上<code>hexo</code>分支目录存储的也都是最新版本。</p><p>如果现在你项实用另一台电脑操作你的博客，首先你需要做的是底层工具安装：</p><blockquote><p>安装 Git<br>安装 Node.js</p></blockquote><p>这里不清楚的可以参考我之前的博客<a href="https://www.xiemingzhao.com/posts/Github+Hexo+Next_blog">使用Github+Hexo+Next免费搭建自己的博客（最细攻略）</a>。</p><p>然后需要将新电脑生成<code>SSH key</code>配置到github上，这样新电脑才能得到信任，与线上github进行相连。这一步不会的也可以参考上述提到的我的另一篇博客。</p><p>然后在新电脑本地创建一个管理目录，命名为hexo也行。紧接着将线上的<code>hexo</code>分支clone到本地，这一步与上述一样。然后安装<code>hexo</code>相关依赖：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install</span><br></pre></td></tr></table></figure></p><p>如此便完成了将Hexo博客迁移到新电脑上了，很简单。后面更新部署和发表新文章就可以使用上一步中那几条命令。<strong>切记每次要拉取和更新线上最新版本哦。</strong></p><p><strong>参考博文</strong><br><a href="https://blog.csdn.net/white_idiot/article/details/80685990" target="_blank" rel="noopener">GitHub创建Git分支将Hexo博客迁移到其它电脑</a><br><a href="https://andyvj.coding.me/2019/02/19/190219-03/" target="_blank" rel="noopener">hexo 迁移更换电脑，或多电脑终端更新博客</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;想要小白详细版本的Github+Hexo+Next搭建博客教程，可访问我的另一篇博客&lt;a href=&quot;https://www.xiemingzhao.com/posts/GithubHexoNextblog&quot;&gt;使用Github+Hexo+Next免费搭建自己的博客（最细攻略）&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;多设备管理博客&quot;&gt;&lt;a href=&quot;#多设备管理博客&quot; class=&quot;headerlink&quot; title=&quot;多设备管理博客&quot;&gt;&lt;/a&gt;多设备管理博客&lt;/h2&gt;&lt;p&gt;博客建立好之后，面临的就是维护和更新博客，但是总不能每次都带着自己的电脑吧，如果想在自己的办公电脑上也操作自己的博客呢？于是广大的IT人才们想出了构建github分支来管理自己的博客。&lt;/p&gt;
&lt;h3 id=&quot;1-github-创建分支&quot;&gt;&lt;a href=&quot;#1-github-创建分支&quot; class=&quot;headerlink&quot; title=&quot;1. github 创建分支&quot;&gt;&lt;/a&gt;1. github 创建分支&lt;/h3&gt;&lt;p&gt;不管你有无看过我的另一篇博客&lt;a href=&quot;https://www.xiemingzhao.com/posts/GithubHexoNextblog&quot;&gt;使用Github+Hexo+Next免费搭建自己的博客（最细攻略）&lt;/a&gt;，相信你自己博客的时候都是在yourname.github.io仓库下的master分支上创建的。既然我们是在本地上管理离线文档的，那我们就领创建一个分值，只用来存储每次更新的离线文件，相当于一个本地了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="博客搭建" scheme="https://www.xiemingzhao.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="Hexo" scheme="https://www.xiemingzhao.com/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客绑定域名</title>
    <link href="https://www.xiemingzhao.com/posts/Hexoblogdomain.html"/>
    <id>https://www.xiemingzhao.com/posts/Hexoblogdomain.html</id>
    <published>2019-05-24T16:00:00.000Z</published>
    <updated>2019-10-13T14:13:41.776Z</updated>
    
    <content type="html"><![CDATA[<p>想要小白详细版本的Github+Hexo+Next搭建博客教程，可访问我的另一篇博客<a href="https://www.xiemingzhao.com/posts/GithubHexoNextblog">使用Github+Hexo+Next免费搭建自己的博客（最细攻略）</a>。</p><h2 id="Hexo博客域名绑定"><a href="#Hexo博客域名绑定" class="headerlink" title="Hexo博客域名绑定"></a>Hexo博客域名绑定</h2><p>在我们建好了博客后，我们就可以通过<code>yourname.github.io</code>来访问你的博客，但是这个域名明显看起来不够厉害。这时候我们想的是如何将自己的博客的域名设置成像一般网址一样呢，例如我的原本的链接是<a href="www.xiemingzhao.com">xiemingzhao.github.io</a>，但是经过设置绑定后将我得博客的新域名变成了<a href="www.xiemingzhao.com">www.xiemingzhao.com</a>，并且打开网之后各个页面显示的连接也是www.xiemingzhao.com作为开头。接下来我们就开始。</p><h3 id="1-域名购买"><a href="#1-域名购买" class="headerlink" title="1. 域名购买"></a>1. 域名购买</h3><p>域名这个东西当然不是免费的啦，毕竟网址这个东西还是需要有管控的。购买域名的地方有很多，本人是在<a href="https://www.aliyun.com/" target="_blank" rel="noopener">阿里云https://www.aliyun.com/</a>上面购买的，原因就不多说，大品牌值得信奈。打开阿里云官网，你需要做一下两件事情：</p><a id="more"></a><blockquote><p>注册阿里云账号，也可以用淘宝或者支付宝账号登录，毕竟是一家子<br>然后进行实名认证，毕竟买域名还是需要正式一点，要备案的</p></blockquote><p><img src="https://i.postimg.cc/fyvHFNrt/aliyun1.jpg" alt="aliyun"></p><h4 id="注意啦！敲黑板啦！大写加粗划重点啦！领券啦！"><a href="#注意啦！敲黑板啦！大写加粗划重点啦！领券啦！" class="headerlink" title="注意啦！敲黑板啦！大写加粗划重点啦！领券啦！"></a><strong>注意啦！敲黑板啦！大写加粗划重点啦！领券啦！</strong></h4><blockquote><p>买东西没优惠怎么行，当然土豪请绕路！一般购买一个<code>.com</code>的域名，最便宜也得60左右一年，像我等底层人士还是觉得蛮贵的，那么优惠有木有，当然啦！可直接搜索<code>阿里云 优惠券</code>仔细找一找能够找得到。既然看了我的博客，肯定要对得起看官了，这里附上两个常用渠道，一个是<a href="https://promotion.aliyun.com/ntms/yunparter/invite.html?userCode=r3yteowb" target="_blank" rel="noopener">官方大礼包</a>，这个一般有一定限制，优惠不一定能够满足条件。另一个就是<a href="https://www.langtto.com/aliyun/54/" target="_blank" rel="noopener">云优惠大全</a>，这里长期更新，有各种优惠口令，我的优惠就是从这里领取的，总价300左右的单子省了好几十大洋，还是蛮不错的。</p></blockquote><p>目前实名认证后的审核应该是很快的，秒速。接着你就可以在最上方点击域名，然后在搜索框里输入你想搜的域名，一般<code>.com</code>最抢手也是最贵的，而且决定价格很重要的一个因素就是域名的通识性，辨识度或者寓意于浩价格肯定越贵。得益于本人的名字较长，全拼的<code>.com</code>是基准价，于是就购买了，跟后面流程没什么好说的，主要就是填写一些个人信息包括地址等等。</p><h3 id="2-获取博客站点ip"><a href="#2-获取博客站点ip" class="headerlink" title="2. 获取博客站点ip"></a>2. 获取博客站点ip</h3><p>首先使用<code>win+R</code>快捷键打开“运行”窗口，输入cmd运行调出命令行控制台。输入以下命令行，查询你自己博客站点的ip：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping yourname.github.io</span><br></pre></td></tr></table></figure></p><p>注意上述代码中的<code>yourname</code>要换成你自己的哦。如下图，即使静秋超市也没关系，只需要第一行信息，你就可以找到你自己博客站点对应的ip了，这个在后续的域名绑定中有用。</p><p><img src="https://i.postimg.cc/3xxqsk7K/aliyun2.jpg" alt="ping blogip"></p><h3 id="3-域名解析配置"><a href="#3-域名解析配置" class="headerlink" title="3. 域名解析配置"></a>3. 域名解析配置</h3><p>我们接着第一步购买域名后的步骤，回到首页点击用户信息旁边的<code>控制台</code>：</p><p><img src="https://i.postimg.cc/RZpY4vVw/aliyun3.jpg" alt="aliyun home"></p><p>再点击<code>域名</code>选项，当然你通过其他渠道进入到这里也行：</p><p><img src="https://i.postimg.cc/5N3GKwh7/aliyun4.jpg" alt="aliyun cmd"></p><p>接下来，我们找到你购买的域名，点击后面的解析，进入域名解析页面：</p><p><img src="https://i.postimg.cc/BQskChVP/aliyun5.jpg" alt="域名解析"></p><p>然后删除默认的，添加如下两条解析配置，最好按照我这里的配置来，因为亲测在后续的站点收录等地方这么设置最好不会出bug。</p><p><img src="https://i.postimg.cc/W4DH4xhC/aliyun6.jpg" alt="解析配置"></p><h3 id="4-站点域名绑定"><a href="#4-站点域名绑定" class="headerlink" title="4. 站点域名绑定"></a>4. 站点域名绑定</h3><p>在解析配置好了之后，登录你自己的<code>github</code>，进入到博客站点对应的仓库，进入<code>settings</code>，找到如下图的<code>custom domain</code>配置区域，填写你购买的域名，这里加不加<code>www.</code>都是阔以的，我是加了的，并且勾选上<code>Enforce HTTPS</code>选项，勾选这个在以后其他地方有用，有利于收录。</p><p><img src="https://i.postimg.cc/d0zSZnC1/aliyun7.jpg" alt="绑定站点域名"></p><h3 id="5-解析文件配置"><a href="#5-解析文件配置" class="headerlink" title="5. 解析文件配置"></a>5. 解析文件配置</h3><p>这是最后一步了，进入你本地博客站点根目录下的<code>/source/</code>文件夹中，创建一个名为<code>CNAME</code>的文件，没有错，不带任何后缀名，里面只需要协商你刚才购买的域名就可以了。这里面填写的域名加不加<code>www.</code>会有不同的效果：</p><blockquote><p>a. 如果你填写的是没有www的，比如 xiemingzhao.com，那么无论是访问 <a href="https://www.xiemingzhao.com">https://www.xiemingzhao.com</a> 还是 <a href="http://xiemingzhao.me" target="_blank" rel="noopener">http://xiemingzhao.me</a> ，都会自动跳转到 <a href="http://xiemingzhao.com。" target="_blank" rel="noopener">http://xiemingzhao.com。</a><br>b. 如果你填写的是带www的，比如 www.xiemingzhao.com ，那么无论是访问 <a href="http://www.xiemingzhao.com">http://www.xiemingzhao.com</a> 还是 <a href="http://xiemingzhao.com" target="_blank" rel="noopener">http://xiemingzhao.com</a> ，都会自动跳转到 <a href="http://www.xiemingzhao.com。" target="_blank" rel="noopener">http://www.xiemingzhao.com。</a><br>c. 如果你填写的是其它子域名，比如 abc.xiemingzhao.com，那么访问 <a href="http://abc.xiemingzhao.com" target="_blank" rel="noopener">http://abc.xiemingzhao.com</a> 没问题，但是访问 <a href="http://xiemingzhao.com" target="_blank" rel="noopener">http://xiemingzhao.com</a> ，不会自动跳转到 <a href="http://abc.xiemingzhao.com。" target="_blank" rel="noopener">http://abc.xiemingzhao.com。</a></p></blockquote><p><img src="https://i.postimg.cc/2jdX3QSk/aliyun8.jpg" alt="CNAME"></p><p><strong>另外，在绑定了这个新的域名后，原来的<code>yourname.github.io</code>并没有失效哦，会自动解析到新域名上，是不是很酷！</strong></p><p>最后在站点配置文件<code>_config.yml</code>文件中将站点的url改成自己购买的新域名即可，例如下方我自己的配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># URL</span><br><span class="line">## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;</span><br><span class="line">url: http://www.xiemingzhao.com</span><br><span class="line">root: /</span><br><span class="line">permalink: :year/:month/:day/:title/</span><br><span class="line">permalink_defaults:</span><br></pre></td></tr></table></figure></p><p>到这里就结束了，使用三个经典的发布命令后于就可以测试一下了。</p><p><strong>参考博文</strong><br><a href="https://www.jianshu.com/p/e3169b681038" target="_blank" rel="noopener">Hexo个人博客域名绑定 简明教程（小白篇）</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;想要小白详细版本的Github+Hexo+Next搭建博客教程，可访问我的另一篇博客&lt;a href=&quot;https://www.xiemingzhao.com/posts/GithubHexoNextblog&quot;&gt;使用Github+Hexo+Next免费搭建自己的博客（最细攻略）&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;Hexo博客域名绑定&quot;&gt;&lt;a href=&quot;#Hexo博客域名绑定&quot; class=&quot;headerlink&quot; title=&quot;Hexo博客域名绑定&quot;&gt;&lt;/a&gt;Hexo博客域名绑定&lt;/h2&gt;&lt;p&gt;在我们建好了博客后，我们就可以通过&lt;code&gt;yourname.github.io&lt;/code&gt;来访问你的博客，但是这个域名明显看起来不够厉害。这时候我们想的是如何将自己的博客的域名设置成像一般网址一样呢，例如我的原本的链接是&lt;a href=&quot;www.xiemingzhao.com&quot;&gt;xiemingzhao.github.io&lt;/a&gt;，但是经过设置绑定后将我得博客的新域名变成了&lt;a href=&quot;www.xiemingzhao.com&quot;&gt;www.xiemingzhao.com&lt;/a&gt;，并且打开网之后各个页面显示的连接也是www.xiemingzhao.com作为开头。接下来我们就开始。&lt;/p&gt;
&lt;h3 id=&quot;1-域名购买&quot;&gt;&lt;a href=&quot;#1-域名购买&quot; class=&quot;headerlink&quot; title=&quot;1. 域名购买&quot;&gt;&lt;/a&gt;1. 域名购买&lt;/h3&gt;&lt;p&gt;域名这个东西当然不是免费的啦，毕竟网址这个东西还是需要有管控的。购买域名的地方有很多，本人是在&lt;a href=&quot;https://www.aliyun.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;阿里云https://www.aliyun.com/&lt;/a&gt;上面购买的，原因就不多说，大品牌值得信奈。打开阿里云官网，你需要做一下两件事情：&lt;/p&gt;
    
    </summary>
    
    
      <category term="博客搭建" scheme="https://www.xiemingzhao.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="Hexo" scheme="https://www.xiemingzhao.com/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>LightGBM A Highly Efficient Gradient Boosting Decision Tree （论文解析）</title>
    <link href="https://www.xiemingzhao.com/posts/c7ab2b84.html"/>
    <id>https://www.xiemingzhao.com/posts/c7ab2b84.html</id>
    <published>2019-05-22T16:00:00.000Z</published>
    <updated>2019-11-10T09:35:12.079Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf" target="_blank" rel="noopener">原始论文：LightGBM-A Highly Efficient Gradient Boosting Decision Tree</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Gradient Boosting Decision Tree (GBDT)是一个非常流行的机器学习算法，却只有像XGBoost和pGBRT的一些实现。尽管许多工程上的优化方案已经在这些实现中应用了，但是当特征维度较高和数据量巨大的时候，仍然存在效率和可扩展性的问题。一个主要原因就是对于每一个特征的每一个分裂点，都需要遍历全部数据计算信息增益，这一过程非常耗时。针对这一问题，本文提出两种新方法：Gradient-based One-Side Sampling (GOSS) 和Exclusive Feature Bundling (EFB)（基于梯度的one-side采样和互斥的特征捆绑）。在GOSS中，我们排除了一部分重要的具有小梯度实例数据的比例，只用剩下的来估计信息增益。我们证明，这些梯度大的实例在计算信息增益中扮演重要角色，GOSS可以用更小的数据量对信息增益进行相当准确的估计。对于EFB，我们捆绑互斥的特征（例如，特征间很少同时非零的特征），来降低特征的个数。我们完美地证明了捆绑互斥特征是NP难的，但贪心算法能够实现相当好的逼近率，因此我们能够在不损害分割点准确率许多的情况下，有效减少特征的数量。（牺牲一点分割准确率降低特征数量），这一算法命名为LightGBM。我们在多个公共数据集实验证明，LightGBM加速了传统GBDT训练过程20倍以上，同时达到了几乎相同的精度。</p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>GBDT是一个广泛应用地机器学习算法，这得益于其本身的有效性、准确性、可解释性。GBDT在许多机器学习任务上均取得了最好的效果，例如多分类，点击预测，排序。但最近几年随着大数据的爆发（特征量和数据量），GBDT正在面临新的挑战，特别是在平衡准确率和效率的调整方面。常见的GBDT的实现，对于每个特征,都需要遍历全部数据来计算所有可能分裂点的信息增益。因此，其计算复杂度将受到特征数量和数据量双重影响，造成处理大数据时十分耗时。</p><p>为了解决这一问题，一个直接的方法就是减少特征量和数据量而且不影响精确度。然而，这将是非常重要的。例如，我们不清楚如何针对提升GBDT来进行数据抽样。而有部分工作根据数据权重采样来加速boosting的过程，它们不能直接地应用于GBDT，因为gbdt没有样本权重。在本文中，我们提出两种新方法实现此目标。</p><p>Gradient-based One-Side Sampling (GOSS)。尽管GBDT虽然没有数据实例权重，但每个数据实例有不同的梯度，从而在信息增益的计算中扮演不同的角色。特别地，根据计算信息增益的定义，梯度大的实例对信息增益有更大的影响。因此，在数据实例下采样时，为了保持信息增益预估的准确性，我们应该尽量保留梯度大的样本（预先设定阈值，或者最高百分位间），并且随机去掉梯度小的样本。我们证明此措施在相同的采样率下比随机采样获得更准确的结果，尤其是在信息增益范围较大时。</p><p>Exclusive Feature Bundling (EFB)。通常在真实应用中，虽然特征量比较多，但是由于特征空间十分稀疏，那我们是否可以设计一种无损的方法来减少有效特征呢？特别在，稀疏特征空间上，许多特征几乎都是互斥的（例如像文本挖掘中的one-hot特征）。我们就可以捆绑这些互斥的特征。最后，我们设计了一个有效的算法，将捆绑问题简化成图着色问题（方法是将特征作为节点，在每两个不完全互斥的特征之间添加边），并且通过贪心算法可以求得近似解。</p><p>我们将这种结合了 GOSS 和 EFB 的新 GBDT 算法称为<em>LightGBM</em>。我们在多个公开数据集上的实验结果证明了 LightGBM 在得到几乎相同准确率的情况下能够提升20倍的训练速度。</p><p>这篇文章剩下的部分将按如下安排。首先，我们在第二部分回顾了 GBDT 算法和相关工作。然后，我们分别在第三和第四部分介绍了 GOSS 和 EFB 的详细内容。在第五部分，展示了我们在公共数据集上所做的关于 LightGBM 的实验结果。最后，我们在第六部分进行了总结。</p><h2 id="2-预研"><a href="#2-预研" class="headerlink" title="2 预研"></a>2 预研</h2><h3 id="2-1-GBDT-和它的复杂度分析"><a href="#2-1-GBDT-和它的复杂度分析" class="headerlink" title="2.1 GBDT 和它的复杂度分析"></a>2.1 GBDT 和它的复杂度分析</h3><p>GBDT是一种集成模型的决策树，顺序训练决策树。每次迭代中，GBDT通过拟合负梯度（也被称为残差）来学到决策树。</p><p>学习决策树是GBDT主要的时间花销，而学习决策树中找到最优切分点最消耗时间。有一种最常用的预排序算法来找到最优切分点，这种方法会列举预排序中所有可能的切分点。这种算法虽然能够找到最优的切分点，但在训练速度和内存消耗上的效率都很低。另一种流行算法是直方图算法（histogram-based algorithm），如 Alg.1 所示。直方图算法并不通过特征排序找到最优的切分点，而是将连续的特征值抽象成离散的分箱，并使用这些分箱在训练过程中构建特征直方图。这种算法更加训练速度和内存消耗上都更加高效，lightGBM使用此种算法。</p><p>histogram-based算法通过直方图寻找最优切分点，其建直方图消耗O(#data <em> #feature)，寻找最优切分点消耗O(#bin </em> # feature)，而#bin的数量远小于#data，所以建直方图为主要时间消耗。如果能够减少数据量或特征量，那么还能够够加速GBDT的训练。（寻找最优切分点已经进行了优化，那么我们现在应该对建直方图的时间进行优化）</p><h2 id="2-2-相关工作"><a href="#2-2-相关工作" class="headerlink" title="2.2 相关工作"></a>2.2 相关工作</h2><p>GBDT有许多实现，如XGBoost，PGBRT，Scikit-learn，gbm in R。Scikit-learn和gbm in R实现都用了预排序，pGBRT使用了直方图算法。XGBoost支持预排序和直方图算法，由于XGBoost胜过其他算法，我们用它作为实验的baseline。</p><p>为了减小训练数据集，通常做法是下采样。例如过滤掉权重小于阈值的数据。SGB每次迭代中用随机子集训练弱学习器。或者采样率基于训练过程动态调整。然而，这些都是使用基于AdaBoost的SGB，其不能直接应用于GBDT是因为GBDT中没有原始的权重。虽然SGB也能间接应用于GBDT，但往往会影响精度。</p><p>同样，可以考虑过滤掉弱特征（什么是弱特征）来减少特征量。通常用主成分分析或者投影法。当然，这些方法依赖于一个假设-特征有高冗余性，但实际中往往不是。（设计特征来自于其独特的贡献，移除任何一维度都可以某种程度上影响精度）。</p><p>实际中大规模的数据集通常都是非常稀疏的，使用预排序算法的GBDT能够通过无视为0的特征来降低训练时间消耗。然而直方图算法没有优化稀疏的方案。因为直方图算法无论特征值是否为0，都需要为每个数据检索特征区间值。如果基于直方图的GBDT能够有效解决稀疏特征中的0值，并且这样将会有很好的性能。</p><p>为了解决前面工作的局限性，我们提出了两个全新的技术分别是 Gradient-based One-Side Sampling (GOSS) 和 Exclusive Feature Bundling (EFB)（基于梯度的one-side采样和互斥的特征捆绑）。跟多的细节会再下一部分介绍。</p><p><img src="https://i.postimg.cc/xj7q7cL6/lgbm1.jpg" alt="Alg.1 &amp; Alg.2"></p><h2 id="3-基于梯度的one-side采样"><a href="#3-基于梯度的one-side采样" class="headerlink" title="3 基于梯度的one-side采样"></a>3 基于梯度的one-side采样</h2><p>在这一部分，我们为 GBDT 提出了一个新的抽样方法， 这能够在减少数据实例个数和保持学习到的决策树的准确度之间达到一个平衡。</p><h3 id="3-1-算法描述"><a href="#3-1-算法描述" class="headerlink" title="3.1 算法描述"></a>3.1 算法描述</h3><p>在AdaBoost中，样本权重是数据实例重要性的指标。然而在GBDT中没有原始样本权重，不能应用权重采样。幸运的事，我们观察到GBDT中每个数据都有不同的梯度值，对采样十分有用，即实例的梯度小，实例训练误差也就较小，已经被学习得很好了，直接想法就是丢掉这部分梯度小的数据。然而这样做会改变数据的分布，将会影响训练的模型的精确度，为了避免此问题，我们提出了GOSS。</p><p>GOSS保留所有的梯度较大的实例，在梯度小的实例上使用随机采样。为了抵消对数据分布的影响，计算信息增益的时候，GOSS对小梯度的数据引入常量乘数。GOSS首先根据数据的梯度绝对值排序，选取top a x 100%个实例。然后在剩余的数据中随机采样bx100%个实例。接着计算信息增益时为采样出的小梯度数据乘以(1-a)/b（即，小梯度样本总数/随机采样出的小梯度样本数量），这样算法就会更关注训练不足的实例，而不会过多改变原数据集的分布。</p><h3 id="3-2-理论分析"><a href="#3-2-理论分析" class="headerlink" title="3.2 理论分析"></a>3.2 理论分析</h3><p>GBDT使用决策树，来学习获得一个将输入空间$\mathcal \chi^s$映射到梯度空间$\mathcal G$的函数。假设训练集有n个实例 ${x_1,…,x_n}$，每个$x_i$都是一个维度为s的特征向量。每次迭代时，模型数据变量的损失函数的负梯度方向表示为$g_1,…,g_n$，决策树通过最优切分点（最大信息增益点）将数据分到各个节点。对于GBDT，一般通过分割后的方差衡量信息增益，具体由下定义。</p><p><strong>定义3.1</strong>：$O$表示某个固定叶子节点的训练集，分割特征j的分割点d对应的方差增益定义为：</p><script type="math/tex; mode=display">V_{j|O} (d) = \frac{1}{n_O} ( \frac{(\sum_{ \{x_i \in O:x_{ij} \leq d\} } g_i)^2} {n_{l|O}^j (d)} + \frac{(\sum_{ \{x_i \in O:x_{ij} > d\} } g_i)^2} {n_{r|O}^j (d)} )</script><p>其中$n_O = \sum I[x_i \in O]$(<em>某个固定叶子节点的训练集样本的个数</em>)，$n_{l|O}^j (d) = \sum I[x_i \in O:x_{ij} \leq d]$（<em>在第j个特征上值小于等于d的样本个数</em>），和 $n_{r|O}^j (d) = \sum I[x_i \in O:x_{ij} &gt; d]$（<em>在第j个特征上值大于d的样本个数</em>）。</p><p>对于特征 j，决策树算法选择$d_j^<em> = argmax_d V_j(d)$并且计算最大信息增益$V_j(d_j^</em>)$。然后，数据集会根据特征$j^<em>$在点$d_j^</em>$分到左右子节点中去。</p><p>在我们所提出的GOSS方法中，首先，我们训练实例按照它们梯度的绝对值进行降序排列；第二，我们保留梯度最大的top-a x 100%个实例作为样本子集A；再者，对于剩下的包含(1-a) x 100%个更小梯度实例的子集$A^c$，我们进一步随机抽样一个大小为$b x |A^c|$的子集B；最后，我们我们将样本实例按照下列公式在子集$A \cup B$上的方法增益估计值进行分割：</p><script type="math/tex; mode=display">\tilde V_j(d) = \frac{1}{n} (\frac{(\sum_{x_i \in A_l} g_i + \frac{1-a}{b} \sum_{x_i \in B_l} g_i)^2}{n_l^j (d)} + \frac{(\sum_{x_i \in A_r} g_i + \frac{1-a}{b} \sum_{x_i \in B_r} g_i)^2}{n_r^j (d)}),     (1)</script><p>其中，$A_l = {x_i \in A:x_{ij} \leq A}, A_r = {x_i \in A:x_{ij} &gt; d}, B_l = {x_i \in b:x_{ij} \leq d}, B_r = {x_i \in B:x_{ij} &gt; d}$，并且系数(1-a)/b是用来将B上的梯度和归一化到$A^c$的大小上去。</p><p>因此，在GOSS中，我们使用更小实例子集上的估计值$\tilde V_j (d)$而不是使用所有的实例来计算精确的$V_j (d)$来得到分裂点，并且这种计算成本也可以得到大大地降低。更重要的是，下列定理表名了GOSS不会损失更多的训练精度并且会优于随机抽样。由于空间限制，我们将定理的证明放在了补充材料中。</p><p><strong>定理3.2</strong> 我们将GOSS的近似误差定义为$\varepsilon (d) = |\tilde V_j (d) - V_j (d)| \ and\ \bar g_l^j (d) = \frac{\sum_{x_i \in (A \cup A^c)_l |g_i|} }{n_l^j (d)}, \bar g_r^j (d)  = \frac{\sum_{x_i \in (A \cup A^c)_r |g_i|} }{n_r^j (d)}$。概率至少是$1- \delta$，我们有：</p><script type="math/tex; mode=display">\varepsilon (d) \leq C_{a,b}^2 ln 1/\delta \cdot max\{ \frac{1}{n_l^j(d)}, \frac{1}{n_r^j(d)} \} + 2DC_{a,b} \sqrt{\frac{ln 1/\delta}{n} },   (2)</script><p>其中$C_{a,b} = \frac{1-a}{\sqrt{b}} max_{x_i \in A^c} |g_i|$， 和 $D = max(\bar g_l^j (d), \bar g_r^j (d) )$。</p><p>根据定理，我们可以得到以下结论：(1)GOSS的渐进近似比率是$\mathcal O(\frac{1}{n_l^j (d)} + \frac{1}{n_r^j (d)} + \frac{1}{\sqrt{n}} )$。如果分割的不是特别不平衡(即$n_l^h \geq \mathcal O (\sqrt n)$ 且 $n_r^h \geq \mathcal O (\sqrt n)$)，近似误差可以由公式(2)中的第二项来表示，其中当$n \rightarrow \infty$时$\mathcal O (\sqrt n)$将趋向于0。这意味着当数据集个数很大的时候，近似值将是很准确的。(2)随机抽样是一个$a = 0$时GOSS的特例。在许多案例中，GOSS都会表现地比随机抽样要好，在$C_{0,\beta} &gt; C_{a,\beta - a}$条件下，这等价于$\frac{\alpha_a}{\sqrt \beta} &gt; \frac{1-a}{\sqrt{\beta - a} }$且有$\alpha_a = max_{x_i \in A\cup A^c} |g_i|/max_{x_i \in A^c |g_i|}$。</p><p>下一步，我们分析了GOSS的泛化表现。我们考虑了GOSS的泛化误差$\varepsilon_{gen}^{GOSS} (d) = |\tilde V_j (d) - V_<em> (d)|$，这个值是由GOSS中抽样训练得到的方差增益和潜在分布的真实方差增益之间的差值。我们有$\varepsilon_{gen}^{GOSS} (d) \leq |\tilde V_j (d) - V_j (d)| + |V_j (d) - V_</em> (d)| \triangleq \varepsilon_{GOSS} (d) + \varepsilon_{gen} (d)$。因此，如果GOSS近似是准确的，那么带GOSS的泛化误差是接近于使用全量数据集计算得结果。另一方面，抽样会增加基础学习器之间的多样性，这潜在地帮助提升了泛化的表现。</p><h2 id="4-互斥特征捆绑"><a href="#4-互斥特征捆绑" class="headerlink" title="4 互斥特征捆绑"></a>4 互斥特征捆绑</h2><p>这一章，我们提出了一个全新的方法来有效地减少特征数量。</p><p><img src="https://i.postimg.cc/7hp6TWqF/lgbm2.jpg" alt="Alg.3 &amp; Alg.4"></p><p>高维的数据通常是非常稀疏的。这种稀疏性启发我们可以设计一种无损地方法来减少特征的维度。特别地，在稀疏特征空间中，许多特征是完全互斥的，即它们从不同时为非零值。我们可以绑定互斥的特征为单一特征（这就是我们所说的互斥特征捆绑）。通过仔细设计特征扫描算法，我们从特征捆绑中构建了与单个特征相同的特征直方图。这种方式的构建直方图时间复杂度从O(#data <em> #feature)降到O(#data </em> #bundle)，由于#bundle &lt;&lt; # feature，我们能够极大地加速GBDT的训练过程而且不损失精度。(构造直方图的时候，遍历一个“捆绑的大特征”可以得到一组exclusive feature的直方图。这样只需要遍历这些“大特征”就可以获取到所有特征的直方图，降低了需要遍历的特征量。)在下面，我们将会展示如何实现这些方法的细节。</p><p>有两个问题需要被解决。第一个就是需要确定哪些特征后应该绑定在一起。第二个就是如何构造捆绑。</p><p><strong>定理4.1</strong> <em>将特征分割为较小量的互斥特征群是NP难的。</em></p><p><em>证明：</em>将图着色问题归约为此问题。而图着色是NP难的，所以我们可以得到我们的结论。</p><p>给定图着色的一个实例G=(V, E)。可以构建一个我们问题的一个实例如下所示。以G的关联矩阵的每一行为特征，得到我们问题的一个实例有|V|个特征。 很容易看到，在我们的问题中，一个独特的特征捆绑与一组具有相同颜色的顶点相对应，反之亦然。</p><p>对于第1个问题，我们在定理4.1说明寻找一个最优的捆绑策略是NP难的，这就表明不可能找到一个能够在多项式时间内解决的办法。为了寻找好的近似算法，我们将最优捆绑问题归结为图着色问题，如果两个特征之间不是相互排斥，那么我们用一个边将他们连接，然后用合理的贪婪算法（具有恒定的近似比）用于图着色来做特征捆绑。 此外，我们注意到通常有很多特征，尽管不是100％相互排斥的，也很少同时取非零值。 如果我们的算法可以允许一小部分的冲突，我们可以得到更少的特征包，进一步提高计算效率。经过简单的计算，随机污染小部分特征值将影响精度最多为$\mathcal O([(1-\gamma) n]^{-2/3})$(参考文献【2】)，$\gamma$是每个绑定中的最大冲突比率。所以，如果我们能选择一个相对较小的$\gamma$时，能够完成精度和效率之间的平衡。</p><p>基于上述的讨论，我们针对互斥特征捆绑设计了一个算法如Alg.3所示。首先，我们建立一个图，每个点代表特征，每个边有权重，其权重和特征之间总体冲突相关。第二，我们按照降序排列图中点的度来排序特征。最后，我们检查排序之后的每个特征，对它进行特征绑定或者建立新的绑定使得操作之后的总体冲突最小（由$\gamma$控制）。算法3的时间复杂度是$\mathcal O (# feature ^2)$，并且只在训练之前处理一次。其时间复杂度在特征不是特别多的情况下是可以接受的，但难以应对百万维的特征。为了继续提高效率，我们提出了一个更加高效的不用构建图的排序策略：将特征按照非零值个数排序，这和使用图节点的度排序相似，因为更多的非零值通常会导致冲突。新算法在算法3基础上只是改变了排序策略来避免重复。</p><p>对于第2个问题，我们需要一个好的办法合并同一个bundle的特征来降低训练时间复杂度。关键在于原始特征值可以从bundle中区分出来。鉴于直方图算法存储离散值而不是连续特征值，我们通过将互斥特征放在不同的箱中来构建bundle。这可以通过将偏移量添加到特征原始值中实现，例如，假设bundle中有两个特征，原始特征A取值[0, 10]，B取值[0, 20]。我们添加偏移量10到B中，因此B取值[10, 30]。通过这种做法，就可以安全地将A、B特征合并，使用一个取值[0, 30]的特征取代A和B。算法见Alg.4。</p><p>EFB算法能够将许多互斥的特征变为低维稠密的特征，就能够有效的避免不必要0值特征的计算。实际，对每一个特征，建立一个记录数据中的非零值的表，通过用这个表，来忽略零值特征，达到优化基础的直方图算法的目的。通过扫描表中的数据，建直方图的时间复杂度将从O(#data)降到O(#non_zero_data)。当然，这种方法在构建树过程中需要而额外的内存和计算开销来维持这种表。我们在lightGBM中将此优化作为基本函数.因为当bundles是稀疏的时候，这个优化与EFB不冲突（可以用于EFB）.</p><h2 id="5-实验"><a href="#5-实验" class="headerlink" title="5 实验"></a>5 实验</h2><p>在这一部分，我们汇报了我们提出的LightGBM算法的实验结果。我们使用五个不同的公开数据集。这些数据集的细节列在了表1中。在它们中，微软的排序数据集包含30K网站搜索请求数据。这个数据集中的特征大多是稠密数值特征。Allstate<br>Insurance Claim和Flight Delay数据集都包含许多one-hot编码特征。并且最后两个数据集来自KDD CUP 2010 and KDD CUP 2012。我们直接地使用这些由获胜者NTU提供的特征，其中包含稠密特征和稀疏特征，并且这两个数据集非常大。这些数据集都是很大的，同时包含稀疏特征和稠密特征，并且涵盖了许多真实的任务。因此，我们直接地可以使用它们来测试我们的算法。</p><p>我们的实验环境是一个Linux服务器，包含两个E5-2670 v3 CPUs（总共24核）和256GB的内存。所有试验都是多线程运行并且线程的个数固定在16。</p><h3 id="5-1-全部对比"><a href="#5-1-全部对比" class="headerlink" title="5.1 全部对比"></a>5.1 全部对比</h3><p><img src="https://i.postimg.cc/qM3gd4L4/lgbm3.jpg" alt="table of experiment"></p><p>我们在这一部分展示了所有的实验对比。XGBoost和不包含GOSS以及EFB（称为lgb_baseline）的LightGBM用作基准线。对于XGBoost，我们使用两个版本，xgb_exa(预排序算法)和xgb_his(基于直方图的算法)。对于xgb_his，lgb_baseline，和LightGBM，我们使用leaf-wise树增长方法。对于xgb_exa，因为它仅仅支持layer-wise增长策略，我们将xgb_exa的参数设成使其和其他方法增长相似的树。我们也可以通过调整参数使其在所有的数据集上能在速度和准确率上面达到平衡。我们在Allstate, KDD10 和 KDD12上设定a=0.05,b=0.05，并且在Flight Delay 和 LETOR上设定a = 0.1; b = 0.1。我们对于EFB设定$\gamma = 0$。所有的算法都运行固定的线程数，并且我们从迭代过程中获取最好的分数的准确率结果。</p><p><img src="https://i.postimg.cc/VvSvv8P9/lgbm4.jpg" alt="training curves"></p><p>训练时间和测试准确率分别汇总在表2和表3中。从这些结果中，我们能够看到在于基准线保持几乎相同准确率的时候是最快速的。xgb_exa是基于预排序的算法，这相对于基于直方图的算法是非常慢的。相对于lgb_baseline，LightGBM在Allstate, Flight Delay, LETOR, KDD10 和 KDD12数据集上分别加速了21，6，1.6，14和13倍。因xgb_his非常消耗内存，导致其在KDD10 和 KDD12数据集上内存溢出而不能成功运行。在剩下的数据集上，LightGBM都是最快的，最高是在Allstate数据集上加速了9倍。由于所有的算法都在差不多的迭代次数后收敛了，所以加速是基于平均每次迭代时间计算得到的。为了展示整个训练过程，我们基于Flight Delay 和 LETOR的经过的时间也分别展示了训练曲线在图1和图2中。为了节省空间，我们将其他数据集的训练曲线放在了补充材料中。</p><p><img src="https://i.postimg.cc/PxVNdq9r/lgbm5.jpg" alt="Accuracy comparison"></p><p>在所有的数据集上，LightGBM都能够得到几乎和基准线一致的测试准确率。这表明GOSS和EFB都不会降低准确率并且能够带来显著地加速。这也与我们前面的理论分析保持一致。</p><p>LightGBM在不同的数据集上得到了不同的加速率。整体的加速结果是来自GOSS和EFB二者的联合，我们将下一部分分开讨论二者的贡献。</p><h3 id="5-2-GOSS的分析"><a href="#5-2-GOSS的分析" class="headerlink" title="5.2 GOSS的分析"></a>5.2 GOSS的分析</h3><p>首先，我们研究了GOSS的加速性能。从表2中LightGBM和EFB_only的对比来看，我们能够发现GOSS能够通过其自己在使用10%-20%的数据时候带来近2倍的加速。GOSS能够紧紧使用抽样数据进行学习树。然而，它依然保留了一些在全部数据集上的一些计算，例如预测和计算梯度。因此，我们能够发现整体的加速相对于抽样数据的百分比并不是线性的。然而，GOSS带来的加速又是非常显著地，并且这一技术可以普遍的应用在不同的数据集上。</p><p>第二，我们通过和SGB（随机梯度提升）对比评估了GOSS的准确率。为了没有泛化性的损失，我们使用LETOR数据集来进行测试。我们通过选择GOSS中不同的a和b值来设定抽样率，并且在SGB上使用同样的整体抽样率。我们使用这些设定运行并且使用early stopping直到其收敛。结果如表4所示。我们能够看到但我们使用相同的抽样率的时候GOSS的准确率总是比SGB要好。这一结果和我们3.2部分的讨论保持一致。所有的实验结果都表明了GOSS相比于随机抽样是一个更有效的抽样方法。</p><h3 id="5-3-EFB的分析"><a href="#5-3-EFB的分析" class="headerlink" title="5.3 EFB的分析"></a>5.3 EFB的分析</h3><p>我们通过对比lgb_baseline和EFB_only来检测了EFB在加速方面的贡献。结果如表2所示。这里我们没有允许捆绑发现流程中冲突的存在（即$\gamma = 0$）。我们发现EFB能够有助于在大规模数据集上获得显著性的加速。</p><p>请注意lgb_baseline已经在系数特征上进行了优化，且EFB依然能够在训练过程中进行加速。这是因为EFB将许多稀疏特征（one-hot编码的特征和一些潜在的互斥特征）合并成了很少的特征。基础的稀疏特征优化包含在了捆绑程序中。然而，EFB在树训练过程中为每个特征维持非零数据表上没有额外的成本。而且，由于许多预先独立出的特征捆绑到了一起，它能够增加本地空间并且能够显著地改善缓存冲击率。因此，在效率上的整体改进是显著地。基于上述分析，EFB是一个非常有效能够在基于直方图的算法中充分利用稀疏性的算法，并且它能够再GBDT训练过程中带来显著性加速。</p><h2 id="6-结论"><a href="#6-结论" class="headerlink" title="6 结论"></a>6 结论</h2><p>在这篇文章中，我们提出了全新的GBDT算法叫做LightGBM，它包含了连个新颖的技术：Gradient-based One-Side Sampling (GOSS) 和Exclusive Feature Bundling (EFB)（基于梯度的one-side采样和互斥的特征捆绑）分别来处理大数据量和高维特征的场景。我们在理论分析和实验研究表明，得益于GOSS和EFB，LightGBM在计算速度和内存消耗上明显优于XGBoost和SGB。未来工作中，我们将研究在GOSS中选择a，b值的优化方案，并且继续提高EFB在高维特征上的性能，无论其是否是稀疏的。</p><p><strong>参考文章</strong><br><a href="https://blog.csdn.net/anshuai_aw1/article/details/83048709" target="_blank" rel="noopener">Lightgbm源论文解析-anshuai_aw1</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener
      
    
    </summary>
    
    
      <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="LightGBM" scheme="https://www.xiemingzhao.com/tags/LightGBM/"/>
    
  </entry>
  
  <entry>
    <title>Github+Hexo+Next博客的编辑方法小记</title>
    <link href="https://www.xiemingzhao.com/posts/GithubHexoNexttips.html"/>
    <id>https://www.xiemingzhao.com/posts/GithubHexoNexttips.html</id>
    <published>2019-05-18T16:00:00.000Z</published>
    <updated>2019-10-13T14:13:11.159Z</updated>
    
    <content type="html"><![CDATA[<p>想要小白详细版本的Github+Hexo+Next搭建博客教程，可访问我的另一篇博客<a href="https://www.xiemingzhao.com/posts/GithubHexoNextblog">使用Github+Hexo+Next免费搭建自己的博客（最细攻略）</a>。</p><h2 id="博客撰写"><a href="#博客撰写" class="headerlink" title="博客撰写"></a>博客撰写</h2><h3 id="1-Markdown"><a href="#1-Markdown" class="headerlink" title="1. Markdown"></a>1. Markdown</h3><p>Hexo是基于标准的<code>Markdown</code>格式进行解析博客文章的，<code>markdown</code>应该不用多说了，如果你除了office全家桶外不知道全加的编辑器也没关系，学习起来很简单，网上教程比比皆是，看看语法就学会了。然后你就会爱上这类文档编辑器，什么word那些妖艳贱货都是不能比的，你会因此爱上写作。其语法简洁易学，可参考<a href="https://markdown-zh.readthedocs.io/en/latest/" target="_blank" rel="noopener">markdown官方中文文档</a>。</p><p>当然，它只是一个通用型很高的文档编辑器，而Hexo博客的头部包含一些并不是很通用的格式模块，例如<code>tile</code>,<code>tags</code>以及<code>date</code>等等，这一块在创建博客的文章用已经阐述过，或者去Hexo的官方文档<a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">https://hexo.io/zh-cn/</a>一探究竟。还有一个需要提的是，markdown本身的语法在标题上面用#来区分，无其他要求，但是hexo解析的时候要求标题类的#与文字之间要有一个空格，反正养成一个良好的习惯，<strong>格式符号与文字之间保留空格。</strong></p><a id="more"></a><h3 id="2-编辑器"><a href="#2-编辑器" class="headerlink" title="2. 编辑器"></a>2. 编辑器</h3><p>提到这里，<code>Markdown</code>本身只是一种编辑格式，那么真正的编辑器用什么呢，可能你已经有自己喜欢的编辑器了，这里推荐几款个人绝对很好用的编辑器仅供参考：</p><blockquote><p><a href="https://www.zybuluo.com/cmd/" target="_blank" rel="noopener">Cmd Markdown</a>，作业部落出品，本人使用最多的，强推<br><a href="http://markdownpad.com/" target="_blank" rel="noopener">MarkdownPad</a>，使用免费的版本 MarkdownPad2 足以<br><a href="http://soft.xiaoshujiang.com/" target="_blank" rel="noopener">小书匠</a>，也分为分为免费版和收费版，文件管理功能强<br><a href="http://marxi.co/" target="_blank" rel="noopener">Marxico</a>，中文名马克飞象，可以直接把文本存到印象笔记</p></blockquote><p><em>更多的可以参考<a href="https://blog.csdn.net/qq_36759224/article/details/82229243" target="_blank" rel="noopener">这里</a></em></p><h3 id="3-图床"><a href="#3-图床" class="headerlink" title="3. 图床"></a>3. 图床</h3><p>既然要写作，在这个信息爆炸的时代，大家都很赶时间，一篇只有文字的博客难免使人心生倦意，图文并茂的方式往往更好。那么博客附属图片常常食用的就是图床，而一般的网盘是不能够生成外链的，这里推荐几款好用的 <strong>免费</strong> 图床：</p><blockquote><p><a href="https://postimages.org" target="_blank" rel="noopener">postimg</a>，本人在用，国外的图床，但是速度也很快。永久存储免注册，图片链接支持https，可以删除上传的图片，提供多种图片链接格式。<br><a href="https://portal.qiniu.com" target="_blank" rel="noopener">七牛云</a>，中文名七牛云，注册认证后有10G永久免费空间，每月10G国内和10G国外流量，速度相当快，需要实名认证较为麻烦。<br><a href="http://jiantuku.com" target="_blank" rel="noopener">极简图床</a>，不太熟悉，据说是主要提供图片上传和管理界面，需要用户自己设置微博、七牛云或者阿里云OSS信息。</p></blockquote><h3 id="4-公式"><a href="#4-公式" class="headerlink" title="4. 公式"></a>4. 公式</h3><p>作为技术博客，就难免会使用公式，相信经历过word中的公式编辑mathtype的难友们一定难以忘怀其如恶魔般的体验。编辑一个公式，点来点去费时费力，修改和转移都复杂得多，关键是正版的还需要注册收费。而<code>markdown</code>大法就完美地解决了这一问题，其内部支持<code>Latex</code>公式编辑格式，行内编辑可用<script type="math/tex">latex公式</script>格式来操作，地理成行的则用双刀符号$$$latex公式$$$格式。举例：</p><ol><li>这里展示行内公式，开始$f(x) = \sum_{i=1}^m \frac{1}{x_i}$结束。结果就会如下：<br>这里展示行内公式，开始$f(x) = \sum_{i=1}^m \frac{1}{x_i}$结束。</li><li>这里展示行外独立公式，开始$$f(x) = \sum_{i=1}^m \frac{1}{x_i}$$结束。结果就会如下：<br>这里展示行内公式，开始<script type="math/tex">f(x) = \sum_{i=1}^m \frac{1}{x_i}</script>结束。<br><strong>双$符号就是行外公式，公式本身会独立成一行</strong></li></ol><p>Latex公式编辑语法也不难学，可参考其<a href="https://www.latex-project.org/" target="_blank" rel="noopener">Latex官方网站</a>的语法指南，分分钟让你爱上公式编辑，再也不会害怕编辑公式了。</p><p><strong>参考博文</strong><br><a href="https://blog.csdn.net/qq80583600/article/details/72828063" target="_blank" rel="noopener">可能是最详细的 Hexo + GitHub Pages 搭建博客的教程</a><br><a href="https://blog.csdn.net/qq_36759224/article/details/82229243" target="_blank" rel="noopener">最新主流 Markdown 编辑器推荐</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;想要小白详细版本的Github+Hexo+Next搭建博客教程，可访问我的另一篇博客&lt;a href=&quot;https://www.xiemingzhao.com/posts/GithubHexoNextblog&quot;&gt;使用Github+Hexo+Next免费搭建自己的博客（最细攻略）&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;博客撰写&quot;&gt;&lt;a href=&quot;#博客撰写&quot; class=&quot;headerlink&quot; title=&quot;博客撰写&quot;&gt;&lt;/a&gt;博客撰写&lt;/h2&gt;&lt;h3 id=&quot;1-Markdown&quot;&gt;&lt;a href=&quot;#1-Markdown&quot; class=&quot;headerlink&quot; title=&quot;1. Markdown&quot;&gt;&lt;/a&gt;1. Markdown&lt;/h3&gt;&lt;p&gt;Hexo是基于标准的&lt;code&gt;Markdown&lt;/code&gt;格式进行解析博客文章的，&lt;code&gt;markdown&lt;/code&gt;应该不用多说了，如果你除了office全家桶外不知道全加的编辑器也没关系，学习起来很简单，网上教程比比皆是，看看语法就学会了。然后你就会爱上这类文档编辑器，什么word那些妖艳贱货都是不能比的，你会因此爱上写作。其语法简洁易学，可参考&lt;a href=&quot;https://markdown-zh.readthedocs.io/en/latest/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;markdown官方中文文档&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;当然，它只是一个通用型很高的文档编辑器，而Hexo博客的头部包含一些并不是很通用的格式模块，例如&lt;code&gt;tile&lt;/code&gt;,&lt;code&gt;tags&lt;/code&gt;以及&lt;code&gt;date&lt;/code&gt;等等，这一块在创建博客的文章用已经阐述过，或者去Hexo的官方文档&lt;a href=&quot;https://hexo.io/zh-cn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://hexo.io/zh-cn/&lt;/a&gt;一探究竟。还有一个需要提的是，markdown本身的语法在标题上面用#来区分，无其他要求，但是hexo解析的时候要求标题类的#与文字之间要有一个空格，反正养成一个良好的习惯，&lt;strong&gt;格式符号与文字之间保留空格。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="博客搭建" scheme="https://www.xiemingzhao.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="Hexo" scheme="https://www.xiemingzhao.com/tags/Hexo/"/>
    
      <category term="markdown" scheme="https://www.xiemingzhao.com/tags/markdown/"/>
    
      <category term="mathjax" scheme="https://www.xiemingzhao.com/tags/mathjax/"/>
    
  </entry>
  
  <entry>
    <title>使用Github+Hexo+Next免费搭建自己的博客（最细攻略）</title>
    <link href="https://www.xiemingzhao.com/posts/GithubHexoNextblog.html"/>
    <id>https://www.xiemingzhao.com/posts/GithubHexoNextblog.html</id>
    <published>2019-05-08T16:00:00.000Z</published>
    <updated>2019-10-13T14:14:09.580Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、开篇"><a href="#一、开篇" class="headerlink" title="一、开篇"></a>一、开篇</h2><p>在这个信息爆发的时代，有着各种各样的社交平台和工具，而博客则是宣传和交流个人信息的一种重要方式。无论你是否从事IT行业，都可以通过博客来发布自己的一些学习所得、生活感悟或者喜怒哀乐。而目前主流的方式都是基于新浪微博、CSDN以及简书等，将人群割裂，且缺乏个性化和自主性。由其是对于大部分的互联网从业者，建立一个自己的博客网站是一件有意思的事情，当然偶尔也可以用来装个X。</p><p>刚刚转入互联网行业网的时候，一直就想拥有一个自己的博客，奈何一开始对这一类编程不是很熟悉，初次尝试失败后搁置了一些时间（现在才发现都是一些很简单的问题）。所以只要你想完成这个，抽点时间出来你肯定可以完成，又变成底子最好，没有也不要紧，照葫芦画瓢就行了。</p><p>话不多说先奉上本人的博客<a href="www.xiemingzhao.com">小火箭的博客</a>。本人技术有限，但是以实用为主，本篇博文能够带领想我这样的小白使用Github+Hexo+Next一步一步的完成博客搭建。虽然目前搭建博客的方式有很多，但我们选择是目前最主流且体验下来感觉最舒适的一种。</p><p><strong>本文基于Windows 10 x64 专业版搭建，其他环境方法基本通用</strong></p><a id="more"></a><h2 id="二、git和Node-js的安装和配置"><a href="#二、git和Node-js的安装和配置" class="headerlink" title="二、git和Node.js的安装和配置"></a>二、git和Node.js的安装和配置</h2><h3 id="1-git安装"><a href="#1-git安装" class="headerlink" title="1. git安装"></a>1. git安装</h3><p>这一步比较简单，进入<a href="https://git-scm.com/downloads" target="_blank" rel="noopener">git的官网下载页面</a>，找到对应于自己的系统环境的安装包点击下载。</p><p><img src="https://i.postimg.cc/Jzf6DRFZ/hexo1.jpg" alt="gitweb"></p><p>找到下载后的exe文件，点击就可以进入到安装页面了，如下图所示：</p><p><img src="https://i.postimg.cc/DZFx6Bnz/hexo2.jpg" alt="gitexe"></p><p>剩下基本上是傻瓜式点点点，直到碰到下面这一个图：</p><p><img src="https://i.postimg.cc/SRxDFRXF/hexo3.jpg" alt="gitinstall"></p><p>这一步是选择Git的操作路径环境，第一个就是只能在Git Bash中才能进行Git的操作，第二个则是将Git加入到系统环境中，这样你就可以在cmd中进行Git操作了。作为一个不断向大牛学习的小白，自然为了方便操作（毕竟cmd已经成了日常）会选择第二项。当然选择第一个也无碍，在需要git的地方右键调出<code>git bash</code>即可。</p><p><img src="https://i.postimg.cc/rw0ZwDfq/hexo4.jpg" alt="gitbash"></p><h3 id="2-Node-js安装"><a href="#2-Node-js安装" class="headerlink" title="2. Node.js安装"></a>2. Node.js安装</h3><p>接下来安装<code>Node.js</code>一样的，进入<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">Node.js的官网下载页面</a>，找到对应自己的系统环境安装包点击下载。</p><p><img src="https://i.postimg.cc/503nRL2S/hexo5.jpg" alt="nodeweb"></p><p>找到下载后的exe文件，点击就可以进入到安装页面了，如下图所示：</p><p><img src="https://i.postimg.cc/d0GWGzMX/hexo6.jpg" alt="nodeinstall"></p><p>后面全部点点点，一直到最后完成即可。到这里，两个最重要的工具已经安装完成，我们打开控制台命令行，按Ctrl+R调出运行，输入cmd后回车即可。<br><img src="https://i.postimg.cc/wTBbnfJy/hexo7.jpg" alt="cmd"></p><p>分别运行下列两行代码来检测上面两个工具安装是否正确：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git --version</span><br><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure></p><p>如果结果如下图一样显示各个工具的版本号，那么就说明安装完成。否则要回去检查哪一步安装错误。</p><p><img src="https://i.postimg.cc/tCmmb3tr/hexo8.jpg" alt="test"></p><h2 id="三、github账户的注册和配置"><a href="#三、github账户的注册和配置" class="headerlink" title="三、github账户的注册和配置"></a>三、github账户的注册和配置</h2><p>打开<a href="https://github.com/" target="_blank" rel="noopener">github官网:https://github.com/</a>，在如下图的注册页面中输入自己的注册信息，注意这里的用户名最好用一个标准化常用的，因为在后面创建代码库的时候需要保持统一。点击注册后，一定要去对应的邮箱中，将github官网发给你的确认邮件打开并确认注册才可以完成注册。</p><p><img src="https://i.postimg.cc/DfxxQrD2/hexo9.jpg" alt="githubweb"></p><p>我们知道<code>github</code>是一个全球性的开发者项目开源交流平台，接下来就可以创建自己的代码库了。登录自己的账号后，点击下图中的+号，选择<code>New repository</code>进入代码库创建页面。然后你只需要在<code>Repository name</code>框中填入你的代码库名称即可。</p><p><strong>（格式为yourname.github.io，yourname是你上述注册的时候的用户名，也即页面上的Owner）</strong>。例如，如果我的注册名是xiaoming，那么此处我就该填写<code>xiaoming.github.io</code>。后面的内容我们将以yourname来代替你的用户名，记得随时替换成自己的哦。</p><p><img src="https://i.postimg.cc/Ls0zYD57/hexo10.jpg" alt="githubcreate"></p><p>在你点击<code>Create repository</code>正确创建代码库之后，你将会看到如下的页面：</p><p><img src="https://i.postimg.cc/nc5TgHpg/hexo11.jpg" alt="giothub.io"></p><p>下面就需要打开<code>gh-pages</code>功能，这样才能进行后续的博客创建。我们点击页面功能区右侧的<code>Settings</code>选项，进入后下来找到<code>Github pages</code>模块，点击<code>Launch Automatic page generator</code>按钮，就会完成<code>gh-pages</code>页面的创建了。过几分钟后，尝试用浏览器访问一下<code>yourname.github.io</code>网址，如果可以正常打开页面，如下图所示（当然你的内容可能跟我不一样，因为这里已经是我添加了很多内容之后的了），那么Github部分的工作就完成了。</p><p><img src="https://i.postimg.cc/TwLnrbWP/hexo14.jpg" alt="ghpages"></p><h2 id="四、Hexo的安装和配置"><a href="#四、Hexo的安装和配置" class="headerlink" title="四、Hexo的安装和配置"></a>四、Hexo的安装和配置</h2><p>本篇博客讲的是用Github+Hexo+Next来搭建博客，那么Hexo必不可少。这里是Hexo的官方文档<a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">https://hexo.io/zh-cn/</a>，有兴趣的可详细阅读。</p><h3 id="1-Hexo的安装"><a href="#1-Hexo的安装" class="headerlink" title="1. Hexo的安装"></a>1. Hexo的安装</h3><p>首先在你的电脑本地选择一个盘，单独建立一个文件夹目录，方便用来管理后面的博客文件。假设你的目录是<code>E:/Blog</code>，那么这个时候将cmd的控制台操作目录cd到对应的目录下，可参考在控制台输入以下两行代码进行切换：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">E：</span><br><span class="line">cd Blog</span><br></pre></td></tr></table></figure></p><p>这时候控制台的操作目录就变成了你的博客管理目录了。接着在命令行中分别运行下面的代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br><span class="line">npm install hexo --save</span><br></pre></td></tr></table></figure></p><p><strong>在第一行代码运行后也许会报出一个WARN，不用去管。</strong></p><p>最后在控制台输入下面的code来测试Hexo是否正常安装完毕：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo -v</span><br></pre></td></tr></table></figure></p><p>如果显示出如下图的一系列工具版本号，那么就说明没什么问题了，Hexo安装到此结束。</p><p><img src="https://i.postimg.cc/5NjnsHd8/hexo13.jpg" alt="hexotest"></p><h3 id="2-Hexo的配置"><a href="#2-Hexo的配置" class="headerlink" title="2. Hexo的配置"></a>2. Hexo的配置</h3><p>接下来需要对Hexo进行初始化，建立一系列文件，在命令行中连续运行下面三行代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo init yourname.github.io</span><br><span class="line">cd yourname.github.io</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure></p><ul><li>第一行是新建初始化目录，这一步名字也可以改，但是为了容易区分以及后续的多端管理博客建议可以这么命名。</li><li>第二行则是将工作目录换到初始化的目录下。</li><li>第三行是初始化环境，安装所需要的一系列文件。</li></ul><p>运行完成后，对应目录下面应该多了很多文件，其中包含一下6个重要的文件或文件夹。</p><blockquote><p>node_modules<br>public<br>source<br>themes<br>_config.yml<br>package.json</p></blockquote><h3 id="3-Hexo初体验"><a href="#3-Hexo初体验" class="headerlink" title="3. Hexo初体验"></a>3. Hexo初体验</h3><p>到这一步Hexo基本上已经配置完成，可以进行初体验了。在控制台的命令行连续运行下列的代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure></p><p>运行结束你会得到一堆信息，其中包含一行关键信息如下：</p><blockquote><p>INFO Hexo is running at <a href="http://0.0.0.0:4000/" target="_blank" rel="noopener">http://0.0.0.0:4000/</a>. Press Ctrl+C to stop.</p></blockquote><p>这就表明你的博客网站已经在本地开启了服务，这时候你可以尝试用浏览器访问网址<a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a>，如果能够正常访问你将会看到如下的初始博客页面。怎么样，颈不惊喜，意不意外，到这里你就完成了本地的基本框架的搭建和配置。</p><p><img src="https://i.postimg.cc/0ywZqLNQ/hexo12.jpg" alt="localhost"></p><h2 id="五、关联Hexo和Github-Pages"><a href="#五、关联Hexo和Github-Pages" class="headerlink" title="五、关联Hexo和Github Pages"></a>五、关联Hexo和Github Pages</h2><p>利用Hexo来构建博客，必须要有对应的主机，并不是任何的电脑都能操作的。这时候就需要身份验证了，而这里使用的就是<code>SSH keys</code>。</p><h3 id="1-配置SSH-keys"><a href="#1-配置SSH-keys" class="headerlink" title="1. 配置SSH keys"></a>1. 配置SSH keys</h3><p>接上文，首先在命令行输入如下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;youremail&quot;</span><br></pre></td></tr></table></figure></p><p>将代码中的youremail换位你注册github时候的邮箱。回车运行后会出提示让你输入一个密码，这个密码就是用来在以后体检项目的时候使用的，一版可以不用设置，省的自己忘了，毕竟已经限制了电脑。我们直接按回车，连续回车后运行结束。</p><p>下面你就可以去你电脑的C盘找到<code>C:\Users\bxm09\.ssh\id_rsa.pub</code>文件，这个文件里的内容就是刚才生成的秘钥，打开这个文件并原样复制里面的所有内容。再打开github的SSH keys配置页面<a href="https://github.com/settings/ssh" target="_blank" rel="noopener">https://github.com/settings/ssh</a>，点击 <code>new SSH keys</code>后，<code>Title</code>可以填写这个<code>SSH keys</code>的名字，例如mySHHkeys，然后将之前复制的内容原模原样的粘贴到<code>Key</code>里面，最后点击<code>Add SSH key</code>完成配置。</p><h3 id="2-测试SSH-key"><a href="#2-测试SSH-key" class="headerlink" title="2. 测试SSH key"></a>2. 测试SSH key</h3><p>可以在命令行输入下列代码进行测试，<strong>注意直接原样运行，git@github.com也不用更改</strong>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure></p><p>你将会得到如下的信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">The authenticity of host ‘github.com (207.97.227.239)’ can’t be established. </span><br><span class="line">RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48. </span><br><span class="line">Are you sure you want to continue connecting (yes/no)?</span><br></pre></td></tr></table></figure></p><p>这时候直接输入<code>yes</code>就好了，你将会得到如下的信息，就说明配置成功：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hi yourname! You&apos;ve successfully authenticated, but GitHub does not provide shell access.</span><br></pre></td></tr></table></figure></p><h3 id="3-配置个人信息"><a href="#3-配置个人信息" class="headerlink" title="3. 配置个人信息"></a>3. 配置个人信息</h3><p>目前你的电脑可以连接到Github并进行操作了。Git会根据用户名和邮箱来记录你的每一次操作，所以需要对这些信息进行配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;yourname&quot;</span><br><span class="line">git config --global user.email &quot;youremail&quot;</span><br></pre></td></tr></table></figure></p><p><strong>记得将上述的<code>yourname</code>和<code>youremail</code>换位自己的用户名和邮箱哦</strong></p><h3 id="4-配置Deployment"><a href="#4-配置Deployment" class="headerlink" title="4. 配置Deployment"></a>4. 配置Deployment</h3><p>上文中提到的6个主要文件，我们打开其中的<code>_config.yml</code>，找到<code>Deployment</code>配置的地方，按照如下的内容进行修改，改成你自己的信息，主要是<code>yourname</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Deployment## 标题 ##</span><br><span class="line">## Docs: https://hexo.io/docs/deployment.html</span><br><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: git@github.com:yourname/yourname.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure></p><h3 id="5-发文初体验"><a href="#5-发文初体验" class="headerlink" title="5. 发文初体验"></a>5. 发文初体验</h3><p>新建一篇博客，可运行下列的代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#paper-title是你的文章的标题</span><br><span class="line">hexo new &apos;paper-title&apos;</span><br></pre></td></tr></table></figure></p><p>而后你就可以在你电脑的博客目录下的<code>/source/_posts/</code>文件夹中将看到刚才新建的<code>paper-title.md</code>文件。使用<code>markdown</code>编辑器编辑完成博客后就可以进行发布了。</p><p>使用Hexo发布文章提交到Github Pages的三条经典命令是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 删除旧的 public 文件</span><br><span class="line">hexo clean</span><br><span class="line"></span><br><span class="line"># 生成新的 public 文件</span><br><span class="line">hexo generate</span><br><span class="line"></span><br><span class="line"># 开始部署</span><br><span class="line">hexo deploye</span><br></pre></td></tr></table></figure></p><p>或者可以简写成如下也是等价的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 删除旧的 public 文件</span><br><span class="line">hexo clean</span><br><span class="line"></span><br><span class="line"># 生成新的 public 文件</span><br><span class="line">hexo g</span><br><span class="line"></span><br><span class="line"># 开始部署</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure></p><p>再或者可以将最后两条命令合并为一条：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 删除旧的 public 文件</span><br><span class="line">hexo clean</span><br><span class="line"></span><br><span class="line"># 在部署前先生成</span><br><span class="line">hexo d -g</span><br></pre></td></tr></table></figure></p><p>到这里你就完成了发布新博客文章的初体验，你可以访问你的博客地址<code>https://yourName.github.io</code>，将会展示你刚刚创建的文章。</p><p><strong>两个坑</strong></p><p>a. 如果在执行部署的命令时报错：</p><blockquote><p>deloyer not found:git</p></blockquote><p>这时候需要提前安装一个扩展工具：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure></p><p>b. 如果出现了如下的报错信息：</p><blockquote><p>Permission denied (publickey).<br>fatal: Could not read from remote repository.<br>Please make sure you have the correct access rights<br>and the repository exists.</p></blockquote><p>这表明之前的<code>SSH key</code>没有配置好，重回到前面检查哪里不对，修复后再执行。</p><h2 id="六、主题配置"><a href="#六、主题配置" class="headerlink" title="六、主题配置"></a>六、主题配置</h2><p>Hexo可配置的主题特别多，本文选择了一个较为目前主流和简介的主题Next，本人的博客也是基于此主题构建的。该主题的作者也提供了详细的文档，感兴趣的可以多参考<a href="http://theme-next.iissnan.com/getting-started.html" target="_blank" rel="noopener">Next官方文档</a>。</p><h3 id="1-安装Next"><a href="#1-安装Next" class="headerlink" title="1. 安装Next"></a>1. 安装Next</h3><p>Hexo安装主题比较简单，直接将主题温江拷贝到站点目录下的themes文件夹后，再进入站点配置文件中进行相应主题配置修改即可。这里以Next为例，我们依然将命令行路径切到你电脑的博客目录下，然后执行下列命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure></p><p>运行完成后进入对应的themes目录中即可发现next主题文件夹。这里介绍两个配置文件，分别是<strong>站点配置文件</strong>和<strong>主题配置文件</strong>，他们的名称都是<code>_config.yml</code>，但是内容和路径都不一样，前者是在博客站点根目录下面，后者是在<code>themes/next/</code>子目录的主题文件夹中。例如，我的两个配置文件目录分别是<code>E:/Bolg/myname.github.io/_config.yml</code>和<code>E:/Bolg/myname.github.io/themes/next/_config.yml</code>。前者是对Hexo本身的属性进行配置，后者则是对主题相关属性的配置。</p><h3 id="2-启动主题"><a href="#2-启动主题" class="headerlink" title="2. 启动主题"></a>2. 启动主题</h3><p>Hexo启动任何主题的方法都一样，在完成克隆下载后，打开站点配置文件，找到themes配置字段，设置为对应的主题就可以了，例如这里配置如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Extensions</span><br><span class="line">## Plugins: https://hexo.io/plugins/</span><br><span class="line">## Themes: https://hexo.io/themes/</span><br><span class="line">theme: next</span><br></pre></td></tr></table></figure></p><p>这时候就可以使用hexo发布提交的三条经典命令来测试效果了：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure></p><blockquote><p>这里提一个小技巧，因为在博客配置完善过程中，经常需要进行效果测试，每次都这么运行挺麻烦，一般都不使用<code>hexo d</code>而是使用<code>hexo s</code>在本地进行测试就行了，但是想要在<code>https://yourName.github.io</code>线上看到必须使用<code>hexo d</code>来发布啦。而且前两条命令也不是每次都用，不牵扯新文件生成的时候就可以不用<code>hexo g</code>，不需要清理public文件的时候就不要<code>hexo clean</code>，当然如果搞不清楚就都运行吧。</p></blockquote><p>在使用<code>hexo s</code>后，与前文一致，打开本地的访问连接<a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a>就可以看到修改后效果了。到这里基本上完成了Github+Hexo+Next的博客基础框架的搭建。</p><h3 id="3-设置scheme"><a href="#3-设置scheme" class="headerlink" title="3. 设置scheme"></a>3. 设置scheme</h3><p>Next主题也有多种scheme，不同的scheme会呈现出不同的外观，并且主题其他的配置都可以使用不同的scheme。目前Next主要支持三种scheme:</p><blockquote><p>Muse - 默认 Scheme，横栏<br>Mist - 单栏外观<br>Pisces - 双栏设置</p></blockquote><p> 在主题配置文件中搜索scheme，能够找到对应的配置位置，想要启动哪一个，就将其他的注释掉即可。例如博主使用的是Pisces风格，则设置如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#scheme: Muse</span><br><span class="line">#scheme: Mist</span><br><span class="line">scheme: Pisces</span><br></pre></td></tr></table></figure></p><p>同样的，在这里也可以使用三个三个景点的发布语句，来测试不同scheme的效果，选择一个你最中意的即可。 </p><h3 id="4-设置站点"><a href="#4-设置站点" class="headerlink" title="4. 设置站点"></a>4. 设置站点</h3><p>打开站点配置文件，在前面你就可以发现如下的<code>site</code>配置区域：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Site</span><br><span class="line">title: 我的博客</span><br><span class="line">subtitle: 愿世界和平！！！</span><br><span class="line">description: 小白的进阶</span><br><span class="line">author: 小火箭</span><br><span class="line">language: zh-Hans</span><br><span class="line">timezone:</span><br></pre></td></tr></table></figure><p>上面是我配置好的示例，每一项的配置内容都一目了然，对应的含义如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Site</span><br><span class="line">title: 你博客的大标题</span><br><span class="line">subtitle: 你博客的副标题</span><br><span class="line">description: 个人的描述</span><br><span class="line">author: 作者名称</span><br><span class="line">language: 语言类型</span><br><span class="line">timezone: 时区</span><br></pre></td></tr></table></figure></p><p>其他的没什么好说的，这里提一下language的配置。目前可用的语种有很多，这个示例中的<code>zh-Hans</code>是中文，详细可参考前面的Hexo官方文档。设置好站点的语言后，对应的一些关键词翻译可在主题文件中配置，打开<code>/themes/next/languages/</code>路径下的文件夹，可以找到对应的语言配置文件，例如中文的就是<code>zh-Hans.yml</code>。</p><p>到这里你可以仔细的看一下站点配置文件，内容并不多，而且大部分你都不用修改，例如<code>URL</code>模块是配置站点的链接地址生成格式的，<code>Directory</code>模块是配置站点的目录的，等等。</p><h3 id="5-设置菜单"><a href="#5-设置菜单" class="headerlink" title="5. 设置菜单"></a>5. 设置菜单</h3><p>设置菜单的时候，主要有三项：</p><blockquote><ol><li>菜单项的名称和连接配置</li><li>对应主题语言的显示文本</li><li>菜单项对应的图标</li></ol></blockquote><p>对于第一项，我们打开主题配置文件，找到<code>menu</code>的配置部分，如下所示，将你需要的模块取消注释，不需要的模块继续注释掉即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">menu:</span><br><span class="line">  home: / || home</span><br><span class="line">  about: /about/ || user</span><br><span class="line">  tags: /tags/ || tags</span><br><span class="line">  categories: /categories/ || th</span><br><span class="line">  archives: /archives/ || archive</span><br><span class="line">  commonweal: /404/ || heartbeat</span><br><span class="line">  others: /others/ || folder</span><br></pre></td></tr></table></figure></p><p>上面是一个配置的示例，其中格式是item : link || icon，分别是菜单名称，连接以及图标。其中名称是不直接显示的，而是通过这个在语言配置中找到对应的翻译来显示。例如，你打开上述提到的主题配置文件中的语言配置文件，我这里的就是<code>zh-Hans.yml</code>，就可以找到对应主题各个部分的翻译，其中menu如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">menu:</span><br><span class="line">  home: 首页</span><br><span class="line">  archives: 归档</span><br><span class="line">  categories: 分类</span><br><span class="line">  tags: 标签</span><br><span class="line">  about: 关于</span><br><span class="line">  commonweal: 公益404</span><br><span class="line">  others: 其他</span><br></pre></td></tr></table></figure></p><p>Next图标使用的是<code>Font Awesome</code>图标，其提供了上千种图标，基本上能够满足日常需求，详细图标可参考<a href="https://fontawesome.com/icons" target="_blank" rel="noopener">Font Awesome官网</a>。</p><p>上面的<code>others: /others/ || folder</code>是给的新增的示例，默认配置是没有的，可参考配置你想要的菜单模块，在主题配置中新增后，也需要在对应的语言文件中配置相关翻译。</p><p>这里需要提一下的时候，<code>menu</code>的配置还有另一种方式，你可以看到如下的<code>menu_icons</code>配置模块，是用来配置菜单图标的，如果你是如上述配置，图标已经在<code>menu</code>中通过<code>||</code>配置完成，这里只需要将enable设为true即可。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">menu_icons:</span><br><span class="line">  enable: true</span><br></pre></td></tr></table></figure></p><p>或者你可以如下配置也是与上述等价的，只是将图标和内容分开配置了而已：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">menu:</span><br><span class="line">  home: /</span><br><span class="line">  about: /about</span><br><span class="line">  tags: /tags</span><br><span class="line">  categories: /categories</span><br><span class="line">  archives: /archives</span><br><span class="line">  commonweal: /404</span><br><span class="line">  others: /others</span><br><span class="line">  </span><br><span class="line">menu_icons:</span><br><span class="line">  enable: true</span><br><span class="line">  # Icon Mapping.</span><br><span class="line">  home: home</span><br><span class="line">  about: user</span><br><span class="line">  categories: th</span><br><span class="line">  tags: tags</span><br><span class="line">  archives: archive</span><br><span class="line">  commonweal: heartbeat</span><br><span class="line">  others: folder</span><br></pre></td></tr></table></figure></p><p><strong>切记配置的时候英文大小写要注意，非特殊说明一般都默认是小写</strong></p><h3 id="6-创建分类和标签等页面"><a href="#6-创建分类和标签等页面" class="headerlink" title="6. 创建分类和标签等页面"></a>6. 创建分类和标签等页面</h3><p>虽然在上面我们配置了菜单中的categories和tags等等模块，但是对应的页面还是需要从新创建。方法比较简单，可以接着在上面的命令行中运行下面命令，也可以在本地的博客管理根目录中邮件选择<code>git bash here</code>调出git bash在其中运行下面的代码也是一样的效果，这就是之前我们安装的时候选择第二项的好处：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo new page categories</span><br><span class="line">hexo new page tags</span><br></pre></td></tr></table></figure></p><p>这时候会返回两条对应创建页面成功的信息，主要是<code>/source/categories/index.md</code>和<code>/source/tags/index.md</code>的文件路径。找到对应的文件路径，打开后，默认内容应该只有tile和date两个字段的配置，分别按照页面类型进行如下配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: 文章分类</span><br><span class="line">date: 2017-05-27 13:47:40</span><br><span class="line">type: &quot;categories&quot;</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">title: 文章标签</span><br><span class="line">date: 2017-05-27 13:47:40</span><br><span class="line">type: &quot;tags&quot;</span><br><span class="line">---</span><br></pre></td></tr></table></figure></p><p>配置完成保存关闭即可。这时候在写文章的时候就可以加进去分类和标签了，并且发布后会再分类和标签页面进行展示，例如本篇博文的配置如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: 使用Github+Hexo+Next免费搭建自己的博客（最细攻略）</span><br><span class="line">date: 2019-05-09</span><br><span class="line">categories:</span><br><span class="line">- 博客搭建</span><br><span class="line">tags:</span><br><span class="line">- Hexo</span><br><span class="line">- Next</span><br><span class="line">---</span><br></pre></td></tr></table></figure></p><p><strong>小技巧</strong>,如果每次写文章都需要手动增加tags和categories两个单词很麻烦，我们打开<code>scaffolds/post.md</code>文件，在里面新增<code>tages:</code>和<code>categories:</code>两行就行了，这样每次执行<code>hexo new &#39;paper&#39;</code>的后，文件里面就会自动包含这两个配置了。scaffolds目录下，是新建页面的模板，执行新建命令时，是根据这里的模板页来完成的，所以可以在这里根据你自己的需求添加一些默认值。好了，到这里你就学会和新增模块和对应的页面了。</p><h3 id="7-写作小配置"><a href="#7-写作小配置" class="headerlink" title="7. 写作小配置"></a>7. 写作小配置</h3><p>在hexo上发文章的是，一篇博文的大部分配置都在头部的配置区域中进行。上面提到了tile、date、tags等配置，以后会有更多的配置。</p><p><strong>多个标签</strong><br>一篇文章的分类和标签往往会有多个，多个标签怎么配置呢，如下所示两种方法等价：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tags: [a, b, c]</span><br><span class="line">#或</span><br><span class="line">tags:</span><br><span class="line">  - a</span><br><span class="line">  - b</span><br><span class="line">  - c</span><br></pre></td></tr></table></figure></p><p>分类的配置也是如此，但是不一样的是，多个tags的配置是评级的，多个categories的配置则是分级的，你可以亲自测试一下就了解了。</p><p><strong>阅读全文</strong><br>经常为了在首页更美观的展示博文的时候，我们对于每篇博文只会展示一部分信息，隐藏后面的，读者有兴趣了可以点击<code>阅读全文</code>再展开阅读。这个功能的实现也很方便，你只需要在想要折叠的部位插入一行<code>&lt;!-- more --&gt;</code>即可。</p><h3 id="8-侧栏"><a href="#8-侧栏" class="headerlink" title="8. 侧栏"></a>8. 侧栏</h3><p>侧栏默认是在有目录列表的情况下才会显示，如果你如上述配置，这时候使用那三条测试命令一定能够访问到你的页面，并且展示出侧栏的。侧栏的配置主要有两个属性，如下所示，找到<code>sidebar</code>模块就是配置侧栏的位置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sidebar:</span><br><span class="line">  # Sidebar Position, available value: left | right (only for Pisces | Gemini).</span><br><span class="line">  position: left</span><br><span class="line">  #position: right</span><br><span class="line"></span><br><span class="line">  # Sidebar Display, available value (only for Muse | Mist):</span><br><span class="line">  #  - post    expand on posts automatically. Default.</span><br><span class="line">  #  - always  expand for all pages automatically</span><br><span class="line">  #  - hide    expand only when click on the sidebar toggle icon.</span><br><span class="line">  #  - remove  Totally remove sidebar including sidebar toggle.</span><br><span class="line">  display: post</span><br><span class="line">  #display: always</span><br><span class="line">  #display: hide</span><br><span class="line">  #display: remove</span><br></pre></td></tr></table></figure></p><p>其中配置内容和注释都特别详细，一个属性是<code>position</code>，侧栏的位置，两个选择放左边还是右边，按照你的个人喜好来选择即可。另一个属性则是<code>display</code>，侧栏的展示模式，有四种配置，翻译一下就是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">post - 默认，在文章页面（拥有目录列表）时显示</span><br><span class="line">always - 总是显示</span><br><span class="line">hide - 总是隐藏（可以手动展开）</span><br><span class="line">remove - 移除</span><br></pre></td></tr></table></figure></p><h3 id="9-设置头像"><a href="#9-设置头像" class="headerlink" title="9. 设置头像"></a>9. 设置头像</h3><p>在这个时代，一个博客怎么能没有彰显自己个性的头像呢。Next主题设置头像也是很简单的，依然在主题配置文件里面，搜索<code>avatar</code>字段，找到头像配置模块，如果搜索不到，可能是版本太老，可以自己新添加。如下配置示例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Sidebar Avatar</span><br><span class="line"># in theme directory(source/images): /images/avatar.gif</span><br><span class="line"># in site  directory(source/uploads): /uploads/avatar.gif</span><br><span class="line">avatar: https://example.com/youravatar.jpg</span><br></pre></td></tr></table></figure></p><p>上述的<code>https://example.com/youravatar.jpg</code>就是对应头像的连接，换成你自己的就可以了。这里有两个方式，一个是如此例一样，已连接形式配置，如果是本地图片可上传到第三方图床上生成连接。另一种方法就是存在站点内地址，将头像放置主题目录下的 <code>source/uploads/</code> （新建uploads目录若不存在） 配置为：<code>avatar: /uploads/avatar.png</code> 或者 放置在 <code>source/images/</code> 目录下 , 配置为：<code>avatar: /images/avatar.png</code>。</p><h3 id="10-添加插件"><a href="#10-添加插件" class="headerlink" title="10. 添加插件"></a>10. 添加插件</h3><p>这里添加的插件是指sitemap和feed插件，具体有何用，大概就是可以生成博客的RSS，在连入互联网被一些搜索网站收录后，能够快速的建立站点底图，将你的页面展示在搜索结果中。</p><p>话不多说，我们开始，这里需要将控制台切到你博客的根目录下面，执行下面两条命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-feed -save</span><br><span class="line">npm install hexo-generator-sitemap -save</span><br></pre></td></tr></table></figure></p><p>在这之后需要打开站点配置文件<code>_config.yml</code>，新增以下内容，当然提前先搜索以下有没有这个模块，如果有的话就直接修改就好了，目前的版本是没有的，然后随便找个空白地方粘贴进去即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># Extensions</span><br><span class="line">Plugins:</span><br><span class="line">- hexo-generator-feed</span><br><span class="line">- hexo-generator-sitemap</span><br><span class="line">#Feed Atom</span><br><span class="line">feed:</span><br><span class="line">  type: atom</span><br><span class="line">  path: atom.xml</span><br><span class="line">  limit: 20</span><br><span class="line">#sitemap</span><br><span class="line">sitemap:</span><br><span class="line">  path: sitemap.xml</span><br></pre></td></tr></table></figure></p><p>最后执行三条境地啊匿名了来发布测试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure></p><p>都完成之后，你就会在自己的github主目录下<a href="https://gdutxiaoxu.github.io" target="_blank" rel="noopener">https://gdutxiaoxu.github.io</a>找到两个新增的文件，<code>atom.xml</code>和<code>sitemap.xml</code>，并且博客侧栏头像下面应该会多出一个<code>RSS</code>模块。</p><h3 id="附加：-404页面"><a href="#附加：-404页面" class="headerlink" title="附加： 404页面"></a>附加： 404页面</h3><p>每个网站都应该有自己的404页面，404大家都不陌生也就是Not Found的意思。为自己的博客添加404页面也是比较简单的。直接在博客的文件主目录（一般就是根目录的source文件夹<code>/source/</code>）下面新增一个<code>404.html</code>文件，然后在里面构建自己的页面内容即可。<br><strong>需要注意的是404页面仅仅对绑定顶级域名的项目才起作用，像github这种默认分配的二级域名是不起作用的，及时你用<code>hexo s</code>在本地测试也不行</strong></p><p>大部分博主都喜欢使用<a href="https://www.qq.com/404/" target="_blank" rel="noopener">腾讯公益404</a>的页面作为自己的404页面，这也不为一个不错的idea，这里我们也以此为例吧，可以在<code>404.html</code>文件中新增：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;script type=&quot;text/javascript&quot;</span><br><span class="line">        src=&quot;//qzonestyle.gtimg.cn/qzone/hybrid/app/404/search_children.js&quot;</span><br><span class="line">        charset=&quot;utf-8&quot;</span><br><span class="line">        homePageUrl=&quot;http://www.lovebxm.com/&quot;</span><br><span class="line">        homePageName=&quot;回到我的主页&quot;&gt;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure></p><h3 id="END"><a href="#END" class="headerlink" title="END"></a>END</h3><p>其实建站的方案有很多，例如：</p><blockquote><p><a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">Hexo + GitHub Pages </a><br><a href="https://www.jekyll.com.cn/" target="_blank" rel="noopener">Jekyll + GitHub Pages </a><br><a href="https://cn.wordpress.org/" target="_blank" rel="noopener">WordPress + 服务器 + 域名</a><br><a href="http://www.dedecms.com/" target="_blank" rel="noopener">DeDeCMS + 服务器 + 域名 </a><br>…</p></blockquote><p>但是个人最喜欢Hexo + GitHub方案，一来是免费，二来是能够和自己的代码库一起管理。但是其也有自己的缺点，那就是不支持数据库管理，所以你只能做静态页面的博客，不能像其他博客（如 WordPress）那样通过数据库管理自己的博客内容。 但是GitHub Pages 无需购置服务器，免服务器费的同时还能做负载均衡，github pages有300M免费空间。静态的博客更有利于搜索引擎蜘蛛爬取，轻量化的感觉真的很好。 </p><p><strong>参考博文</strong><br><a href="https://blog.csdn.net/gdutxiaoxu/article/details/53576018" target="_blank" rel="noopener">手把手教你用Hexo+Github 搭建属于自己的博客-gdutxiaoxu</a><br><a href="https://blog.csdn.net/qq80583600/article/details/72828063" target="_blank" rel="noopener">可能是最详细的 Hexo + GitHub Pages 搭建博客的教程-QQ80583600</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、开篇&quot;&gt;&lt;a href=&quot;#一、开篇&quot; class=&quot;headerlink&quot; title=&quot;一、开篇&quot;&gt;&lt;/a&gt;一、开篇&lt;/h2&gt;&lt;p&gt;在这个信息爆发的时代，有着各种各样的社交平台和工具，而博客则是宣传和交流个人信息的一种重要方式。无论你是否从事IT行业，都可以通过博客来发布自己的一些学习所得、生活感悟或者喜怒哀乐。而目前主流的方式都是基于新浪微博、CSDN以及简书等，将人群割裂，且缺乏个性化和自主性。由其是对于大部分的互联网从业者，建立一个自己的博客网站是一件有意思的事情，当然偶尔也可以用来装个X。&lt;/p&gt;
&lt;p&gt;刚刚转入互联网行业网的时候，一直就想拥有一个自己的博客，奈何一开始对这一类编程不是很熟悉，初次尝试失败后搁置了一些时间（现在才发现都是一些很简单的问题）。所以只要你想完成这个，抽点时间出来你肯定可以完成，又变成底子最好，没有也不要紧，照葫芦画瓢就行了。&lt;/p&gt;
&lt;p&gt;话不多说先奉上本人的博客&lt;a href=&quot;www.xiemingzhao.com&quot;&gt;小火箭的博客&lt;/a&gt;。本人技术有限，但是以实用为主，本篇博文能够带领想我这样的小白使用Github+Hexo+Next一步一步的完成博客搭建。虽然目前搭建博客的方式有很多，但我们选择是目前最主流且体验下来感觉最舒适的一种。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本文基于Windows 10 x64 专业版搭建，其他环境方法基本通用&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="博客搭建" scheme="https://www.xiemingzhao.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="Hexo" scheme="https://www.xiemingzhao.com/tags/Hexo/"/>
    
      <category term="Next" scheme="https://www.xiemingzhao.com/tags/Next/"/>
    
  </entry>
  
  <entry>
    <title>Slope One Predictors for Online Rating-Based Collaborative Filtering(论文解析)</title>
    <link href="https://www.xiemingzhao.com/posts/c800c340.html"/>
    <id>https://www.xiemingzhao.com/posts/c800c340.html</id>
    <published>2019-04-18T16:00:00.000Z</published>
    <updated>2019-09-21T06:27:40.078Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://epubs.siam.org/doi/pdf/10.1137/1.9781611972757.43" target="_blank" rel="noopener">原始论文：Slope One Predictors for Online Rating-Based Collaborative Filtering</a></p><h2 id="Slope-One-基于在线评分的协同过滤算法"><a href="#Slope-One-基于在线评分的协同过滤算法" class="headerlink" title="Slope One: 基于在线评分的协同过滤算法"></a>Slope One: 基于在线评分的协同过滤算法</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>基于评级的协同过滤是预测的程序，即根据用户对其他物品的评分来预测用户会如何评分当前给定的物品。我们提出了三个形式为f（x）= x + b的关于slop one机制的预测模型，预先计算出用户共同评分过的一个物品和另一个物品的评分之间的平均差异。slop one算法是易于实现的，查询效率高，相当准确，同时它们支持在线查询和动态更新，这使它们成为现实系统的良好候选者。建议将基本的SLOPE ONE方案作为协同过滤方案的新参考。通过考虑将用户喜欢和不喜欢的物品从全集中分出来，我们通过较慢的基于记忆的方式实现了结果超过基准EveryMovie和Movielens数据集，同时更好地满足了它对协同过滤应用的需求。</p><p>关键词：协同过滤，推荐工具，电子商务，数据挖掘，知识发现</p><a id="more"></a><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a><strong>1 介绍</strong></h3><p>基于在线评级的协同过滤CF查询由来自单个用户的（物品，评分）对的数组组成。对该查询的响应是一个由用户还没有评分的物品集合构成的预测数组对（物品，评分）。我们旨在提供强大的CF机制，包括：</p><ol><li>易于实现和维持：所有的或者那个数据应该可以有跑一版的工程师很轻松地解读，并且算法应该很容易地被实现和测试；</li><li>即时可更新：新评分的添加应该可以立即改变所有预测;</li><li>查询时效性：查询应该很快，可能以储存为代价;</li><li>对第一个访客的期望很少：很少评分的用户应该也能收到有效的推荐;</li><li>准确无误：算法机制应争先用最准确的方案，除非准确性收益微薄的话，并不总是值得在简单性或可扩展性方面做出重大牺牲。</li></ol><p>我们在本文中的目标不是比较准确性各种CF算法，而是演示Slope One计划同时满足所有五个目标。尽管我们的计划很简单，它们具有可更新性，计算高效性和可扩展性，它们的准确性与放弃某些其他优点的方案相当。</p><p>我们的Slope One算法通过用户的项目之间的“流行度差异”以直观的原理起作用。以成对的方式，我们确定一个物品比另一个更好多少。衡量这种差异的一种方法只是简单地这两个项目的平均评分相减。反过来，给定用户对一个物品的评分后，这种差异可以用来预测另一个用户对其中一个物品的评分。考虑两个用户A和B，两个物品I和J以及图1。用户A给予物品I评分为1，而用户B给予它一个评分为2，而用户A给予物品J评级为1.5。我们观察物品J的评分大于物品I的1.5-1 = 0.5分，因此我们可以预测用户B将给出物品J的评分为：2 + 0.5 = 2.5。我们将用户B称为预测用户和项目J是预测项目。许多这样的差异存在于每个未知评分的训练集，我们取这些差异的平均值。slop one机制在这里呈现了我们选择三种相关的差异方式达到单一预测。</p><p>本文的主要贡献是提出slop one协同过滤预测算法并证明它们具有竞争力，和基于记忆的方案具有几乎相同的准确度，同时更适合CF任务。</p><h3 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a><strong>2 相关工作</strong></h3><p><strong>2.1 基于记忆和基于模型的机制</strong><br>基于记忆的协同过滤算法使用用户间的相似度来进行预测，最经典的就是通过加权平均。<br>所选择的相似性度量决定了预测准确性，并且已经研究了众多替代方案。基于存储器的CF的一些潜在缺点包括可扩展性和对数据稀疏性的敏感性。一般来说，依赖于跨用户相似性的方案在快速在线查询的时候进行预先是不可能的。另一个关键问题是基于记忆的方案必须计算用户之间的相似性，并且衡量标准通常需要一些最小用户数（比如说，至少有100个用户）输入了一些最小个数的评分（比如说至少是20个评分）包括当前用户。我们会将我们的算法和着名的基于内存的方案进行对比，皮尔逊算法。</p><p>CF有许多基于模型的方法。一些基于线性代数（SVD，PCA或Eigenvectors）;或者直接借用来自人工智能的技术，如贝叶斯方法，隐含分类，和神经网络，或聚类。与基于内存的方案相比，基于模型CF算法通常在查询时更快但是可能有昂贵的学习或更新阶段。基于模型方案可以优于基于存储器的方案，当查询速度至关重要时。</p><p>我们会将我们的预测算法与在下面的代数文献中描述的某些类型的预测方法进行比较。因此，我们的预测模型的形式为$f(x)= x + b$，因此名称定为“slope one”，其中b是常数，x是变量代表评分值。对于任何一对物品，我们试图找到从其他物品的评分来预测此物品评分的最佳函数f。这个函数可能对于每个物品对都不一样。 CF机制将加权预测模型产生的诸多预测。在[14]中，作者考虑了成对项目之间的相关性然后导出用户评分的加权平均值作为预测。在他们算法的简单版本中，他们的预测模型形式为$f(x)=x$。在他们的以回归为基础的算法版本中，他们的预测模型形式是$f(x)= ax + b$。在[17]中，作者也采用了预测因子形式$f(x)= ax + b$。基于这两篇论文一个自然延伸的研究，将会考虑这样的预测模型的形式：$f(x)=ax^2 + bx +c$。相反，在这篇文章，我们使用简单的预测模型形式$f(x)= ax + b$。我们也是用最普通的加权方法。可在[14]看到的是，甚至他们的基于回归方程$f(x)= ax + b$的算法依然不能够获得相对于基于记忆算法较大的改进。因此可以得到一个重要的结论就是基于$f(x)= ax + b$形式的预测模型可以与基于记忆的算法机制进行竞争。</p><h3 id="3-CF-算法"><a href="#3-CF-算法" class="headerlink" title="3 CF 算法"></a><strong>3 CF 算法</strong></h3><p>我们提出了三种新的CF方案，并将我们剔除的机制和之前提到的四中算法进行对比：PER USER AVERAGE, BIAS FROM MEAN, ADJUSTED COSINE ITEMBASED,这是一个基于模型的方案，以及PEARSON机制是代表基于记忆的方案。</p><p><strong>3.1 符号</strong><br>我们在算法描述中使用以下符号。来自给定用户的评分，称为<em>评估</em>，表示为一个不完整的数组u，其中$u_i$是该用户给出了物品i的评分。又被用户u评分过的所有物品组成的子集表示成S(u)。训练集中所有评估的集合表示成$\chi$。集合S中的元素个数是card(S)。用户u所有评分的平均评分为$\bar u$。集合$S_i(\chi)$是所有评估$u \in \chi$中包含物品$i(i \in S(u))$组成的集合。给定两个评估u，v，我们定义标量积$(u,v) = \sum_{i \in S(u) \cap S(v)} u_i v_i$。预测，我们写成P(u)，表示每个分量都是对应一个物品预测结果的向量：预测隐含地依赖于训练集$\chi$。</p><p><strong>3.2 基准方案</strong><br>一个最基础的预测算法就是PER USER AVERAGE方案，给定的等式是$P(u)=\bar u$。也就是说，我们预测用户将根据该用户的平均评分对所有内容进行评级。<br>另一个简单的方案称为BIAS FROM MEAN（有时候也称为NON PERSONALIZED)。等式给定为：</p><script type="math/tex; mode=display">P(u)_i = \bar u + \frac{1}{card(S_i(\chi))} \sum_{v \in S_i(\chi)} v_i - \bar v</script><p>也就是说，这个预测是基于用户平均评分再加上训练集中所有用户对该物品的评分与其用户的评分平均值的平均偏差。我们也比较了基于物品的算法并且结果显示效果最好[14]，其中给出了使用以下调整后的余弦相似性度量，当给定两个物品i和j：</p><script type="math/tex; mode=display">sim_{i,j} = \frac{\sum_{u \in S_{i,j}(X)}(u_i-\bar u)(u_j - \bar u)}{\sum_{u \in S_{i,j}(\chi)}(u_i - \bar u)^2 \sum_{u \in S_{i,j}(\chi)}(u_j - \bar u)^2}</script><p>最终预测是由这些度量加权求和得到的：</p><script type="math/tex; mode=display">P(u)_i = \frac{\sum_{j \in S(u)} |sim_{i,j}|(\alpha_{i,j}u_j + \beta_{i,j})}{\sum_{j \in S(u)}|sim_{i,j}}</script><p>其中回归系数$\alpha_{i,j},\beta_{i,j}$是由在i和j固定的条件下最小化$\sum_{u \in S_{i,j}(u)}(\alpha_{i,j} u_j \beta_{i,j} - u_i)^2$</p><p><strong>3.3 参考PEARSON方案</strong><br>因为我们希望证明我们的方案相比于基于记忆的方案的预测能力更具有可比性，但由于意识到这一类的方案有许多种，所以我们选择的是实现其中一个算法作为这类方案的代表。其中最受欢迎和准确的记忆基础算法是PEARSON方案。需要的$\chi$中所有用户的加权总和形式：</p><script type="math/tex; mode=display">P(u)_i = \bar u + \frac{\sum_{v \in S_i(\chi)} \gamma (u,v)(v_i - \bar v)}{\sum_{V \in S_i(\chi)} |\gamma (u,v)|}</script><p>其中$\gamma$是Pearson相关性计算得到的相似性度量：</p><script type="math/tex; mode=display">Corr(u,v) = \frac{<u - \bar u, w - \bar w>}{\sqrt{\sum_{i \in S(u) \cap S(w)} (u_i - \bar u^2) \sum_{i \in S(u) \cap S(w)} (w_i - \bar w)^2}}</script><p>基于[2,8]，我们设定：</p><script type="math/tex; mode=display">\gamma (u,w) = Corr(u,w) |Corr(u,w)|^{\rho - 1}</script><p>其中$\rho = 2.5$，它是样本的权重。此值降低了数据中的噪声：如果相关性是特别高的话，例如0.9，那么经过这层变化后依然可以保持高相关性$(0.9^{2.5} \cong 0.8)$，而当相关性较低的时候例如0.1，那么经过变化后会变得很小$(0.1^{2.5} \cong 0.003)$。论文[2]已经证明了相比于已经存在一些方案，结合样例加权的皮尔逊被证明了在CF算法中更具合理性和准确性。</p><p><img src="https://i.postimg.cc/FztgbNNY/relate-papers7-1.jpg" alt="relate-papers7-1"></p><p><strong>3.4 SLOPE ONE算法</strong><br>slope one算法不仅考虑了评分过当前物品的其他用户的信息，同时还考虑了被当前用户评分过的其他物品的信息。然而，这些算法也是如此依赖于既不属于用户数组也不属于物品数据的数据点（例如，用户A对图1中项目I的评级），但是这些数据仍然是评分预测的重要信息。该方法的大部分优势来自数据没有考虑到的因素。具体来说，只有那些与预测用户评分了一些共同物品并且只有与预测用户拥有的物品评分的用户评分进入slop one的评分预测方案。</p><p>正式的，给定两个评分数组$v_i$和$w_i$，其中$i = 1,…,n$，我们寻找形式为$f(x)=x + b$的最好的预测模型来基于v通过最小化$\sum_i (v_i + b - w_i)^2$预测w。将上式对b进行求导并将导数设置为零，我们可以得到$b = \frac{\sum_i w_i - v_i}{n}$。换句话说，常数b必须选自两个数组间的平均差异。这就可以推导出一下的算法。</p><p>给定训练集$\chi$，以及两个物品j和i以及一些用户对它们的评分$u_j$和$u_i$（其中$u \in S_{j,i}(\chi)$），我们考虑物品i和j之间的平均偏差为：</p><script type="math/tex; mode=display">dev_{j,i} = \sum_{u \in S_{j,i}(\chi)} \frac{u_j - u_i}{card(S_{J,I}(\chi))}</script><p>注意任何不包含对i或j评分$u_i,u_j$的用户评论都不包含在上述的求和中。对称矩阵$dev_{j,i}$可以在新数据尽来的时候快速地计算和更新。</p><p>固定$u_i$的时候，$dev_{j,i} + u_i$即为$u_j$的预测值，一个合理的预测应该对这些预测值进行平均：</p><script type="math/tex; mode=display">P(u)_j = \frac{1}{card(R_j)} {\sum_{i \in R_j} (dev_{j,i} + u_i)}</script><p>其中$R_j = {i|i \in S(u), i \neq j, card(S_{j,i}(\chi)) &gt; 0}$是所有相关的物品集合。有一个近似的方案可以简化预测的计算。对于一个足够密集的数据集，即任意一对物品都有评分数据，也就是，对于几乎所有的i和j都有$card(S_{j,i}(\chi)) &gt; 0$， 大多数时候，当$j \in S(u)$的时候，对于$ j \notin S(u) \ and \ R_j = S(u) -{j}$都有$R_j = S(u)$。由于对于大多数的j有$\bar u = \sum_{i \in S(u)} \frac{u_i}{card(S(u))} \simeq \sum_{i \in R_j} \frac{u_i}{card(R_j}$，我们可以对slop one的预测公式简化成：</p><script type="math/tex; mode=display">P^{S1}(u)_j = \bar u + \frac{1}{card(R_j)} \sum_{i \in R_j} dev_{j,i}</script><p>有趣的是注意到我们实现的SLOPE ONE算法是不依赖于用户是如何评论每个单个物品的，仅仅依赖用户的平均评分以及那些物品被当前用户评分过。</p><p><strong>3.5 加权SLOPE ONE算法</strong><br>虽然加权相对于不常见的评级模式来说是有利于经常出现的评级模式的，我们现在将会考虑另一种特别相关的评级模式。我们通过将预测分为两部分来实现这一目标。使用WEIGHTED SLOPE ONE算法，我们得到一个用户喜欢的物品预测和另一个使用用户不喜欢物品的预测。</p><p>给定一个评分范围，例如0到10，将此范围的中间值5作为阈值看上去是比较合理的，即物品评分大于5认为用户是喜欢的，相反小于5则是不喜欢的。这个方法对于用户评分是均匀分布的时候是特别有效果的。然而，每部电影超过70%的平方根都是大于这个中位数的。因为我们想要支持所有类型的用户，包括平衡，乐观，悲观和双峰用户，我们将用户的平均值应用为用户喜欢和不喜欢的物品之间的阈值。例如，乐观的用户，就是那些评价的每一个物品都是喜欢的用户，那么评分低于其平均评分的都被认为不喜欢这些物品。该阈值确保了这一点我们的算法对于每个用户都有一定数量的喜欢和不喜欢的物品。</p><p>再次参考图1，像往常一样，我们对用户B对J评分的预测是基于其他用户对J和物品I评分的差（例如用户A）这些用户是同时评论过物品I和J的。BI-POLAR SLOPE ONE算法进一步限制了这组评分这是预测性的。首先是物品，只有两个都喜欢的物品评分的或两个都不喜欢的物品的偏差才会被考虑在内。再次对于用户，对同时评论过物品I和J的用户的偏差以及展现出喜欢或者不喜欢物品I的用户会被用来预测物品J。</p><p>将每个用户分成用户喜欢和用户不喜欢有效地使用户数增加一倍。显然，但请注意两极限制刚刚概述了在计算中减少预测评级的总数预测。虽然准确度有所提高对于这种减少的看法可能看似违反了直觉即数据稀疏性始终是一个问题，未能过滤掉那些无关紧要可能证明更有问题的评论。最重要的是，BI-POLAR SLOPE ONE方案无法预测出用户A喜欢物品K而用户B不喜欢物品K这一事实。</p><p>正式的，我们将每一个u的评论分成两个评论物品的集合：$S^{like}(u) = { i \in S(u)|u_i &gt; \bar u}$和$S^{dislike}(u) = { i \in S(u)|u_i &lt;\bar u}$。对于每个物品对i和j，将所有相关评论组成的集合$\chi$分成$S_{ij}^{like}= { u \in \chi|i,j \in S_{like}(u)}$和$S_{i,j}^{dislike} = {u \in \chi| i,j \in S^{dislike}(u)}$。使用这两个集合，我们计算下面的喜欢物品偏差矩阵，类似的不喜欢的物品偏差矩阵就是$dev_{j,i}^{dislike}$：</p><script type="math/tex; mode=display">dev_{j,i}^like = \sum_{u \in S_{j,i}^{like}(\chi)} \frac{u_j - u_i}{card(S_{j,i}^{like}(\chi))}</script><p>物品j的评分预测是基于物品i的评分$p_{j,i}^{like} = dev_{j,i}^{like} + u_i$或者$p_{j,i}^{dislike} = dev_{j,i}^{dislike} + u_i$依赖于i分别属于$S^{like}(u)$还是$S^{dislike}(u)$。</p><p>最终BI-POLAR SLOPE ONE算法可有下式给出：</p><script type="math/tex; mode=display">P^{bpS1}(u)_j = \frac{\sum_{i \in S^{like}(u) - {j}} P_{j,i}^{like} c_{j,i}^{like} + \sum_{i \in S^{dislike}(u) - {j}} p_{j,i}^{dislike} c_{j,i}^{dislike}}{\sum_{i \in S^{like}(u) - {j}} c_{j,i}^{like} + \sum_{i \in S^{dislike}(u) - {j}} c_{j,i}^{dislike}}</script><p>其中权重$c_{j,i}^{like} = card(S_{j,i}^{like})$以及$c_{j,i}^{dislike} = card(S_{j,i}^{dislike})$是类似于一个加权SLOPE ONE算法。</p><h3 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4 实验结果"></a><strong>4 实验结果</strong></h3><p>一个给定的CF算法的有效性是可以被精确测算的。为此，我们使用了All But One Mean Average Error（MAE）[2]。在计算MAE时，我们先后从所有评估中每一次隐藏一个评分剩下的作为测试集，同时预测这个被隐藏的评分，计算我们在预测中犯的错误平均值。给定一个预测模型P以及一个用户的评论u，那么通过评论集合$\chi’$可以得到P的误差率可由下式给到：</p><script type="math/tex; mode=display">MAE = \frac{1}{card(\chi')} \sum_{u \in \chi'} \frac{1}{card(S(u))} \sum_{i \in S(u)} |P(u^{(i)}) - u_i|</script><p>其中$u^{(i)}$是评论集合u，并且其中隐藏了用户对第i个物品的评分。</p><p>我们在由Compaq Research提供EveryMovie数据集以及来自明尼苏达州大学的Grouplens研究小组的Movielens数据上测试我们的方案。数据来自电影评级网站，其中EachMovie评分范围从0.0到1.0，增量为0.2，Movielens的每个电影评分是从1到5的，且增量为1。根据[8,11]，我们使用了足够的评论数据来得到总数为50000个评分数据作为训练集$(\chi)$，和另外一组总数至少100000个评分数据作为测试集$(\chi’)$。当预测结果对给定数据集的评级超出允许范围时，它们会相应地进行更正：一个电影的预测值为1.2，若是范围从0到1则将其看作是预测结果为1。因为Movielens的电影评分范围比MovieMns的每个电影大4倍，那么除以4使结果直接可比。</p><p>不同算法的测试结果汇总在了表1中，它们都是基于同一个数据集以及相同的误差度量得到的。不同的子结果都列在了表格的后面。</p><div class="table-container"><table><thead><tr><th style="text-align:center">Scheme</th><th style="text-align:center">EachMovie</th><th style="text-align:center">Movielens</th></tr></thead><tbody><tr><td style="text-align:center">BI-POLAR SLOPE ONE</td><td style="text-align:center">0.194</td><td style="text-align:center">0.188</td></tr><tr><td style="text-align:center">WEIGHTED SLOPE ONE</td><td style="text-align:center">0.198</td><td style="text-align:center">0.188</td></tr><tr><td style="text-align:center">SLOPE ONE</td><td style="text-align:center">0.200</td><td style="text-align:center">0.188</td></tr><tr><td style="text-align:center">BIAS FROM MEAN</td><td style="text-align:center">0.203</td><td style="text-align:center">0.191</td></tr><tr><td style="text-align:center">ADJUSTED COSINE ITEM-BASED</td><td style="text-align:center">0.209</td><td style="text-align:center">0.198</td></tr><tr><td style="text-align:center">PER USER AVERAGE</td><td style="text-align:center">0.231</td><td style="text-align:center">0.208</td></tr><tr><td style="text-align:center">PEARSON</td><td style="text-align:center">0.194</td><td style="text-align:center">0.190</td></tr></tbody></table></div><p><em>Table 1: All Schemes Compared: All But One Mean Average Error Rates for the EachMovie and Movielens data sets, lower is better.</em></p><p>考虑不同基准方案的测试结果。如期所致，我们发现在本文3.2部分描述的3个基准方案中BIAS FROM MEAN算法表现的最好。然而有趣的是3.4中提到的基础SLOPE ONE方案的准确性比BIAS FROM MEAN还要高。</p><p>在3.5和3.6部分提到的对基础SLOPE ONE进行扩充的算法确实改进了在EachMovie数据集上的准确性。SLOPE ONE算法和WEIGHTED SLOPE ONE之间只存在一点点差距（大概1%）。将不喜欢和喜欢的评论分开的处理能够将结果提高1.5%-2%。</p><p>最后，我们一方面对比了基于记忆的PEARSON方案，另一方面也对比了slope one方案。slope one算法取得了一个相对于PEARSON更具准确性的的结果。这个结果足够支持我们声称的slopeone算法是更合理准确的，尽管他们很简单以及其他理想的特点。</p><h3 id="5-结论"><a href="#5-结论" class="headerlink" title="5 结论"></a><strong>5 结论</strong></h3><p>本文展示了一个易于实现的基于平均评分误差的CF模型，它可以与更多昂贵的基于记忆的方案进行竞争。与目前使用的方案相反，使用我们的方法能够满足5个对抗目标。slope one方案易于实施，动态可更新，在查询时有效，并且对于第一次访问的用户不期望有太多的信息，但相对于其他经常报道的模型依然具有相当的准确性（例如，对于MovieLens，1.90对1.88 MAE）。相比之下，给定一个相对复杂的基于记忆的模型来说slope one算法更为卓越。我们方法的进一步创新是将评论分成不喜欢和喜欢子集，这是一种能够提高准确性的有效技术。希望这里提出的通用型的slope one算法能够给CF算法舍去提供一个有用的参考方案。<br>。<br>请注意，截至2004年11月，WEIGHTED SLOPE ONE是Bell / MSN网站在Disverver.net中使用的协同过滤算法。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://epubs.siam.org/doi/pdf/10.1137/1.9781611972757.43&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：Slope One Predictors for Online Rating-Based Collaborative Filtering&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Slope-One-基于在线评分的协同过滤算法&quot;&gt;&lt;a href=&quot;#Slope-One-基于在线评分的协同过滤算法&quot; class=&quot;headerlink&quot; title=&quot;Slope One: 基于在线评分的协同过滤算法&quot;&gt;&lt;/a&gt;Slope One: 基于在线评分的协同过滤算法&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;基于评级的协同过滤是预测的程序，即根据用户对其他物品的评分来预测用户会如何评分当前给定的物品。我们提出了三个形式为f（x）= x + b的关于slop one机制的预测模型，预先计算出用户共同评分过的一个物品和另一个物品的评分之间的平均差异。slop one算法是易于实现的，查询效率高，相当准确，同时它们支持在线查询和动态更新，这使它们成为现实系统的良好候选者。建议将基本的SLOPE ONE方案作为协同过滤方案的新参考。通过考虑将用户喜欢和不喜欢的物品从全集中分出来，我们通过较慢的基于记忆的方式实现了结果超过基准EveryMovie和Movielens数据集，同时更好地满足了它对协同过滤应用的需求。&lt;/p&gt;
&lt;p&gt;关键词：协同过滤，推荐工具，电子商务，数据挖掘，知识发现&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="CF" scheme="https://www.xiemingzhao.com/tags/CF/"/>
    
  </entry>
  
  <entry>
    <title>Amazon.com Recommendations Item-to-item collaborative filtering (论文解析)</title>
    <link href="https://www.xiemingzhao.com/posts/3c1887e0.html"/>
    <id>https://www.xiemingzhao.com/posts/3c1887e0.html</id>
    <published>2019-04-14T16:00:00.000Z</published>
    <updated>2019-09-21T06:27:40.034Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf" target="_blank" rel="noopener">原始论文：Amazon.com Recommendations: Item-to-item collaborative filtering</a></p><h2 id="亚马逊推荐：物到物的协同过滤"><a href="#亚马逊推荐：物到物的协同过滤" class="headerlink" title="亚马逊推荐：物到物的协同过滤"></a>亚马逊推荐：物到物的协同过滤</h2><p>推荐算法因在电子商务网站的应用而广为人知，它们用客户的兴趣爱好作为输入来生成物品的推荐列表。许多应用仅仅用用户明确购买的物品来代表兴趣爱好，dan但其实它们可以用更多的其他特征，包括看过的物品，人口统计下数据，主题兴趣以及最爱的艺术。</p><p>在Amazon.com，我们使用推荐算法为每个客户个性化在线商店。商店根据客户的兴趣从根本上改变，达到给软件工程师显示编程主题和给一位新妈妈展示婴儿玩具。点击率和转化率这两个基于Web和电子邮件的重要测算结果显示了其二者上的广告效果要远远超过横幅广告等非目标内容和畅销书清单。</p><p>电子商务推荐算法经常在不断变化的环境中运行。例如：</p><a id="more"></a><ul><li>一个大的零售商一般会有大量的数据。数以千万计的客户和百万级的不同品类的商品。</li><li>许多应用就需要推荐的结果可以实时返回，不能超过半秒，同时还要保证一定的高质量推荐。</li><li>新用户是基于其仅有的一些购买和产品评分导致拥有极其有限信息的典型案例。</li><li>老用户由于有大量的购买和评分数据使得其拥有大量的信息。</li><li>用户数据是不稳定的：每一次交互都会产生有价值的用户数据，算法必须及时的根据新信息做出反馈。</li></ul><p>一般有三种方法来解决推荐问题：传统的协同过滤，聚类模型，基于搜索的方法。这里，我们用这些方法和我们的算法进行比较，我们的算法称为物到物的协同过滤。不像传统的协同过滤，我们算法的在线大规模计算能力不收用户量和产品量以及产品类别的影响。我们的算法可以实时的生成推荐，并且可以大规模地处理数据集，同时能够生成高质量的推荐。</p><h2 id="推荐算法"><a href="#推荐算法" class="headerlink" title="推荐算法"></a>推荐算法</h2><p>大多数的推荐算法开始都是找一群购买以及评论的产品和推荐目标用户购买过以及评论过的产品有交集的用户。然后从这些相似的用户中聚合出来这些物品，再去除他们已经购买和评论过的物品。这些算法里两个比较流行的版本是协同过滤和聚类模型。其他的算法-包括基于搜索的方法以及我们的物到物的协同过滤，都是集中于找到相似的物品而不是相似的用户。对于每个用户购买和评论过的商品来说，算法尝试去找到相似的物品。然后它聚合出这些相似的物品并推荐它们。</p><h2 id="传统的协同过滤"><a href="#传统的协同过滤" class="headerlink" title="传统的协同过滤"></a>传统的协同过滤</h2><p>一个传统的协同过滤算法将一个用户表示成一个N维的物品向量，N是不用品类的物品数。向量中的元素正的代表用户购买过或者正向评分过的物品，负的代表负向评分的物品。为了补偿那些畅销的产品，该算法通常将用户向量乘以逆频率（对物品有购买或者评分行为的用户数量），使得较不为人知的物品更具有相关性。对于大多数用户来说，这个向量极度稀疏。</p><p>算法基于和目标用户极为相似的一小部分用户产生推荐。有各种各样的方法计算A和B两个用户之间的相似度，普遍采取的方法是两个用户向量之间的cosine角度：</p><script type="math/tex; mode=display">similarity(\vec{A},\vec{B})=\cos(\vec{A},\vec{B})=\frac{\vec{A} \bullet \vec{B}}{||\vec{A}|| \ast ||\vec{B}||}</script><p>从相似用户的物品中选择推荐物品的算法也有很多，一种通用的方法是按照物品被相似用户购买的数量排序。</p><p>使用协同过滤产生推荐计算花费大。最坏的复杂度是O(MN)，其中M是用户数N是产品数，因为对于每个目标用户测试了M个用户以及产品数的上限N。然而，由于用户购买行为的稀疏性，算法最终的花费接近于o(M+N)，因为大部分用户的向量只包含很小数量的物品，不论产品类目有多少。但是有一小部分用户购买和评论了大量的物品质的计算花费时间接近o(N)。因此，算法最终的花费大约为o(M+N)。甚至因此，对于非常大的数据集-例如1000万或更多客户和100万或更多类目产品-算法遇到严重的性能和扩展问题。</p><p>可以通过减小数据规模部分解决计算花费问题。我们可以通过随机抽样客户或丢弃购买少的客户减少M，通过丢弃非常受欢迎或不受欢迎的项目减少N。也可以基于产品类别或主题分类的空间通过分割项目的一个小的、恒定的因素来减少检查的项目数量。降维等技术作为聚类和主成分分析可以大幅减少M或N。</p><p>不幸的是，所有减小数据规模的方法都会降低推荐质量。首先，如果算法近检测一小部分用户样本，那么这些被选中的用户就不会与目标用户那么的相似。第二，品类空间的划分限制了特定产品和主题领域的推荐。第三，如果算法丢弃了最受欢迎或者最不受欢迎的物品，那么它们经永远不会出现在推荐之中，并且仅购买这些物品的客户也得不到这些推荐。将为技术应用于物品空间往往会起到消除低频品类物品的类似效应。降维技术类似于用户分组有效地应用于用户空间，就如我们现在所描述的，这样的聚类也可以降维推荐质量。</p><h2 id="聚类模型"><a href="#聚类模型" class="headerlink" title="聚类模型"></a>聚类模型</h2><p>为了找到那些与目标用户相似的客户，聚类模型将用户分为很多segments，将寻找目标用户相似用户的任务视为一个分类任务。算法目标是将目标用户分配到包含最相似用户的segment中，然后使用segment中用户购买的商品和评分产生推荐。</p><p>通常segments是用聚类模型或者其他无监督的学习算法构建的，虽然有些应用程序使用手动确定segments。使用相似性矩阵，聚类算法将最相似的客户分组一起形成集群或segments。因为对大数据集进行最优聚类是不切实际的，大多数应用程序使用各种形式贪婪的聚类生成算法。通常这些算法从一组初始段开始，且经常会包含一个随机选择的客户。然后他们反复匹配客户到现有的segments中，通常碎玉创建新的或合并现有的segments有一些规定。对于非常大的数据集-特别是那些高数据集维度 - 抽样或降维也是必要的。</p><p>一旦算法生成了segments，就会计算每个用户与每个segments总结向量之间的相似性，然后选择具有最强的相似性segments并根据此对用户进行分类。一些算法将用户分类为多个部分并描述其每个关系的强弱。</p><p>聚类模型相比CF有更好的在线可扩展性和表现，因为聚类算法只将用户和可控制的segments数量进行比较而不是所有用户。复杂花费高的聚类计算是在离线进行的。然而，推荐质量却很低。聚类模型将许多用户分组在一起形成一个segment，将一个用户匹配到一个segment中，然后考虑在这个细分市场中说所有客户的相似客户来产生推荐。由于聚类模型找到的相似客户并不一定是最相似的客户，所以他们产生的推荐并没有太大的相关性。为了提高推荐质量，可以增加类别数量，但这会加大用户在线计算类别的花费。</p><h2 id="基于搜索的模型"><a href="#基于搜索的模型" class="headerlink" title="基于搜索的模型"></a>基于搜索的模型</h2><p>基于搜索或者内容的模型将推荐看作是一个搜索相关物品的问题。给定一些用户的购买和评级的物品，算法会构造搜索查询找到同一作者的其他热门产品，艺术家，导演，以及类似的关键词或<br>主题。如果客户购买了教父DVD收藏，例如，系统可能会推荐其他犯罪剧集，其他马龙白兰度主演的，或其他弗朗西斯福特科波拉导演的电影。</p><p>如果用户只有很少的购买和评分记录，基于搜索的推荐算法可规模化并表现地很好。然而，对于那些有成千上万的购买记录的用户来说，基于一个所有物品的请求来进行推荐是不实际的。算法必须只是用数据集中的一个子集或者汇总数据，这会降低推荐质量。以上例子中，推荐的质量相对较差。推荐结果经常会太宽泛（例如最好卖的电视剧DVD主题）或者太狭隘（例如相同作者的所有书籍）。推荐应该是帮助客户去寻找和发现新的，相关的并且有趣的物品。同一作者的流行作品以及相似主题的类别物品都是不能满足这一目标的。</p><h2 id="物到物的协同过滤"><a href="#物到物的协同过滤" class="headerlink" title="物到物的协同过滤"></a>物到物的协同过滤</h2><p>Amazon.com将推荐作为许多电子邮件活动以及它的大部分网站页面中的营销工具，包括高流量的Amazon.com主页。点击“您的推荐”链接将会引导客户访问一个推荐区域，在这里他们可以通过产品线和主题领域来进行筛选，也可以评价推荐的产品，评价他们以前购买的物品，同时可以看到为什么这些物品被推荐了（如图片1所示）。</p><p>如图2所示，是我们的购物车推荐，根据客户购物车中的物品给他们推荐了一些商品。该功能类似于在超市收银台旁的那些易冲动消费的物品，但我们的冲动项目针对每个客户的。</p><p>亚马逊网站基于他们客户的兴趣广泛地使用推荐算法来个性化他们的网站。由于现存的推荐算法无法扩展到亚马逊网站上数以千万的客户和产品，所以我们开发自己的推荐算法。我们的算法是物到物的协同过滤，可以扩展到巨大的数据集并实时产生高质量的推荐。</p><p><img src="https://i.postimg.cc/g09pWKK0/relate-papers6-1.jpg" alt="图1"><br><img src="https://i.postimg.cc/BnP3kzHy/relate-papers6-2.jpg" alt="图2"></p><h2 id="它是怎么工作的"><a href="#它是怎么工作的" class="headerlink" title="它是怎么工作的"></a>它是怎么工作的</h2><p>物到物的协同过滤并不是对目标用户进行匹配到他们相似的客户，而是对他们购买和评论过的物品匹配到相似的物品，然后聚合这些相似的物品生成推荐列表。</p><p>为了确定地匹配出给定物品的最相似取票，算法通过寻找那些用户会一起购买的物品来建立了一个相似物品表。我们可以构建产品到产品的矩阵通过迭代所有项目对和计算每对的相似性度量。然而，许多产品对没有共同的客户，因此，这种方法效率低下在处理时间和内存使用情况上面。下面的迭代算法提供了一个更好地方法来计算一个商品和其他所有商品之间的相似性。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">For each item in product catalog, I_1</span><br><span class="line">    For each customer C who purchased I_1</span><br><span class="line">        For each item I_2 purchased by</span><br><span class="line">            customer C</span><br><span class="line">            Record that a customer purchased I_1</span><br><span class="line">            and I_2</span><br><span class="line">    For each item I_2</span><br><span class="line">        Compute the similiarity between I_1 and I_2</span><br></pre></td></tr></table></figure></p><p>有各种各样的方法可以计算两者之间的相似性，但一个常见的方法是使用我们之前描述的余弦量度，其中每个向量对应一个物品而不是一个客户，矢量的M维度对应已购买该商品的客户。</p><p>这种相似物品表的离线计算是非常耗时的，O（N2M）为最糟糕的情况。然而，在实践中，它更接近于O（NM），因为大多数客户购买的很少。对购买最畅销主题的客户进行抽样可以进一步减少运行时间，同时会伴随一点质量降低。</p><p>给定一个相似物品表，算法会找到与用户购买的每个项目类似的项目评分，汇总这些项目，然后推荐最受欢迎或相关的项目。这个计算非常快，仅取决于用户购买或评级的商品数量。</p><h2 id="扩展性：比较"><a href="#扩展性：比较" class="headerlink" title="扩展性：比较"></a>扩展性：比较</h2><p>Amazon.com拥有超过2900万客户和数百万品类物品。其他专业零售商拥有相对较大的数据来源。这些数据是一个机会也是一个诅咒，打破了设计算法的背后对于数据集小三个数量级。几乎所有现有的算法都经过了小数据集评估。例如，MovieLens数据set4包含35,000个客户和3,000个项目，并且EveryMovie数据集3包含4,000个客户和1,600项。</p><p>对于非常大的数据集，可扩展的推荐算法必须执行最昂贵的离线计算。如下简要比较显示，现有方法不足：</p><ul><li>传统的协调过滤做很少的甚至没有离线计算，并且它的在线计算的扩展性受到客户和物品数量的限制。算法在大数据集上运行是不现实的，除非它用降维，抽样或者分区等方法，这些都会降低推荐质量。</li><li>聚类模型可以在离线计算中有很大的表现，但是推荐质量相对很差。为了提升它，可以增加聚类中的segments，但是这会使得在线用户的segment分类变得很复杂。</li><li>基于搜索的模型离线建立了关键词，品类和作者指标，但是没能够提供一个又去的目标推荐。他们都很难扩展到那些有大量购买和评论的记录的用户。</li></ul><p>物到物协同过滤扩展性和表现的关键创建一个花费很高的离线计算得到的相似物品表。这个算法的在线部分就是与寻找用户购买和评论过物品的相似物品，其可扩展性与品类大小和总客户数量不相关；仅仅与用户有多少的购买和评论记录有关。因此，即使在很大的数据集上算法也可以运行的很快。由于算法推荐高度相关的相似物品，因此推荐质量是极高的。不像传统的协同过滤，算法也可以在有限的用户数据的条件下表现得很好，可以基于两到三个物品的数据产生高质量的推荐。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>推荐算法通过为每位客户创建个性化的购物体验提供了有效的目标营销形式。对于亚马逊等大型零售商，一个很好的推荐算法可扩展到非常大客户群和产品目录，要求仅仅亚秒处理时间以生成在线推荐，能够对改变用户的数据立即做出反应，并为所有用户提供吸引人的推荐，无论他们的购买和评级物品的数量多少。不像其他的算法，物到物的协同过滤能够迎接这一挑战。</p><p>在未来，我们期待零售业更广泛地应用推荐算法来达到有针对性的营销，在线和离线均是如此。而电子商务企业拥有最简单的个性化工具，技术的转换率提高与传统的大规模方法相比这些方法对于离线的零售商来说也会使其脱颖而出，在用户的邮件邮寄，优惠券和其他形式的客户沟通。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：Amazon.com Recommendations: Item-to-item collaborative filtering&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;亚马逊推荐：物到物的协同过滤&quot;&gt;&lt;a href=&quot;#亚马逊推荐：物到物的协同过滤&quot; class=&quot;headerlink&quot; title=&quot;亚马逊推荐：物到物的协同过滤&quot;&gt;&lt;/a&gt;亚马逊推荐：物到物的协同过滤&lt;/h2&gt;&lt;p&gt;推荐算法因在电子商务网站的应用而广为人知，它们用客户的兴趣爱好作为输入来生成物品的推荐列表。许多应用仅仅用用户明确购买的物品来代表兴趣爱好，dan但其实它们可以用更多的其他特征，包括看过的物品，人口统计下数据，主题兴趣以及最爱的艺术。&lt;/p&gt;
&lt;p&gt;在Amazon.com，我们使用推荐算法为每个客户个性化在线商店。商店根据客户的兴趣从根本上改变，达到给软件工程师显示编程主题和给一位新妈妈展示婴儿玩具。点击率和转化率这两个基于Web和电子邮件的重要测算结果显示了其二者上的广告效果要远远超过横幅广告等非目标内容和畅销书清单。&lt;/p&gt;
&lt;p&gt;电子商务推荐算法经常在不断变化的环境中运行。例如：&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="推荐系统" scheme="https://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="CF" scheme="https://www.xiemingzhao.com/tags/CF/"/>
    
  </entry>
  
  <entry>
    <title>Factorization Machines (论文解析)</title>
    <link href="https://www.xiemingzhao.com/posts/399ba6ee.html"/>
    <id>https://www.xiemingzhao.com/posts/399ba6ee.html</id>
    <published>2019-04-14T16:00:00.000Z</published>
    <updated>2019-09-21T06:27:40.066Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf" target="_blank" rel="noopener">原始论文：Factorization Machines</a></p><h2 id="因式分解机"><a href="#因式分解机" class="headerlink" title="因式分解机"></a>因式分解机</h2><p><strong>摘要</strong>：在本文中，我们介绍了一种因式分解机，这是一种新的模型，结合了SVM的优点，利用了因式分解模型。类似SVM，因式分解机是一种通用的预测器，可以适用于任意的实值特征向量。对比SVM，FMs利用因式分解对变量之间的关系进行建模。因此，FMs可以在大量稀疏特征中进行相互关系的估计。我们展示了，模型的表达式可以在线性时间内求解，FMs可以进行直接的优化。所以，不像非线性的SVM，不需要进行对偶变换，模型的参数可以直接的进行估计，不需要用到支持向量。我们展示了和SVM的关系，以及在稀疏的设置下的参数估计的优势。</p><p>另外，有许多因式分解模型如矩阵分解，并行因子分析如SVD++，PITF，FPMC。这些方法的缺点是通用性不好，只对特殊的输入数据有用。优化方法对于不同的任务也各不相同。我们展示了，FMs通过制定不同的输入就可以模拟这些模型。这就使得FMs非常的易用，甚至可以不需要分解模型的专业知识都可以。</p><a id="more"></a><h3 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h3><p>SVM是机器学习和数据挖掘中最流行的算法之一。然而在协同过滤的场景中，SVM并不重要，最好的模型要么直接使用矩阵的因式分解或者使用因式分解参数。本文中，我们会展示，SVM之所以在这些任务中表现不好，是因为SVM在复杂的非线性的稀疏的核空间中很难找到一个好的分割超平面。而张量分解模型的缺点在于（1）不用应用于标准的预测数据（2）不同的任务需要特殊的模型设计和学习算法。</p><p>在本文中，我们介绍了一个新的预测器，Factorization Machine（FM），是一个像SVM一样的通用的预测模型，但是可以在非常稀疏的数据中估计出可靠的参数。FM对所有变量的相互关系的进行建模（对比SVM的多项式核），但是利用了可因式分解的参数，而不是像SVM一样使用了稠密的参数。我们展示了，模型的表达式可以在线性时间内求解，而且只依赖与线性数量大小的参数。这就允许了直接进行优化和存储模型的参数，而不需要存储任何的训练数据。（SVM是需要存储支持向量的）。非线性的SVM通常使用对偶形式进行求解，而且会使用到支持向量。我们也显示了在协同过滤的业务上FMs比许多很成功的模型如带偏置的MF，SVD++，PITF，FPMC等都好。</p><p>总的来说，我们提出的FM的优点有：<br>1）FMs可以在非常稀疏的数据上进行参数估计。<br>2）FMs的复杂度是线性的，方便优化，不像SVM需要依赖支持向量。我们证明FM可以扩展应用在大数据集上，例如有1亿训练样例的Netflix数据集。<br>3）FMs是通用的预测模型，可以适用于任意的实值的特征向量。与此相反，其他先进的分解模型只在特定输入数据的情况下起作用。我们将通过定义输入数据的特征向量来证明这一点，FM可以模仿其他最先进的模型例如带偏置项的MF，SVD++,PITF以及FPMC模型。</p><h3 id="2、在稀疏数据下进行预测"><a href="#2、在稀疏数据下进行预测" class="headerlink" title="2、在稀疏数据下进行预测"></a>2、在稀疏数据下进行预测</h3><p>大部分的常用的预测任务是估计一个预测的函数$y:\mathbb{R}^n \rightarrow T$，从一个实数向量$x \in \mathbb{R}^n$到目标$T$（如果是回归任务$T=R$，如果是分类任务$T={+，-}$）。在监督学习中，假设有个给定y值的样本训练数据集$D = \{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…\}$。我们也研究了排序的任务，拥有目标值$T=\mathbb{R}$的函数y可以适用于对x向量的评分和排序。评分函数可以通过成对的数据进行训练，当一个样本组合$(x_{(A)},x_{(B)})\in D$表示$x_{(A)}$应该排在$x_{(B)}$的前面。由于成对数据是反对称的，可以直接使用正的实例。</p><p>在本文中，我们要解决的问题是数据的稀疏问题，也就是说在x向量中，大部分的值都是0，只有少部分不是0。让$m(x)$表示特征向量x中非0元素的个数，$\bar m_D$表示所有特征向量$x \in D$的非零元素个数$m(x)$的平均值。高稀疏性的特征在现实世界中是非常常见的，如文本分析和推荐系统中。高稀疏性的一个原因是在处理超多类别变量域的潜在问题。</p><p><strong>例1</strong> 假设我们有个电影评分系统的交互数据。系统记录了用户$u\in U$在特定的时间$t \in R$对电影$i \in I$的评分$r \in {1,2,3,4,5}$.用户U和电影I为：</p><p>$U = \{Alice (A), Bob (B), Charlie (C), . . .\}$<br>$I = \{Titanic (TI),Notting Hill (NH), Star Wars (SW),Star Trek (ST), . . .\}$</p><p>用观察到的数据S表示：<br>$S = \{(A, TI, 2010-1, 5), (A,NH, 2010-2, 3), (A, SW, 2010-4, 1),$<br>      $(B, SW, 2009-5, 4), (B, ST, 2009-8, 5),$<br>      $(C, TI, 2009-9, 1), (C, SW, 2009-12, 5)\}$<br>任务是使用这些数据，估计一个函数$\hat y$，这个函数能够预测一个用户在某个时间对某个电影的评分。</p><p><img src="https://i.postimg.cc/qRd59r8J/relate-papers18-1.jpg" alt="relate-papers18-1.jpg"></p><p>图1展示了一个示例，在这个任务中如何从观测数据S中构建特征向量。在这里，首先$|U|$是一个二值示性变量（蓝色的），它表示一个交互中活跃的用户，总是可以确定的是在一次交互$(u,i,t,r) \in S$中有一个确定的活跃用户。例如，第一行中的Alice($x_A^{(1)} = 1$)。下一个二值示性变量$|I|$（红色的）表示活跃的物品，同样的总是有一个活跃的物品，例如$x_{TI}^{(1)}=1$。图1中的特征向量也包含了用来表示用户曾经评价过的其他物品的表示向量（黄色的）。对于每个用户来说，变量均是被归一化之后的。例如Alice评价过Notting Hill 和 Star Wars。此外，样本还包含一个从2019年一月开始的月份向量（绿色的）来表示时间。最后几列表示用户评价过的最后一个电影，最右边的是当前电影的评分y。在第五部分，我们将展示因式分解机是如何利用输入数据中的特征向量来做到最特殊的顶级的因式分解模型的。</p><p>我们将通过这篇论文用这个示例数据集来证明。然而，请注意FMs是一个像SVMs一样的通用模型，可以应用在任何一个现实中的特征向量，并且对推荐系统没有什么限制。</p><h3 id="3-因式分解机-FM"><a href="#3-因式分解机-FM" class="headerlink" title="3.因式分解机(FM)"></a>3.因式分解机(FM)</h3><p>在这一部分，我们将来介绍因式分解机。我们会详细地讨论模型中的公式推导，并且会展示怎么使用FMs进行多预测任务。</p><p><em>A. 因式分解模型</em><br>1）模型方程：2维的因式分解机模型方程：</p><script type="math/tex; mode=display">\hat y(x):=w_0 + \sum_{i=1}^n w_i x_i + \sum_{i=1}^n \sum_{j=i+1}^n  \langle v_i,v_j \rangle x_i x_j</script><p>公式中的模型参数必须在下面的值域中进行估计：</p><script type="math/tex; mode=display">w_0 \in \mathbb{R}, w \in \mathbb{R}^n, V \in \mathbb{R}^{n \times k}</script><p>其中，$ \langle ·,· \rangle $表示长度为k的点乘，k是一个超参数：</p><script type="math/tex; mode=display">\langle v_i, v_j \rangle  := \sum_{f=1}^kv_{i,f} \cdot v_{j,f}</script><p>V中的行向量$v_i$表示第k个因子的第i个变量。$k \in \mathbb{N}_0^+$是一个产参数定义了因式分解的维度。</p><p>一个2阶的FM能过获取所有的单个特征和配对特征的相互关系：</p><ul><li>$w_0$是全局偏置项。</li><li>$w_i$是模型中的第i个变量的权重。</li><li>$ \hat w_{i,j}:= \langle v_i,v_j \rangle $表示模型中第i个变量和第j个变量之间的交互项。如此就不是用唯一的模型参数$w_{i,j} \in \mathbb{R}$来作为FM模型中因式分解交互项的权重了。在后面我们将看到，当遇到高维且稀疏的数据的时候，这是进行高质量参数估计的关键点。</li></ul><p>2）表达能力：我们知道对于正定矩阵W，存在矩阵V，使得$W=V\cdot V^t$，k足够大。这表明了当k足够大的时候FM能够表示矩阵W中的任何交互项。然而对于稀疏的情况，应该选择一个比较小的k，因为没有足够的数据去预测一个复杂的W。限制k，也就是FM的表达能力，能够提高稀疏情况下的相互关系矩阵的泛化性能。</p><p>3）稀疏情况下的参数估计：在稀疏情况下，通常没有足够的数据进行直接的参数估计。因式分解机可以进行稀疏的估计，甚至在稀疏的情况下可以估计的很好，这是因为它打破了交互项参数和因式分解之间的独立性。总的来说是因为进行了因式分解之后，用来估计一个参数的数据也可以用来估计相关的另一个参数。我们将利用图1中的数据举个例子来更清晰地描述我们的想法。假设我们想估计Alice(A)和Star Trek(ST)交互项的参数来预测目标值y（这里是评分）。很显然，在一个样本中，两个用户$x_A,x_{ST}$的参数不会都是非0数，如果直接进行估计的话，那么A和ST的相互关系参数会估计成0。但是如果使用因式分解将参数分解长$ \langle v_A,v_{ST} \rangle $的话，在这个案例中我们就可以直接进行估计了。</p><p>4）计算量：接下来，我们展示如何让FMs变得实际可用。前面提到的方程（1）的计算复杂度是O(kn2)，因为所有的称为交互项必须倍计算。但是改变一下之后将会使其复杂度降低到线性的。</p><p>引理3.1：因式分解机的计算复杂度可以变成线性的时间复杂度O(kn)。</p><p>证明：由于所有的成对交互项都会做因式分解，于是模型中就没有需要直接利用两个变量进行直接估计的参数。所有成对的交互项可以进行如下的变化：</p><script type="math/tex; mode=display">\begin{align}&\sum_{i=1}^n \sum_{j=i+1}^n  \langle v_i, v_j \rangle x_i x_j\\=&\frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n  \langle v_i, v_j \rangle x_i x_j - \frac{1}{2} \sum_{i=1}^n  \langle v_i, v_i \rangle x_i x_i \\=&\frac{1}{2} (\sum_{i=1}^n \sum_{j=1}^n \sum_{f=1}^k v_{i,f} v_{j,f} x_i x_j - \sum_{i=1}^n \sum_{f=1}^k v_{i,f} v_{i,f} x_i x_i) \\=&\frac{1}{2} \sum_{f=1}^k ((\sum_{i=1}^n v_{i,f} x_i)(\sum_{j=1}^n v_{j,f} x_j)-\sum_{i=1}^n v_{i,f}^2  x_i^2) \\=&\frac{1}{2} \sum_{f=1}^k((\sum_{i=1}^n v_{i,f} x_i)^2 - \sum_{i=1}^n v_{i,f}^2 x_i^2)\end{align}</script><p>以上的公式的结果仅仅有线性的计算复杂度，当k和n固定的时候，计算复杂度就为O(kn)。</p><p>进一步，在稀疏性的条件下，x中的大部分元素值都是0，因此求和就可以只在非0的元素中进行。因此在稀疏数据中因式分解机的计算复杂度就在$O(k\bar m_D)$，例如当$\bar m_D=2$时就是一个经典的推荐系统例如MF算法。</p><p><em>B. 使用因式分解机进行预测</em><br>因式分解机可以用在各种预测任务中：</p><ul><li>回归：直接进行预测，使用最小均方误差进行优化。</li><li>二分类：使用合页损失或者对数几率损失进行优化。</li><li>排序：对预测的分数进行排序，可以通过成对实例的分类损失进行优化。</li></ul><p>在上面所有的情况下，都可以使用L2的正则化来防止过拟合。</p><p><em>C. 因式分解机的学习</em><br>我们已经证明，FMs有一个确定的模型公式使其计算复杂度达到线性的。因此，FMs的参数$（w_0,w , V）$可以通过梯度下降的方式来求解，例如随机梯度下降法(SGD).FM模型的梯度是：</p><script type="math/tex; mode=display">\frac{\partial}{\partial \theta} \hat y(x)  = \begin{cases}1,& if \ \theta \ is \ w_0 \\x_i,& if \ \theta \ is \ w_i \\x_i\sum_{j=1}^n v_{j,f}x_j - v_{j,f}x_i^2,& if \ \theta \ is \ v_{i,f}\end{cases}</script><p>其中，求和项$\sum_{j=1}^n v_{j,f}x_j$是和i无关的，可以事先求出来。总的来说，每个梯度都可以在O(1)时间内求得。对于给个案例(x,y)整体的参数更新的时间为O(kn)，稀疏数据的时候则为O(km(x))。</p><p>我们提供了一个通用的实现，<a href="http://www.libfm.org" target="_blank" rel="noopener">LIBFM</a>，使用SGD，支持元素和配对的loss。</p><p><em>D. d阶的因式分解机</em><br>2阶的因式分解机可以很容易的推广到d阶：</p><script type="math/tex; mode=display">\hat y(x) := w_0 + \sum_{i=1}^n w_i x_i + \sum_{l=2}^d \sum_{i_1=1}^n \cdots \sum_{i_l = i_{l-1} + 1}^n (\prod_{j=1}^l x_{i_j}) (\sum_{f=1}^{k_l} \prod_{j=1}^l v_{i_j, f}^{(l)})</script><p>其中，第l个相互关系参数可以通过PARAFAC模型进行因式分解:</p><script type="math/tex; mode=display">V^{(l)} \in \mathbb{R}^{n \times k_l}, k_l \in \mathbb{N}_0^+</script><p>通过变换，同样可以在线性的时间复杂度上求解，复杂度降为$O(k_d n^d)$。</p><p><em>E. 总结</em><br>FMs的优点：<br>1）可以在稀疏的情况下进行很好的参数估计，特别是可以估计没有观测到的相互关系。<br>2）参数的大小和运算时间都是线性的，可以通过SGD进行参数的更新，可以使用多种loss。</p><h3 id="4、FMs-vs-SVMs"><a href="#4、FMs-vs-SVMs" class="headerlink" title="4、FMs vs. SVMs"></a>4、FMs vs. SVMs</h3><p><em>A. SVM模型</em><br>我们知道SVM可以表示成变换后的特征向量x和参数w的内积的形式:$\hat y(x) =  \langle \phi (x),w \rangle $，其中$\phi$是一个映射将特征空间$\mathbb{R}^n$映射到一个更复杂的空间$\mathcal{F}$。这个映射通常使用核函数来进行：</p><script type="math/tex; mode=display">K:\mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}, K(x,z) =  \langle \phi (x),\phi(z) \rangle</script><p>下面我们通过分析SVMs主要形式来讨论FM和SVM之间的关系。</p><p><em>1）线性核</em>：最简单的核函数就是线性核：$ K_l(x,z):=1 +  \langle x,z \rangle  $，这对应的映射就是$\phi (x) := (1,x_1, \cdots , x_n)$。因此线性核的SVM模型等式可以重写为：</p><script type="math/tex; mode=display">\hat y(x) = w_0 + \sum_{i=1}^n w_i x_i, w_0 \in \mathbb{R}, w \in \mathbb{R}^n</script><p>很明显可以发现线性的SVM模型和FM为1阶的情况完全等效</p><p><em>2）多项式核</em>：多项式的核函数可以让SVM模型去拟合更高维的变量交互项。可以定义：$K(x,z) := ( \langle x,z \rangle  + 1)^d$。例如当多项式为2阶的时候，对应如下的映射：</p><script type="math/tex; mode=display">\phi (x) := (1, \sqrt2 x_1, \cdots , \sqrt2 x_n, x_1^2, \cdots ,x_n^2, \sqrt2 x_1 x_2, \cdots , \sqrt2 x_1 x_n, \sqrt2 x_2 x_3, \cdots, \sqrt2 x_{n-1} x_n)</script><p>因此，多项式核函数的SVM模型等式可以重写为：</p><script type="math/tex; mode=display">\hat y(x) = w_0 + \sqrt2 \sum_{i=1}^n w_i x_i + \sum_{i=1}^n w_{i,i}^{(2)} x_i^2 + \sqrt2 \sum_{i=1}^n \sum_{j = i + 1}^n w_{i,j}^{(2)} x_i x_j</script><p>其中模型的参数是：</p><script type="math/tex; mode=display">w_0 \in \mathbb{R}^n, w \in \mathbb{R}^n, W^{(2)} \in \mathbb{R}^{n \times n} (symmetric matix)</script><p>对比多项式核函数的SVM模型和FM模型，可以发现的一点是两个模型交互项全部上升到了2维。而这主要的差别是参数：SVMs的所有交互项参数之间是相互独立的。相反，对于FMs模型来说所有的交互项参数都是经过因式分解的，因此$ \langle v_i, v_j \rangle  and  \langle v_i, v_l \rangle $依赖于各自交叉共享的参数($v_i$)。</p><p><em>B. 稀疏情况下的参数估计</em><br>我们下面解释一下为什么线性和多项式的SVM在稀疏的情况下表现不好。我们将使用用户和物品的表征向量的数据来证明这个协同过滤的例子。这里，特征向量是稀疏的，并且仅仅两个参数是非0的。</p><p><em>1）线性SVM</em>：对于这种数据x,线性的SVM模型等价于下面的等式：</p><script type="math/tex; mode=display">\hat y(x) = w_0 + w_u + w_i</script><p>因为当且仅当$j = u \ or \ j = i$的时候$x_j = 1$。这个模型对应于一个最基础的协同过滤模型，即只有用户和巫婆的偏置项存在。由于这个模型很简单，因为只有少数的几个参数，所以模型的参数的预测在这种稀疏情况下也会不错。但是预测的质量却不好，见图2。</p><p><img src="https://i.postimg.cc/zG6MFKvR/relate-papers18-2.jpg" alt="relate-papers18-2.jpg"></p><p><em>2）多项式SVM</em>：这种情况下，SVM可以获取高阶的相互关系。在我们的系数数据案例中，$m(x)=2$，这时候SVMs模型的等式等价于：</p><script type="math/tex; mode=display">\hat y(x) = w_0 + \sqrt2 (w_u + w_i) + w_{u,u}^{(2)} + w_{i,i}^{(2)} + \sqrt2 w_{u,i}^{(2)}</script><p>首先，$w_u \ and \ w_{u,u}^{(2)}$代表的是同样的，可以期初其中一个例如后者。现在模型的等式就变成了线性的除了有一个额外的用户交叉项$w_{u,i}^{(2)}$。在经典的协同过滤(FM)问题中，对于每个交叉项参数$w_{u,i}^{(2)}$，训练数据中至少有一个观测样本(u,i)，而在测试数据中的案例$(u’,i’)$就一般不会在训练数据及中再次出现了。这意味着对于所有的测试案例(u,i)的交叉项参数来说，最大边际解是0。因此对于预测测试集的时候，多项式SVM对于二阶的交叉项来说没有任何作用；所以多项式核的SVM模型仅仅依赖于用户和物品偏置项，在效果上并没有比线性的SVM好多少。</p><p>对于SVM模型，估计一个高级的交叉项并不是CF模型中的问题，但是当数据是高稀疏性的时候这个问题就存在了。因为对于一个成对的交叉项$(i,j)$想要得到一个可靠的参数估计$w_{i,j}^{(2)}$的话，必须提供足够多的样例$x \in D,where \ x_i \neq 0 \wedge x_i \neq 0$。只要不同时出现$x_i=0,x_j=0$，这个样例就可以用来进行参数估计。<br>总结一下，只要数据比较稀疏的时候，即没有足够的(i,j)的样例的时候，SVMs模型基本上失效的。</p><p><em>C. 总结</em><br>1）SVM的稠密的参数需要相互关系的直接的观测值，而在稀疏的输入的情况下，这种直接的观测值很少。但是FMs模型就可以在稀疏的情况将进行很好的参数估计。<br>2）FMs可以直接进行学习，非线性的SVM通常在对偶形式进行求解。<br>3）FMs的函数不依赖与训练数据SVM的预测依赖部分训练数据（支持向量）。</p><h3 id="5、FMs-vs-其他的因式分解模型"><a href="#5、FMs-vs-其他的因式分解模型" class="headerlink" title="5、FMs vs. 其他的因式分解模型"></a>5、FMs vs. 其他的因式分解模型</h3><p>有各种各样的分解模型，从m-ary类别变量关系的标准模型（例如MF，PARAFAC）到用于特定数据和任务的专用模型（例如SVD ++，PITF，FPMC）。接下来，我们展示一下FM可以仅仅通过使用正确的输入数据就可以模仿很多其他的因式分解模型（例如特征向量x）。</p><p><em>A.矩阵和张量分解</em><br>矩阵分解（MF）是研究最多的因子分解模型之一。它是分解了在两个分类变量之间的关系（例如U和I）。标准处理分类变量的方法是为每个U和I级别定义二值的指标变量（例如见图1，<br>第一个（蓝色）和第二个（红色）组）：</p><script type="math/tex; mode=display">n:=|U \cup I|, x_j := \delta(j=i \vee j=u)</script><p>使用这个特征向量x的FM模型与矩阵分解模型相同，因为$x_j$仅仅在当前u和i是非0的，所以其他的偏置项和交互项都可以舍去：</p><script type="math/tex; mode=display">\hat y(x)=w_0 + w_u + w_i +  \langle v_u, v_i \rangle</script><p>同样的考虑，当有两个以上的分类变量的时候可以发现存在一样的问题，FM包括了一个嵌套并行因子分析模型（PARAFAC）。</p><p><em>B.SVD++</em><br>对于评分预测任务（即回归）来说，Koren将矩阵分解模型改进成了SVD++模型。FM模型就可以使用下列的输入数据来模拟这个模型（就像图一中的前三组）：</p><script type="math/tex; mode=display">\ n:=|U \cup I \cup L|, \ x_j  = \begin{cases}1,& if \ j=i \vee j=u \\\frac{1}{\sqrt{|N_u|}},& if \ j \in N_u \\0,& else\end{cases}</script><p>其中$N_u$是当前用户曾经评论过的所有电影的集合。一个二维的FM模型将以如下方式处理这个数据集：</p><script type="math/tex; mode=display">\hat y(x) = w_0 + w_u + w_i +  \langle v_u, v_i \rangle  + \frac{1}{\sqrt{|N_u|}} \sum_{l \in N_U}  \langle v_i, v_l \rangle  + \\\frac{1}{\sqrt{|N_u|}}\sum_{l \in N_U}(w_l +  \langle v_u, v_l \rangle  + \frac{1}{\sqrt{|N_u|}}\sum_{l' \in N_u, l'  \rangle  l} \langle v_l, v_l' \rangle )</script><p>其中第一部分（即第一行）就等价于一个SVD++模型。但FM还包含一些额外的用户和电影$N_u$之间的交互项，以及$N_u$中电影对之间的电影$N_u$本身和交互项的基础效应。</p><p><em>C.PITF的标签推荐</em><br>标签预测的问题被定义为对于给定的用户和项目组合来排名标签。这意味着有涉及三个分类域：用户U，项目I和标签T.在关于标签推荐的ECML / PKDD发现挑战中，基于分解成对的交互项的模型（PITF）取得了最好成绩[3]。我们将展示FM如何<br>可以模仿这个模型。一个对于活动用户u，项目i和标签t有二值表示变量的分解机的可以写成以下模型：</p><script type="math/tex; mode=display">n:=|U \cup I \cup L|, x_j := \delta (j = i \vee j = u \vee j = t)\\\Longrightarrow \hat y(x)= w_0 + w_u + w_i +  \langle v_u, v_i \rangle  +  \langle v_u, v_t \rangle  +  \langle v_i, v_t \rangle</script><p>由于该模型用于在相同的用户/项目组合（u，i）内的两个标签$t_A,t_B$之间进行排序的，两者都是始终致力于优化和预测案例$（u,i,t_A）和（u,i,t_B）之间的得分差异。因此对于成对排序的优化，FM模型等价于：</p><script type="math/tex; mode=display">\hat y(x) := w_t +  \langle v_u, v_t \rangle  +  \langle v_i, v_t \rangle</script><p>现在二元指标的原始PITF模型和FM模型几乎是相同的。唯一的区别在于（1）FM模型对t具有偏差项$w_t$，（2）$(u,t)-(i,t)$交叉项的标签之间的分解参数$(v_t)$在FM模型中是共享的，但是又不同于原始PITF模型。除了这个理论分析，图3显示了两种模型实现此任务的可比预测质量的经验分布。</p><p><img src="https://i.postimg.cc/LsPWC5gQ/relate-papers18-3.jpg" alt="relate-papers18-3.jpg"></p><p><em>D.分解个性化的马尔科夫链</em><br>FPMC模型尝试基于用户u的最后一次购买(时间t-1)在线上商店进行商品排序。</p><p>再一次仅仅用特征生成，一个二维的因式分解机可以来近似：</p><script type="math/tex; mode=display">\ n:=|U \cup I \cup L|, \ x_j  = \begin{cases}1,& if \ j=i \vee j=u \\\frac{1}{|B_{t-1}^u|},& if \ j \in B_{t-1}^u \\0,& else\end{cases}</script><p>其中$B_{t}^u \subseteq L$是一个用户u在时间t可购买的所有物品的集合，然后：</p><script type="math/tex; mode=display">\hat y(x) = w_0 + w_u + w_i +  \langle v_u, v_i \rangle  + \frac{1}{|B_{t-1}^u|} \sum_{l \in B_{t-1}^u}  \langle v_i, v_l \rangle  + \\\frac{1}{|B_{t-1}^u|}\sum_{l \in B_{t-1}^u}(w_l +  \langle v_u, v_l \rangle  + \frac{1}{|B_{t-1}^u|}\sum_{l' \in B_{t-1}^u, l'  \rangle  l} \langle v_l, v_l' \rangle )</script><p>就像标签推荐一样，这个模型被用来优化排名（这里是排序物品i），因此只有$(u,i_A,t)$和$(u,i_B,t)$之间的评分存在差异的时候会被用于预测和优化的评断标准中。因此，所有额外的不依赖于i都可以消失，FM模型的等式就相当于：</p><script type="math/tex; mode=display">\hat y(x) = w_i +  \langle v_u, v_i \rangle  + \frac{1}{|B_{t-1}^u|}\sum_{l \in B_{t-1}^u} \langle v_i, v_l \rangle</script><p>现在人们可以看到原始的FPMC模型和FM模型几乎是相同的，仅在附加的偏置项$w_i$中有所不同，以及FM模型中的(u,i)和(i,l)交互项物品的分解参数的共享。</p><p><em>E.总结</em><br>1）标准分解模型，如PARAFAC或MF不是像因式分解机这样的一般预测模型。相反，他们需要特征向量被分成m个部分，每个部分都是精确的一个元素是1，其余元素是0。<br>2）有许多关于专业化因子分解的建议为单个任务设计的模型。我们已经证明了这一点，因式分解机可以模仿许多最成功的分解模型（包括MF，PARAFAC，SVD++，PITF，FPMC）只需通过特征提取即可，这使得FM在实践中很容易应用。</p><h3 id="6、结论"><a href="#6、结论" class="headerlink" title="6、结论"></a>6、结论</h3><p>在这片论文中，我们介绍了因式分解机。FMs融合了SVM模型的泛化能力以及因式分解模型的优势。不同于SVM模型，1)FMs可以在高稀疏的情况下进行参数估计，2)模型等式是线性的并且仅依赖于模型的参数，因此3)它们可以在原始等式中进行优化。FMs模型的解释力相当于多项式SVMs模型。不同于像PARAFAC这种张量因子分解模型，FMs是一个泛化的模型，它可以处理任何实值向量。再者，可以通过在输入特征向量中使用正确的表征来进行简化，FMs相对于其他特别高级的模型来说是更单一且非常简单的，不像那些模型仅仅只能应用在特定的任务重，例如MF, SVD++, PITF和FPMC。</p><p><a href="https://www.jianshu.com/p/a194e05aeb53" target="_blank" rel="noopener">参考博文:点击率预测《Factorization Machines》论文精读-ronghuaiyang</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原始论文：Factorization Machines&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;因式分解机&quot;&gt;&lt;a href=&quot;#因式分解机&quot; class=&quot;headerlink&quot; title=&quot;因式分解机&quot;&gt;&lt;/a&gt;因式分解机&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;：在本文中，我们介绍了一种因式分解机，这是一种新的模型，结合了SVM的优点，利用了因式分解模型。类似SVM，因式分解机是一种通用的预测器，可以适用于任意的实值特征向量。对比SVM，FMs利用因式分解对变量之间的关系进行建模。因此，FMs可以在大量稀疏特征中进行相互关系的估计。我们展示了，模型的表达式可以在线性时间内求解，FMs可以进行直接的优化。所以，不像非线性的SVM，不需要进行对偶变换，模型的参数可以直接的进行估计，不需要用到支持向量。我们展示了和SVM的关系，以及在稀疏的设置下的参数估计的优势。&lt;/p&gt;
&lt;p&gt;另外，有许多因式分解模型如矩阵分解，并行因子分析如SVD++，PITF，FPMC。这些方法的缺点是通用性不好，只对特殊的输入数据有用。优化方法对于不同的任务也各不相同。我们展示了，FMs通过制定不同的输入就可以模拟这些模型。这就使得FMs非常的易用，甚至可以不需要分解模型的专业知识都可以。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="FM" scheme="https://www.xiemingzhao.com/tags/FM/"/>
    
  </entry>
  
</feed>
